{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiIFqVwSxT6c",
        "outputId": "e9e8e37c-260d-466d-8939-cd37a730b733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sdv\n",
            "  Downloading sdv-1.22.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting boto3<2.0.0,>=1.28 (from sdv)\n",
            "  Downloading boto3-1.38.36-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting botocore<2.0.0,>=1.31 (from sdv)\n",
            "  Downloading botocore-1.38.36-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cloudpickle>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (3.1.1)\n",
            "Requirement already satisfied: graphviz>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from sdv) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.29 in /usr/local/lib/python3.11/dist-packages (from sdv) (4.67.1)\n",
            "Collecting copulas>=0.12.1 (from sdv)\n",
            "  Downloading copulas-0.12.3-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting ctgan>=0.11.0 (from sdv)\n",
            "  Downloading ctgan-0.11.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting deepecho>=0.7.0 (from sdv)\n",
            "  Downloading deepecho-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting rdt>=1.17.0 (from sdv)\n",
            "  Downloading rdt-1.17.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting sdmetrics>=0.21.0 (from sdv)\n",
            "  Downloading sdmetrics-0.21.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: platformdirs>=4.0 in /usr/local/lib/python3.11/dist-packages (from sdv) (4.3.8)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from sdv) (6.0.2)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.28->sdv)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3<2.0.0,>=1.28->sdv)\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<2.0.0,>=1.31->sdv) (2.4.0)\n",
            "Requirement already satisfied: plotly>=5.10.0 in /usr/local/lib/python3.11/dist-packages (from copulas>=0.12.1->sdv) (5.24.1)\n",
            "Requirement already satisfied: scipy>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from copulas>=0.12.1->sdv) (1.15.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ctgan>=0.11.0->sdv) (2.6.0+cu124)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdv) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->sdv) (2025.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from rdt>=1.17.0->sdv) (1.6.1)\n",
            "Collecting Faker>=17 (from rdt>=1.17.0->sdv)\n",
            "  Downloading faker-37.4.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.10.0->copulas>=0.12.1->sdv) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=5.10.0->copulas>=0.12.1->sdv) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.31->sdv) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt>=1.17.0->sdv) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt>=1.17.0->sdv) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->ctgan>=0.11.0->sdv)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan>=0.11.0->sdv) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->ctgan>=0.11.0->sdv) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->ctgan>=0.11.0->sdv) (3.0.2)\n",
            "Downloading sdv-1.22.1-py3-none-any.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.2/180.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.38.36-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.38.36-py3-none-any.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading copulas-0.12.3-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctgan-0.11.0-py3-none-any.whl (24 kB)\n",
            "Downloading deepecho-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading rdt-1.17.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.8/73.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sdmetrics-0.21.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.5/193.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faker-37.4.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, Faker, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, s3transfer, rdt, nvidia-cusolver-cu12, copulas, sdmetrics, boto3, deepecho, ctgan, sdv\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed Faker-37.4.0 boto3-1.38.36 botocore-1.38.36 copulas-0.12.3 ctgan-0.11.0 deepecho-0.7.0 jmespath-1.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rdt-1.17.0 s3transfer-0.13.0 sdmetrics-0.21.0 sdv-1.22.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sdv # install the synthetic data vault library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IETqs_BvBoSS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import data\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "import pandas as pd\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# import scikit-learn preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer,PowerTransformer\n",
        "\n",
        "# import pytorch libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# import synthetic data value libraries\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "import sdv.evaluation.single_table as sdv_st\n",
        "\n",
        "# import utility libs\n",
        "from tqdm import tqdm\n",
        "import xlrd\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from datetime import datetime\n",
        "\n",
        "# import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "seed= 1234\n",
        "\n",
        "# set dimension of categorical embedding\n",
        "cat_emb_dim= 2\n",
        "\n",
        "# set number of neurons per layes\n",
        "mlp_layers=[1024,1024,1024,1024]\n",
        "\n",
        "# set non-linear activation function\n",
        "activation='lrelu'\n",
        "\n",
        "# set number of diffusion steps\n",
        "diffusion_steps= 1000\n",
        "\n",
        "# set diffusion stop and end betas\n",
        "diffusion_beta_start= 1e-4\n",
        "diffusion_beta_end= 0.02\n",
        "\n",
        "# set diffusion scheduler\n",
        "scheduler= 'exp'\n",
        "\n",
        "# set number of training epochs\n",
        "epochs= 500\n",
        "\n",
        "# set the training batch size\n",
        "batch_size= 512\n",
        "\n",
        "# set the training learning rate\n",
        "learning_rate= 1e-4\n",
        "\n",
        "# set the device\n",
        "device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\").type\n",
        "\n",
        "beta_start=1e-4\n",
        "beta_end=0.02"
      ],
      "metadata": {
        "id": "cTwijrDDzk1H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "betas = torch.exp(torch.linspace(math.log(beta_start), math.log(beta_end), 1000))\n",
        "alphas = 1.0 - betas\n",
        "\n",
        "\n",
        "# x = torch.linspace(-6, 6, 1000)\n",
        "# betas = torch.sigmoid(x) * (beta_end - beta_start) + beta_start\n",
        "# alphas = 1.0 - betas\n",
        "\n",
        "\n",
        "# betas = torch.linspace(beta_start**0.5, beta_end**0.5, 1000) ** 2\n",
        "# alphas = 1.0 - betas\n",
        "\n",
        "\n",
        "# betas = torch.linspace(beta_start, beta_end, 1000)\n",
        "# alphas = 1.0 - betas"
      ],
      "metadata": {
        "id": "-9UUUIjxX7zW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(betas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "kDtHhyUWXkak",
        "outputId": "75cae481-4c28-45fb-db49-4ad6e0d30b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x78592e8456d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYnX1Ph0JBei"
      },
      "source": [
        "Set Initialize experiment parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Vbn2OFUgKZJ6"
      },
      "outputs": [],
      "source": [
        "# set numpy seed\n",
        "np.random.seed(seed)\n",
        "\n",
        "# set pytorch seed\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# set cuda seed\n",
        "torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQI-_Slcg26O"
      },
      "source": [
        "# FinDiff on czeck dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8UsWLnis21a"
      },
      "source": [
        "Initialization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a preproces data function\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set seeds\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "\n",
        "def preprocess_data_czech(df):\n",
        "    #df = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "\n",
        "    czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "    df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "    #df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
        "\n",
        "    df[\"month\"] = df[\"datetime\"].dt.month\n",
        "    df[\"day\"] = df[\"datetime\"].dt.day\n",
        "    df[\"dow\"] =  df[\"datetime\"].dt.dayofweek\n",
        "    df[\"year\"] = df[\"datetime\"].dt.year\n",
        "    df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "    df[\"td\"] = df[[\"account_id\", \"datetime\"]].groupby(\"account_id\").diff()\n",
        "    df[\"td\"] = df[\"td\"].apply(lambda x: x.days)\n",
        "    df[\"td\"].fillna(0.0, inplace=True)\n",
        "\n",
        "\n",
        "    # dtme - days till month end\n",
        "    df[\"dtme\"] = df.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "\n",
        "    df['raw_amount'] = df.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "\n",
        "    cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "    TCODE_SEP = \"__\"\n",
        "    # create tcode by concating fields in \"cat_code_fields\"\n",
        "    tcode = df[cat_code_fields[0]].astype(str)\n",
        "    for ccf in cat_code_fields[1:]:\n",
        "        tcode += TCODE_SEP + df[ccf].astype(str)\n",
        "\n",
        "    df[\"tcode\"] = tcode\n",
        "\n",
        "    conditions = [\n",
        "    (df['day'] >= 1) & (df['day'] <= 10),\n",
        "    (df['day'] > 10) & (df['day'] <= 20),\n",
        "    (df['day'] > 20) & (df['day'] <= 31)\n",
        "      ]\n",
        "\n",
        "    categories = ['first', 'middle', 'last']\n",
        "\n",
        "    # Use numpy.select() to map the numbers to categories\n",
        "    df['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "\n",
        "    bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "    labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "\n",
        "    # Use pd.cut() to convert ages to categorical groups\n",
        "    df['age_group'] = pd.cut(df['age'], bins=bin_edges, labels=labels, right=False)\n",
        "    df['age_group'] = df['age_group'].astype('object')\n",
        "\n",
        "    result = df.groupby('account_id')['datetime'].agg(['min', 'max'])\n",
        "    result['duration'] = result['max'] - result['min']\n",
        "    result_sorted = result.sort_values('duration', ascending=False)\n",
        "\n",
        "    df['log_amount'] = np.log10(df['amount'] + 1)\n",
        "    LOG_AMOUNT_SCALE = df['log_amount'].std()\n",
        "    df['log_amount_sc'] = df['log_amount']/ LOG_AMOUNT_SCALE\n",
        "    TD_SCALE = df['td'].std()\n",
        "    df['td_sc'] = df['td']/TD_SCALE\n",
        "\n",
        "    return df, LOG_AMOUNT_SCALE , TD_SCALE"
      ],
      "metadata": {
        "id": "KB5eGK4Hpfqv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "real = real.sort_values(by = [\"account_id\", \"date\"])\n",
        "raw_data, LOG_AMOUNT_SCALE, TD_SCALE = preprocess_data_czech(real)\n",
        "\n",
        "\n",
        "\n",
        "all_real = raw_data[['account_id', 'tcode', 'datetime', 'amount', 'td', 'day', 'month', 'year']]\n",
        "all_real['type'] = all_real['tcode'].str.split('__').str[0]\n",
        "all_real['raw_amount'] = all_real.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "all_real_cf = all_real[[\"account_id\", \"month\", \"raw_amount\", \"year\"]].groupby([\"account_id\", \"month\", \"year\"],as_index=False)[\"raw_amount\"].sum()"
      ],
      "metadata": {
        "id": "66aBNHtZpyw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e881fdcc-6314-43f0-d829-f527149fa3a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3939612794>:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"td\"].fillna(0.0, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data.to_csv('raw_data.csv')"
      ],
      "metadata": {
        "id": "-N1IEH5xR-c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOG_AMOUNT_SCALE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rKsBwhuSMf_",
        "outputId": "cb7905db-0fb2-4933-f9ed-19fdcbd7076a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0625705442977056"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TD_SCALE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qRzZ4JhSOA5",
        "outputId": "8908dc73-dcb3-4b5c-cc5e-03ca2278354a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.063912193703339"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst=[1,2,3]\n",
        "\n",
        "all_real[all_real.account_id.isin(lst)].to_csv('real_data_check.csv')"
      ],
      "metadata": {
        "id": "essw-k1AyXyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# raw_data\n",
        "\n",
        "raw_data['raw_amount'] = raw_data.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)"
      ],
      "metadata": {
        "id": "REi3j-BHqFlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im0JYR7viRJe",
        "outputId": "576e86a5-afd9-49fe-9184-a0cef5bf3364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1056320 entries, 0 to 1056319\n",
            "Data columns (total 25 columns):\n",
            " #   Column         Non-Null Count    Dtype         \n",
            "---  ------         --------------    -----         \n",
            " 0   Unnamed: 0     1056320 non-null  int64         \n",
            " 1   account_id     1056320 non-null  int64         \n",
            " 2   date           1056320 non-null  int64         \n",
            " 3   type           1056320 non-null  object        \n",
            " 4   operation      873206 non-null   object        \n",
            " 5   amount         1056320 non-null  float64       \n",
            " 6   balance        1056320 non-null  float64       \n",
            " 7   k_symbol       574439 non-null   object        \n",
            " 8   client_id      1056320 non-null  int64         \n",
            " 9   age            1056320 non-null  int64         \n",
            " 10  datetime       1056320 non-null  datetime64[ns]\n",
            " 11  month          1056320 non-null  int32         \n",
            " 12  day            1056320 non-null  int32         \n",
            " 13  dow            1056320 non-null  int32         \n",
            " 14  year           1056320 non-null  int32         \n",
            " 15  doy            1056320 non-null  int32         \n",
            " 16  td             1056320 non-null  float64       \n",
            " 17  dtme           1056320 non-null  int64         \n",
            " 18  raw_amount     1056320 non-null  float64       \n",
            " 19  tcode          1056320 non-null  object        \n",
            " 20  DoM_cat        1056320 non-null  object        \n",
            " 21  age_group      1048677 non-null  object        \n",
            " 22  log_amount     1056320 non-null  float64       \n",
            " 23  log_amount_sc  1056320 non-null  float64       \n",
            " 24  td_sc          1056320 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(7), int32(5), int64(6), object(6)\n",
            "memory usage: 181.3+ MB\n"
          ]
        }
      ],
      "source": [
        "raw_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X00M1abGk08b",
        "outputId": "16827c24-e18f-439f-8c1e-3e683c14053d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'account_id', 'date', 'type', 'operation', 'amount',\n",
              "       'balance', 'k_symbol', 'client_id', 'age', 'datetime', 'month', 'day',\n",
              "       'dow', 'year', 'doy', 'td', 'dtme', 'raw_amount', 'tcode', 'DoM_cat',\n",
              "       'age_group', 'log_amount', 'log_amount_sc', 'td_sc'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "raw_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8OxUPSSk9BG"
      },
      "outputs": [],
      "source": [
        "df_trans=raw_data\n",
        "\n",
        "df_trans_filtered=df_trans[['account_id','tcode','amount','raw_amount','age','day','month','year','td']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2j93qMEUlXDU",
        "outputId": "6efa6c66-d8a0-4bd7-856a-138305b5a96e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         account_id                                      tcode   amount  \\\n",
              "0                 1                CREDIT__CREDIT IN CASH__nan   1000.0   \n",
              "1                 1  CREDIT__COLLECTION FROM ANOTHER BANK__nan   3679.0   \n",
              "2                 1                CREDIT__CREDIT IN CASH__nan  12600.0   \n",
              "3                 1             CREDIT__nan__INTEREST CREDITED     19.2   \n",
              "4                 1  CREDIT__COLLECTION FROM ANOTHER BANK__nan   3679.0   \n",
              "...             ...                                        ...      ...   \n",
              "1056315       11382                DEBIT__CASH WITHDRAWAL__nan  25600.0   \n",
              "1056316       11382  CREDIT__COLLECTION FROM ANOTHER BANK__nan  46248.0   \n",
              "1056317       11382                DEBIT__CASH WITHDRAWAL__nan   6300.0   \n",
              "1056318       11382             CREDIT__nan__INTEREST CREDITED    311.3   \n",
              "1056319       11382             CREDIT__nan__INTEREST CREDITED    301.1   \n",
              "\n",
              "         raw_amount  age  day  month  year    td  \n",
              "0            1000.0   29   24      3  1995   0.0  \n",
              "1            3679.0   29   13      4  1995  20.0  \n",
              "2           12600.0   29   23      4  1995  10.0  \n",
              "3              19.2   29   30      4  1995   7.0  \n",
              "4            3679.0   29   13      5  1995  13.0  \n",
              "...             ...  ...  ...    ...   ...   ...  \n",
              "1056315    -25600.0   46    2     12  1998   2.0  \n",
              "1056316     46248.0   46   10     12  1998   8.0  \n",
              "1056317     -6300.0   46   25     12  1998  15.0  \n",
              "1056318       311.3   46   31     12  1998   6.0  \n",
              "1056319       301.1   46   31     12  1998   0.0  \n",
              "\n",
              "[1056320 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f025f0b2-d68e-4e56-a86b-278f6eac2bb7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_id</th>\n",
              "      <th>tcode</th>\n",
              "      <th>amount</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>age</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>td</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>29</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>1995</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__nan</td>\n",
              "      <td>3679.0</td>\n",
              "      <td>3679.0</td>\n",
              "      <td>29</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>1995</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>12600.0</td>\n",
              "      <td>12600.0</td>\n",
              "      <td>29</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>1995</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>19.2</td>\n",
              "      <td>19.2</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>1995</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__nan</td>\n",
              "      <td>3679.0</td>\n",
              "      <td>3679.0</td>\n",
              "      <td>29</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>1995</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056315</th>\n",
              "      <td>11382</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
              "      <td>25600.0</td>\n",
              "      <td>-25600.0</td>\n",
              "      <td>46</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1998</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056316</th>\n",
              "      <td>11382</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__nan</td>\n",
              "      <td>46248.0</td>\n",
              "      <td>46248.0</td>\n",
              "      <td>46</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>1998</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056317</th>\n",
              "      <td>11382</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
              "      <td>6300.0</td>\n",
              "      <td>-6300.0</td>\n",
              "      <td>46</td>\n",
              "      <td>25</td>\n",
              "      <td>12</td>\n",
              "      <td>1998</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056318</th>\n",
              "      <td>11382</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>311.3</td>\n",
              "      <td>311.3</td>\n",
              "      <td>46</td>\n",
              "      <td>31</td>\n",
              "      <td>12</td>\n",
              "      <td>1998</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056319</th>\n",
              "      <td>11382</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>301.1</td>\n",
              "      <td>301.1</td>\n",
              "      <td>46</td>\n",
              "      <td>31</td>\n",
              "      <td>12</td>\n",
              "      <td>1998</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1056320 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f025f0b2-d68e-4e56-a86b-278f6eac2bb7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f025f0b2-d68e-4e56-a86b-278f6eac2bb7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f025f0b2-d68e-4e56-a86b-278f6eac2bb7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-00c7fd26-adec-43b9-b39f-c7a2ab6d6bdc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00c7fd26-adec-43b9-b39f-c7a2ab6d6bdc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-00c7fd26-adec-43b9-b39f-c7a2ab6d6bdc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_34576729-d3ee-4ae1-822e-584e2c82316b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_trans_filtered')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_34576729-d3ee-4ae1-822e-584e2c82316b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_trans_filtered');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_trans_filtered"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df_trans_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRsMb2oBmiuz",
        "outputId": "4c534660-5d57-4508-87cb-95a7d1560cda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CREDIT__CREDIT IN CASH__nan',\n",
              "       'CREDIT__COLLECTION FROM ANOTHER BANK__nan',\n",
              "       'CREDIT__nan__INTEREST CREDITED', 'DEBIT__CASH WITHDRAWAL__nan',\n",
              "       'DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__LOAN PAYMENT',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__ ',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE PAYMENT',\n",
              "       'CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE PENSION',\n",
              "       'DEBIT__CREDIT CARD WITHDRAWAL__nan',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__nan',\n",
              "       'DEBIT__CASH WITHDRAWAL__HOUSEHOLD',\n",
              "       'DEBIT__CASH WITHDRAWAL__SANCTION INTEREST',\n",
              "       'DEBIT__CASH WITHDRAWAL__ ',\n",
              "       'DEBIT__CASH WITHDRAWAL__INSURANCE PAYMENT'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df_trans_filtered.tcode.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6Ih5YdZ5S5R"
      },
      "outputs": [],
      "source": [
        "# df_trans_filtered['tcode'] = df_trans_filtered['tcode'].str.replace(r'__nan$', '', regex=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EsI09hSmm8cw",
        "outputId": "5e737f03-4bc8-421a-dbaf-db2989afde47"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1500 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df_trans_filtered.hist(figsize=(18,15));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3eMQwQRntho",
        "outputId": "d2983baa-233f-4fd6-969c-80f9380e725f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['account_id', 'tcode', 'amount', 'raw_amount', 'age', 'day', 'month',\n",
              "       'year', 'td'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "df_trans_filtered.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ-gKKzznrK-"
      },
      "outputs": [],
      "source": [
        "# determine categotical attributes\n",
        "cat_attrs= ['age','day','td','month','tcode']\n",
        "\n",
        " # determine numerical attributes\n",
        "num_attrs= ['amount','raw_amount','account_id','year']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBH_L14cqc4f"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the data\n",
        "df_trans_filtered['tcode'] = label_encoder.fit_transform(df_trans['tcode'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_trans_filtered['tcode_str'] = df_trans_filtered['tcode'].apply(lambda x: original_tcodes[int(x)])\n",
        "# df_trans_filtered['tcode_str'] = label_encoder.inverse_transform(df_trans_filtered['tcode'])\n"
      ],
      "metadata": {
        "id": "i0BRaIGxZDjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trans_filtered['tcode'].hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Pf8EyDmSsHx8",
        "outputId": "0a0a6e32-6da5-4472-b0fb-af56bea05540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PVcpZxFuqost",
        "outputId": "744a4bf9-6991-413d-d912-3a4ceeef3a38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   account_id  tcode   amount  raw_amount  age  day  month  year    td\n",
              "0           1      2   1000.0      1000.0   29   24      3  1995   0.0\n",
              "1           1      1   3679.0      3679.0   29   13      4  1995  20.0\n",
              "2           1      2  12600.0     12600.0   29   23      4  1995  10.0\n",
              "3           1      3     19.2        19.2   29   30      4  1995   7.0\n",
              "4           1      1   3679.0      3679.0   29   13      5  1995  13.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-410908da-4147-4822-892f-705c663fddcf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_id</th>\n",
              "      <th>tcode</th>\n",
              "      <th>amount</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>age</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>td</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>29</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>1995</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3679.0</td>\n",
              "      <td>3679.0</td>\n",
              "      <td>29</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>1995</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>12600.0</td>\n",
              "      <td>12600.0</td>\n",
              "      <td>29</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>1995</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>19.2</td>\n",
              "      <td>19.2</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>1995</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3679.0</td>\n",
              "      <td>3679.0</td>\n",
              "      <td>29</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>1995</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-410908da-4147-4822-892f-705c663fddcf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-410908da-4147-4822-892f-705c663fddcf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-410908da-4147-4822-892f-705c663fddcf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-26417df9-9937-4c96-83f4-632c542d4d00\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26417df9-9937-4c96-83f4-632c542d4d00')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-26417df9-9937-4c96-83f4-632c542d4d00 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_trans_filtered"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "df_trans_filtered.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "TyT9_zp6nNxP",
        "outputId": "3b1997ab-ca25-4610-fd13-76ecd62569ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# retrieve just the numeric input values\n",
        "data = df_trans_filtered[num_attrs].values\n",
        "# perform a normal quantile transform of the dataset\n",
        "trans = QuantileTransformer(n_quantiles=100, output_distribution='normal')\n",
        "data = trans.fit_transform(data)\n",
        "# convert the array back to a dataframe\n",
        "dataset = pd.DataFrame(data)\n",
        "# histograms of the variables\n",
        "dataset.hist(figsize=(10,5),bins=50)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fb-rSQLsqol"
      },
      "outputs": [],
      "source": [
        "train= df_trans_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y05zVbuD7kB2"
      },
      "source": [
        "only choose 2 hundered thousdand data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNstKyw07m2d"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# stratifiled sampling by 'tcode'\n",
        "\n",
        "df_sampled, _= train_test_split(\n",
        "    train, train_size=200000,stratify=train['tcode'],\n",
        "    random_state=seed\n",
        ")\n",
        "\n",
        "train= df_sampled.sample(frac=1, random_state=seed).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2RQLGJpB8Udn",
        "outputId": "12d9f548-70e4-4e28-b964-cdfcd93c7707"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        account_id  tcode   amount  raw_amount  age  day  month  year    td\n",
              "0             1920      2   5356.0      5356.0   51   12     11  1996   2.0\n",
              "1             2052      7     14.6       -14.6   38   30      9  1996  19.0\n",
              "2             1821      3    168.1       168.1   38   30      4  1996  16.0\n",
              "3             1029      3    231.8       231.8   32   31      7  1997   4.0\n",
              "4             2723      9   2280.0     -2280.0   22    6      4  1997   6.0\n",
              "...            ...    ...      ...         ...  ...  ...    ...   ...   ...\n",
              "199995         271      7     14.6       -14.6   81   31      7  1997  17.0\n",
              "199996        4337      2  26515.0     26515.0   50    5      6  1996   2.0\n",
              "199997        3264     12   1886.0     -1886.0   75    7      6  1996   7.0\n",
              "199998        1950      2  12757.0     12757.0   43   12      2  1998   1.0\n",
              "199999        3225     12   8030.0     -8030.0   56    5     12  1996   5.0\n",
              "\n",
              "[200000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecd7987e-a2ca-4d90-be0e-3dc91af2e4ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_id</th>\n",
              "      <th>tcode</th>\n",
              "      <th>amount</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>age</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>td</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1920</td>\n",
              "      <td>2</td>\n",
              "      <td>5356.0</td>\n",
              "      <td>5356.0</td>\n",
              "      <td>51</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>1996</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2052</td>\n",
              "      <td>7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>-14.6</td>\n",
              "      <td>38</td>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>1996</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1821</td>\n",
              "      <td>3</td>\n",
              "      <td>168.1</td>\n",
              "      <td>168.1</td>\n",
              "      <td>38</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>1996</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1029</td>\n",
              "      <td>3</td>\n",
              "      <td>231.8</td>\n",
              "      <td>231.8</td>\n",
              "      <td>32</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>1997</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2723</td>\n",
              "      <td>9</td>\n",
              "      <td>2280.0</td>\n",
              "      <td>-2280.0</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>1997</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>271</td>\n",
              "      <td>7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>-14.6</td>\n",
              "      <td>81</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>1997</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>4337</td>\n",
              "      <td>2</td>\n",
              "      <td>26515.0</td>\n",
              "      <td>26515.0</td>\n",
              "      <td>50</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1996</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>3264</td>\n",
              "      <td>12</td>\n",
              "      <td>1886.0</td>\n",
              "      <td>-1886.0</td>\n",
              "      <td>75</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1996</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>1950</td>\n",
              "      <td>2</td>\n",
              "      <td>12757.0</td>\n",
              "      <td>12757.0</td>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>1998</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>3225</td>\n",
              "      <td>12</td>\n",
              "      <td>8030.0</td>\n",
              "      <td>-8030.0</td>\n",
              "      <td>56</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>1996</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecd7987e-a2ca-4d90-be0e-3dc91af2e4ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ecd7987e-a2ca-4d90-be0e-3dc91af2e4ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ecd7987e-a2ca-4d90-be0e-3dc91af2e4ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ada98aa8-a7ce-44bd-a339-2c145f2cc1b7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ada98aa8-a7ce-44bd-a339-2c145f2cc1b7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ada98aa8-a7ce-44bd-a339-2c145f2cc1b7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_66992d67-a228-4cbd-bcfe-c789a6fd12b8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_66992d67-a228-4cbd-bcfe-c789a6fd12b8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6CvkUy41od0"
      },
      "outputs": [],
      "source": [
        "# train.to_csv('train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHn4N9knsmu1"
      },
      "outputs": [],
      "source": [
        "# init the quantile transofrmation\n",
        "num_scaler= QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "\n",
        "# fit transform to numerical attributes\n",
        "num_scaler.fit(train[num_attrs])\n",
        "\n",
        "# transformed numerical attributes\n",
        "train_num_scaled= num_scaler.transform(train[num_attrs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcahuqHYpKIC"
      },
      "outputs": [],
      "source": [
        "vocabulary_classes= np.unique(train[cat_attrs])\n",
        "\n",
        "# init categorical attribute encoder\n",
        "label_encoder= LabelEncoder()\n",
        "\n",
        "# fit encoder to categorical attributes\n",
        "label_encoder.fit(vocabulary_classes)\n",
        "\n",
        "# transform cateforical attributes\n",
        "train_cat_scaled= train[cat_attrs].apply(label_encoder.transform)\n",
        "\n",
        "# collect unique values of each categorical attribute\n",
        "vocab_per_attr = {cat_attr: set(train_cat_scaled[cat_attr]) for cat_attr in cat_attrs}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWkZ8WIFr5Ec",
        "outputId": "ce789448-bb41-4f61-cbda-47e1334e9060"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': {17,\n",
              "  18,\n",
              "  19,\n",
              "  20,\n",
              "  21,\n",
              "  22,\n",
              "  23,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  36,\n",
              "  37,\n",
              "  38,\n",
              "  39,\n",
              "  40,\n",
              "  41,\n",
              "  42,\n",
              "  43,\n",
              "  44,\n",
              "  45,\n",
              "  46,\n",
              "  47,\n",
              "  48,\n",
              "  49,\n",
              "  50,\n",
              "  51,\n",
              "  52,\n",
              "  53,\n",
              "  54,\n",
              "  55,\n",
              "  56,\n",
              "  57,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  73,\n",
              "  74,\n",
              "  75,\n",
              "  76,\n",
              "  77,\n",
              "  78,\n",
              "  79,\n",
              "  80,\n",
              "  81},\n",
              " 'day': {1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  19,\n",
              "  20,\n",
              "  21,\n",
              "  22,\n",
              "  23,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  30,\n",
              "  31},\n",
              " 'td': {0,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  19,\n",
              "  20,\n",
              "  21,\n",
              "  22,\n",
              "  23,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  30,\n",
              "  31,\n",
              "  33,\n",
              "  36,\n",
              "  45,\n",
              "  47,\n",
              "  49,\n",
              "  54,\n",
              "  57,\n",
              "  58,\n",
              "  60,\n",
              "  61,\n",
              "  69,\n",
              "  82,\n",
              "  83,\n",
              "  84,\n",
              "  85,\n",
              "  86,\n",
              "  87,\n",
              "  88},\n",
              " 'month': {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12},\n",
              " 'tcode': {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15}}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "vocab_per_attr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "0j0Sj3qTsNye",
        "outputId": "96e110fd-02d9-4d88-902e-66c2a1b4e840"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  day  td  month  tcode\n",
              "0        51   12   2     11      2\n",
              "1        38   30  19      9      7\n",
              "2        38   30  16      4      3\n",
              "3        32   31   4      7      3\n",
              "4        22    6   6      4      9\n",
              "...     ...  ...  ..    ...    ...\n",
              "199995   81   31  17      7      7\n",
              "199996   50    5   2      6      2\n",
              "199997   75    7   7      6     12\n",
              "199998   43   12   1      2      2\n",
              "199999   56    5   5     12     12\n",
              "\n",
              "[200000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28550be4-f726-472e-be24-3c03dc6513af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>day</th>\n",
              "      <th>td</th>\n",
              "      <th>month</th>\n",
              "      <th>tcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>30</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>30</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>81</td>\n",
              "      <td>31</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>50</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>75</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>56</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28550be4-f726-472e-be24-3c03dc6513af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28550be4-f726-472e-be24-3c03dc6513af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28550be4-f726-472e-be24-3c03dc6513af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-15d3dffe-d143-4f27-a758-b6bd226f5615\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15d3dffe-d143-4f27-a758-b6bd226f5615')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-15d3dffe-d143-4f27-a758-b6bd226f5615 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_9cd3bfde-65bd-4383-b30a-84f240f77cb7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_cat_scaled')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9cd3bfde-65bd-4383-b30a-84f240f77cb7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_cat_scaled');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_cat_scaled"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "train_cat_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZwu0ELb1Ewk"
      },
      "outputs": [],
      "source": [
        "# convert the numerical attributes\n",
        "train_num_torch= torch.FloatTensor(train_num_scaled)\n",
        "\n",
        "# convert the categorical attributes\n",
        "train_cat_torch= torch.LongTensor(train_cat_scaled.values) # the train_cat_scaled was a dataframe so we have to get values\n",
        "\n",
        "# init tensor dataset\n",
        "train_set= TensorDataset(\n",
        "    train_cat_torch, # categorical attributes\n",
        "    train_num_torch,\n",
        "    # label_torch # dataset labels\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHqezpCY1Kei"
      },
      "outputs": [],
      "source": [
        "dataloader= DataLoader(dataset=train_set, batch_size=batch_size, num_workers=0, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOz_7wek1LFS",
        "outputId": "e1c4d16a-cf9a-4f85-dcc7-6259602e8298"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[64, 23, 11,  9,  9],\n",
              "         [51,  6,  6,  2,  9],\n",
              "         [29,  3,  1,  6,  9],\n",
              "         ...,\n",
              "         [50, 31, 20,  8,  3],\n",
              "         [38,  4,  4,  9,  2],\n",
              "         [19, 30, 14,  9,  3]]),\n",
              " tensor([[ 0.5351, -1.0318,  0.8038, -1.4642],\n",
              "         [ 0.0552, -0.5761,  1.3383,  0.1537],\n",
              "         [ 0.9415, -1.4903,  0.9230,  5.1993],\n",
              "         ...,\n",
              "         [-0.8904,  0.3485,  0.8495,  0.1537],\n",
              "         [ 0.4280,  0.9979, -0.1615, -0.4294],\n",
              "         [-0.5555,  0.6092,  1.1081,  5.1993]])]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "next(iter(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "cGqzeMNRFA2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cRipReJnK7EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Synthesizer"
      ],
      "metadata": {
        "id": "zcPjTziZ1mQy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcn_kGLW1VSJ"
      },
      "outputs": [],
      "source": [
        "# LSTM-based Architecture\n",
        "class LSTMSynthesizer(nn.Module):\n",
        "    def __init__(self, d_in, hidden_layers, activation='lrelu',\n",
        "                 dim_t=64, n_cat_tokens=None, n_cat_emb=None,\n",
        "                 embedding=None, embedding_learned=True,\n",
        "                 lstm_layers=1, bidirectional=True):\n",
        "        super(LSTMSynthesizer, self).__init__()\n",
        "\n",
        "        # init\n",
        "        self.dim_t = dim_t\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        # Handle categorical embeddings\n",
        "        if embedding is not None:\n",
        "            self.cat_embedding = nn.Embedding.from_pretrained(embeddings=embedding)\n",
        "        else:\n",
        "            self.cat_embedding = nn.Embedding(n_cat_tokens, n_cat_emb, max_norm=None, scale_grad_by_freq=False)\n",
        "            self.cat_embedding.weight.requires_grad = embedding_learned\n",
        "\n",
        "        # For label embedding if needed\n",
        "        # if n_classes is not None:\n",
        "        #     self.label_embedding = nn.Embedding(n_classes, dim_t)\n",
        "\n",
        "        # Input projection\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(d_in, dim_t),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(dim_t, dim_t)\n",
        "        )\n",
        "\n",
        "        # Time embedding projection\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(dim_t, dim_t),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(dim_t, dim_t)\n",
        "        )\n",
        "\n",
        "        # LSTM Backbone\n",
        "        lstm_input_size = dim_t\n",
        "        lstm_hidden_size = hidden_layers[0] if hidden_layers else dim_t\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=lstm_input_size,\n",
        "            hidden_size=lstm_hidden_size,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        # Output projection based on LSTM output size\n",
        "        lstm_output_size = lstm_hidden_size * 2 if bidirectional else lstm_hidden_size\n",
        "        self.head = nn.Linear(lstm_output_size, d_in)\n",
        "\n",
        "    def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "        # half output dimension\n",
        "        half_dim_out = dim_out // 2\n",
        "\n",
        "        # determine tensor of frequencies\n",
        "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0,\n",
        "                                                 end=half_dim_out, dtype=torch.float32) / half_dim_out)\n",
        "\n",
        "        freqs = freqs.to(device=timesteps.device)\n",
        "\n",
        "        # create timesteps vs frequency grid\n",
        "        args = timesteps[:, None].float() * freqs[None]\n",
        "\n",
        "        # creating the time embedding\n",
        "        time_embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "\n",
        "        # case odd output dimension\n",
        "        if dim_out % 2:\n",
        "            # append additional dimension\n",
        "            time_embedding = torch.cat([time_embedding, torch.zeros_like(time_embedding[:, :1])], dim=-1)\n",
        "\n",
        "        # return timestep embedding\n",
        "        return time_embedding\n",
        "\n",
        "    # get categorical embedding\n",
        "    def get_embedding(self):\n",
        "        # return categorical embedding\n",
        "        return self.cat_embedding.weight.data\n",
        "\n",
        "    # perform categorical embedding\n",
        "    def embed_categorical(self, x_cat):\n",
        "        # perform categorical embedding\n",
        "        x_cat_emb = self.cat_embedding(x_cat)\n",
        "\n",
        "        # reshape embedding to original input\n",
        "        x_cat_emb = x_cat_emb.view(-1, x_cat_emb.shape[1] * x_cat_emb.shape[2])\n",
        "\n",
        "        return x_cat_emb\n",
        "\n",
        "    # define forward pass\n",
        "    def forward(self, x, timesteps):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # init time embeddings\n",
        "        time_emb = self.embed_time(timesteps, self.dim_t)\n",
        "\n",
        "        # embed time embedding\n",
        "        time_emb = self.time_embed(time_emb)\n",
        "\n",
        "        # case: data classes available\n",
        "        # if label is not None:\n",
        "        #     time_label_emb = time_emb + self.label_embedding(label)\n",
        "        # else:\n",
        "        time_label_emb = time_emb\n",
        "\n",
        "        # run initial projection layer\n",
        "        x = self.projection(x)\n",
        "\n",
        "        # add time and label embedding\n",
        "        x = x + time_label_emb\n",
        "\n",
        "        # Reshape for LSTM (batch_size, seq_len=1, features)\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        x, _ = self.lstm(x)\n",
        "\n",
        "        # Extract the last output for each sequence\n",
        "        x = x[:, -1, :]\n",
        "\n",
        "        # Pass through output layer\n",
        "        x = self.head(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### student-t distribution"
      ],
      "metadata": {
        "id": "qd2xKN8dIWAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import math\n",
        "from scipy import stats\n",
        "\n",
        "# define Student's t-Distribution DDPM Diffuser network\n",
        "class StudentTDDPMDiffuser(object):\n",
        "  # define the constructor\n",
        "  def __init__(self, total_steps=1000, beta_start=1e-4, beta_end=0.02, device='cpu', scheduler='exp', df=10):\n",
        "     # set diffusion steps\n",
        "     self.total_steps = total_steps\n",
        "\n",
        "     # set diffusion start beta\n",
        "     self.beta_start = beta_start\n",
        "\n",
        "     # set diffusion end beta\n",
        "     self.beta_end = beta_end\n",
        "\n",
        "     # set compute device\n",
        "     self.device = device\n",
        "\n",
        "     # set degrees of freedom for t-distribution\n",
        "     self.df = df\n",
        "\n",
        "     # set noise schedule alphas and betas\n",
        "     self.alphas, self.betas = self.prepare_noise_schedule(scheduler=scheduler)\n",
        "\n",
        "     # set noise schedule alpha hat\n",
        "     self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "  # define noise schedule\n",
        "  def prepare_noise_schedule(self, scheduler: str):\n",
        "    # define noise scheduler scale\n",
        "    scale = 1000 / self.total_steps\n",
        "\n",
        "    # scale beta start\n",
        "    beta_start = scale * self.beta_start\n",
        "\n",
        "    # scale beta end\n",
        "    beta_end = scale * self.beta_end\n",
        "\n",
        "    if scheduler == 'linear':\n",
        "        betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "        alphas = 1.0 - betas\n",
        "\n",
        "    elif scheduler == 'quad':\n",
        "        betas = torch.linspace(self.beta_start**0.5, self.beta_end**0.5, self.total_steps) ** 2\n",
        "        alphas = 1.0 - betas\n",
        "\n",
        "    elif scheduler == 'exp':\n",
        "        betas = torch.exp(torch.linspace(math.log(beta_start), math.log(beta_end), self.total_steps))\n",
        "        alphas = 1.0 - betas\n",
        "\n",
        "    elif scheduler == 'sigm':\n",
        "        x = torch.linspace(-6, 6, self.total_steps)\n",
        "        betas = torch.sigmoid(x) * (beta_end - beta_start) + beta_start\n",
        "        alphas = 1.0 - betas\n",
        "\n",
        "    return alphas.to(self.device), betas.to(self.device)\n",
        "\n",
        "  # define random timesteps sampler\n",
        "  def sample_random_timesteps(self, n:int):\n",
        "    # sample random timesteps\n",
        "     t = torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "     return t\n",
        "\n",
        "  # Generate samples from Student's t-distribution\n",
        "  def sample_student_t(self, shape):\n",
        "    # Use the reparameterization trick for Student's t-distribution\n",
        "    # t = sqrt(df/(df-2)) * X / sqrt(Z/df) where X ~ N(0,1) and Z ~ Chi^2(df)\n",
        "    # For df > 2, this gives a t-distribution with variance 1\n",
        "\n",
        "    if self.df <= 2:\n",
        "        # Ensure finite variance\n",
        "        df_sample = 3.0\n",
        "    else:\n",
        "        df_sample = float(self.df)\n",
        "\n",
        "    # Generate normal samples - FIX: shape should be a tuple or list, not a tensor\n",
        "    if isinstance(shape, torch.Tensor):\n",
        "        shape = tuple(shape.tolist())\n",
        "    x = torch.randn(shape, device=self.device)\n",
        "\n",
        "    # Generate chi-squared samples using gamma distribution\n",
        "    # Chi^2(k) is equivalent to Gamma(k/2, 2)\n",
        "    gamma_shape = df_sample / 2.0\n",
        "    gamma_samples = torch.tensor(stats.gamma.rvs(gamma_shape, scale=2.0, size=shape[0]),\n",
        "                                 dtype=torch.float32,\n",
        "                                 device=self.device).view(-1, 1)\n",
        "\n",
        "    # Compute the t-distributed noise\n",
        "    # Scaling factor ensures variance = 1 for df > 2\n",
        "    scaling = torch.sqrt(torch.tensor(df_sample / (df_sample - 2.0), device=self.device)) if df_sample > 2 else torch.tensor(1.0, device=self.device)\n",
        "\n",
        "    t_noise = scaling * x / torch.sqrt(gamma_samples / df_sample)\n",
        "\n",
        "    return t_noise\n",
        "\n",
        "  # define Student-t noise addition for forward process\n",
        "  def add_t_noise(self, x_num, t):\n",
        "    # determine noise alpha hat\n",
        "    sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None]\n",
        "\n",
        "    # determine noise one minus alpha hat\n",
        "    sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None]\n",
        "\n",
        "    # determine Student-t noise instead of Gaussian\n",
        "    noise_shape = x_num.shape\n",
        "    batch_size = noise_shape[0]\n",
        "    noise_num = self.sample_student_t((batch_size, x_num.shape[1]))\n",
        "\n",
        "    # determine x numeric noise (same formula as Gaussian, but with t-distribution noise)\n",
        "    x_noise_num = sqrt_alpha_hat * x_num + sqrt_one_minus_alpha_hat * noise_num\n",
        "\n",
        "    return x_noise_num, noise_num\n",
        "\n",
        "  # define Student-t noise sampling for reverse process\n",
        "  def p_sample_t(self, model_out, z_norm, timesteps):\n",
        "    # determine noise alpha\n",
        "    sqrt_alpha_t = torch.sqrt(self.alphas[timesteps])[:, None]\n",
        "\n",
        "    # determine noise beta\n",
        "    betas_t = self.betas[timesteps][:, None]\n",
        "\n",
        "    # determine noise one minus alpha hat\n",
        "    sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[timesteps])[:, None]\n",
        "\n",
        "    epsilon_t = torch.sqrt(self.betas[timesteps][:, None])\n",
        "\n",
        "    # determine t-distribution noise instead of Gaussian\n",
        "    batch_size = z_norm.shape[0]\n",
        "    random_noise = self.sample_student_t((batch_size, z_norm.shape[1]))\n",
        "    random_noise[timesteps == 0] = 0.0\n",
        "\n",
        "    # determine model mean (same formula as Gaussian case)\n",
        "    model_mean = ((1 / sqrt_alpha_t) * (z_norm - (betas_t * model_out / sqrt_one_minus_alpha_hat_t)))\n",
        "\n",
        "    # determine z norm with t-distribution noise\n",
        "    z_norm = model_mean + (epsilon_t * random_noise)\n",
        "\n",
        "    return z_norm\n",
        "\n",
        "  # Full sampling process - FIX: Modify the method signature to match your usage\n",
        "  def sample(self, model_out, z_norm, timesteps):\n",
        "    # This is a simplified version that directly uses the p_sample_t method\n",
        "    return self.p_sample_t(model_out, z_norm, timesteps)\n",
        "\n",
        "  # The original sample method can be renamed to sample_full if you still need it\n",
        "  def sample_full(self, model, shape, device):\n",
        "    # Start from pure noise (t-distributed)\n",
        "    x = self.sample_student_t(shape).to(device)\n",
        "\n",
        "    # Iterate backward through timesteps\n",
        "    for t in range(self.total_steps - 1, -1, -1):\n",
        "        # Create a batch of the same timestep\n",
        "        timesteps = torch.full((shape[0],), t, device=device, dtype=torch.long)\n",
        "\n",
        "        # Predict noise\n",
        "        predicted_noise = model(x, timesteps)\n",
        "\n",
        "        # Sample for this timestep\n",
        "        x = self.p_sample_t(predicted_noise, x, timesteps)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "ciKOw5EnIYIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8jca1La1l5h"
      },
      "outputs": [],
      "source": [
        "# determine number of unique categorical tokens\n",
        "n_cat_tokens= len(np.unique(train[cat_attrs]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlLmCwIf1m6R",
        "outputId": "bfc911b5-af3f-4734-c721-4cac045490a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "n_cat_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSMcr4ho1r30"
      },
      "outputs": [],
      "source": [
        "# detrermine total categorical embedding dimension\n",
        "cat_dim= cat_emb_dim * len(cat_attrs)\n",
        "\n",
        "# determine total numerical embedding dimension\n",
        "num_dim= len(num_attrs)\n",
        "\n",
        "# detrmine total embedding dimension\n",
        "encoded_dim= cat_dim + num_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6xEnKzv1snw",
        "outputId": "bc8c3b02-e82b-4f50-f7bd-2d752c9b46ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "encoded_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M375SQuf11Ki"
      },
      "outputs": [],
      "source": [
        "synthesizer_model = LSTMSynthesizer(\n",
        "    d_in=encoded_dim,  # the input shape\n",
        "    hidden_layers=mlp_layers,\n",
        "    activation=activation,\n",
        "    n_cat_tokens=n_cat_tokens,\n",
        "    n_cat_emb=cat_emb_dim,\n",
        "    embedding_learned=False,\n",
        "    # num_layers=4,\n",
        "    # dim_feedforward=2048\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn8BTTyi12px",
        "outputId": "a66ce6e4-40e2-4000-9d2d-dbf2a342eee2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMSynthesizer(\n",
              "  (cat_embedding): Embedding(89, 2)\n",
              "  (projection): Sequential(\n",
              "    (0): Linear(in_features=14, out_features=64, bias=True)\n",
              "    (1): SiLU()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  )\n",
              "  (time_embed): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (1): SiLU()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  )\n",
              "  (lstm): LSTM(64, 1024, batch_first=True, bidirectional=True)\n",
              "  (head): Linear(in_features=2048, out_features=14, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "synthesizer_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X2hi6I_198m"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize the Student-t distribution diffuser\n",
        "diffuser = StudentTDDPMDiffuser(\n",
        "    total_steps=diffusion_steps,\n",
        "    beta_start=diffusion_beta_start,\n",
        "    beta_end=diffusion_beta_end,\n",
        "    scheduler='exp',\n",
        "    device=device,\n",
        "    df=10  # Set degrees of freedom - adjust based on your data characteristics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SequentialBankingDataset(Dataset):\n",
        "    \"\"\"Dataset that handles sequences of transactions per account\"\"\"\n",
        "\n",
        "    def __init__(self, df, cat_attrs, num_attrs, sequence_length=50, min_seq_length=10):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.min_seq_length = min_seq_length\n",
        "        self.cat_attrs = cat_attrs\n",
        "        self.num_attrs = num_attrs\n",
        "\n",
        "        # Group by account and create sequences\n",
        "        self.sequences = []\n",
        "        self.account_sequences = {}\n",
        "\n",
        "        for account_id in df['account_id'].unique():\n",
        "            account_data = df[df['account_id'] == account_id].sort_values('datetime')\n",
        "\n",
        "            if len(account_data) >= min_seq_length:\n",
        "                # Store full sequence for this account\n",
        "                cat_data = account_data[cat_attrs].values\n",
        "                num_data = account_data[num_attrs].values\n",
        "\n",
        "                # Create overlapping windows of transactions\n",
        "                for i in range(len(account_data) - sequence_length + 1):\n",
        "                    seq_cat = cat_data[i:i+sequence_length]\n",
        "                    seq_num = num_data[i:i+sequence_length]\n",
        "\n",
        "                    self.sequences.append({\n",
        "                        'account_id': account_id,\n",
        "                        'cat_data': seq_cat,\n",
        "                        'num_data': seq_num,\n",
        "                        'start_idx': i\n",
        "                    })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        return (\n",
        "            torch.LongTensor(seq['cat_data']),\n",
        "            torch.FloatTensor(seq['num_data']),\n",
        "            seq['account_id']\n",
        "        )\n",
        "\n",
        "class SequentialLSTMSynthesizer(nn.Module):\n",
        "    \"\"\"Enhanced LSTM model for sequential transaction generation\"\"\"\n",
        "\n",
        "    def __init__(self, d_in, hidden_layers, activation='relu',\n",
        "                 dim_t=64, n_cat_tokens=None, n_cat_emb=None,\n",
        "                 sequence_length=50, lstm_layers=2, bidirectional=False,\n",
        "                 dropout=0.1):\n",
        "        super(SequentialLSTMSynthesizer, self).__init__()\n",
        "\n",
        "        self.dim_t = dim_t\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "        # Categorical embeddings\n",
        "        self.cat_embedding = nn.Embedding(n_cat_tokens, n_cat_emb)\n",
        "\n",
        "        # Input projection for combined cat + num features\n",
        "        self.input_projection = nn.Sequential(\n",
        "            nn.Linear(d_in, dim_t),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim_t, dim_t)\n",
        "        )\n",
        "\n",
        "        # Time embedding\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(dim_t, dim_t),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim_t, dim_t)\n",
        "        )\n",
        "\n",
        "        # Sequential LSTM backbone\n",
        "        lstm_input_size = dim_t\n",
        "        lstm_hidden_size = hidden_layers[0] if hidden_layers else dim_t\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=lstm_input_size,\n",
        "            hidden_size=lstm_hidden_size,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Attention mechanism for sequence modeling\n",
        "        lstm_output_size = lstm_hidden_size * 2 if bidirectional else lstm_hidden_size\n",
        "        self.attention = nn.MultiheadAttention(\n",
        "            embed_dim=lstm_output_size,\n",
        "            num_heads=8,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Output projection\n",
        "        self.output_layers = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, hidden_layers[0] if hidden_layers else dim_t),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_layers[0] if hidden_layers else dim_t, d_in)\n",
        "        )\n",
        "\n",
        "    def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "        \"\"\"Sinusoidal time embedding\"\"\"\n",
        "        half_dim_out = dim_out // 2\n",
        "        freqs = torch.exp(-math.log(max_period) * torch.arange(\n",
        "            start=0, end=half_dim_out, dtype=torch.float32) / half_dim_out)\n",
        "        freqs = freqs.to(device=timesteps.device)\n",
        "\n",
        "        args = timesteps[:, None].float() * freqs[None]\n",
        "        time_embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "\n",
        "        if dim_out % 2:\n",
        "            time_embedding = torch.cat([\n",
        "                time_embedding,\n",
        "                torch.zeros_like(time_embedding[:, :1])\n",
        "            ], dim=-1)\n",
        "\n",
        "        return time_embedding\n",
        "\n",
        "    def embed_categorical(self, x_cat):\n",
        "        \"\"\"Embed categorical variables\"\"\"\n",
        "        # x_cat shape: (batch_size, seq_len, n_cat_features)\n",
        "        batch_size, seq_len, n_cat = x_cat.shape\n",
        "\n",
        "        # Flatten for embedding\n",
        "        x_cat_flat = x_cat.view(-1, n_cat)\n",
        "        x_cat_emb = self.cat_embedding(x_cat_flat)\n",
        "\n",
        "        # Reshape back to sequence format\n",
        "        emb_dim = x_cat_emb.shape[-1] * n_cat\n",
        "        x_cat_emb = x_cat_emb.view(batch_size, seq_len, emb_dim)\n",
        "\n",
        "        return x_cat_emb\n",
        "\n",
        "    def forward(self, x_seq, timesteps):\n",
        "        \"\"\"\n",
        "        Forward pass for sequence data\n",
        "        x_seq: (batch_size, seq_len, features)\n",
        "        timesteps: (batch_size,) - same timestep for entire sequence\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = x_seq.shape\n",
        "\n",
        "        # Time embedding (broadcast to all sequence positions)\n",
        "        time_emb = self.embed_time(timesteps, self.dim_t)  # (batch_size, dim_t)\n",
        "        time_emb = self.time_embed(time_emb)\n",
        "        time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)  # (batch_size, seq_len, dim_t)\n",
        "\n",
        "        # Input projection\n",
        "        x = self.input_projection(x_seq)  # (batch_size, seq_len, dim_t)\n",
        "\n",
        "        # Add time embedding\n",
        "        x = x + time_emb\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x)  # (batch_size, seq_len, lstm_hidden_size)\n",
        "\n",
        "        # Self-attention for better sequence modeling\n",
        "        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
        "\n",
        "        # Residual connection\n",
        "        x = lstm_out + attn_out\n",
        "\n",
        "        # Output projection\n",
        "        output = self.output_layers(x)  # (batch_size, seq_len, d_in)\n",
        "\n",
        "        return output\n",
        "\n",
        "class SequentialStudentTDDPMDiffuser:\n",
        "    \"\"\"Modified diffuser for sequential data\"\"\"\n",
        "\n",
        "    def __init__(self, total_steps=1000, beta_start=1e-4, beta_end=0.02,\n",
        "                 device='cpu', scheduler='exp', df=10):\n",
        "        self.total_steps = total_steps\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.device = device\n",
        "        self.df = df\n",
        "\n",
        "        self.alphas, self.betas = self.prepare_noise_schedule(scheduler=scheduler)\n",
        "        self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "    def prepare_noise_schedule(self, scheduler: str):\n",
        "        \"\"\"Same as original but for sequence data\"\"\"\n",
        "        scale = 1000 / self.total_steps\n",
        "        beta_start = scale * self.beta_start\n",
        "        beta_end = scale * self.beta_end\n",
        "\n",
        "        if scheduler == 'exp':\n",
        "            betas = torch.exp(torch.linspace(\n",
        "                math.log(beta_start), math.log(beta_end), self.total_steps))\n",
        "            alphas = 1.0 - betas\n",
        "\n",
        "        return alphas.to(self.device), betas.to(self.device)\n",
        "\n",
        "    def sample_random_timesteps(self, n: int):\n",
        "        t = torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "        return t\n",
        "\n",
        "    def add_t_noise_sequence(self, x_seq, t):\n",
        "        \"\"\"Add noise to sequence data\"\"\"\n",
        "        batch_size, seq_len, features = x_seq.shape\n",
        "\n",
        "        sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None, None]\n",
        "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None, None]\n",
        "\n",
        "        # Generate t-distributed noise for the entire sequence\n",
        "        noise_seq = torch.randn_like(x_seq)  # Simplified - use Gaussian for now\n",
        "\n",
        "        x_noise_seq = sqrt_alpha_hat * x_seq + sqrt_one_minus_alpha_hat * noise_seq\n",
        "\n",
        "        return x_noise_seq, noise_seq\n",
        "\n",
        "# Training function for sequential model\n",
        "def train_sequential_model(model, diffuser, dataloader, optimizer, device, epochs=100):\n",
        "    \"\"\"Training loop for sequential transaction model\"\"\"\n",
        "    model.train()\n",
        "    model = model.to(device)\n",
        "\n",
        "    loss_fnc = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_losses = []\n",
        "\n",
        "        for batch_cat, batch_num, account_ids in dataloader:\n",
        "            batch_cat = batch_cat.to(device)\n",
        "            batch_num = batch_num.to(device)\n",
        "\n",
        "            batch_size, seq_len, _ = batch_cat.shape\n",
        "\n",
        "            # Embed categorical variables\n",
        "            batch_cat_emb = model.embed_categorical(batch_cat)\n",
        "\n",
        "            # Combine categorical and numerical features\n",
        "            batch_combined = torch.cat([batch_cat_emb, batch_num], dim=-1)\n",
        "\n",
        "            # Sample timesteps (one per batch, applied to entire sequence)\n",
        "            timesteps = diffuser.sample_random_timesteps(batch_size)\n",
        "\n",
        "            # Add noise to the entire sequence\n",
        "            batch_noisy, noise_target = diffuser.add_t_noise_sequence(batch_combined, timesteps)\n",
        "\n",
        "            # Forward pass\n",
        "            predicted_noise = model(batch_noisy, timesteps)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fnc(predicted_noise, noise_target)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_losses.append(loss.item())\n",
        "\n",
        "        # if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {np.mean(epoch_losses):.4f}\")\n",
        "\n",
        "# Usage example:\n",
        "\n",
        "# Create sequential dataset\n",
        "seq_dataset = SequentialBankingDataset(\n",
        "    df=df_trans_filtered,\n",
        "    cat_attrs=cat_attrs,\n",
        "    num_attrs=num_attrs,\n",
        "    sequence_length=30,  # 30 transactions per sequence\n",
        "    min_seq_length=10\n",
        ")\n",
        "\n",
        "seq_dataloader = DataLoader(seq_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Initialize sequential model\n",
        "sequential_model = SequentialLSTMSynthesizer(\n",
        "    d_in=encoded_dim,\n",
        "    hidden_layers=[256, 128],\n",
        "    sequence_length=30,\n",
        "    n_cat_tokens=n_cat_tokens,\n",
        "    n_cat_emb=cat_emb_dim,\n",
        "    lstm_layers=2,\n",
        "    dropout=0.1\n",
        ")\n",
        "\n",
        "# Initialize sequential diffuser\n",
        "seq_diffuser = SequentialStudentTDDPMDiffuser(\n",
        "    total_steps=1000,\n",
        "    device=device,\n",
        "    df=10\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "optimizer = torch.optim.Adam(sequential_model.parameters(), lr=1e-3)\n",
        "train_sequential_model(sequential_model, seq_diffuser, seq_dataloader, optimizer, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "AewCQCWIK_91",
        "outputId": "4e99af45-91ed-46bc-90c8-0d9ff15a71ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'datetime'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-1793cee42a02>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;31m# Create sequential dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m seq_dataset = SequentialBankingDataset(\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_trans_filtered\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mcat_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-1793cee42a02>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, cat_attrs, num_attrs, sequence_length, min_seq_length)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maccount_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'account_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0maccount_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'account_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maccount_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datetime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_seq_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7187\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7189\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7191\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'datetime'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUtFcpYR2Dvq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "9c44a7d4-b617-4a89-d531-b5cd27052e15"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'synthesizer_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-9d8e6de183bf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# determine synthesizer model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynthesizer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# init adam optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'synthesizer_model' is not defined"
          ]
        }
      ],
      "source": [
        "# determine synthesizer model parameters\n",
        "\n",
        "parameters= filter(lambda p: p.requires_grad, synthesizer_model.parameters())\n",
        "\n",
        "# init adam optimizer\n",
        "optimizer= optim.Adam(parameters, lr= learning_rate)\n",
        "\n",
        "# init learning rate scheduler\n",
        "lr_scheduler= CosineAnnealingLR(optimizer, T_max=epochs, verbose=False)\n",
        "\n",
        "# int mse loss\n",
        "\n",
        "loss_fnc= nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128,expandable_segments:True\"\n"
      ],
      "metadata": {
        "id": "-o0EiAqg1NVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for student t- test\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "# used for student-t distribution\n",
        "\n",
        "# Init collection of training epoch losses\n",
        "train_epoch_losses = []\n",
        "\n",
        "# Set the model in training mode\n",
        "synthesizer_model.train()\n",
        "\n",
        "# Move to the device\n",
        "synthesizer_model = synthesizer_model.to(device)\n",
        "\n",
        "# Init the training progress bar\n",
        "pbar = tqdm(iterable=range(500), position=0, leave=True)\n",
        "\n",
        "# Iterate over training epochs\n",
        "for epoch in pbar:\n",
        "    base_params = {'epoch': epoch, 'seed': seed, 'mlp_layers': mlp_layers}\n",
        "\n",
        "    # Init epoch training batch losses\n",
        "    batch_losses = []\n",
        "\n",
        "    # Iterate over epoch batches\n",
        "    for batch_cat, batch_num in dataloader:\n",
        "        # Move tensor to device\n",
        "        batch_cat = batch_cat.to(device)\n",
        "        batch_num = batch_num.to(device)\n",
        "\n",
        "        # Determine diffusion timestep\n",
        "        timesteps = diffuser.sample_random_timesteps(n=batch_cat.shape[0])\n",
        "\n",
        "        # Determine categorical embeddings\n",
        "        batch_cat_emb = synthesizer_model.embed_categorical(x_cat=batch_cat)\n",
        "\n",
        "        # Concat categorical and numerical embedding\n",
        "        batch_cat_num = torch.cat((batch_cat_emb, batch_num), dim=1)\n",
        "\n",
        "        # *** KEY CHANGE 1: Use t-distribution noise instead of Gaussian ***\n",
        "        batch_noise_t, noise_t = diffuser.add_t_noise(batch_cat_num, t=timesteps)\n",
        "\n",
        "        # Conduct synthesizer model forward pass\n",
        "        predicted_noise = synthesizer_model(x=batch_noise_t, timesteps=timesteps)\n",
        "\n",
        "        # Compute training batch loss\n",
        "        batch_loss = loss_fnc(input=noise_t, target=predicted_noise)\n",
        "\n",
        "        # Reset the model gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Run model backward pass\n",
        "        batch_loss.backward()\n",
        "\n",
        "        # Optimize model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Collect training batch losses\n",
        "        batch_losses.append(batch_loss.detach().cpu().numpy())\n",
        "\n",
        "    # Determine mean training batch loss\n",
        "    batch_losses_mean = np.mean(np.array(batch_losses))\n",
        "\n",
        "    # Update learning rate scheduler\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    # Collect mean training epochs loss\n",
        "    train_epoch_losses.append(batch_losses_mean)\n",
        "\n",
        "    # Prepare and set training epochs progress bar update\n",
        "    now = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    pbar.set_description('[LOG {}] epoch: {}, train-loss: {}'.format(\n",
        "        str(now), str(epoch).zfill(4), str(batch_losses_mean)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5a09-Hqaetp",
        "outputId": "2d13a30b-000f-4dfd-e321-c03c0e9e35ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[LOG 2025-06-08 14:48:46] epoch: 0499, train-loss: 0.5554529: 100%|██████████| 500/500 [44:13<00:00,  5.31s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Init samples to be generated\n",
        "# generated= torch.randn((len(train), encoded_dim), device=device)\n",
        "\n",
        "# generated = torch.randn((len(train), int(encoded_dim)), device=device)\n",
        "\n",
        "\n",
        "# # init the generation progress bar\n",
        "# pbar= tqdm(iterable=reversed(range(0, diffusion_steps)), position=0, leave=True)\n",
        "\n",
        "# with torch.no_grad():\n",
        "#   # iterate over diffusion steps\n",
        "#   for diffusion_step in pbar:\n",
        "#       # prepare and set the training epoch progress bar update\n",
        "#       now= datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "#       pbar.set_description('[LOG {}] Diffusion Step: {}'.format(str(now), str(diffusion_step).zfill(4)))\n",
        "\n",
        "#       #init diffusin timesteps\n",
        "#       timesteps=  torch.full((len(train),), diffusion_step, dtype=torch.long, device=device)\n",
        "\n",
        "#       # run synthesizer model forward pass\n",
        "#       model_out= synthesizer_model(x=generated.float(), timesteps=timesteps)\n",
        "\n",
        "#       # run diffuser model forward pass- Equation 4 here\n",
        "#       generated= diffuser.sample(model_out, generated, timesteps) # for DDPM\n",
        "      # generated = diffuser.sample(model_out, generated, timesteps, eta=0.0) # for DDIM\n",
        "\n",
        "\n",
        "## this is for laplacian distribution\n",
        "# generated = torch.randn((len(train), int(encoded_dim)), device=device)\n",
        "\n",
        "# # init the generation progress bar\n",
        "# pbar = tqdm(iterable=reversed(range(0, diffusion_steps)), position=0, leave=True)\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     # iterate over diffusion steps\n",
        "#     for diffusion_step in pbar:\n",
        "#         # prepare and set the training epoch progress bar update\n",
        "#         now = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "#         pbar.set_description('[LOG {}] Diffusion Step: {}'.format(str(now), str(diffusion_step).zfill(4)))\n",
        "\n",
        "#         # init diffusion timesteps\n",
        "#         timesteps = torch.full((len(train),), diffusion_step, dtype=torch.long, device=device)\n",
        "\n",
        "#         # run synthesizer model forward pass\n",
        "#         model_out = synthesizer_model(x=generated.float(), timesteps=timesteps)\n",
        "\n",
        "#         # run diffuser model forward pass- Equation 4 here\n",
        "#         generated = diffuser.p_sample_laplace(model_out, generated, timesteps)  # for DDPM\n",
        "\n",
        "\n",
        "\n",
        "### this is for student t-test\n",
        "\n",
        "# generated = torch.randn((len(train), int(encoded_dim)), device=device)\n",
        "\n",
        "# # init the generation progress bar\n",
        "# pbar = tqdm(iterable=reversed(range(0, diffusion_steps)), position=0, leave=True)\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     # iterate over diffusion steps\n",
        "#     for diffusion_step in pbar:\n",
        "#         # prepare and set the training epoch progress bar update\n",
        "#         now = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "#         pbar.set_description('[LOG {}] Diffusion Step: {}'.format(str(now), str(diffusion_step).zfill(4)))\n",
        "\n",
        "#         # init diffusion timesteps\n",
        "#         timesteps = torch.full((len(train),), diffusion_step, dtype=torch.long, device=device)\n",
        "\n",
        "#         # run synthesizer model forward pass\n",
        "#         model_out = synthesizer_model(x=generated.float(), timesteps=timesteps)\n",
        "\n",
        "#         # run diffuser model forward pass- Equation 4 here\n",
        "#         generated = diffuser.sample(model_out, generated, timesteps)  # for DDPM\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 512  # Adjust based on available memory\n",
        "num_samples = len(train)\n",
        "generated = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for start in tqdm(range(0, num_samples, batch_size), desc=\"Generating Samples\"):\n",
        "        end = min(start + batch_size, num_samples)\n",
        "\n",
        "        samples = torch.randn((end - start, encoded_dim), device=device)\n",
        "\n",
        "        for diffusion_step in reversed(range(0, diffusion_steps)):\n",
        "            timesteps = torch.full((samples.shape[0],), diffusion_step, dtype=torch.long, device=device)\n",
        "            model_out = synthesizer_model(x=samples.float(), timesteps=timesteps)\n",
        "            samples = diffuser.sample(model_out, samples, timesteps)\n",
        "\n",
        "        generated.append(samples.cpu())  # move to CPU to save GPU memory\n",
        "\n",
        "# Combine all batches\n",
        "generated = torch.cat(generated, dim=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkc0rbO9lohD",
        "outputId": "443efdf7-01ac-4b6c-9fd7-a8d429a20ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Samples: 100%|██████████| 391/391 [22:00<00:00,  3.38s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diffusion_steps = 1000  # or 100, 50, etc.\n"
      ],
      "metadata": {
        "id": "MFSMef2Rip3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayuADVsyDtE-",
        "outputId": "1f1a9e49-1a90-46df-b027-de728b3c437c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200000, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myFfjvEgEmyN",
        "outputId": "da12b91a-18f2-45b7-8db6-f4fa0ab4b2e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but QuantileTransformer was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# split sample into numeric and categorical parts\n",
        "samples = generated.detach().cpu().numpy()\n",
        "# samples=samples\n",
        "samples_num = samples[:, cat_dim:]\n",
        "samples_cat = samples[:, :cat_dim]\n",
        "\n",
        "# denormalize numeric attributes\n",
        "z_norm_upscaled = num_scaler.inverse_transform(samples_num)\n",
        "z_norm_df = pd.DataFrame(z_norm_upscaled, columns=num_attrs)\n",
        "\n",
        "# get embedding lookup matrix\n",
        "embedding_lookup = synthesizer_model.get_embedding().cpu()\n",
        "\n",
        "# reshape back to batch_size * n_dim_cat * cat_emb_dim\n",
        "samples_cat = samples_cat.reshape(-1, len(cat_attrs), cat_emb_dim)\n",
        "\n",
        "# compute pairwise distances\n",
        "distances = torch.cdist(x1=embedding_lookup, x2=torch.Tensor(samples_cat))\n",
        "\n",
        "# get the closest distance based on the embeddings that belong to a column category\n",
        "z_cat_df = pd.DataFrame(index=range(len(samples_cat)), columns=cat_attrs)\n",
        "\n",
        "nearest_dist_df = pd.DataFrame(index=range(len(samples_cat)), columns=cat_attrs)\n",
        "\n",
        "# iterate over categorical attributes\n",
        "for attr_idx, attr_name in enumerate(cat_attrs):\n",
        "\n",
        "    attr_emb_idx = list(vocab_per_attr[attr_name])\n",
        "    attr_distances = distances[:, attr_emb_idx, attr_idx]\n",
        "\n",
        "    nearest_values, nearest_idx = torch.min(attr_distances, dim=1)\n",
        "    nearest_idx = nearest_idx.cpu().numpy()\n",
        "\n",
        "    z_cat_df[attr_name] = np.array(attr_emb_idx)[nearest_idx]  # need to map emb indices back to column indices\n",
        "    nearest_dist_df[attr_name] = nearest_values.cpu().numpy()\n",
        "\n",
        "z_cat_df = z_cat_df.apply(label_encoder.inverse_transform)\n",
        "\n",
        "samples_decoded = pd.concat([z_cat_df, z_norm_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_decoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "JMSPZaN2CPje",
        "outputId": "b4729ab9-5fbe-41e6-b264-250cab5f7a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         age   day     td  month  tcode        amount    raw_amount  \\\n",
              "0       47.0  31.0    0.0    3.0    3.0    200.000000    207.204376   \n",
              "1       28.0  11.0  270.0    3.0    2.0  27719.798828  24746.908203   \n",
              "2       47.0   8.0    3.0    4.0    0.0   5047.853516   5409.837402   \n",
              "3       27.0   7.0    7.0    1.0    9.0   4722.251953  -4722.953613   \n",
              "4       32.0  14.0    0.0    5.0    2.0   5461.159668   5630.391602   \n",
              "...      ...   ...    ...    ...    ...           ...           ...   \n",
              "199995  47.0  11.0    7.0    7.0    0.0   4216.837891   4183.875977   \n",
              "199996  79.0  14.0   36.0    3.0   12.0    298.415802   -363.671906   \n",
              "199997  32.0  31.0    1.0    5.0    7.0     14.600000    -14.600000   \n",
              "199998  28.0  30.0    0.0    6.0    7.0     14.600000    -14.600000   \n",
              "199999  59.0  25.0    3.0    1.0    9.0   1052.986450  -1076.399414   \n",
              "\n",
              "          account_id    year  \n",
              "0        3654.337646  1996.0  \n",
              "1        9017.931641  1998.0  \n",
              "2         998.038513  1993.0  \n",
              "3       10788.117188  1998.0  \n",
              "4        1857.147095  1997.0  \n",
              "...              ...     ...  \n",
              "199995   1155.157349  1994.0  \n",
              "199996   2616.096924  1998.0  \n",
              "199997   3347.891846  1995.0  \n",
              "199998   2141.631104  1998.0  \n",
              "199999    981.222534  1998.0  \n",
              "\n",
              "[200000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bba881af-e9d1-43a7-baf6-43c77d76519b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>day</th>\n",
              "      <th>td</th>\n",
              "      <th>month</th>\n",
              "      <th>tcode</th>\n",
              "      <th>amount</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>account_id</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>47.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>207.204376</td>\n",
              "      <td>3654.337646</td>\n",
              "      <td>1996.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>27719.798828</td>\n",
              "      <td>24746.908203</td>\n",
              "      <td>9017.931641</td>\n",
              "      <td>1998.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5047.853516</td>\n",
              "      <td>5409.837402</td>\n",
              "      <td>998.038513</td>\n",
              "      <td>1993.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4722.251953</td>\n",
              "      <td>-4722.953613</td>\n",
              "      <td>10788.117188</td>\n",
              "      <td>1998.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5461.159668</td>\n",
              "      <td>5630.391602</td>\n",
              "      <td>1857.147095</td>\n",
              "      <td>1997.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>47.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4216.837891</td>\n",
              "      <td>4183.875977</td>\n",
              "      <td>1155.157349</td>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>79.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>298.415802</td>\n",
              "      <td>-363.671906</td>\n",
              "      <td>2616.096924</td>\n",
              "      <td>1998.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>32.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>3347.891846</td>\n",
              "      <td>1995.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>28.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>2141.631104</td>\n",
              "      <td>1998.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>59.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1052.986450</td>\n",
              "      <td>-1076.399414</td>\n",
              "      <td>981.222534</td>\n",
              "      <td>1998.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bba881af-e9d1-43a7-baf6-43c77d76519b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bba881af-e9d1-43a7-baf6-43c77d76519b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bba881af-e9d1-43a7-baf6-43c77d76519b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ceccf6e3-5900-4943-a9ef-328c8725aa4b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ceccf6e3-5900-4943-a9ef-328c8725aa4b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ceccf6e3-5900-4943-a9ef-328c8725aa4b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_41733fa4-7e14-4a38-b6b5-ff25b05003d7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('samples_decoded')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_41733fa4-7e14-4a38-b6b5-ff25b05003d7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('samples_decoded');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "samples_decoded"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_decoded02=samples_decoded"
      ],
      "metadata": {
        "id": "y-Fy6m7JDCbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Round account_id to nearest int\n",
        "samples_decoded02['account_id'] = samples_decoded02['account_id'].round().astype(int)\n",
        "\n",
        "# Create a datetime column from year/month/day\n",
        "samples_decoded02['date'] = pd.to_datetime({\n",
        "    'year': samples_decoded02['year'].astype(int),\n",
        "    'month': samples_decoded02['month'].astype(int),\n",
        "    'day': samples_decoded02['day'].astype(int)\n",
        "}, errors='coerce')  # invalid dates become NaT\n"
      ],
      "metadata": {
        "id": "4FmAc9zKC6BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_decoded02 = samples_decoded02.sort_values(by=['account_id', 'date','tcode']).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "ypOammFcECu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_decoded02[\"date\"] = pd.to_datetime(samples_decoded02[\"date\"]).dt.date.astype(str)\n"
      ],
      "metadata": {
        "id": "PI_8nFZ-Mfyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = samples_decoded02[samples_decoded02.date=='NaT']\n",
        "synth=samples_decoded02[~samples_decoded02.date.isin(lst.date)]"
      ],
      "metadata": {
        "id": "PsUn04rrL50j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synth.date.values.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JBm6-IlM1tE",
        "outputId": "bafa7818-7473-4f94-9664-b884e9adc9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1994-01-05',\n",
              " '1994-11-15',\n",
              " '1995-10-31',\n",
              " '1996-11-13',\n",
              " '1997-01-25',\n",
              " '1997-03-11',\n",
              " '1997-03-15',\n",
              " '1997-10-11',\n",
              " '1998-01-27',\n",
              " '1998-04-30',\n",
              " '1998-10-12',\n",
              " '1998-11-29',\n",
              " '1998-12-13',\n",
              " '1993-10-31',\n",
              " '1994-05-02',\n",
              " '1994-06-10',\n",
              " '1994-06-30',\n",
              " '1994-10-06',\n",
              " '1995-06-30',\n",
              " '1995-09-12',\n",
              " '1995-09-30',\n",
              " '1995-12-08',\n",
              " '1996-01-10',\n",
              " '1996-01-11',\n",
              " '1996-03-08',\n",
              " '1996-04-08',\n",
              " '1996-09-10',\n",
              " '1997-01-08',\n",
              " '1997-02-05',\n",
              " '1997-04-06',\n",
              " '1997-04-13',\n",
              " '1997-04-27',\n",
              " '1997-05-18',\n",
              " '1997-05-21',\n",
              " '1997-06-02',\n",
              " '1997-07-31',\n",
              " '1997-09-02',\n",
              " '1997-09-06',\n",
              " '1997-11-13',\n",
              " '1997-11-15',\n",
              " '1997-12-11',\n",
              " '1997-12-11',\n",
              " '1998-01-31',\n",
              " '1998-03-29',\n",
              " '1998-05-13',\n",
              " '1998-06-12',\n",
              " '1998-06-22',\n",
              " '1998-07-26',\n",
              " '1993-01-05',\n",
              " '1993-11-05',\n",
              " '1994-02-28',\n",
              " '1994-03-10',\n",
              " '1994-09-24',\n",
              " '1994-09-30',\n",
              " '1994-10-13',\n",
              " '1994-11-05',\n",
              " '1995-02-20',\n",
              " '1995-06-20',\n",
              " '1995-10-07',\n",
              " '1996-03-31',\n",
              " '1996-06-02',\n",
              " '1996-07-31',\n",
              " '1996-09-09',\n",
              " '1996-11-05',\n",
              " '1996-11-08',\n",
              " '1997-01-02',\n",
              " '1997-01-06',\n",
              " '1997-01-08',\n",
              " '1997-01-08',\n",
              " '1997-03-01',\n",
              " '1997-08-13',\n",
              " '1997-08-19',\n",
              " '1997-10-05',\n",
              " '1997-10-10',\n",
              " '1997-12-11',\n",
              " '1997-12-15',\n",
              " '1997-12-31',\n",
              " '1998-01-24',\n",
              " '1998-03-31',\n",
              " '1998-04-30',\n",
              " '1998-08-14',\n",
              " '1998-09-07',\n",
              " '1998-09-30',\n",
              " '1998-11-13',\n",
              " '1998-11-16',\n",
              " '1998-12-04',\n",
              " '1994-10-05',\n",
              " '1994-12-25',\n",
              " '1994-12-31',\n",
              " '1995-01-08',\n",
              " '1995-03-13',\n",
              " '1996-01-31',\n",
              " '1996-04-06',\n",
              " '1996-09-30',\n",
              " '1996-10-31',\n",
              " '1996-11-30',\n",
              " '1996-12-10',\n",
              " '1997-07-31',\n",
              " '1997-08-08',\n",
              " '1997-08-18',\n",
              " '1998-01-27',\n",
              " '1998-04-08',\n",
              " '1998-05-14',\n",
              " '1998-08-02',\n",
              " '1998-08-10',\n",
              " '1998-09-02',\n",
              " '1994-02-13',\n",
              " '1994-04-09',\n",
              " '1994-04-11',\n",
              " '1994-05-13',\n",
              " '1994-06-17',\n",
              " '1994-12-04',\n",
              " '1995-05-05',\n",
              " '1995-05-07',\n",
              " '1995-07-07',\n",
              " '1995-10-10',\n",
              " '1996-05-31',\n",
              " '1996-08-20',\n",
              " '1996-09-30',\n",
              " '1996-10-01',\n",
              " '1996-12-10',\n",
              " '1996-12-10',\n",
              " '1997-01-09',\n",
              " '1997-06-10',\n",
              " '1997-06-30',\n",
              " '1997-07-31',\n",
              " '1997-08-02',\n",
              " '1997-08-31',\n",
              " '1997-09-10',\n",
              " '1997-10-12',\n",
              " '1997-10-31',\n",
              " '1997-11-24',\n",
              " '1997-12-12',\n",
              " '1998-01-05',\n",
              " '1998-01-11',\n",
              " '1998-01-31',\n",
              " '1998-02-09',\n",
              " '1998-02-10',\n",
              " '1998-03-07',\n",
              " '1998-06-30',\n",
              " '1998-09-15',\n",
              " '1998-11-14',\n",
              " '1993-01-31',\n",
              " '1993-06-10',\n",
              " '1994-01-28',\n",
              " '1994-02-02',\n",
              " '1994-02-25',\n",
              " '1994-06-10',\n",
              " '1994-07-17',\n",
              " '1994-08-18',\n",
              " '1994-11-05',\n",
              " '1994-12-25',\n",
              " '1995-03-31',\n",
              " '1995-08-25',\n",
              " '1995-12-22',\n",
              " '1996-01-31',\n",
              " '1996-02-05',\n",
              " '1996-03-31',\n",
              " '1996-05-31',\n",
              " '1996-06-08',\n",
              " '1996-07-31',\n",
              " '1996-09-19',\n",
              " '1996-10-07',\n",
              " '1997-01-05',\n",
              " '1997-07-31',\n",
              " '1997-07-31',\n",
              " '1997-09-30',\n",
              " '1997-09-30',\n",
              " '1997-12-01',\n",
              " '1998-01-12',\n",
              " '1998-01-21',\n",
              " '1998-01-31',\n",
              " '1998-04-08',\n",
              " '1998-06-05',\n",
              " '1998-06-27',\n",
              " '1998-10-08',\n",
              " '1998-11-11',\n",
              " '1993-12-14',\n",
              " '1994-02-10',\n",
              " '1994-03-14',\n",
              " '1994-08-19',\n",
              " '1994-11-26',\n",
              " '1994-12-09',\n",
              " '1995-04-30',\n",
              " '1995-12-31',\n",
              " '1996-01-21',\n",
              " '1996-02-02',\n",
              " '1996-03-06',\n",
              " '1996-08-02',\n",
              " '1996-11-14',\n",
              " '1997-01-31',\n",
              " '1997-02-12',\n",
              " '1997-04-06',\n",
              " '1997-09-30',\n",
              " '1997-11-30',\n",
              " '1998-01-12',\n",
              " '1998-01-29',\n",
              " '1998-01-31',\n",
              " '1998-02-13',\n",
              " '1998-03-31',\n",
              " '1998-04-06',\n",
              " '1998-05-03',\n",
              " '1998-07-31',\n",
              " '1998-08-31',\n",
              " '1998-09-12',\n",
              " '1998-10-02',\n",
              " '1998-10-31',\n",
              " '1998-11-30',\n",
              " '1998-11-30',\n",
              " '1998-11-30',\n",
              " '1993-02-06',\n",
              " '1994-01-28',\n",
              " '1994-04-08',\n",
              " '1994-05-08',\n",
              " '1994-09-12',\n",
              " '1994-10-12',\n",
              " '1994-10-27',\n",
              " '1994-11-02',\n",
              " '1994-12-13',\n",
              " '1995-01-19',\n",
              " '1995-01-31',\n",
              " '1995-03-06',\n",
              " '1995-03-17',\n",
              " '1995-04-25',\n",
              " '1995-05-12',\n",
              " '1995-05-13',\n",
              " '1995-07-31',\n",
              " '1995-09-05',\n",
              " '1996-03-05',\n",
              " '1996-04-30',\n",
              " '1996-05-05',\n",
              " '1996-09-18',\n",
              " '1996-10-31',\n",
              " '1996-12-31',\n",
              " '1997-01-10',\n",
              " '1997-01-16',\n",
              " '1997-01-25',\n",
              " '1997-01-28',\n",
              " '1997-02-24',\n",
              " '1997-02-25',\n",
              " '1997-02-28',\n",
              " '1997-03-18',\n",
              " '1997-06-30',\n",
              " '1997-06-30',\n",
              " '1997-07-06',\n",
              " '1997-07-31',\n",
              " '1997-07-31',\n",
              " '1997-08-05',\n",
              " '1997-08-31',\n",
              " '1997-09-30',\n",
              " '1997-10-11',\n",
              " '1997-10-14',\n",
              " '1997-12-05',\n",
              " '1997-12-31',\n",
              " '1997-12-31',\n",
              " '1998-01-02',\n",
              " '1998-01-08',\n",
              " '1998-01-11',\n",
              " '1998-01-14',\n",
              " '1998-04-05',\n",
              " '1998-05-09',\n",
              " '1998-06-04',\n",
              " '1998-06-10',\n",
              " '1998-07-31',\n",
              " '1998-08-12',\n",
              " '1998-08-13',\n",
              " '1998-08-31',\n",
              " '1998-09-30',\n",
              " '1998-11-13',\n",
              " '1998-12-11',\n",
              " '1998-12-15',\n",
              " '1993-07-30',\n",
              " '1994-04-06',\n",
              " '1994-06-02',\n",
              " '1994-08-31',\n",
              " '1994-08-31',\n",
              " '1994-09-05',\n",
              " '1994-09-30',\n",
              " '1994-10-06',\n",
              " '1994-10-18',\n",
              " '1994-10-29',\n",
              " '1994-10-31',\n",
              " '1994-11-18',\n",
              " '1994-12-28',\n",
              " '1995-01-31',\n",
              " '1995-02-15',\n",
              " '1995-05-10',\n",
              " '1995-06-07',\n",
              " '1995-07-24',\n",
              " '1996-01-31',\n",
              " '1996-01-31',\n",
              " '1996-03-14',\n",
              " '1996-03-31',\n",
              " '1996-05-08',\n",
              " '1996-05-13',\n",
              " '1996-08-31',\n",
              " '1996-09-01',\n",
              " '1996-09-27',\n",
              " '1997-01-02',\n",
              " '1997-01-12',\n",
              " '1997-01-15',\n",
              " '1997-01-23',\n",
              " '1997-02-10',\n",
              " '1997-03-31',\n",
              " '1997-04-14',\n",
              " '1997-05-31',\n",
              " '1997-06-30',\n",
              " '1997-07-10',\n",
              " '1997-07-31',\n",
              " '1997-08-16',\n",
              " '1997-08-30',\n",
              " '1997-08-31',\n",
              " '1997-09-07',\n",
              " '1997-09-25',\n",
              " '1997-11-06',\n",
              " '1997-11-09',\n",
              " '1997-11-10',\n",
              " '1997-12-07',\n",
              " '1997-12-10',\n",
              " '1997-12-22',\n",
              " '1998-01-12',\n",
              " '1998-01-13',\n",
              " '1998-02-05',\n",
              " '1998-02-14',\n",
              " '1998-03-10',\n",
              " '1998-03-17',\n",
              " '1998-04-10',\n",
              " '1998-04-10',\n",
              " '1998-04-12',\n",
              " '1998-04-18',\n",
              " '1998-04-23',\n",
              " '1998-05-02',\n",
              " '1998-05-09',\n",
              " '1998-05-24',\n",
              " '1998-05-31',\n",
              " '1998-06-10',\n",
              " '1998-06-14',\n",
              " '1998-06-26',\n",
              " '1998-07-31',\n",
              " '1998-09-05',\n",
              " '1998-09-09',\n",
              " '1998-09-17',\n",
              " '1998-09-18',\n",
              " '1998-10-11',\n",
              " '1998-11-30',\n",
              " '1998-11-30',\n",
              " '1998-11-30',\n",
              " '1998-12-09',\n",
              " '1993-09-30',\n",
              " '1994-04-30',\n",
              " '1994-10-06',\n",
              " '1994-10-20',\n",
              " '1994-10-27',\n",
              " '1994-11-28',\n",
              " '1994-12-24',\n",
              " '1995-05-13',\n",
              " '1995-06-12',\n",
              " '1995-07-04',\n",
              " '1995-09-30',\n",
              " '1996-02-29',\n",
              " '1996-03-08',\n",
              " '1996-03-09',\n",
              " '1996-03-14',\n",
              " '1996-04-18',\n",
              " '1996-04-30',\n",
              " '1996-05-13',\n",
              " '1996-05-31',\n",
              " '1996-07-12',\n",
              " '1996-08-31',\n",
              " '1996-09-14',\n",
              " '1996-10-16',\n",
              " '1996-10-31',\n",
              " '1996-11-30',\n",
              " '1996-12-31',\n",
              " '1997-01-07',\n",
              " '1997-01-20',\n",
              " '1997-01-24',\n",
              " '1997-01-31',\n",
              " '1997-02-06',\n",
              " '1997-02-09',\n",
              " '1997-03-31',\n",
              " '1997-04-30',\n",
              " '1997-05-13',\n",
              " '1997-05-23',\n",
              " '1997-05-28',\n",
              " '1997-06-25',\n",
              " '1997-06-30',\n",
              " '1997-07-17',\n",
              " '1997-09-25',\n",
              " '1997-10-05',\n",
              " '1997-10-12',\n",
              " '1997-10-16',\n",
              " '1997-10-30',\n",
              " '1997-10-31',\n",
              " '1997-11-04',\n",
              " '1997-11-30',\n",
              " '1998-01-10',\n",
              " '1998-02-26',\n",
              " '1998-03-10',\n",
              " '1998-04-30',\n",
              " '1998-05-31',\n",
              " '1998-05-31',\n",
              " '1998-06-30',\n",
              " '1998-07-09',\n",
              " '1998-07-31',\n",
              " '1998-08-17',\n",
              " '1998-09-10',\n",
              " '1998-10-11',\n",
              " '1998-11-13',\n",
              " '1998-11-27',\n",
              " '1998-12-16',\n",
              " '1993-08-20',\n",
              " '1993-11-12',\n",
              " '1994-04-06',\n",
              " '1994-04-25',\n",
              " '1994-10-01',\n",
              " '1994-10-12',\n",
              " '1994-11-30',\n",
              " '1995-01-05',\n",
              " '1995-01-12',\n",
              " '1995-01-27',\n",
              " '1995-01-31',\n",
              " '1995-02-10',\n",
              " '1995-04-01',\n",
              " '1995-04-20',\n",
              " '1995-12-31',\n",
              " '1995-12-31',\n",
              " '1996-02-09',\n",
              " '1996-02-27',\n",
              " '1996-04-06',\n",
              " '1996-05-20',\n",
              " '1996-07-15',\n",
              " '1996-08-25',\n",
              " '1996-08-31',\n",
              " '1996-10-05',\n",
              " '1996-12-05',\n",
              " '1996-12-10',\n",
              " '1996-12-31',\n",
              " '1997-01-12',\n",
              " '1997-01-13',\n",
              " '1997-01-27',\n",
              " '1997-01-28',\n",
              " '1997-01-31',\n",
              " '1997-02-05',\n",
              " '1997-02-15',\n",
              " '1997-04-30',\n",
              " '1997-06-05',\n",
              " '1997-08-08',\n",
              " '1997-08-11',\n",
              " '1997-10-31',\n",
              " '1997-12-31',\n",
              " '1998-01-28',\n",
              " '1998-02-07',\n",
              " '1998-02-10',\n",
              " '1998-02-28',\n",
              " '1998-03-10',\n",
              " '1998-04-08',\n",
              " '1998-04-30',\n",
              " '1998-05-31',\n",
              " '1998-06-14',\n",
              " '1998-07-23',\n",
              " '1998-07-31',\n",
              " '1998-08-12',\n",
              " '1998-08-13',\n",
              " '1998-08-28',\n",
              " '1998-09-30',\n",
              " '1998-10-06',\n",
              " '1998-10-10',\n",
              " '1998-10-28',\n",
              " '1998-10-31',\n",
              " '1998-11-30',\n",
              " '1998-12-02',\n",
              " '1998-12-05',\n",
              " '1993-11-26',\n",
              " '1994-01-02',\n",
              " '1994-05-11',\n",
              " '1994-05-11',\n",
              " '1994-05-31',\n",
              " '1994-06-14',\n",
              " '1994-07-31',\n",
              " '1994-09-05',\n",
              " '1994-10-09',\n",
              " '1994-11-25',\n",
              " '1995-01-06',\n",
              " '1995-05-09',\n",
              " '1995-06-30',\n",
              " '1995-07-31',\n",
              " '1995-10-14',\n",
              " '1996-05-24',\n",
              " '1996-05-31',\n",
              " '1996-06-30',\n",
              " '1996-10-20',\n",
              " '1996-12-03',\n",
              " '1996-12-10',\n",
              " '1997-01-10',\n",
              " '1997-02-14',\n",
              " '1997-03-08',\n",
              " '1997-03-13',\n",
              " '1997-04-03',\n",
              " '1997-04-10',\n",
              " '1997-04-29',\n",
              " '1997-05-31',\n",
              " '1997-06-05',\n",
              " '1997-06-05',\n",
              " '1997-06-09',\n",
              " '1997-06-26',\n",
              " '1997-08-08',\n",
              " '1997-08-09',\n",
              " '1997-09-09',\n",
              " '1997-09-11',\n",
              " '1997-10-16',\n",
              " '1997-10-31',\n",
              " '1997-12-12',\n",
              " '1997-12-12',\n",
              " '1998-01-11',\n",
              " '1998-01-31',\n",
              " '1998-04-07',\n",
              " '1998-05-12',\n",
              " '1998-05-31',\n",
              " '1998-05-31',\n",
              " '1998-06-05',\n",
              " '1998-06-08',\n",
              " '1998-06-08',\n",
              " '1998-06-21',\n",
              " '1998-08-08',\n",
              " '1998-09-05',\n",
              " '1998-09-30',\n",
              " '1998-10-06',\n",
              " '1998-11-05',\n",
              " '1998-11-06',\n",
              " '1998-11-14',\n",
              " '1993-07-20',\n",
              " '1994-01-31',\n",
              " '1994-03-11',\n",
              " '1994-05-31',\n",
              " '1994-06-18',\n",
              " '1994-08-31',\n",
              " '1994-09-12',\n",
              " '1994-10-10',\n",
              " '1994-11-30',\n",
              " '1995-01-31',\n",
              " '1995-05-31',\n",
              " '1995-07-12',\n",
              " '1995-08-31',\n",
              " '1995-10-08',\n",
              " '1996-01-09',\n",
              " '1996-02-29',\n",
              " '1996-03-08',\n",
              " '1996-04-10',\n",
              " '1996-05-30',\n",
              " '1996-08-24',\n",
              " '1996-09-13',\n",
              " '1996-11-30',\n",
              " '1997-01-05',\n",
              " '1997-01-08',\n",
              " '1997-01-08',\n",
              " '1997-01-15',\n",
              " '1997-01-28',\n",
              " '1997-02-28',\n",
              " '1997-03-13',\n",
              " '1997-03-15',\n",
              " '1997-06-30',\n",
              " '1997-08-14',\n",
              " '1997-10-11',\n",
              " '1997-10-27',\n",
              " '1997-11-30',\n",
              " '1998-01-05',\n",
              " '1998-02-08',\n",
              " '1998-04-13',\n",
              " '1998-04-30',\n",
              " '1998-05-09',\n",
              " '1998-06-08',\n",
              " '1998-06-23',\n",
              " '1998-07-18',\n",
              " '1998-08-03',\n",
              " '1998-08-21',\n",
              " '1998-09-06',\n",
              " '1998-11-18',\n",
              " '1998-12-14',\n",
              " '1993-07-25',\n",
              " '1993-11-09',\n",
              " '1993-12-25',\n",
              " '1994-01-28',\n",
              " '1994-03-31',\n",
              " '1994-04-30',\n",
              " '1994-07-07',\n",
              " '1994-07-31',\n",
              " '1994-10-31',\n",
              " '1994-12-31',\n",
              " '1995-03-23',\n",
              " '1995-05-18',\n",
              " '1995-05-31',\n",
              " '1995-05-31',\n",
              " '1995-12-23',\n",
              " '1996-03-05',\n",
              " '1996-04-30',\n",
              " '1996-07-09',\n",
              " '1996-08-10',\n",
              " '1996-11-30',\n",
              " '1996-12-09',\n",
              " '1997-01-11',\n",
              " '1997-01-13',\n",
              " '1997-02-13',\n",
              " '1997-03-07',\n",
              " '1997-03-31',\n",
              " '1997-04-11',\n",
              " '1997-06-08',\n",
              " '1997-06-30',\n",
              " '1997-06-30',\n",
              " '1997-08-07',\n",
              " '1997-08-14',\n",
              " '1997-09-19',\n",
              " '1997-09-26',\n",
              " '1997-09-28',\n",
              " '1997-09-30',\n",
              " '1997-10-23',\n",
              " '1997-10-25',\n",
              " '1997-11-30',\n",
              " '1997-11-30',\n",
              " '1997-11-30',\n",
              " '1998-01-08',\n",
              " '1998-01-18',\n",
              " '1998-01-20',\n",
              " '1998-02-28',\n",
              " '1998-03-02',\n",
              " '1998-03-25',\n",
              " '1998-03-31',\n",
              " '1998-03-31',\n",
              " '1998-05-13',\n",
              " '1998-06-06',\n",
              " '1998-06-07',\n",
              " '1998-07-28',\n",
              " '1998-09-10',\n",
              " '1998-11-30',\n",
              " '1998-11-30',\n",
              " '1998-12-31',\n",
              " '1993-09-09',\n",
              " '1993-11-11',\n",
              " '1994-03-10',\n",
              " '1994-12-22',\n",
              " '1995-01-05',\n",
              " '1995-04-25',\n",
              " '1995-04-30',\n",
              " '1995-10-05',\n",
              " '1995-11-05',\n",
              " '1996-01-02',\n",
              " '1996-01-27',\n",
              " '1996-03-07',\n",
              " '1996-06-04',\n",
              " '1996-07-05',\n",
              " '1996-08-08',\n",
              " '1996-08-31',\n",
              " '1996-09-24',\n",
              " '1996-10-15',\n",
              " '1996-11-05',\n",
              " '1996-11-12',\n",
              " '1996-12-10',\n",
              " '1997-01-03',\n",
              " '1997-01-06',\n",
              " '1997-01-22',\n",
              " '1997-03-09',\n",
              " '1997-05-11',\n",
              " '1997-06-30',\n",
              " '1997-09-13',\n",
              " '1997-09-23',\n",
              " '1997-10-08',\n",
              " '1997-10-14',\n",
              " '1997-10-31',\n",
              " '1997-11-13',\n",
              " '1997-12-10',\n",
              " '1997-12-25',\n",
              " '1997-12-31',\n",
              " '1998-01-30',\n",
              " '1998-02-28',\n",
              " '1998-03-05',\n",
              " '1998-03-31',\n",
              " '1998-04-11',\n",
              " '1998-04-30',\n",
              " '1998-06-04',\n",
              " '1998-09-13',\n",
              " '1998-09-30',\n",
              " '1998-09-30',\n",
              " '1998-10-31',\n",
              " '1998-11-12',\n",
              " '1998-12-08',\n",
              " '1993-10-06',\n",
              " '1993-12-09',\n",
              " '1994-06-08',\n",
              " '1994-07-06',\n",
              " '1994-08-31',\n",
              " '1994-09-27',\n",
              " '1995-01-15',\n",
              " '1995-03-22',\n",
              " '1996-04-30',\n",
              " '1996-06-13',\n",
              " '1996-08-31',\n",
              " '1996-08-31',\n",
              " '1996-09-30',\n",
              " '1996-10-01',\n",
              " '1996-10-13',\n",
              " '1997-01-04',\n",
              " '1997-01-14',\n",
              " '1997-01-27',\n",
              " '1997-04-30',\n",
              " '1997-04-30',\n",
              " '1997-06-18',\n",
              " '1997-12-23',\n",
              " '1998-04-11',\n",
              " '1998-05-31',\n",
              " '1998-06-10',\n",
              " '1998-07-08',\n",
              " '1998-08-09',\n",
              " '1998-11-08',\n",
              " '1998-12-07',\n",
              " '1998-12-08',\n",
              " '1993-04-08',\n",
              " '1993-11-04',\n",
              " '1994-08-25',\n",
              " '1994-09-30',\n",
              " '1995-01-13',\n",
              " '1995-03-11',\n",
              " '1995-11-08',\n",
              " '1995-11-12',\n",
              " '1996-02-11',\n",
              " '1996-02-13',\n",
              " '1996-04-30',\n",
              " '1996-06-25',\n",
              " '1996-07-31',\n",
              " '1996-09-30',\n",
              " '1996-12-08',\n",
              " '1996-12-11',\n",
              " '1997-02-28',\n",
              " '1997-03-31',\n",
              " '1997-04-08',\n",
              " '1997-04-30',\n",
              " '1997-08-30',\n",
              " '1997-08-31',\n",
              " '1997-09-30',\n",
              " '1997-10-03',\n",
              " '1997-10-08',\n",
              " '1997-12-05',\n",
              " '1997-12-08',\n",
              " '1998-02-13',\n",
              " '1998-02-13',\n",
              " '1998-05-31',\n",
              " '1998-07-12',\n",
              " '1998-07-12',\n",
              " '1998-07-30',\n",
              " '1994-02-23',\n",
              " '1994-07-10',\n",
              " '1994-08-05',\n",
              " '1994-09-30',\n",
              " '1995-01-14',\n",
              " '1995-06-26',\n",
              " '1995-08-31',\n",
              " '1995-12-05',\n",
              " '1996-01-31',\n",
              " '1996-03-08',\n",
              " '1996-03-13',\n",
              " '1996-05-20',\n",
              " '1996-07-12',\n",
              " '1996-08-01',\n",
              " '1996-08-30',\n",
              " '1996-09-10',\n",
              " '1996-09-30',\n",
              " '1996-12-31',\n",
              " '1997-01-16',\n",
              " '1997-04-05',\n",
              " '1997-06-08',\n",
              " '1997-09-10',\n",
              " '1997-09-14',\n",
              " '1997-10-10',\n",
              " '1997-11-07',\n",
              " '1997-12-30',\n",
              " '1998-01-02',\n",
              " '1998-01-21',\n",
              " '1998-01-31',\n",
              " '1998-03-11',\n",
              " '1998-07-31',\n",
              " '1998-08-31',\n",
              " '1998-10-11',\n",
              " '1998-10-30',\n",
              " '1998-12-06',\n",
              " '1998-12-12',\n",
              " '1994-01-13',\n",
              " '1994-01-25',\n",
              " '1994-03-16',\n",
              " '1994-06-12',\n",
              " '1994-07-05',\n",
              " '1994-11-30',\n",
              " '1995-01-09',\n",
              " '1995-01-10',\n",
              " '1995-01-15',\n",
              " '1995-06-14',\n",
              " '1995-11-12',\n",
              " '1996-01-31',\n",
              " '1996-08-05',\n",
              " '1996-09-10',\n",
              " '1996-09-14',\n",
              " '1996-10-31',\n",
              " '1997-01-05',\n",
              " '1997-01-10',\n",
              " '1997-01-24',\n",
              " '1997-03-30',\n",
              " '1997-04-08',\n",
              " '1997-05-02',\n",
              " '1997-06-22',\n",
              " '1997-08-11',\n",
              " '1998-01-31',\n",
              " '1998-03-09',\n",
              " '1998-04-14',\n",
              " '1998-05-31',\n",
              " '1998-06-05',\n",
              " '1998-10-10',\n",
              " '1998-10-12',\n",
              " '1993-06-06',\n",
              " '1994-01-20',\n",
              " '1994-02-13',\n",
              " '1994-05-31',\n",
              " '1994-10-05',\n",
              " '1994-10-14',\n",
              " '1995-02-08',\n",
              " '1995-02-11',\n",
              " '1995-02-16',\n",
              " '1995-03-30',\n",
              " '1995-12-15',\n",
              " '1996-01-31',\n",
              " '1996-06-03',\n",
              " '1996-07-16',\n",
              " '1996-10-10',\n",
              " '1996-11-08',\n",
              " '1997-01-14',\n",
              " '1997-01-26',\n",
              " '1997-07-20',\n",
              " '1997-10-31',\n",
              " '1997-12-08',\n",
              " '1997-12-31',\n",
              " '1998-01-13',\n",
              " '1998-01-30',\n",
              " '1998-01-31',\n",
              " '1998-01-31',\n",
              " '1998-05-05',\n",
              " '1998-06-30',\n",
              " '1998-09-30',\n",
              " '1998-10-08',\n",
              " '1998-11-24',\n",
              " '1994-08-08',\n",
              " '1995-02-06',\n",
              " '1995-03-31',\n",
              " '1995-06-01',\n",
              " '1995-11-30',\n",
              " '1996-04-25',\n",
              " '1996-05-13',\n",
              " '1996-05-31',\n",
              " '1996-09-11',\n",
              " '1997-03-20',\n",
              " '1997-05-11',\n",
              " '1997-05-31',\n",
              " '1997-06-30',\n",
              " '1997-08-06',\n",
              " '1997-08-12',\n",
              " '1997-09-10',\n",
              " '1997-09-12',\n",
              " '1997-09-28',\n",
              " '1997-10-08',\n",
              " '1998-05-31',\n",
              " '1998-07-31',\n",
              " '1998-07-31',\n",
              " '1998-10-31',\n",
              " '1994-02-05',\n",
              " '1994-03-31',\n",
              " '1994-04-24',\n",
              " '1994-09-02',\n",
              " '1994-11-12',\n",
              " '1994-12-05',\n",
              " '1994-12-31',\n",
              " '1995-03-31',\n",
              " '1995-04-30',\n",
              " '1995-05-26',\n",
              " '1995-06-14',\n",
              " '1995-06-30',\n",
              " '1995-09-08',\n",
              " '1995-11-30',\n",
              " '1996-03-06',\n",
              " '1996-05-31',\n",
              " '1996-07-29',\n",
              " '1996-08-10',\n",
              " '1996-10-05',\n",
              " '1996-10-22',\n",
              " '1996-11-30',\n",
              " '1996-11-30',\n",
              " '1997-01-02',\n",
              " '1997-03-25',\n",
              " '1997-04-13',\n",
              " '1997-06-30',\n",
              " '1997-08-31',\n",
              " '1997-10-30',\n",
              " '1997-10-31',\n",
              " '1997-12-11',\n",
              " '1997-12-12',\n",
              " '1997-12-20',\n",
              " '1998-01-05',\n",
              " '1998-01-10',\n",
              " '1998-02-09',\n",
              " '1998-02-28',\n",
              " '1998-04-02',\n",
              " '1998-05-16',\n",
              " '1998-05-31',\n",
              " '1998-06-05',\n",
              " '1998-06-08',\n",
              " '1998-07-31',\n",
              " '1998-09-05',\n",
              " '1998-09-06',\n",
              " '1998-11-08',\n",
              " '1998-11-30',\n",
              " '1993-12-14',\n",
              " '1994-01-16',\n",
              " '1994-02-05',\n",
              " '1994-07-09',\n",
              " '1994-08-31',\n",
              " '1994-09-12',\n",
              " '1994-09-13',\n",
              " '1994-10-06',\n",
              " '1994-11-30',\n",
              " '1994-12-15',\n",
              " '1995-03-31',\n",
              " '1995-04-10',\n",
              " '1995-05-02',\n",
              " '1995-05-13',\n",
              " '1995-08-05',\n",
              " '1995-11-30',\n",
              " '1996-02-13',\n",
              " '1996-02-28',\n",
              " '1996-05-31',\n",
              " '1996-07-31',\n",
              " '1996-08-08',\n",
              " '1996-10-31',\n",
              " '1996-12-31',\n",
              " '1997-01-11',\n",
              " '1997-01-16',\n",
              " '1997-03-04',\n",
              " '1997-03-14',\n",
              " '1997-04-30',\n",
              " '1997-06-02',\n",
              " '1997-06-13',\n",
              " '1997-06-18',\n",
              " '1997-07-31',\n",
              " '1997-07-31',\n",
              " '1997-08-31',\n",
              " '1997-08-31',\n",
              " '1997-09-15',\n",
              " '1997-10-08',\n",
              " '1997-10-14',\n",
              " '1997-10-28',\n",
              " '1997-11-07',\n",
              " '1997-11-26',\n",
              " '1997-12-05',\n",
              " '1997-12-05',\n",
              " '1998-01-09',\n",
              " '1998-03-31',\n",
              " '1998-04-10',\n",
              " '1998-04-30',\n",
              " '1998-06-30',\n",
              " '1998-08-08',\n",
              " '1998-09-30',\n",
              " '1998-09-30',\n",
              " '1998-11-08',\n",
              " '1998-12-01',\n",
              " '1998-12-31',\n",
              " '1993-05-31',\n",
              " '1993-09-22',\n",
              " '1993-09-30',\n",
              " '1994-05-17',\n",
              " '1994-05-31',\n",
              " '1994-06-08',\n",
              " '1994-06-14',\n",
              " '1994-08-15',\n",
              " '1994-10-28',\n",
              " '1994-11-25',\n",
              " '1994-12-08',\n",
              " '1994-12-31',\n",
              " '1995-04-01',\n",
              " '1995-04-30',\n",
              " '1995-08-05',\n",
              " '1995-08-14',\n",
              " '1995-11-12',\n",
              " '1995-11-13',\n",
              " '1996-05-10',\n",
              " '1996-07-06',\n",
              " '1996-07-26',\n",
              " '1996-08-06',\n",
              " '1996-09-06',\n",
              " '1996-10-11',\n",
              " '1996-10-16',\n",
              " '1997-02-13',\n",
              " '1997-02-26',\n",
              " '1997-02-28',\n",
              " '1997-07-03',\n",
              " '1997-07-13',\n",
              " '1997-08-10',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_tcodes = np.array([\n",
        "    'CREDIT__CREDIT IN CASH__nan',\n",
        "    'CREDIT__COLLECTION FROM ANOTHER BANK__nan',\n",
        "    'CREDIT__nan__INTEREST CREDITED',\n",
        "    'DEBIT__CASH WITHDRAWAL__nan',\n",
        "    'DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT',\n",
        "    'DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD',\n",
        "    'DEBIT__REMITTANCE TO ANOTHER BANK__LOAN PAYMENT',\n",
        "    'DEBIT__REMITTANCE TO ANOTHER BANK__ ',\n",
        "    'DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE PAYMENT',\n",
        "    'CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE PENSION',\n",
        "    'DEBIT__CREDIT CARD WITHDRAWAL__nan',\n",
        "    'DEBIT__REMITTANCE TO ANOTHER BANK__nan',\n",
        "    'DEBIT__CASH WITHDRAWAL__HOUSEHOLD',\n",
        "    'DEBIT__CASH WITHDRAWAL__SANCTION INTEREST',\n",
        "    'DEBIT__CASH WITHDRAWAL__ ',\n",
        "    'DEBIT__CASH WITHDRAWAL__INSURANCE PAYMENT'\n",
        "])\n",
        "samples_decoded02['tcode'] = samples_decoded02['tcode'].apply(lambda x: original_tcodes[int(x)])\n",
        "\n",
        "# samples_decoded02['tcode_str'] = label_encoder.inverse_transform(samples_decoded02['tcode'])\n"
      ],
      "metadata": {
        "id": "fRqZDaI_W5D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synth.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS2mfndhNj2e",
        "outputId": "b4fc48f2-6085-4ab4-cc5f-48d1b3114088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 197691 entries, 0 to 199999\n",
            "Data columns (total 11 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   age         197691 non-null  float64\n",
            " 1   day         197691 non-null  float64\n",
            " 2   td          197691 non-null  float64\n",
            " 3   month       197691 non-null  float64\n",
            " 4   tcode       197691 non-null  object \n",
            " 5   amount      197691 non-null  float32\n",
            " 6   raw_amount  197691 non-null  float32\n",
            " 7   account_id  197691 non-null  int64  \n",
            " 8   year        197691 non-null  float32\n",
            " 9   date        197691 non-null  object \n",
            " 10  tcode_str   197691 non-null  object \n",
            "dtypes: float32(3), float64(4), int64(1), object(3)\n",
            "memory usage: 15.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "QeGHSUa0RPrg",
        "outputId": "f94a6bba-3e9b-4a4f-d10a-a43b183f34d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         age   day    td  month  \\\n",
              "0       55.0   5.0   5.0    1.0   \n",
              "1       67.0  15.0  15.0   11.0   \n",
              "2       79.0  31.0   0.0   10.0   \n",
              "3       70.0  13.0   0.0   11.0   \n",
              "4       20.0  25.0   3.0    1.0   \n",
              "...      ...   ...   ...    ...   \n",
              "199995  48.0  30.0  58.0    9.0   \n",
              "199996  46.0  16.0   2.0   12.0   \n",
              "199997  35.0  11.0   2.0   10.0   \n",
              "199998  55.0  31.0   2.0    8.0   \n",
              "199999  76.0  31.0   0.0    1.0   \n",
              "\n",
              "                                                    tcode        amount  \\\n",
              "0                          CREDIT__nan__INTEREST CREDITED  14228.897461   \n",
              "1       CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...   3931.709717   \n",
              "2                    DEBIT__REMITTANCE TO ANOTHER BANK__      14.600000   \n",
              "3                       DEBIT__CASH WITHDRAWAL__HOUSEHOLD    131.345657   \n",
              "4                  DEBIT__REMITTANCE TO ANOTHER BANK__nan    195.329590   \n",
              "...                                                   ...           ...   \n",
              "199995  CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...  19064.570312   \n",
              "199996  CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...  22912.185547   \n",
              "199997                  DEBIT__CASH WITHDRAWAL__HOUSEHOLD  11977.993164   \n",
              "199998               DEBIT__REMITTANCE TO ANOTHER BANK__      14.600000   \n",
              "199999               DEBIT__REMITTANCE TO ANOTHER BANK__      14.600000   \n",
              "\n",
              "          raw_amount  account_id    year        date  \\\n",
              "0       14573.928711           1  1994.0  1994-01-05   \n",
              "1       -3810.031250           1  1994.0  1994-11-15   \n",
              "2         -14.600000           1  1995.0  1995-10-31   \n",
              "3        -100.000000           1  1996.0  1996-11-13   \n",
              "4        -277.246155           1  1997.0  1997-01-25   \n",
              "...              ...         ...     ...         ...   \n",
              "199995 -19184.113281       11381  1997.0  1997-09-30   \n",
              "199996 -23233.933594       11381  1997.0  1997-12-16   \n",
              "199997 -12072.161133       11381  1998.0  1998-10-11   \n",
              "199998    -14.600000       11382  1996.0  1996-08-31   \n",
              "199999    -14.600000       11382  1998.0  1998-01-31   \n",
              "\n",
              "                                                tcode_str  \n",
              "0                          CREDIT__nan__INTEREST CREDITED  \n",
              "1       CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...  \n",
              "2                    DEBIT__REMITTANCE TO ANOTHER BANK__   \n",
              "3                       DEBIT__CASH WITHDRAWAL__HOUSEHOLD  \n",
              "4                  DEBIT__REMITTANCE TO ANOTHER BANK__nan  \n",
              "...                                                   ...  \n",
              "199995  CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...  \n",
              "199996  CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...  \n",
              "199997                  DEBIT__CASH WITHDRAWAL__HOUSEHOLD  \n",
              "199998               DEBIT__REMITTANCE TO ANOTHER BANK__   \n",
              "199999               DEBIT__REMITTANCE TO ANOTHER BANK__   \n",
              "\n",
              "[197691 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c94db33-6826-46b3-91fb-fe40fc161752\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>day</th>\n",
              "      <th>td</th>\n",
              "      <th>month</th>\n",
              "      <th>tcode</th>\n",
              "      <th>amount</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>account_id</th>\n",
              "      <th>year</th>\n",
              "      <th>date</th>\n",
              "      <th>tcode_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>14228.897461</td>\n",
              "      <td>14573.928711</td>\n",
              "      <td>1</td>\n",
              "      <td>1994.0</td>\n",
              "      <td>1994-01-05</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>3931.709717</td>\n",
              "      <td>-3810.031250</td>\n",
              "      <td>1</td>\n",
              "      <td>1994.0</td>\n",
              "      <td>1994-11-15</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>79.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>1</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>1995-10-31</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__HOUSEHOLD</td>\n",
              "      <td>131.345657</td>\n",
              "      <td>-100.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>1996-11-13</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__HOUSEHOLD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__nan</td>\n",
              "      <td>195.329590</td>\n",
              "      <td>-277.246155</td>\n",
              "      <td>1</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>1997-01-25</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>48.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>19064.570312</td>\n",
              "      <td>-19184.113281</td>\n",
              "      <td>11381</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>1997-09-30</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>46.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>22912.185547</td>\n",
              "      <td>-23233.933594</td>\n",
              "      <td>11381</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>1997-12-16</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>35.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__HOUSEHOLD</td>\n",
              "      <td>11977.993164</td>\n",
              "      <td>-12072.161133</td>\n",
              "      <td>11381</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>1998-10-11</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__HOUSEHOLD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>55.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>11382</td>\n",
              "      <td>1996.0</td>\n",
              "      <td>1996-08-31</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>76.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>11382</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>1998-01-31</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197691 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c94db33-6826-46b3-91fb-fe40fc161752')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c94db33-6826-46b3-91fb-fe40fc161752 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c94db33-6826-46b3-91fb-fe40fc161752');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-393e40db-e7a3-401e-be4b-71800bf7b6c9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-393e40db-e7a3-401e-be4b-71800bf7b6c9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-393e40db-e7a3-401e-be4b-71800bf7b6c9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_49760d22-210e-4ebc-9191-3b6569b90f33\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('synth')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_49760d22-210e-4ebc-9191-3b6569b90f33 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('synth');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "synth"
            }
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synth.to_csv('lstm_generated.csv')"
      ],
      "metadata": {
        "id": "05ZJyRYLXLcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "synth = synth\n",
        "czech_date_parser = lambda x: datetime.strptime(str(x), \"%Y-%m-%d\")\n",
        "synth[\"datetime\"] = synth[\"date\"].apply(czech_date_parser)\n",
        "synth[\"month\"] = synth[\"datetime\"].dt.month\n",
        "synth[\"day\"] = synth[\"datetime\"].dt.day\n",
        "synth[\"dow\"] =  synth[\"datetime\"].dt.dayofweek\n",
        "synth[\"year\"] = synth[\"datetime\"].dt.year\n",
        "\n",
        "# synth.rename(columns={'days_passed': 'td'}, inplace=True)\n",
        "synth['type'] = synth['tcode_str'].str.split('__').str[0]\n",
        "synth['raw_amount'] = synth.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "synth_sorted = synth.sort_values(['account_id', 'year', 'month', 'day'])\n",
        "\n",
        "synth_cf = synth[[\"account_id\", \"month\", \"raw_amount\", \"year\"]].groupby([\"account_id\", \"month\", \"year\"],as_index=False)[\"raw_amount\"].sum()"
      ],
      "metadata": {
        "id": "5rQm5L5qLLB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synth_sorted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "1TTq8KHzNo_R",
        "outputId": "658b1099-6f3d-4a83-d143-59de35bb41f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         age  day    td  month  \\\n",
              "0       55.0    5   5.0      1   \n",
              "1       67.0   15  15.0     11   \n",
              "2       79.0   31   0.0     10   \n",
              "3       70.0   13   0.0     11   \n",
              "4       20.0   25   3.0      1   \n",
              "...      ...  ...   ...    ...   \n",
              "199995  48.0   30  58.0      9   \n",
              "199996  46.0   16   2.0     12   \n",
              "199997  35.0   11   2.0     10   \n",
              "199998  55.0   31   2.0      8   \n",
              "199999  76.0   31   0.0      1   \n",
              "\n",
              "                                                    tcode        amount  \\\n",
              "0                          CREDIT__nan__INTEREST CREDITED  14228.897461   \n",
              "1       CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...   3931.709717   \n",
              "2                    DEBIT__REMITTANCE TO ANOTHER BANK__      14.600000   \n",
              "3                       DEBIT__CASH WITHDRAWAL__HOUSEHOLD    131.345657   \n",
              "4                  DEBIT__REMITTANCE TO ANOTHER BANK__nan    195.329590   \n",
              "...                                                   ...           ...   \n",
              "199995  CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...  19064.570312   \n",
              "199996  CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...  22912.185547   \n",
              "199997                  DEBIT__CASH WITHDRAWAL__HOUSEHOLD  11977.993164   \n",
              "199998               DEBIT__REMITTANCE TO ANOTHER BANK__      14.600000   \n",
              "199999               DEBIT__REMITTANCE TO ANOTHER BANK__      14.600000   \n",
              "\n",
              "          raw_amount  account_id  year        date  \\\n",
              "0       14228.897461           1  1994  1994-01-05   \n",
              "1        3931.709717           1  1994  1994-11-15   \n",
              "2         -14.600000           1  1995  1995-10-31   \n",
              "3        -131.345657           1  1996  1996-11-13   \n",
              "4        -195.329590           1  1997  1997-01-25   \n",
              "...              ...         ...   ...         ...   \n",
              "199995  19064.570312       11381  1997  1997-09-30   \n",
              "199996  22912.185547       11381  1997  1997-12-16   \n",
              "199997 -11977.993164       11381  1998  1998-10-11   \n",
              "199998    -14.600000       11382  1996  1996-08-31   \n",
              "199999    -14.600000       11382  1998  1998-01-31   \n",
              "\n",
              "                                                tcode_str   datetime  dow  \\\n",
              "0                          CREDIT__nan__INTEREST CREDITED 1994-01-05    2   \n",
              "1       CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ... 1994-11-15    1   \n",
              "2                    DEBIT__REMITTANCE TO ANOTHER BANK__  1995-10-31    1   \n",
              "3                       DEBIT__CASH WITHDRAWAL__HOUSEHOLD 1996-11-13    2   \n",
              "4                  DEBIT__REMITTANCE TO ANOTHER BANK__nan 1997-01-25    5   \n",
              "...                                                   ...        ...  ...   \n",
              "199995  CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ... 1997-09-30    1   \n",
              "199996  CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ... 1997-12-16    1   \n",
              "199997                  DEBIT__CASH WITHDRAWAL__HOUSEHOLD 1998-10-11    6   \n",
              "199998               DEBIT__REMITTANCE TO ANOTHER BANK__  1996-08-31    5   \n",
              "199999               DEBIT__REMITTANCE TO ANOTHER BANK__  1998-01-31    5   \n",
              "\n",
              "          type  \n",
              "0       CREDIT  \n",
              "1       CREDIT  \n",
              "2        DEBIT  \n",
              "3        DEBIT  \n",
              "4        DEBIT  \n",
              "...        ...  \n",
              "199995  CREDIT  \n",
              "199996  CREDIT  \n",
              "199997   DEBIT  \n",
              "199998   DEBIT  \n",
              "199999   DEBIT  \n",
              "\n",
              "[197691 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a589219d-dd28-4bfb-a0e7-0a67b08ee7bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>day</th>\n",
              "      <th>td</th>\n",
              "      <th>month</th>\n",
              "      <th>tcode</th>\n",
              "      <th>amount</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>account_id</th>\n",
              "      <th>year</th>\n",
              "      <th>date</th>\n",
              "      <th>tcode_str</th>\n",
              "      <th>datetime</th>\n",
              "      <th>dow</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55.0</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>14228.897461</td>\n",
              "      <td>14228.897461</td>\n",
              "      <td>1</td>\n",
              "      <td>1994</td>\n",
              "      <td>1994-01-05</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>1994-01-05</td>\n",
              "      <td>2</td>\n",
              "      <td>CREDIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67.0</td>\n",
              "      <td>15</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>3931.709717</td>\n",
              "      <td>3931.709717</td>\n",
              "      <td>1</td>\n",
              "      <td>1994</td>\n",
              "      <td>1994-11-15</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>1994-11-15</td>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>79.0</td>\n",
              "      <td>31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>1</td>\n",
              "      <td>1995</td>\n",
              "      <td>1995-10-31</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "      <td>1995-10-31</td>\n",
              "      <td>1</td>\n",
              "      <td>DEBIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70.0</td>\n",
              "      <td>13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__HOUSEHOLD</td>\n",
              "      <td>131.345657</td>\n",
              "      <td>-131.345657</td>\n",
              "      <td>1</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996-11-13</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__HOUSEHOLD</td>\n",
              "      <td>1996-11-13</td>\n",
              "      <td>2</td>\n",
              "      <td>DEBIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.0</td>\n",
              "      <td>25</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__nan</td>\n",
              "      <td>195.329590</td>\n",
              "      <td>-195.329590</td>\n",
              "      <td>1</td>\n",
              "      <td>1997</td>\n",
              "      <td>1997-01-25</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__nan</td>\n",
              "      <td>1997-01-25</td>\n",
              "      <td>5</td>\n",
              "      <td>DEBIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>48.0</td>\n",
              "      <td>30</td>\n",
              "      <td>58.0</td>\n",
              "      <td>9</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>19064.570312</td>\n",
              "      <td>19064.570312</td>\n",
              "      <td>11381</td>\n",
              "      <td>1997</td>\n",
              "      <td>1997-09-30</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>1997-09-30</td>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>46.0</td>\n",
              "      <td>16</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>22912.185547</td>\n",
              "      <td>22912.185547</td>\n",
              "      <td>11381</td>\n",
              "      <td>1997</td>\n",
              "      <td>1997-12-16</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>1997-12-16</td>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>35.0</td>\n",
              "      <td>11</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__HOUSEHOLD</td>\n",
              "      <td>11977.993164</td>\n",
              "      <td>-11977.993164</td>\n",
              "      <td>11381</td>\n",
              "      <td>1998</td>\n",
              "      <td>1998-10-11</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__HOUSEHOLD</td>\n",
              "      <td>1998-10-11</td>\n",
              "      <td>6</td>\n",
              "      <td>DEBIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>55.0</td>\n",
              "      <td>31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>11382</td>\n",
              "      <td>1996</td>\n",
              "      <td>1996-08-31</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "      <td>1996-08-31</td>\n",
              "      <td>5</td>\n",
              "      <td>DEBIT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>76.0</td>\n",
              "      <td>31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>11382</td>\n",
              "      <td>1998</td>\n",
              "      <td>1998-01-31</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "      <td>1998-01-31</td>\n",
              "      <td>5</td>\n",
              "      <td>DEBIT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197691 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a589219d-dd28-4bfb-a0e7-0a67b08ee7bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a589219d-dd28-4bfb-a0e7-0a67b08ee7bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a589219d-dd28-4bfb-a0e7-0a67b08ee7bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6df520d8-bec5-47ee-a704-47ca2727a481\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6df520d8-bec5-47ee-a704-47ca2727a481')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6df520d8-bec5-47ee-a704-47ca2727a481 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_029afaaf-166d-4706-879f-a03153c8e6fc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('synth_sorted')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_029afaaf-166d-4706-879f-a03153c8e6fc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('synth_sorted');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "synth_sorted"
            }
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = pd.read_csv('/content/tr_by_acct_w_age.csv')\n",
        "raw_data = raw_data.sort_values(by = [\"account_id\", \"date\"])\n",
        "# data, LOG_AMOUNT_SCALE, TD_SCALE, ATTR_SCALE, START_DATE,TCODE_TO_NUM,NUM_TO_TCODE, field_mappings  = preprocess_data_czech(raw_data)\n",
        "data, LOG_AMOUNT_SCALE, TD_SCALE = preprocess_data_czech(real)\n",
        "df = data[['account_id','tcode', 'datetime','amount', 'raw_amount']]\n",
        "real = df.copy()\n",
        "real[\"month\"] = real[\"datetime\"].dt.month\n",
        "real[\"day\"] = real[\"datetime\"].dt.day\n",
        "real[\"dow\"] =  real[\"datetime\"].dt.dayofweek\n",
        "real[\"year\"] = real[\"datetime\"].dt.year\n",
        "\n",
        "real[\"td\"] = real[[\"account_id\", \"datetime\"]].groupby(\"account_id\").diff()\n",
        "real[\"td\"] = real[\"td\"].apply(lambda x: x.days)\n",
        "real[\"td\"].fillna(0.0, inplace=True)\n",
        "\n",
        "\n",
        "# dtme - days till month end\n",
        "real[\"dtme\"] = real.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "\n",
        "real_cf = real[[\"account_id\", \"month\", \"raw_amount\", \"year\"]].groupby([\"account_id\", \"month\", \"year\"],as_index=False)[\"raw_amount\"].sum()\n",
        "real_sorted = real.sort_values(['account_id', 'year', 'month', 'day'])\n",
        "real"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "id": "6A5vh3ZJKoJj",
        "outputId": "82c60197-ec02-4f0d-940c-39e8f5a4ce65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'date'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-c027578b1df5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"account_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# data, LOG_AMOUNT_SCALE, TD_SCALE, ATTR_SCALE, START_DATE,TCODE_TO_NUM,NUM_TO_TCODE, field_mappings  = preprocess_data_czech(raw_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOG_AMOUNT_SCALE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTD_SCALE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data_czech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'account_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tcode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'datetime'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'raw_amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-cb5a0a441bf3>\u001b[0m in \u001b[0;36mpreprocess_data_czech\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mczech_date_parser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%y%m%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datetime\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mczech_date_parser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m#df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Valid"
      ],
      "metadata": {
        "id": "70hM5W9mTMoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from scipy.special import rel_entr\n",
        "from scipy.special import entr\n",
        "from scipy.spatial import distance\n",
        "\n",
        "from scipy.stats import energy_distance\n",
        "from scipy.stats import wasserstein_distance\n",
        "from scipy.stats import ks_2samp\n",
        "import random\n",
        "import os\n",
        "\n",
        "# random.seed(0)\n",
        "# np.random.seed(0)\n",
        "# os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ks_dist(real_obs, gen_obs):\n",
        "    stat, pval = ks_2samp(real_obs, gen_obs)\n",
        "\n",
        "    return stat\n",
        "\n",
        "def comapre_unidist_cont(CONT_FIELDS,CF_FIELD, real, synth, real_cf, synth_cf):\n",
        "    \"\"\"\n",
        "    CONT_FIELDS : list of continuous columns\n",
        "    CF_FIELD: name of the column in real_cf and synth_cf (used for computing cash flow)\n",
        "    CONTINUOUS_METRICS = {\"wasser\": wasserstein_distance, \"ks\": ks_dist,\"energy_d\": energy_distance}\n",
        "    real_cf, synth_cf: groupby([\"account_id\", \"month\", \"year\"]) real, and synth. and compute the sum of the raw_amount.\n",
        "\n",
        "    \"\"\"\n",
        "    CONTINUOUS_METRICS = {\"wasser\": wasserstein_distance, \"ks\": ks_dist,\"energy_d\": energy_distance}\n",
        "    univariate_cont_res = {}\n",
        "\n",
        "    for field in CONT_FIELDS:\n",
        "        univariate_cont_res[field] = {}\n",
        "        for name, fn in CONTINUOUS_METRICS.items():\n",
        "            univariate_cont_res[field][name] = fn(real[field], synth[field])\n",
        "\n",
        "    univariate_cont_res['CF'] = {}\n",
        "    for name, fn in CONTINUOUS_METRICS.items():\n",
        "        univariate_cont_res['CF'][name] = fn(real_cf[CF_FIELD], synth_cf[CF_FIELD])\n",
        "    return univariate_cont_res\n",
        "\n",
        "def comapre_unidist_cat(real, synth, field):\n",
        "    real_distribution = real[field].value_counts(normalize=True).sort_index()\n",
        "    synthetic_distribution = synth[field].value_counts(normalize=True).sort_index()\n",
        "    df_tcode = pd.merge(real_distribution, synthetic_distribution, left_index=True, right_index=True, how='outer')\n",
        "    df_tcode.columns = ['real', 'synthetic']\n",
        "\n",
        "    # Fill missing values with 0\n",
        "    df_tcode.fillna(0, inplace=True)\n",
        "    df_tcode['mid'] = (df_tcode['real'] + df_tcode['synthetic'])/2\n",
        "    kl_real_M = sum(rel_entr(df_tcode['real'], df_tcode['mid']))\n",
        "    kl_gen_M = sum(rel_entr(df_tcode['synthetic'], df_tcode['mid']))\n",
        "\n",
        "    jsd = (kl_real_M + kl_gen_M)/2\n",
        "    return jsd\n",
        "\n",
        "def create_ngramcount_df(df, n, field):\n",
        "    #gb = df.sort_values(by=[\"account_id\", \"datetime\"]).groupby(\"account_id\", sort=False)[field]\n",
        "    gb = df.groupby(\"account_id\", sort=False)[field]\n",
        "    ngram_list = gb.apply(lambda x: list(ngrams(x, n=n)))\n",
        "\n",
        "    counts = {}\n",
        "    for ngram_seq in ngram_list:\n",
        "        for ngram in ngram_seq:\n",
        "            ngram = str(ngram)[1:-1]\n",
        "            counts[ngram] = counts.get(ngram, 0) + 1\n",
        "\n",
        "\n",
        "    df = pd.DataFrame.from_dict(counts, orient=\"index\", columns=[\"counts\"]).sort_values(\"counts\", ascending=False)\n",
        "\n",
        "\n",
        "    return df.reset_index().rename(columns={\"index\": \"ngram\"})\n",
        "\n",
        "def compute_ngram_metrics(real_df, gen_df, field, n , pseudo_counts=0.0):\n",
        "\n",
        "\n",
        "    n_codes_unique = len(set(real_df[field].unique()).union(set(gen_df[field].unique())))\n",
        "\n",
        "\n",
        "    # create combo_df, which contains counts of all ngrams for both datasets (note: it omits any ngrams which do not occur in either dataset)\n",
        "    real_ngrams = create_ngramcount_df(real_df, n, field)\n",
        "    gen_ngrams = create_ngramcount_df(gen_df, n, field)\n",
        "    combo_df = pd.merge(real_ngrams, gen_ngrams, on=\"ngram\", how=\"outer\", suffixes=(\"_real\", \"_gen\")).fillna(0.0)\n",
        "\n",
        "\n",
        "    N_obs_real = real_ngrams[\"counts\"].sum()\n",
        "    N_obs_gen = gen_ngrams[\"counts\"].sum()\n",
        "    N_possible_ngrams = n_codes_unique**n\n",
        "\n",
        "\n",
        "    # add psudo-counts\n",
        "    combo_df[\"counts_real\"] += pseudo_counts\n",
        "    combo_df[\"ps_real\"] = combo_df[\"counts_real\"] / (N_obs_real + N_possible_ngrams*pseudo_counts)\n",
        "    combo_df[\"counts_gen\"] += pseudo_counts\n",
        "    combo_df[\"ps_gen\"] = combo_df[\"counts_gen\"] / (N_obs_gen + N_possible_ngrams*pseudo_counts)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # compute jsd (note: contribution to jsd from any ngram not in either dataset is 0)\n",
        "    combo_df[\"ps_mid\"] = (combo_df[\"ps_real\"] + combo_df[\"ps_gen\"])/2\n",
        "    kl_real_M = sum(rel_entr(combo_df[\"ps_real\"], combo_df[\"ps_mid\"]))\n",
        "    kl_gen_M = sum(rel_entr(combo_df[\"ps_gen\"], combo_df[\"ps_mid\"]))\n",
        "\n",
        "    jsd = (kl_real_M + kl_gen_M)/2\n",
        "\n",
        "\n",
        "    # compute entropy for both distributions\n",
        "    n_unobs = N_possible_ngrams - len(combo_df)\n",
        "\n",
        "    entr_r = entr(combo_df[\"ps_real\"]).sum()  # from observed\n",
        "\n",
        "    entr_g = entr(combo_df[\"ps_gen\"]).sum()  # from observed\n",
        "\n",
        "    results = {\"jsd\":jsd,\n",
        "                      \"entr_r\":entr_r,\n",
        "                      \"entr_g\":entr_g,\n",
        "                      \"NED\": entr_r - entr_g,\n",
        "                      \"l1\":distance.minkowski(combo_df[\"ps_real\"], combo_df[\"ps_gen\"], p=1),\n",
        "                      \"l2\":distance.minkowski(combo_df[\"ps_real\"], combo_df[\"ps_gen\"], p=2),\n",
        "                      \"jac\": distance.jaccard(combo_df[\"counts_real\"]>0, combo_df[\"counts_gen\"] > 0),\n",
        "                      \"count_r\": len(real_ngrams),\n",
        "                      \"coverage_r\": len(real_ngrams)/N_possible_ngrams,\n",
        "                      \"count_g\": len(gen_ngrams),\n",
        "                      \"coverage_g\": len(gen_ngrams)/N_possible_ngrams,\n",
        "                      \"count_max\": N_possible_ngrams,\n",
        "                      \"field\": field,\n",
        "                       \"n\":n,\n",
        "                       \"pseudo_counts\":pseudo_counts}\n",
        "\n",
        "    return combo_df, results\n",
        "\n",
        "#joint distribution of two categorical columns\n",
        "def compute_2d_categorical_metrics(real_df, gen_df, field1, field2):\n",
        "    f1_opts = set(real_df[field1].unique()).union(set(gen_df[field1].unique()))\n",
        "    f2_opts = set(real_df[field2].unique()).union(set(gen_df[field2].unique()))\n",
        "\n",
        "    n_opts_total = len(f1_opts) * len(f2_opts)\n",
        "\n",
        "    kl_r_m = 0.\n",
        "    kl_g_m = 0.\n",
        "    entr_r = 0.\n",
        "    entr_g = 0.\n",
        "    l1_d = 0.\n",
        "    l2_d = 0.\n",
        "    count_g = 0.\n",
        "    count_r = 0.\n",
        "\n",
        "    observed_opts = 0\n",
        "\n",
        "    cont_metric_results = {}\n",
        "    for code_1 in f1_opts:\n",
        "        for code_2 in f2_opts:\n",
        "            cond_r = np.logical_and(real_df[field1] == code_1, real_df[field2] == code_2)\n",
        "            cond_g = np.logical_and(gen_df[field1] == code_1, gen_df[field2] == code_2)\n",
        "\n",
        "            p_r = (np.sum(cond_r)) / (len(cond_r))\n",
        "            p_g = (np.sum(cond_g)) / (len(cond_g))\n",
        "            p_m = (p_r + p_g) / 2.\n",
        "\n",
        "            if np.sum(cond_r) + np.sum(cond_g) > 0:\n",
        "                observed_opts += 1\n",
        "\n",
        "\n",
        "            count_r += int(np.sum(cond_r) > 0)\n",
        "            count_g += int(np.sum(cond_g) > 0)\n",
        "\n",
        "            l1_d += np.abs(p_r - p_g)\n",
        "            l2_d += (p_r - p_g) ** 2\n",
        "\n",
        "\n",
        "            if p_r > 0:\n",
        "                kl_r_m += p_r * np.log(p_r / p_m)\n",
        "                entr_r += - p_r * np.log(p_r)\n",
        "\n",
        "            if p_g > 0:\n",
        "                kl_g_m += p_g * np.log(p_g / p_m)\n",
        "                entr_g += - p_g * np.log(p_g)\n",
        "\n",
        "    # compute jaccard\n",
        "    sr = set(zip(real_df[field1].to_list(), real_df[field2].to_list()))\n",
        "    sg = set(zip(gen_df[field1].to_list(), gen_df[field2].to_list()))\n",
        "    s_union = len(sr.union(sg))\n",
        "    s_inter = len(sr.intersection(sg))\n",
        "    jacc_d = (s_union - s_inter) / s_union\n",
        "\n",
        "    # finshed l2\n",
        "    l2_d = np.sqrt(l2_d)\n",
        "\n",
        "    # coverage\n",
        "    coverage_g = count_g / n_opts_total\n",
        "    coverage_r = count_r / n_opts_total\n",
        "\n",
        "    #jsd\n",
        "    jsd = (kl_r_m + kl_g_m) / 2\n",
        "\n",
        "\n",
        "    result = {'jsd': jsd,\n",
        "                    'entr_r': entr_r,\n",
        "                    'entr_g': entr_g,\n",
        "                    'l1': l1_d,\n",
        "                    'l2': l2_d,\n",
        "                    'jac': jacc_d,\n",
        "                    'count_r': count_r,\n",
        "                    'coverage_r': coverage_r,\n",
        "                    'count_g': count_g,\n",
        "                    'coverage_g': coverage_g,\n",
        "                    'count_max': n_opts_total}\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "Cj7aCuOxTN1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JSD between the distributions of tcode 3-grams\n",
        "combo_df, result = compute_ngram_metrics(real_sorted, synth, 'tcode', 3)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCMHCgywOLSQ",
        "outputId": "da4ab59f-a411-43aa-df5b-7f89abc07149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'jsd': 0.6931471805599425,\n",
              " 'entr_r': np.float64(5.425261658301508),\n",
              " 'entr_g': np.float64(6.012117424813452),\n",
              " 'NED': np.float64(-0.5868557665119436),\n",
              " 'l1': np.float64(2.0),\n",
              " 'l2': 0.11987633986910275,\n",
              " 'jac': np.float64(1.0),\n",
              " 'count_r': 1431,\n",
              " 'coverage_r': 0.349365234375,\n",
              " 'count_g': 1861,\n",
              " 'coverage_g': 0.454345703125,\n",
              " 'count_max': 4096,\n",
              " 'field': 'tcode',\n",
              " 'n': 3,\n",
              " 'pseudo_counts': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CAT_FIELDS = ['tcode']\n",
        "result_jst_cat = {}\n",
        "for field in CAT_FIELDS:\n",
        "    result_jst_cat[field] = comapre_unidist_cat(real, synth, field)\n",
        "result_jst_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXMzTQqIOaSP",
        "outputId": "586b86e6-0870-46e3-a5c7-053e25863edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tcode': 0.24187790737451337}"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONT_FIELDS = [\"amount\", \"td\"]\n",
        "\n",
        "CF_FIELD = 'raw_amount'\n",
        "\n",
        "#compare univariate distribution of continuous columns\n",
        "comapre_unidist_cont(CONT_FIELDS,CF_FIELD, real, synth, real_cf, synth_cf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3WvcYlMOjlR",
        "outputId": "151f69c2-0fb0-47f8-c66a-dff88e589d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'amount': {'wasser': np.float64(115.61979838240973),\n",
              "  'ks': np.float64(0.1389399170776662),\n",
              "  'energy_d': np.float64(0.8883633791761407)},\n",
              " 'td': {'wasser': np.float64(4.901145315321976),\n",
              "  'ks': np.float64(0.12795812461556033),\n",
              "  'energy_d': np.float64(0.8077030688648473)},\n",
              " 'CF': {'wasser': np.float64(5414.8747823964495),\n",
              "  'ks': np.float64(0.17285455648900935),\n",
              "  'energy_d': np.float64(31.0434898734073)}}"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# JSD result comparing the univariate distributions of the tcode (Tcode), and DOM\n",
        "CAT_FIELDS = ['tcode', 'day', 'month']\n",
        "result_jst_cat = {}\n",
        "for field in CAT_FIELDS:\n",
        "    result_jst_cat[field] = comapre_unidist_cat(real, synth, field)\n",
        "result_jst_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNcjDK12PDc6",
        "outputId": "aa3d3271-1fab-42cd-bf2e-8b2412870750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tcode': 0.24187790737451337,\n",
              " 'day': 0.0030374287541202224,\n",
              " 'month': 0.0004628859076390088}"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "0iDK7ppiGVJL",
        "outputId": "5797f5b5-6eaa-4c50-d255-706e17848ec3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Column        Metric     Score\n",
              "0       tcode  KSComplement  0.958825\n",
              "1      amount  KSComplement  0.859425\n",
              "2  raw_amount  KSComplement  0.843280\n",
              "3         age  KSComplement  0.940060\n",
              "4         day  KSComplement  0.948905\n",
              "5          td  KSComplement  0.897545"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15cbf4ae-a36f-4dc0-8c4e-40ed0940eef1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column</th>\n",
              "      <th>Metric</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tcode</td>\n",
              "      <td>KSComplement</td>\n",
              "      <td>0.958825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amount</td>\n",
              "      <td>KSComplement</td>\n",
              "      <td>0.859425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>raw_amount</td>\n",
              "      <td>KSComplement</td>\n",
              "      <td>0.843280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>age</td>\n",
              "      <td>KSComplement</td>\n",
              "      <td>0.940060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>day</td>\n",
              "      <td>KSComplement</td>\n",
              "      <td>0.948905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>td</td>\n",
              "      <td>KSComplement</td>\n",
              "      <td>0.897545</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15cbf4ae-a36f-4dc0-8c4e-40ed0940eef1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-15cbf4ae-a36f-4dc0-8c4e-40ed0940eef1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-15cbf4ae-a36f-4dc0-8c4e-40ed0940eef1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-01b71a65-3de0-4fda-a538-5dfba80ae8d5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01b71a65-3de0-4fda-a538-5dfba80ae8d5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-01b71a65-3de0-4fda-a538-5dfba80ae8d5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"quality_report\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Column\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"tcode\",\n          \"amount\",\n          \"td\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"KSComplement\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.048870766381003954,\n        \"min\": 0.84328,\n        \"max\": 0.958825,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.958825\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "quality_report.get_details(property_name='Column Shapes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "hREPbHCNGKEr",
        "outputId": "ade4680d-83ab-4b45-b2fa-e94da2a8665a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"fb044940-e9e4-42c9-ad4d-ad2870a700e9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fb044940-e9e4-42c9-ad4d-ad2870a700e9\")) {                    Plotly.newPlot(                        \"fb044940-e9e4-42c9-ad4d-ad2870a700e9\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"tcode\",\"amount\",\"raw_amount\",\"age\",\"day\",\"td\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"tcode\",\"amount\",\"raw_amount\",\"age\",\"day\",\"td\"],\"xaxis\":\"x\",\"y\":[0.958825,0.859425,0.84328,0.94006,0.948905,0.897545],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.91)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fb044940-e9e4-42c9-ad4d-ad2870a700e9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = quality_report.get_visualization(property_name='Column Shapes')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "zF1lvq1GGjuU",
        "outputId": "0ad96c5f-dfba-4edd-ad85-d4ed81650af3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"8bf2d942-a7d3-49ab-aebe-0fcb7c62fd8f\" class=\"plotly-graph-div\" style=\"height:900px; width:900px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8bf2d942-a7d3-49ab-aebe-0fcb7c62fd8f\")) {                    Plotly.newPlot(                        \"8bf2d942-a7d3-49ab-aebe-0fcb7c62fd8f\",                        [{\"coloraxis\":\"coloraxis\",\"hovertemplate\":\"\\u003cb\\u003eColumn Pair\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSimilarity: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"tcode\",\"amount\",\"raw_amount\",\"age\",\"day\",\"td\"],\"y\":[\"tcode\",\"amount\",\"raw_amount\",\"age\",\"day\",\"td\"],\"z\":[[1.0,0.998,1.0,0.998,0.994,0.952],[0.998,1.0,0.997,0.966,0.995,0.979],[1.0,0.997,1.0,0.999,0.999,1.0],[0.998,0.966,0.999,1.0,0.998,0.984],[0.994,0.995,0.999,0.998,1.0,0.918],[0.952,0.979,1.0,0.984,0.918,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,-0.177,-0.538,-0.015,-0.256,-0.038],[-0.177,1.0,0.264,-0.022,-0.313,0.011],[-0.538,0.264,1.0,0.0,-0.065,0.006],[-0.015,-0.022,0.0,1.0,-0.003,0.002],[-0.256,-0.313,-0.065,-0.003,1.0,0.027],[-0.038,0.011,0.006,0.002,0.027,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"tcode\",\"amount\",\"raw_amount\",\"age\",\"day\",\"td\"],\"y\":[\"tcode\",\"amount\",\"raw_amount\",\"age\",\"day\",\"td\"],\"z\":[[1.0,-0.181,-0.538,-0.012,-0.267,-0.134],[-0.181,1.0,0.27,-0.09,-0.324,-0.03],[-0.538,0.27,1.0,-0.001,-0.067,0.007],[-0.012,-0.09,-0.001,1.0,-0.008,0.034],[-0.267,-0.324,-0.067,-0.008,1.0,0.192],[-0.134,-0.03,0.007,0.034,0.192,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"coloraxis\":\"coloraxis2\",\"customdata\":[[1.0,-0.181,-0.538,-0.012,-0.267,-0.134],[-0.181,1.0,0.27,-0.09,-0.324,-0.03],[-0.538,0.27,1.0,-0.001,-0.067,0.007],[-0.012,-0.09,-0.001,1.0,-0.008,0.034],[-0.267,-0.324,-0.067,-0.008,1.0,0.192],[-0.134,-0.03,0.007,0.034,0.192,1.0]],\"hovertemplate\":\"\\u003cb\\u003eCorrelation\\u003c\\u002fb\\u003e\\u003cbr\\u003e(%{x},%{y})\\u003cbr\\u003e\\u003cbr\\u003eSynthetic: %{z}\\u003cbr\\u003e(vs. Real: %{customdata})\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"x\":[\"tcode\",\"amount\",\"raw_amount\",\"age\",\"day\",\"td\"],\"y\":[\"tcode\",\"amount\",\"raw_amount\",\"age\",\"day\",\"td\"],\"z\":[[1.0,-0.177,-0.538,-0.015,-0.256,-0.038],[-0.177,1.0,0.264,-0.022,-0.313,0.011],[-0.538,0.264,1.0,0.0,-0.065,0.006],[-0.015,-0.022,0.0,1.0,-0.003,0.002],[-0.256,-0.313,-0.065,-0.003,1.0,0.027],[-0.038,0.011,0.006,0.002,0.027,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.26,0.74],\"tickangle\":45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"autorange\":\"reversed\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,0.45],\"tickangle\":45},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"autorange\":\"reversed\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,1.0],\"tickangle\":45,\"matches\":\"x2\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"visible\":false,\"matches\":\"y2\",\"autorange\":\"reversed\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Real vs. Synthetic Similarity\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Real Data)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Numerical Correlation (Synthetic Data)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Data Quality: Column Pair Trends (Average Score=0.99)\"},\"coloraxis\":{\"colorbar\":{\"len\":0.5,\"x\":0.8,\"y\":0.8},\"cmin\":0,\"cmax\":1,\"colorscale\":[[0.0,\"#FF0000\"],[0.5,\"#F16141\"],[1.0,\"#36B37E\"]]},\"coloraxis2\":{\"colorbar\":{\"len\":0.5,\"y\":0.2},\"cmin\":-1,\"cmax\":1,\"colorscale\":[[0.0,\"#03AFF1\"],[0.5,\"#000036\"],[1.0,\"#01E0C9\"]]},\"font\":{\"size\":18},\"height\":900,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8bf2d942-a7d3-49ab-aebe-0fcb7c62fd8f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = quality_report.get_visualization(property_name='Column Pair Trends')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43oydHF_C3jW",
        "outputId": "6c89afd4-5a30-49a8-f4df-d393c1c2fce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 14.30it/s]|\n",
            "Column Shapes Score: 92.6%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 35.04it/s]|\n",
            "Column Pair Trends Score: 98.68%\n",
            "\n",
            "Overall Score (Average): 95.64%\n",
            "\n",
            "Average Jensen-Shannon Divergence: 0.07513574058077692\n",
            "\n",
            "JSD Results (Categorical Features):\n",
            "  Column  Jensen-Shannon Divergence\n",
            "0  tcode                   0.082982\n",
            "1    age                   0.103382\n",
            "2    day                   0.039043\n",
            "\n",
            "Average Wasserstein Distance: 63.662275908284386\n",
            "\n",
            "Wasserstein Distance Results (Continuous Features):\n",
            "       Column  Wasserstein Distance\n",
            "0      amount             85.249149\n",
            "1  raw_amount            103.396284\n",
            "2          td              2.341395\n",
            "\n",
            "SDV Quality Report:\n",
            "<sdmetrics.reports.single_table.quality_report.QualityReport object at 0x785e49b96150>\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import entropy, wasserstein_distance\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "\n",
        "\n",
        "# Your existing code\n",
        "metadata= SingleTableMetadata()\n",
        "metadata.detect_from_dataframe(data=train)\n",
        "\n",
        "#generate quality report\n",
        "quality_report= sdv_st.evaluate_quality(\n",
        "    real_data=train,\n",
        "    synthetic_data=samples_decoded,\n",
        "    metadata=metadata\n",
        ")\n",
        "\n",
        "# Function to calculate Jensen-Shannon Divergence for categorical columns\n",
        "def calculate_jsd_categorical(real_data, synthetic_data, column):\n",
        "    # Get value counts for each category\n",
        "    real_counts = real_data[column].value_counts(normalize=True).sort_index()\n",
        "    synth_counts = synthetic_data[column].value_counts(normalize=True).sort_index()\n",
        "\n",
        "    # Ensure both distributions have the same categories\n",
        "    all_categories = sorted(set(real_counts.index) | set(synth_counts.index))\n",
        "\n",
        "    # Create arrays with proper probability for each category\n",
        "    real_probs = np.array([real_counts.get(cat, 0) for cat in all_categories])\n",
        "    synth_probs = np.array([synth_counts.get(cat, 0) for cat in all_categories])\n",
        "\n",
        "    # Add small epsilon to avoid zero probabilities\n",
        "    real_probs = real_probs + 1e-10\n",
        "    synth_probs = synth_probs + 1e-10\n",
        "\n",
        "    # Normalize to ensure they are proper probability distributions\n",
        "    real_probs = real_probs / real_probs.sum()\n",
        "    synth_probs = synth_probs / synth_probs.sum()\n",
        "\n",
        "    # Calculate Jensen-Shannon divergence\n",
        "    jsd = jensenshannon(real_probs, synth_probs)\n",
        "\n",
        "    return jsd\n",
        "\n",
        "# Function to calculate Jensen-Shannon Divergence for numeric columns\n",
        "def calculate_jsd_numeric(real_data, synthetic_data, column):\n",
        "    # Create histograms with the same bins for both distributions\n",
        "    min_val = min(real_data[column].min(), synthetic_data[column].min())\n",
        "    max_val = max(real_data[column].max(), synthetic_data[column].max())\n",
        "\n",
        "    bins = np.linspace(min_val, max_val, 50)  # 50 bins between min and max\n",
        "\n",
        "    # Get histogram values\n",
        "    real_hist, _ = np.histogram(real_data[column].dropna(), bins=bins, density=True)\n",
        "    synth_hist, _ = np.histogram(synthetic_data[column].dropna(), bins=bins, density=True)\n",
        "\n",
        "    # Add small epsilon to avoid zero probabilities\n",
        "    real_hist = real_hist + 1e-10\n",
        "    synth_hist = synth_hist + 1e-10\n",
        "\n",
        "    # Normalize to ensure they are proper probability distributions\n",
        "    real_hist = real_hist / real_hist.sum()\n",
        "    synth_hist = synth_hist / synth_hist.sum()\n",
        "\n",
        "    # Calculate Jensen-Shannon divergence\n",
        "    jsd = jensenshannon(real_hist, synth_hist)\n",
        "\n",
        "    return jsd\n",
        "\n",
        "# Function to calculate Wasserstein Distance for continuous columns\n",
        "def calculate_wasserstein(real_data, synthetic_data, column):\n",
        "    # Drop NAs to ensure valid calculation\n",
        "    real_values = real_data[column].dropna().values\n",
        "    synth_values = synthetic_data[column].dropna().values\n",
        "\n",
        "    # Calculate Wasserstein distance\n",
        "    wd = wasserstein_distance(real_values, synth_values)\n",
        "\n",
        "    return wd\n",
        "\n",
        "# Define continuous features (amount and balance)\n",
        "continuous_features = ['amount','raw_amount','td']\n",
        "\n",
        "# Get all columns\n",
        "all_columns = train.columns.tolist()\n",
        "\n",
        "# Initialize results dictionaries\n",
        "jsd_results = {}\n",
        "wasserstein_results = {}\n",
        "\n",
        "# Apply appropriate metrics based on column type\n",
        "for column in all_columns:\n",
        "    if column in continuous_features:\n",
        "        # Use Wasserstein Distance for continuous features\n",
        "        wasserstein_results[column] = calculate_wasserstein(train, samples_decoded, column)\n",
        "    else:\n",
        "        # Use JSD for categorical features\n",
        "        if train[column].dtype.name == 'category' or train[column].dtype.name == 'object':\n",
        "            jsd_results[column] = calculate_jsd_categorical(train, samples_decoded, column)\n",
        "        else:\n",
        "            # For other numeric columns that are not continuous (like counts, etc.)\n",
        "            jsd_results[column] = calculate_jsd_numeric(train, samples_decoded, column)\n",
        "\n",
        "# Create DataFrames to display the results\n",
        "if jsd_results:\n",
        "    jsd_df = pd.DataFrame({\n",
        "        'Column': list(jsd_results.keys()),\n",
        "        'Jensen-Shannon Divergence': list(jsd_results.values())\n",
        "    })\n",
        "    avg_jsd = np.mean(list(jsd_results.values()))\n",
        "    print(\"Average Jensen-Shannon Divergence:\", avg_jsd)\n",
        "    print(\"\\nJSD Results (Categorical Features):\")\n",
        "    print(jsd_df)\n",
        "\n",
        "if wasserstein_results:\n",
        "    wd_df = pd.DataFrame({\n",
        "        'Column': list(wasserstein_results.keys()),\n",
        "        'Wasserstein Distance': list(wasserstein_results.values())\n",
        "    })\n",
        "    avg_wasserstein = np.mean(list(wasserstein_results.values()))\n",
        "    print(\"\\nAverage Wasserstein Distance:\", avg_wasserstein)\n",
        "    print(\"\\nWasserstein Distance Results (Continuous Features):\")\n",
        "    print(wd_df)\n",
        "\n",
        "# Combine with the quality report results\n",
        "print(\"\\nSDV Quality Report:\")\n",
        "print(quality_report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm results\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 13.96it/s]|\n",
        "# Column Shapes Score: 91.03%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 33.15it/s]|\n",
        "# Column Pair Trends Score: 98.15%\n",
        "\n",
        "# Overall Score (Average): 94.59%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.10546646740787863\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.102114\n",
        "# 1    age                   0.162393\n",
        "# 2    day                   0.051893\n",
        "\n",
        "# Average Wasserstein Distance: 76.42940358421647\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount             97.799765\n",
        "# 1  raw_amount            126.154306\n",
        "# 2          td              5.334140\n",
        "\n",
        "\n",
        "############################################################################\n",
        "\n",
        "# Transformer encoder results.   train-loss: 0.18381597\n",
        "\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 15.62it/s]|\n",
        "# Column Shapes Score: 91.49%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 35.62it/s]|\n",
        "# Column Pair Trends Score: 98.61%\n",
        "\n",
        "# Overall Score (Average): 95.05%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.10272431014595573\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.097515\n",
        "# 1    age                   0.125471\n",
        "# 2    day                   0.085187\n",
        "\n",
        "# Average Wasserstein Distance: 123.85941892630878\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount            174.850645\n",
        "# 1  raw_amount            193.565072\n",
        "# 2          td              3.162540\n",
        "\n",
        "\n",
        "\n",
        "# MLP model.  train-loss: 0.18420126\n",
        "\n",
        "\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 12.08it/s]|\n",
        "# Column Shapes Score: 92.5%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 34.54it/s]|\n",
        "# Column Pair Trends Score: 98.76%\n",
        "\n",
        "# Overall Score (Average): 95.63%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.09265519400370463\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.107892\n",
        "# 1    age                   0.120945\n",
        "# 2    day                   0.049129\n",
        "\n",
        "# Average Wasserstein Distance: 68.20228101830615\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount             88.166575\n",
        "# 1  raw_amount            113.465318\n",
        "# 2          td              2.974950\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################### using Quad schechduler\n",
        "# MLPSynthesizer\n",
        "# Generating report ...\n",
        "\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 10.44it/s]|\n",
        "# Column Shapes Score: 92.91%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 34.12it/s]|\n",
        "# Column Pair Trends Score: 98.52%\n",
        "\n",
        "# Overall Score (Average): 95.71%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.09091220730549797\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.100231\n",
        "# 1    age                   0.105836\n",
        "# 2    day                   0.066670\n",
        "\n",
        "# Average Wasserstein Distance: 55.60029754322721\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount             78.328973\n",
        "# 1  raw_amount             85.715805\n",
        "# 2          td              2.756115"
      ],
      "metadata": {
        "id": "C5QWwpfOtVxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using LSTM which is better than others\n",
        "\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 11.01it/s]|\n",
        "# Column Shapes Score: 93.38%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 33.77it/s]|\n",
        "# Column Pair Trends Score: 98.79%\n",
        "\n",
        "# Overall Score (Average): 96.08%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.0711470429157151\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.079263\n",
        "# 1    age                   0.104683\n",
        "# 2    day                   0.029496\n",
        "\n",
        "# Average Wasserstein Distance: 49.16540971330966\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount             65.965513\n",
        "# 1  raw_amount             80.151411\n",
        "# 2          td              1.379305"
      ],
      "metadata": {
        "id": "3pDdwX_ZaUDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DDIM MLP  using sigmoid with 1000 diffusion step\n",
        "\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 11.86it/s]|\n",
        "# Column Shapes Score: 92.73%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 34.02it/s]|\n",
        "# Column Pair Trends Score: 98.27%\n",
        "\n",
        "# Overall Score (Average): 95.5%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.0932761209763404\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.090567\n",
        "# 1    age                   0.127284\n",
        "# 2    day                   0.061978\n",
        "\n",
        "# Average Wasserstein Distance: 88.23562100605085\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount            111.976560\n",
        "# 1  raw_amount            149.033588\n",
        "# 2          td              3.696715\n",
        "\n",
        "\n",
        "\n",
        "# DDIM MLP  using exp scheduler with 1000 diffusion step\n",
        "# Generating report ...\n",
        "\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 10.79it/s]|\n",
        "# Column Shapes Score: 92.79%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 30.88it/s]|\n",
        "# Column Pair Trends Score: 98.81%\n",
        "\n",
        "# Overall Score (Average): 95.8%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.07421203588139481\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.080919\n",
        "# 1    age                   0.079512\n",
        "# 2    day                   0.062205\n",
        "\n",
        "# Average Wasserstein Distance: 97.68516266476217\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount            137.448405\n",
        "# 1  raw_amount            154.026543\n",
        "# 2          td              1.580540\n",
        "\n",
        "\n",
        "\n",
        "# DDIM MLP  using exp scheduler with 1000 diffusion step\n",
        "# Generating report ...\n",
        "\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00,  9.37it/s]|\n",
        "# Column Shapes Score: 94.01%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 34.01it/s]|\n",
        "# Column Pair Trends Score: 98.81%\n",
        "\n",
        "# Overall Score (Average): 96.41%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.06967537536515332\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.086324\n",
        "# 1    age                   0.064349\n",
        "# 2    day                   0.058353\n",
        "\n",
        "# Average Wasserstein Distance: 70.91739851909651\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount             92.273970\n",
        "# 1  raw_amount            118.976906\n",
        "# 2          td              1.501320"
      ],
      "metadata": {
        "id": "UZOzWS2Nh3w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DDPM MLP  using exp scheduler with 1000 diffusion step\n",
        "\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00,  9.54it/s]|\n",
        "# Column Shapes Score: 93.85%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 31.78it/s]|\n",
        "# Column Pair Trends Score: 99.11%\n",
        "\n",
        "# Overall Score (Average): 96.48%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.07398770080081442\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.098232\n",
        "# 1    age                   0.090414\n",
        "# 2    day                   0.033317\n",
        "\n",
        "# Average Wasserstein Distance: 54.68208152085268\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount             68.014870\n",
        "# 1  raw_amount             94.096965\n",
        "# 2          td              1.934410\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# DDPM LSTM  using exp scheduler with 1000 diffusion step\n",
        "\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 12.87it/s]|\n",
        "# Column Shapes Score: 93.76%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 35.80it/s]|\n",
        "# Column Pair Trends Score: 98.64%\n",
        "\n",
        "# Overall Score (Average): 96.2%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.07032440258834675\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.084887\n",
        "# 1    age                   0.099706\n",
        "# 2    day                   0.026380\n",
        "\n",
        "# Average Wasserstein Distance: 56.3650031828382\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount             73.321336\n",
        "# 1  raw_amount             93.740263\n",
        "# 2          td              2.033410"
      ],
      "metadata": {
        "id": "Sc1UlkT375tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sstudent t-test"
      ],
      "metadata": {
        "id": "Uvq05Ln0VLRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use df=5 and exp schduler mlp\n",
        "\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 15.99it/s]|\n",
        "# Column Shapes Score: 92.18%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 34.55it/s]|\n",
        "# Column Pair Trends Score: 98.45%\n",
        "\n",
        "# Overall Score (Average): 95.31%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.10094353192888607\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.099135\n",
        "# 1    age                   0.124442\n",
        "# 2    day                   0.079253\n",
        "\n",
        "# Average Wasserstein Distance: 205.55558758365933\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount            296.480293\n",
        "# 1  raw_amount            314.772235\n",
        "# 2          td              5.414235\n",
        "\n",
        "# use df =10 and linear schduler mlp model\n",
        "\n",
        "# Generating report ...\n",
        "\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 15.18it/s]|\n",
        "# Column Shapes Score: 91.62%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 34.60it/s]|\n",
        "# Column Pair Trends Score: 98.24%\n",
        "\n",
        "# Overall Score (Average): 94.93%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.10600576890507629\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.106667\n",
        "# 1    age                   0.140350\n",
        "# 2    day                   0.071000\n",
        "\n",
        "# Average Wasserstein Distance: 115.47599496416963\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount            160.373902\n",
        "# 1  raw_amount            175.367158\n",
        "# 2          td             10.686925"
      ],
      "metadata": {
        "id": "QBYq7IbIVNuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian Mixture noise"
      ],
      "metadata": {
        "id": "L6JFh3uTtTMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating report ...\n",
        "\n",
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 17.59it/s]|\n",
        "# Column Shapes Score: 91.43%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 33.09it/s]|\n",
        "# Column Pair Trends Score: 97.87%\n",
        "\n",
        "# Overall Score (Average): 94.65%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.10393999676783035\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.100905\n",
        "# 1    age                   0.142639\n",
        "# 2    day                   0.068277\n",
        "\n",
        "# Average Wasserstein Distance: 406.6957688787161\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount            534.344515\n",
        "# 1  raw_amount            682.389182\n",
        "# 2          td              3.353610"
      ],
      "metadata": {
        "id": "OpJy7LKa0kQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Obtained Results using LSTM ans student-t distribuion with exp scheduler"
      ],
      "metadata": {
        "id": "wFGBGu4G28sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (1/2) Evaluating Column Shapes: |██████████| 6/6 [00:00<00:00, 14.30it/s]|\n",
        "# Column Shapes Score: 92.6%\n",
        "\n",
        "# (2/2) Evaluating Column Pair Trends: |██████████| 15/15 [00:00<00:00, 35.04it/s]|\n",
        "# Column Pair Trends Score: 98.68%\n",
        "\n",
        "# Overall Score (Average): 95.64%\n",
        "\n",
        "# Average Jensen-Shannon Divergence: 0.07513574058077692\n",
        "\n",
        "# JSD Results (Categorical Features):\n",
        "#   Column  Jensen-Shannon Divergence\n",
        "# 0  tcode                   0.082982\n",
        "# 1    age                   0.103382\n",
        "# 2    day                   0.039043\n",
        "\n",
        "# Average Wasserstein Distance: 63.662275908284386\n",
        "\n",
        "# Wasserstein Distance Results (Continuous Features):\n",
        "#        Column  Wasserstein Distance\n",
        "# 0      amount             85.249149\n",
        "# 1  raw_amount            103.396284\n",
        "# 2          td              2.341395"
      ],
      "metadata": {
        "id": "8YE_QQKy3Ea8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# all model"
      ],
      "metadata": {
        "id": "xx1iAP5_1yLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a preproces data function\n",
        "\n",
        "\n",
        "\n",
        "# set random seed\n",
        "seed= 1234\n",
        "\n",
        "# set dimension of categorical embedding\n",
        "cat_emb_dim= 2\n",
        "\n",
        "# set number of neurons per layes\n",
        "mlp_layers=[1024,1024,1024,1024]\n",
        "\n",
        "# set non-linear activation function\n",
        "activation='lrelu'\n",
        "\n",
        "# set number of diffusion steps\n",
        "diffusion_steps= 1000\n",
        "\n",
        "# set diffusion stop and end betas\n",
        "diffusion_beta_start= 1e-4\n",
        "diffusion_beta_end= 0.02\n",
        "\n",
        "# set diffusion scheduler\n",
        "scheduler= 'exp'\n",
        "\n",
        "# set number of training epochs\n",
        "epochs= 500\n",
        "\n",
        "# set the training batch size\n",
        "batch_size= 512\n",
        "\n",
        "# set the training learning rate\n",
        "learning_rate= 1e-4\n",
        "\n",
        "# set the device\n",
        "device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\").type\n",
        "\n",
        "beta_start=1e-4\n",
        "beta_end=0.02\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set seeds\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "\n",
        "def preprocess_data_czech(df):\n",
        "    #df = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "\n",
        "    czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "    df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "    #df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
        "\n",
        "    df[\"month\"] = df[\"datetime\"].dt.month\n",
        "    df[\"day\"] = df[\"datetime\"].dt.day\n",
        "    df[\"dow\"] =  df[\"datetime\"].dt.dayofweek\n",
        "    df[\"year\"] = df[\"datetime\"].dt.year\n",
        "    df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "    df[\"td\"] = df[[\"account_id\", \"datetime\"]].groupby(\"account_id\").diff()\n",
        "    df[\"td\"] = df[\"td\"].apply(lambda x: x.days)\n",
        "    df[\"td\"].fillna(0.0, inplace=True)\n",
        "\n",
        "\n",
        "    # dtme - days till month end\n",
        "    df[\"dtme\"] = df.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "\n",
        "    df['raw_amount'] = df.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "\n",
        "    cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "    TCODE_SEP = \"__\"\n",
        "    # create tcode by concating fields in \"cat_code_fields\"\n",
        "    tcode = df[cat_code_fields[0]].astype(str)\n",
        "    for ccf in cat_code_fields[1:]:\n",
        "        tcode += TCODE_SEP + df[ccf].astype(str)\n",
        "\n",
        "    df[\"tcode\"] = tcode\n",
        "\n",
        "    conditions = [\n",
        "    (df['day'] >= 1) & (df['day'] <= 10),\n",
        "    (df['day'] > 10) & (df['day'] <= 20),\n",
        "    (df['day'] > 20) & (df['day'] <= 31)\n",
        "      ]\n",
        "\n",
        "    categories = ['first', 'middle', 'last']\n",
        "\n",
        "    # Use numpy.select() to map the numbers to categories\n",
        "    df['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "\n",
        "    bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "    labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "\n",
        "    # Use pd.cut() to convert ages to categorical groups\n",
        "    df['age_group'] = pd.cut(df['age'], bins=bin_edges, labels=labels, right=False)\n",
        "    df['age_group'] = df['age_group'].astype('object')\n",
        "\n",
        "    result = df.groupby('account_id')['datetime'].agg(['min', 'max'])\n",
        "    result['duration'] = result['max'] - result['min']\n",
        "    result_sorted = result.sort_values('duration', ascending=False)\n",
        "\n",
        "    df['log_amount'] = np.log10(df['amount'] + 1)\n",
        "    LOG_AMOUNT_SCALE = df['log_amount'].std()\n",
        "    df['log_amount_sc'] = df['log_amount']/ LOG_AMOUNT_SCALE\n",
        "    TD_SCALE = df['td'].std()\n",
        "    df['td_sc'] = df['td']/TD_SCALE\n",
        "\n",
        "    return df, LOG_AMOUNT_SCALE , TD_SCALE\n",
        "\n",
        "\n",
        "\n",
        "real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "real = real.sort_values(by = [\"account_id\", \"date\"])\n",
        "raw_data, LOG_AMOUNT_SCALE, TD_SCALE = preprocess_data_czech(real)\n",
        "\n",
        "\n",
        "\n",
        "all_real = raw_data[['account_id', 'tcode', 'datetime', 'amount', 'td', 'day', 'month', 'year']]\n",
        "all_real['type'] = all_real['tcode'].str.split('__').str[0]\n",
        "all_real['raw_amount'] = all_real.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "all_real_cf = all_real[[\"account_id\", \"month\", \"raw_amount\", \"year\"]].groupby([\"account_id\", \"month\", \"year\"],as_index=False)[\"raw_amount\"].sum()\n",
        "\n",
        "\n",
        "\n",
        "raw_data['raw_amount'] = raw_data.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "\n",
        "df_trans=raw_data\n",
        "\n",
        "df_trans_filtered=df_trans[['account_id','tcode','amount','raw_amount','age','day','month','year','td']]\n",
        "\n",
        "\n",
        "# determine categotical attributes\n",
        "cat_attrs= ['age','day','td','month','tcode']\n",
        "\n",
        " # determine numerical attributes\n",
        "num_attrs= ['amount','raw_amount','account_id','year']\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the data\n",
        "df_trans_filtered['tcode'] = label_encoder.fit_transform(df_trans['tcode'])\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# stratifiled sampling by 'tcode'\n",
        "\n",
        "# init the quantile transofrmation\n",
        "num_scaler= QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "\n",
        "# fit transform to numerical attributes\n",
        "num_scaler.fit(train[num_attrs])\n",
        "\n",
        "# transformed numerical attributes\n",
        "train_num_scaled= num_scaler.transform(train[num_attrs])\n",
        "\n",
        "\n",
        "\n",
        "vocabulary_classes= np.unique(train[cat_attrs])\n",
        "\n",
        "# init categorical attribute encoder\n",
        "label_encoder= LabelEncoder()\n",
        "\n",
        "# fit encoder to categorical attributes\n",
        "label_encoder.fit(vocabulary_classes)\n",
        "\n",
        "# transform cateforical attributes\n",
        "train_cat_scaled= train[cat_attrs].apply(label_encoder.transform)\n",
        "\n",
        "# collect unique values of each categorical attribute\n",
        "vocab_per_attr = {cat_attr: set(train_cat_scaled[cat_attr]) for cat_attr in cat_attrs}\n",
        "\n",
        "\n",
        "\n",
        "# convert the numerical attributes\n",
        "train_num_torch= torch.FloatTensor(train_num_scaled)\n",
        "\n",
        "# convert the categorical attributes\n",
        "train_cat_torch= torch.LongTensor(train_cat_scaled.values) # the train_cat_scaled was a dataframe so we have to get values\n",
        "\n",
        "# init tensor dataset\n",
        "train_set= TensorDataset(\n",
        "    train_cat_torch, # categorical attributes\n",
        "    train_num_torch,\n",
        "    # label_torch # dataset labels\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "dataloader= DataLoader(dataset=train_set, batch_size=batch_size, num_workers=0, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "# LSTM-based Architecture\n",
        "class LSTMSynthesizer(nn.Module):\n",
        "    def __init__(self, d_in, hidden_layers, activation='lrelu',\n",
        "                 dim_t=64, n_cat_tokens=None, n_cat_emb=None,\n",
        "                 embedding=None, embedding_learned=True,\n",
        "                 lstm_layers=1, bidirectional=True):\n",
        "        super(LSTMSynthesizer, self).__init__()\n",
        "\n",
        "        # init\n",
        "        self.dim_t = dim_t\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        # Handle categorical embeddings\n",
        "        if embedding is not None:\n",
        "            self.cat_embedding = nn.Embedding.from_pretrained(embeddings=embedding)\n",
        "        else:\n",
        "            self.cat_embedding = nn.Embedding(n_cat_tokens, n_cat_emb, max_norm=None, scale_grad_by_freq=False)\n",
        "            self.cat_embedding.weight.requires_grad = embedding_learned\n",
        "\n",
        "        # For label embedding if needed\n",
        "        # if n_classes is not None:\n",
        "        #     self.label_embedding = nn.Embedding(n_classes, dim_t)\n",
        "\n",
        "        # Input projection\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(d_in, dim_t),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(dim_t, dim_t)\n",
        "        )\n",
        "\n",
        "        # Time embedding projection\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(dim_t, dim_t),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(dim_t, dim_t)\n",
        "        )\n",
        "\n",
        "        # LSTM Backbone\n",
        "        lstm_input_size = dim_t\n",
        "        lstm_hidden_size = hidden_layers[0] if hidden_layers else dim_t\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=lstm_input_size,\n",
        "            hidden_size=lstm_hidden_size,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        # Output projection based on LSTM output size\n",
        "        lstm_output_size = lstm_hidden_size * 2 if bidirectional else lstm_hidden_size\n",
        "        self.head = nn.Linear(lstm_output_size, d_in)\n",
        "\n",
        "    def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "        # half output dimension\n",
        "        half_dim_out = dim_out // 2\n",
        "\n",
        "        # determine tensor of frequencies\n",
        "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0,\n",
        "                                                 end=half_dim_out, dtype=torch.float32) / half_dim_out)\n",
        "\n",
        "        freqs = freqs.to(device=timesteps.device)\n",
        "\n",
        "        # create timesteps vs frequency grid\n",
        "        args = timesteps[:, None].float() * freqs[None]\n",
        "\n",
        "        # creating the time embedding\n",
        "        time_embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "\n",
        "        # case odd output dimension\n",
        "        if dim_out % 2:\n",
        "            # append additional dimension\n",
        "            time_embedding = torch.cat([time_embedding, torch.zeros_like(time_embedding[:, :1])], dim=-1)\n",
        "\n",
        "        # return timestep embedding\n",
        "        return time_embedding\n",
        "\n",
        "    # get categorical embedding\n",
        "    def get_embedding(self):\n",
        "        # return categorical embedding\n",
        "        return self.cat_embedding.weight.data\n",
        "\n",
        "    # perform categorical embedding\n",
        "    def embed_categorical(self, x_cat):\n",
        "        # perform categorical embedding\n",
        "        x_cat_emb = self.cat_embedding(x_cat)\n",
        "\n",
        "        # reshape embedding to original input\n",
        "        x_cat_emb = x_cat_emb.view(-1, x_cat_emb.shape[1] * x_cat_emb.shape[2])\n",
        "\n",
        "        return x_cat_emb\n",
        "\n",
        "    # define forward pass\n",
        "    def forward(self, x, timesteps):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # init time embeddings\n",
        "        time_emb = self.embed_time(timesteps, self.dim_t)\n",
        "\n",
        "        # embed time embedding\n",
        "        time_emb = self.time_embed(time_emb)\n",
        "\n",
        "        # case: data classes available\n",
        "        # if label is not None:\n",
        "        #     time_label_emb = time_emb + self.label_embedding(label)\n",
        "        # else:\n",
        "        time_label_emb = time_emb\n",
        "\n",
        "        # run initial projection layer\n",
        "        x = self.projection(x)\n",
        "\n",
        "        # add time and label embedding\n",
        "        x = x + time_label_emb\n",
        "\n",
        "        # Reshape for LSTM (batch_size, seq_len=1, features)\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        x, _ = self.lstm(x)\n",
        "\n",
        "        # Extract the last output for each sequence\n",
        "        x = x[:, -1, :]\n",
        "\n",
        "        # Pass through output layer\n",
        "        x = self.head(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import math\n",
        "from scipy import stats\n",
        "\n",
        "# define Student's t-Distribution DDPM Diffuser network\n",
        "class StudentTDDPMDiffuser(object):\n",
        "  # define the constructor\n",
        "  def __init__(self, total_steps=1000, beta_start=1e-4, beta_end=0.02, device='cpu', scheduler='exp', df=10):\n",
        "     # set diffusion steps\n",
        "     self.total_steps = total_steps\n",
        "\n",
        "     # set diffusion start beta\n",
        "     self.beta_start = beta_start\n",
        "\n",
        "     # set diffusion end beta\n",
        "     self.beta_end = beta_end\n",
        "\n",
        "     # set compute device\n",
        "     self.device = device\n",
        "\n",
        "     # set degrees of freedom for t-distribution\n",
        "     self.df = df\n",
        "\n",
        "     # set noise schedule alphas and betas\n",
        "     self.alphas, self.betas = self.prepare_noise_schedule(scheduler=scheduler)\n",
        "\n",
        "     # set noise schedule alpha hat\n",
        "     self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "  # define noise schedule\n",
        "  def prepare_noise_schedule(self, scheduler: str):\n",
        "    # define noise scheduler scale\n",
        "    scale = 1000 / self.total_steps\n",
        "\n",
        "    # scale beta start\n",
        "    beta_start = scale * self.beta_start\n",
        "\n",
        "    # scale beta end\n",
        "    beta_end = scale * self.beta_end\n",
        "\n",
        "    if scheduler == 'linear':\n",
        "        betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "        alphas = 1.0 - betas\n",
        "\n",
        "    elif scheduler == 'quad':\n",
        "        betas = torch.linspace(self.beta_start**0.5, self.beta_end**0.5, self.total_steps) ** 2\n",
        "        alphas = 1.0 - betas\n",
        "\n",
        "    elif scheduler == 'exp':\n",
        "        betas = torch.exp(torch.linspace(math.log(beta_start), math.log(beta_end), self.total_steps))\n",
        "        alphas = 1.0 - betas\n",
        "\n",
        "    elif scheduler == 'sigm':\n",
        "        x = torch.linspace(-6, 6, self.total_steps)\n",
        "        betas = torch.sigmoid(x) * (beta_end - beta_start) + beta_start\n",
        "        alphas = 1.0 - betas\n",
        "\n",
        "    return alphas.to(self.device), betas.to(self.device)\n",
        "\n",
        "  # define random timesteps sampler\n",
        "  def sample_random_timesteps(self, n:int):\n",
        "    # sample random timesteps\n",
        "     t = torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "     return t\n",
        "\n",
        "  # Generate samples from Student's t-distribution\n",
        "  def sample_student_t(self, shape):\n",
        "    # Use the reparameterization trick for Student's t-distribution\n",
        "    # t = sqrt(df/(df-2)) * X / sqrt(Z/df) where X ~ N(0,1) and Z ~ Chi^2(df)\n",
        "    # For df > 2, this gives a t-distribution with variance 1\n",
        "\n",
        "    if self.df <= 2:\n",
        "        # Ensure finite variance\n",
        "        df_sample = 3.0\n",
        "    else:\n",
        "        df_sample = float(self.df)\n",
        "\n",
        "    # Generate normal samples - FIX: shape should be a tuple or list, not a tensor\n",
        "    if isinstance(shape, torch.Tensor):\n",
        "        shape = tuple(shape.tolist())\n",
        "    x = torch.randn(shape, device=self.device)\n",
        "\n",
        "    # Generate chi-squared samples using gamma distribution\n",
        "    # Chi^2(k) is equivalent to Gamma(k/2, 2)\n",
        "    gamma_shape = df_sample / 2.0\n",
        "    gamma_samples = torch.tensor(stats.gamma.rvs(gamma_shape, scale=2.0, size=shape[0]),\n",
        "                                 dtype=torch.float32,\n",
        "                                 device=self.device).view(-1, 1)\n",
        "\n",
        "    # Compute the t-distributed noise\n",
        "    # Scaling factor ensures variance = 1 for df > 2\n",
        "    scaling = torch.sqrt(torch.tensor(df_sample / (df_sample - 2.0), device=self.device)) if df_sample > 2 else torch.tensor(1.0, device=self.device)\n",
        "\n",
        "    t_noise = scaling * x / torch.sqrt(gamma_samples / df_sample)\n",
        "\n",
        "    return t_noise\n",
        "\n",
        "  # define Student-t noise addition for forward process\n",
        "  def add_t_noise(self, x_num, t):\n",
        "    # determine noise alpha hat\n",
        "    sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None]\n",
        "\n",
        "    # determine noise one minus alpha hat\n",
        "    sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None]\n",
        "\n",
        "    # determine Student-t noise instead of Gaussian\n",
        "    noise_shape = x_num.shape\n",
        "    batch_size = noise_shape[0]\n",
        "    noise_num = self.sample_student_t((batch_size, x_num.shape[1]))\n",
        "\n",
        "    # determine x numeric noise (same formula as Gaussian, but with t-distribution noise)\n",
        "    x_noise_num = sqrt_alpha_hat * x_num + sqrt_one_minus_alpha_hat * noise_num\n",
        "\n",
        "    return x_noise_num, noise_num\n",
        "\n",
        "  # define Student-t noise sampling for reverse process\n",
        "  def p_sample_t(self, model_out, z_norm, timesteps):\n",
        "    # determine noise alpha\n",
        "    sqrt_alpha_t = torch.sqrt(self.alphas[timesteps])[:, None]\n",
        "\n",
        "    # determine noise beta\n",
        "    betas_t = self.betas[timesteps][:, None]\n",
        "\n",
        "    # determine noise one minus alpha hat\n",
        "    sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[timesteps])[:, None]\n",
        "\n",
        "    epsilon_t = torch.sqrt(self.betas[timesteps][:, None])\n",
        "\n",
        "    # determine t-distribution noise instead of Gaussian\n",
        "    batch_size = z_norm.shape[0]\n",
        "    random_noise = self.sample_student_t((batch_size, z_norm.shape[1]))\n",
        "    random_noise[timesteps == 0] = 0.0\n",
        "\n",
        "    # determine model mean (same formula as Gaussian case)\n",
        "    model_mean = ((1 / sqrt_alpha_t) * (z_norm - (betas_t * model_out / sqrt_one_minus_alpha_hat_t)))\n",
        "\n",
        "    # determine z norm with t-distribution noise\n",
        "    z_norm = model_mean + (epsilon_t * random_noise)\n",
        "\n",
        "    return z_norm\n",
        "\n",
        "  # Full sampling process - FIX: Modify the method signature to match your usage\n",
        "  def sample(self, model_out, z_norm, timesteps):\n",
        "    # This is a simplified version that directly uses the p_sample_t method\n",
        "    return self.p_sample_t(model_out, z_norm, timesteps)\n",
        "\n",
        "  # The original sample method can be renamed to sample_full if you still need it\n",
        "  def sample_full(self, model, shape, device):\n",
        "    # Start from pure noise (t-distributed)\n",
        "    x = self.sample_student_t(shape).to(device)\n",
        "\n",
        "    # Iterate backward through timesteps\n",
        "    for t in range(self.total_steps - 1, -1, -1):\n",
        "        # Create a batch of the same timestep\n",
        "        timesteps = torch.full((shape[0],), t, device=device, dtype=torch.long)\n",
        "\n",
        "        # Predict noise\n",
        "        predicted_noise = model(x, timesteps)\n",
        "\n",
        "        # Sample for this timestep\n",
        "        x = self.p_sample_t(predicted_noise, x, timesteps)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "# determine number of unique categorical tokens\n",
        "n_cat_tokens= len(np.unique(train[cat_attrs]))\n",
        "\n",
        "\n",
        "\n",
        "# detrermine total categorical embedding dimension\n",
        "cat_dim= cat_emb_dim * len(cat_attrs)\n",
        "\n",
        "# determine total numerical embedding dimension\n",
        "num_dim= len(num_attrs)\n",
        "\n",
        "# detrmine total embedding dimension\n",
        "encoded_dim= cat_dim + num_dim\n",
        "\n",
        "\n",
        "synthesizer_model = LSTMSynthesizer(\n",
        "    d_in=encoded_dim,  # the input shape\n",
        "    hidden_layers=mlp_layers,\n",
        "    activation=activation,\n",
        "    n_cat_tokens=n_cat_tokens,\n",
        "    n_cat_emb=cat_emb_dim,\n",
        "    embedding_learned=False,\n",
        "    # num_layers=4,\n",
        "    # dim_feedforward=2048\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the Student-t distribution diffuser\n",
        "diffuser = StudentTDDPMDiffuser(\n",
        "    total_steps=diffusion_steps,\n",
        "    beta_start=diffusion_beta_start,\n",
        "    beta_end=diffusion_beta_end,\n",
        "    scheduler='exp',\n",
        "    device=device,\n",
        "    df=10  # Set degrees of freedom - adjust based on your data characteristics\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# determine synthesizer model parameters\n",
        "\n",
        "parameters= filter(lambda p: p.requires_grad, synthesizer_model.parameters())\n",
        "\n",
        "# init adam optimizer\n",
        "optimizer= optim.Adam(parameters, lr= learning_rate)\n",
        "\n",
        "# init learning rate scheduler\n",
        "lr_scheduler= CosineAnnealingLR(optimizer, T_max=epochs, verbose=False)\n",
        "\n",
        "# int mse loss\n",
        "\n",
        "loss_fnc= nn.MSELoss()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for student t- test\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "# used for student-t distribution\n",
        "\n",
        "# Init collection of training epoch losses\n",
        "train_epoch_losses = []\n",
        "\n",
        "# Set the model in training mode\n",
        "synthesizer_model.train()\n",
        "\n",
        "# Move to the device\n",
        "synthesizer_model = synthesizer_model.to(device)\n",
        "\n",
        "# Init the training progress bar\n",
        "pbar = tqdm(iterable=range(500), position=0, leave=True)\n",
        "\n",
        "# Iterate over training epochs\n",
        "for epoch in pbar:\n",
        "    base_params = {'epoch': epoch, 'seed': seed, 'mlp_layers': mlp_layers}\n",
        "\n",
        "    # Init epoch training batch losses\n",
        "    batch_losses = []\n",
        "\n",
        "    # Iterate over epoch batches\n",
        "    for batch_cat, batch_num in dataloader:\n",
        "        # Move tensor to device\n",
        "        batch_cat = batch_cat.to(device)\n",
        "        batch_num = batch_num.to(device)\n",
        "\n",
        "        # Determine diffusion timestep\n",
        "        timesteps = diffuser.sample_random_timesteps(n=batch_cat.shape[0])\n",
        "\n",
        "        # Determine categorical embeddings\n",
        "        batch_cat_emb = synthesizer_model.embed_categorical(x_cat=batch_cat)\n",
        "\n",
        "        # Concat categorical and numerical embedding\n",
        "        batch_cat_num = torch.cat((batch_cat_emb, batch_num), dim=1)\n",
        "\n",
        "        # *** KEY CHANGE 1: Use t-distribution noise instead of Gaussian ***\n",
        "        batch_noise_t, noise_t = diffuser.add_t_noise(batch_cat_num, t=timesteps)\n",
        "\n",
        "        # Conduct synthesizer model forward pass\n",
        "        predicted_noise = synthesizer_model(x=batch_noise_t, timesteps=timesteps)\n",
        "\n",
        "        # Compute training batch loss\n",
        "        batch_loss = loss_fnc(input=noise_t, target=predicted_noise)\n",
        "\n",
        "        # Reset the model gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Run model backward pass\n",
        "        batch_loss.backward()\n",
        "\n",
        "        # Optimize model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Collect training batch losses\n",
        "        batch_losses.append(batch_loss.detach().cpu().numpy())\n",
        "\n",
        "    # Determine mean training batch loss\n",
        "    batch_losses_mean = np.mean(np.array(batch_losses))\n",
        "\n",
        "    # Update learning rate scheduler\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    # Collect mean training epochs loss\n",
        "    train_epoch_losses.append(batch_losses_mean)\n",
        "\n",
        "    # # Prepare and set training epochs progress bar update\n",
        "    # now = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    # pbar.set_description('[LOG {}] epoch: {}, train-loss: {}'.format(\n",
        "    #     str(now), str(epoch).zfill(4), str(batch_losses_mean)))"
      ],
      "metadata": {
        "id": "PFSuc89J12fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM-based Architecture\n",
        "class LSTMSynthesizer(nn.Module):\n",
        "    def __init__(self, d_in, hidden_layers, activation='lrelu',\n",
        "                 dim_t=64, n_cat_tokens=None, n_cat_emb=None,\n",
        "                 embedding=None, embedding_learned=True,\n",
        "                 lstm_layers=1, bidirectional=True):\n",
        "        super(LSTMSynthesizer, self).__init__()\n",
        "\n",
        "        # init\n",
        "        self.dim_t = dim_t\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        # Handle categorical embeddings\n",
        "        if embedding is not None:\n",
        "            self.cat_embedding = nn.Embedding.from_pretrained(embeddings=embedding)\n",
        "        else:\n",
        "            self.cat_embedding = nn.Embedding(n_cat_tokens, n_cat_emb, max_norm=None, scale_grad_by_freq=False)\n",
        "            self.cat_embedding.weight.requires_grad = embedding_learned\n",
        "\n",
        "        # For label embedding if needed\n",
        "        # if n_classes is not None:\n",
        "        #     self.label_embedding = nn.Embedding(n_classes, dim_t)\n",
        "\n",
        "        # Input projection\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(d_in, dim_t),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(dim_t, dim_t)\n",
        "        )\n",
        "\n",
        "        # Time embedding projection\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(dim_t, dim_t),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(dim_t, dim_t)\n",
        "        )\n",
        "\n",
        "        # LSTM Backbone\n",
        "        lstm_input_size = dim_t\n",
        "        lstm_hidden_size = hidden_layers[0] if hidden_layers else dim_t\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=lstm_input_size,\n",
        "            hidden_size=lstm_hidden_size,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        # Output projection based on LSTM output size\n",
        "        lstm_output_size = lstm_hidden_size * 2 if bidirectional else lstm_hidden_size\n",
        "        self.head = nn.Linear(lstm_output_size, d_in)\n",
        "\n",
        "    def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "        # half output dimension\n",
        "        half_dim_out = dim_out // 2\n",
        "\n",
        "        # determine tensor of frequencies\n",
        "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0,\n",
        "                                                 end=half_dim_out, dtype=torch.float32) / half_dim_out)\n",
        "\n",
        "        freqs = freqs.to(device=timesteps.device)\n",
        "\n",
        "        # create timesteps vs frequency grid\n",
        "        args = timesteps[:, None].float() * freqs[None]\n",
        "\n",
        "        # creating the time embedding\n",
        "        time_embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "\n",
        "        # case odd output dimension\n",
        "        if dim_out % 2:\n",
        "            # append additional dimension\n",
        "            time_embedding = torch.cat([time_embedding, torch.zeros_like(time_embedding[:, :1])], dim=-1)\n",
        "\n",
        "        # return timestep embedding\n",
        "        return time_embedding\n",
        "\n",
        "    # get categorical embedding\n",
        "    def get_embedding(self):\n",
        "        # return categorical embedding\n",
        "        return self.cat_embedding.weight.data\n",
        "\n",
        "    # perform categorical embedding\n",
        "    def embed_categorical(self, x_cat):\n",
        "        # perform categorical embedding\n",
        "        x_cat_emb = self.cat_embedding(x_cat)\n",
        "\n",
        "        # reshape embedding to original input\n",
        "        x_cat_emb = x_cat_emb.view(-1, x_cat_emb.shape[1] * x_cat_emb.shape[2])\n",
        "\n",
        "        return x_cat_emb\n",
        "\n",
        "    # define forward pass\n",
        "    def forward(self, x, timesteps):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # init time embeddings\n",
        "        time_emb = self.embed_time(timesteps, self.dim_t)\n",
        "\n",
        "        # embed time embedding\n",
        "        time_emb = self.time_embed(time_emb)\n",
        "\n",
        "        # case: data classes available\n",
        "        # if label is not None:\n",
        "        #     time_label_emb = time_emb + self.label_embedding(label)\n",
        "        # else:\n",
        "        time_label_emb = time_emb\n",
        "\n",
        "        # run initial projection layer\n",
        "        x = self.projection(x)\n",
        "\n",
        "        # add time and label embedding\n",
        "        x = x + time_label_emb\n",
        "\n",
        "        # Reshape for LSTM (batch_size, seq_len=1, features)\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # Pass through LSTM\n",
        "        x, _ = self.lstm(x)\n",
        "\n",
        "        # Extract the last output for each sequence\n",
        "        x = x[:, -1, :]\n",
        "\n",
        "        # Pass through output layer\n",
        "        x = self.head(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import math\n",
        "from scipy import stats\n",
        "\n",
        "# define Student's t-Distribution DDPM Diffuser network\n",
        "class StudentTDDPMDiffuser(object):\n",
        "  # define the constructor\n",
        "  def __init__(self, total_steps=1000, beta_start=1e-4, beta_end=0.02, device='cpu', scheduler='exp', df=10):\n",
        "     # set diffusion steps\n",
        "     self.total_steps = total_steps\n",
        "\n",
        "     # set diffusion start beta\n",
        "     self.beta_start = beta_start\n",
        "\n",
        "     # set diffusion end beta\n",
        "     self.beta_end = beta_end\n",
        "\n",
        "     # set compute device\n",
        "     self.device = device\n",
        "\n",
        "     # set degrees of freedom for t-distribution\n",
        "     self.df = df\n",
        "\n",
        "     # set noise schedule alphas and betas\n",
        "     self.alphas, self.betas = self.prepare_noise_schedule(scheduler=scheduler)\n",
        "\n",
        "     # set noise schedule alpha hat\n",
        "     self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "  # define noise schedule\n",
        "  def prepare_noise_schedule(self, scheduler: str):\n",
        "    # define noise scheduler scale\n",
        "    scale = 1000 / self.total_steps\n",
        "\n",
        "    # scale beta start\n",
        "    beta_start = scale * self.beta_start\n",
        "\n",
        "    # scale beta end\n",
        "    beta_end = scale * self.beta_end\n",
        "\n",
        "    if scheduler == 'linear':\n",
        "        betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "        alphas = 1.0 - betas\n",
        "\n",
        "    elif scheduler == 'quad':\n",
        "        betas = torch.linspace(self.beta_start**0.5, self.beta_end**0.5, self.total_steps) ** 2\n",
        "        alphas = 1.0 - betas\n",
        "\n",
        "    elif scheduler == 'exp':\n",
        "        betas = torch.exp(torch.linspace(math.log(beta_start), math.log(beta_end), self.total_steps))\n",
        "        alphas = 1.0 - betas\n",
        "\n",
        "    elif scheduler == 'sigm':\n",
        "        x = torch.linspace(-6, 6, self.total_steps)\n",
        "        betas = torch.sigmoid(x) * (beta_end - beta_start) + beta_start\n",
        "        alphas = 1.0 - betas\n",
        "\n",
        "    return alphas.to(self.device), betas.to(self.device)\n",
        "\n",
        "  # define random timesteps sampler\n",
        "  def sample_random_timesteps(self, n:int):\n",
        "    # sample random timesteps\n",
        "     t = torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "     return t\n",
        "\n",
        "  # Generate samples from Student's t-distribution\n",
        "  def sample_student_t(self, shape):\n",
        "    # Use the reparameterization trick for Student's t-distribution\n",
        "    # t = sqrt(df/(df-2)) * X / sqrt(Z/df) where X ~ N(0,1) and Z ~ Chi^2(df)\n",
        "    # For df > 2, this gives a t-distribution with variance 1\n",
        "\n",
        "    if self.df <= 2:\n",
        "        # Ensure finite variance\n",
        "        df_sample = 3.0\n",
        "    else:\n",
        "        df_sample = float(self.df)\n",
        "\n",
        "    # Generate normal samples - FIX: shape should be a tuple or list, not a tensor\n",
        "    if isinstance(shape, torch.Tensor):\n",
        "        shape = tuple(shape.tolist())\n",
        "    x = torch.randn(shape, device=self.device)\n",
        "\n",
        "    # Generate chi-squared samples using gamma distribution\n",
        "    # Chi^2(k) is equivalent to Gamma(k/2, 2)\n",
        "    gamma_shape = df_sample / 2.0\n",
        "    gamma_samples = torch.tensor(stats.gamma.rvs(gamma_shape, scale=2.0, size=shape[0]),\n",
        "                                 dtype=torch.float32,\n",
        "                                 device=self.device).view(-1, 1)\n",
        "\n",
        "    # Compute the t-distributed noise\n",
        "    # Scaling factor ensures variance = 1 for df > 2\n",
        "    scaling = torch.sqrt(torch.tensor(df_sample / (df_sample - 2.0), device=self.device)) if df_sample > 2 else torch.tensor(1.0, device=self.device)\n",
        "\n",
        "    t_noise = scaling * x / torch.sqrt(gamma_samples / df_sample)\n",
        "\n",
        "    return t_noise\n",
        "\n",
        "  # define Student-t noise addition for forward process\n",
        "  def add_t_noise(self, x_num, t):\n",
        "    # determine noise alpha hat\n",
        "    sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None]\n",
        "\n",
        "    # determine noise one minus alpha hat\n",
        "    sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None]\n",
        "\n",
        "    # determine Student-t noise instead of Gaussian\n",
        "    noise_shape = x_num.shape\n",
        "    batch_size = noise_shape[0]\n",
        "    noise_num = self.sample_student_t((batch_size, x_num.shape[1]))\n",
        "\n",
        "    # determine x numeric noise (same formula as Gaussian, but with t-distribution noise)\n",
        "    x_noise_num = sqrt_alpha_hat * x_num + sqrt_one_minus_alpha_hat * noise_num\n",
        "\n",
        "    return x_noise_num, noise_num\n",
        "\n",
        "  # define Student-t noise sampling for reverse process\n",
        "  def p_sample_t(self, model_out, z_norm, timesteps):\n",
        "    # determine noise alpha\n",
        "    sqrt_alpha_t = torch.sqrt(self.alphas[timesteps])[:, None]\n",
        "\n",
        "    # determine noise beta\n",
        "    betas_t = self.betas[timesteps][:, None]\n",
        "\n",
        "    # determine noise one minus alpha hat\n",
        "    sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[timesteps])[:, None]\n",
        "\n",
        "    epsilon_t = torch.sqrt(self.betas[timesteps][:, None])\n",
        "\n",
        "    # determine t-distribution noise instead of Gaussian\n",
        "    batch_size = z_norm.shape[0]\n",
        "    random_noise = self.sample_student_t((batch_size, z_norm.shape[1]))\n",
        "    random_noise[timesteps == 0] = 0.0\n",
        "\n",
        "    # determine model mean (same formula as Gaussian case)\n",
        "    model_mean = ((1 / sqrt_alpha_t) * (z_norm - (betas_t * model_out / sqrt_one_minus_alpha_hat_t)))\n",
        "\n",
        "    # determine z norm with t-distribution noise\n",
        "    z_norm = model_mean + (epsilon_t * random_noise)\n",
        "\n",
        "    return z_norm\n",
        "\n",
        "  # Full sampling process - FIX: Modify the method signature to match your usage\n",
        "  def sample(self, model_out, z_norm, timesteps):\n",
        "    # This is a simplified version that directly uses the p_sample_t method\n",
        "    return self.p_sample_t(model_out, z_norm, timesteps)\n",
        "\n",
        "  # The original sample method can be renamed to sample_full if you still need it\n",
        "  def sample_full(self, model, shape, device):\n",
        "    # Start from pure noise (t-distributed)\n",
        "    x = self.sample_student_t(shape).to(device)\n",
        "\n",
        "    # Iterate backward through timesteps\n",
        "    for t in range(self.total_steps - 1, -1, -1):\n",
        "        # Create a batch of the same timestep\n",
        "        timesteps = torch.full((shape[0],), t, device=device, dtype=torch.long)\n",
        "\n",
        "        # Predict noise\n",
        "        predicted_noise = model(x, timesteps)\n",
        "\n",
        "        # Sample for this timestep\n",
        "        x = self.p_sample_t(predicted_noise, x, timesteps)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "# determine number of unique categorical tokens\n",
        "n_cat_tokens= len(np.unique(train[cat_attrs]))\n",
        "\n",
        "\n",
        "\n",
        "# detrermine total categorical embedding dimension\n",
        "cat_dim= cat_emb_dim * len(cat_attrs)\n",
        "\n",
        "# determine total numerical embedding dimension\n",
        "num_dim= len(num_attrs)\n",
        "\n",
        "# detrmine total embedding dimension\n",
        "encoded_dim= cat_dim + num_dim\n",
        "\n",
        "\n",
        "synthesizer_model = LSTMSynthesizer(\n",
        "    d_in=encoded_dim,  # the input shape\n",
        "    hidden_layers=mlp_layers,\n",
        "    activation=activation,\n",
        "    n_cat_tokens=n_cat_tokens,\n",
        "    n_cat_emb=cat_emb_dim,\n",
        "    embedding_learned=False,\n",
        "    # num_layers=4,\n",
        "    # dim_feedforward=2048\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the Student-t distribution diffuser\n",
        "diffuser = StudentTDDPMDiffuser(\n",
        "    total_steps=diffusion_steps,\n",
        "    beta_start=diffusion_beta_start,\n",
        "    beta_end=diffusion_beta_end,\n",
        "    scheduler='exp',\n",
        "    device=device,\n",
        "    df=10  # Set degrees of freedom - adjust based on your data characteristics\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# determine synthesizer model parameters\n",
        "\n",
        "parameters= filter(lambda p: p.requires_grad, synthesizer_model.parameters())\n",
        "\n",
        "# init adam optimizer\n",
        "optimizer= optim.Adam(parameters, lr= learning_rate)\n",
        "\n",
        "# init learning rate scheduler\n",
        "lr_scheduler= CosineAnnealingLR(optimizer, T_max=epochs, verbose=False)\n",
        "\n",
        "# int mse loss\n",
        "\n",
        "loss_fnc= nn.MSELoss()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for student t- test\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "# used for student-t distribution\n",
        "\n",
        "# Init collection of training epoch losses\n",
        "train_epoch_losses = []\n",
        "\n",
        "# Set the model in training mode\n",
        "synthesizer_model.train()\n",
        "\n",
        "# Move to the device\n",
        "synthesizer_model = synthesizer_model.to(device)\n",
        "\n",
        "# Init the training progress bar\n",
        "pbar = tqdm(iterable=range(500), position=0, leave=True)\n",
        "\n",
        "# Iterate over training epochs\n",
        "for epoch in pbar:\n",
        "    base_params = {'epoch': epoch, 'seed': seed, 'mlp_layers': mlp_layers}\n",
        "\n",
        "    # Init epoch training batch losses\n",
        "    batch_losses = []\n",
        "\n",
        "    # Iterate over epoch batches\n",
        "    for batch_cat, batch_num in dataloader:\n",
        "        # Move tensor to device\n",
        "        batch_cat = batch_cat.to(device)\n",
        "        batch_num = batch_num.to(device)\n",
        "\n",
        "        # Determine diffusion timestep\n",
        "        timesteps = diffuser.sample_random_timesteps(n=batch_cat.shape[0])\n",
        "\n",
        "        # Determine categorical embeddings\n",
        "        batch_cat_emb = synthesizer_model.embed_categorical(x_cat=batch_cat)\n",
        "\n",
        "        # Concat categorical and numerical embedding\n",
        "        batch_cat_num = torch.cat((batch_cat_emb, batch_num), dim=1)\n",
        "\n",
        "        # *** KEY CHANGE 1: Use t-distribution noise instead of Gaussian ***\n",
        "        batch_noise_t, noise_t = diffuser.add_t_noise(batch_cat_num, t=timesteps)\n",
        "\n",
        "        # Conduct synthesizer model forward pass\n",
        "        predicted_noise = synthesizer_model(x=batch_noise_t, timesteps=timesteps)\n",
        "\n",
        "        # Compute training batch loss\n",
        "        batch_loss = loss_fnc(input=noise_t, target=predicted_noise)\n",
        "\n",
        "        # Reset the model gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Run model backward pass\n",
        "        batch_loss.backward()\n",
        "\n",
        "        # Optimize model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Collect training batch losses\n",
        "        batch_losses.append(batch_loss.detach().cpu().numpy())\n",
        "\n",
        "    # Determine mean training batch loss\n",
        "    batch_losses_mean = np.mean(np.array(batch_losses))\n",
        "\n",
        "    # Update learning rate scheduler\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    # Collect mean training epochs loss\n",
        "    train_epoch_losses.append(batch_losses_mean)\n",
        "\n",
        "    # Prepare and set training epochs progress bar update\n",
        "    now = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    pbar.set_description('[LOG {}] epoch: {}, train-loss: {}'.format(\n",
        "        str(now), str(epoch).zfill(4), str(batch_losses_mean)))"
      ],
      "metadata": {
        "id": "ZMON9Opu3rTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# new generated model"
      ],
      "metadata": {
        "id": "hLYuI2bJM7yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "# from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import random\n",
        "# import os\n",
        "# from datetime import datetime\n",
        "# import calendar\n",
        "# from tqdm import tqdm\n",
        "# from scipy import stats\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# # =============================================================================\n",
        "# # CONFIGURATION AND SETUP\n",
        "# # =============================================================================\n",
        "\n",
        "# # Set seeds for reproducibility\n",
        "# seed = 42\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# torch.manual_seed(seed)\n",
        "# if torch.cuda.is_available():\n",
        "#     torch.cuda.manual_seed(seed)\n",
        "#     torch.cuda.manual_seed_all(seed)\n",
        "# os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "# # Device configuration\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# print(f\"Using device: {device}\")\n",
        "\n",
        "# # Model hyperparameters\n",
        "# sequence_length = 50  # Number of transactions per sequence\n",
        "# min_seq_length = 20   # Minimum sequence length for an account\n",
        "# batch_size = 32\n",
        "# learning_rate = 1e-3\n",
        "# epochs = 500\n",
        "# diffusion_steps = 1000\n",
        "# diffusion_beta_start = 1e-4\n",
        "# diffusion_beta_end = 0.02\n",
        "# cat_emb_dim = 16\n",
        "# mlp_layers = [256, 128]\n",
        "# activation = 'relu'\n",
        "# dropout_rate = 0.1\n",
        "\n",
        "# # =============================================================================\n",
        "# # DATA PREPROCESSING\n",
        "# # =============================================================================\n",
        "\n",
        "# def preprocess_data_czech(df):\n",
        "#     \"\"\"Enhanced preprocessing function for Czech banking data\"\"\"\n",
        "\n",
        "#     # Parse dates\n",
        "#     czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "#     df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "\n",
        "#     # Extract temporal features\n",
        "#     df[\"month\"] = df[\"datetime\"].dt.month\n",
        "#     df[\"day\"] = df[\"datetime\"].dt.day\n",
        "#     df[\"dow\"] = df[\"datetime\"].dt.dayofweek\n",
        "#     df[\"year\"] = df[\"datetime\"].dt.year\n",
        "#     df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "#     # Calculate time differences between transactions\n",
        "#     df = df.sort_values(['account_id', 'datetime'])\n",
        "#     df[\"td\"] = df.groupby(\"account_id\")[\"datetime\"].diff().dt.days\n",
        "#     df[\"td\"].fillna(0.0, inplace=True)\n",
        "\n",
        "#     # Days till month end\n",
        "#     df[\"dtme\"] = df.datetime.apply(\n",
        "#         lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day\n",
        "#     )\n",
        "\n",
        "#     # Create raw amount (positive for credit, negative for debit)\n",
        "#     df['raw_amount'] = df.apply(\n",
        "#         lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'],\n",
        "#         axis=1\n",
        "#     )\n",
        "\n",
        "#     # Create transaction codes\n",
        "#     cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "#     TCODE_SEP = \"__\"\n",
        "#     tcode = df[cat_code_fields[0]].astype(str)\n",
        "#     for ccf in cat_code_fields[1:]:\n",
        "#         tcode += TCODE_SEP + df[ccf].astype(str)\n",
        "#     df[\"tcode\"] = tcode\n",
        "\n",
        "#     # Day of month categories\n",
        "#     conditions = [\n",
        "#         (df['day'] >= 1) & (df['day'] <= 10),\n",
        "#         (df['day'] > 10) & (df['day'] <= 20),\n",
        "#         (df['day'] > 20) & (df['day'] <= 31)\n",
        "#     ]\n",
        "#     categories = ['first', 'middle', 'last']\n",
        "#     df['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "#     # Age groups\n",
        "#     bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "#     labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "#     df['age_group'] = pd.cut(df['age'], bins=bin_edges, labels=labels, right=False)\n",
        "#     df['age_group'] = df['age_group'].astype('object')\n",
        "\n",
        "#     # Log transformations\n",
        "#     df['log_amount'] = np.log10(df['amount'] + 1)\n",
        "#     LOG_AMOUNT_SCALE = df['log_amount'].std()\n",
        "#     df['log_amount_sc'] = df['log_amount'] / LOG_AMOUNT_SCALE\n",
        "#     TD_SCALE = df['td'].std()\n",
        "#     df['td_sc'] = df['td'] / TD_SCALE\n",
        "\n",
        "#     # Calculate running balance per account\n",
        "#     df = df.sort_values(['account_id', 'datetime'])\n",
        "#     df['balance'] = df.groupby('account_id')['raw_amount'].cumsum()\n",
        "#     df['log_balance'] = np.log10(np.abs(df['balance']) + 1) * np.sign(df['balance'])\n",
        "\n",
        "#     return df, LOG_AMOUNT_SCALE, TD_SCALE\n",
        "\n",
        "# # =============================================================================\n",
        "# # SEQUENTIAL DATASET CLASS\n",
        "# # =============================================================================\n",
        "\n",
        "# class SequentialBankingDataset(Dataset):\n",
        "#     \"\"\"Dataset that creates sequences of transactions per account\"\"\"\n",
        "\n",
        "#     def __init__(self, df, cat_attrs, num_attrs, sequence_length=50, min_seq_length=20, stride=10):\n",
        "#         self.sequence_length = sequence_length\n",
        "#         self.min_seq_length = min_seq_length\n",
        "#         self.cat_attrs = cat_attrs\n",
        "#         self.num_attrs = num_attrs\n",
        "#         self.stride = stride\n",
        "\n",
        "#         self.sequences = []\n",
        "#         self.account_info = {}\n",
        "\n",
        "#         print(\"Creating sequences from transaction data...\")\n",
        "\n",
        "#         # Group by account and create sequences\n",
        "#         for account_id in tqdm(df['account_id'].unique()):\n",
        "#             account_data = df[df['account_id'] == account_id].sort_values('datetime').reset_index(drop=True)\n",
        "\n",
        "#             if len(account_data) >= min_seq_length:\n",
        "#                 # Store account metadata\n",
        "#                 self.account_info[account_id] = {\n",
        "#                     'age': account_data['age'].iloc[0],\n",
        "#                     'age_group': account_data['age_group'].iloc[0],\n",
        "#                     'total_transactions': len(account_data)\n",
        "#                 }\n",
        "\n",
        "#                 # Create sliding windows with stride\n",
        "#                 for i in range(0, len(account_data) - sequence_length + 1, stride):\n",
        "#                     seq_data = account_data.iloc[i:i+sequence_length]\n",
        "\n",
        "#                     cat_data = seq_data[cat_attrs].values\n",
        "#                     num_data = seq_data[num_attrs].values\n",
        "\n",
        "#                     self.sequences.append({\n",
        "#                         'account_id': account_id,\n",
        "#                         'cat_data': cat_data,\n",
        "#                         'num_data': num_data,\n",
        "#                         'start_idx': i,\n",
        "#                         'dates': seq_data['datetime'].values\n",
        "#                     })\n",
        "\n",
        "#         print(f\"Created {len(self.sequences)} sequences from {len(df['account_id'].unique())} accounts\")\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.sequences)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         seq = self.sequences[idx]\n",
        "#         return (\n",
        "#             torch.LongTensor(seq['cat_data']),\n",
        "#             torch.FloatTensor(seq['num_data']),\n",
        "#             seq['account_id']\n",
        "#         )\n",
        "\n",
        "# # =============================================================================\n",
        "# # SEQUENTIAL LSTM SYNTHESIZER MODEL\n",
        "# # =============================================================================\n",
        "\n",
        "# class SequentialLSTMSynthesizer(nn.Module):\n",
        "#     \"\"\"Enhanced LSTM model for sequential transaction generation\"\"\"\n",
        "\n",
        "#     def __init__(self, d_in, hidden_layers, activation='relu',\n",
        "#                  dim_t=64, n_cat_tokens=None, n_cat_emb=None,\n",
        "#                  sequence_length=50, lstm_layers=2, bidirectional=False,\n",
        "#                  dropout=0.1, use_attention=True):\n",
        "#         super(SequentialLSTMSynthesizer, self).__init__()\n",
        "\n",
        "#         self.dim_t = dim_t\n",
        "#         self.lstm_layers = lstm_layers\n",
        "#         self.bidirectional = bidirectional\n",
        "#         self.sequence_length = sequence_length\n",
        "#         self.use_attention = use_attention\n",
        "\n",
        "#         # Categorical embeddings\n",
        "#         self.cat_embedding = nn.Embedding(n_cat_tokens, n_cat_emb)\n",
        "\n",
        "#         # Input projection for combined cat + num features\n",
        "#         self.input_projection = nn.Sequential(\n",
        "#             nn.Linear(d_in, dim_t),\n",
        "#             self._get_activation(activation),\n",
        "#             nn.Dropout(dropout),\n",
        "#             nn.Linear(dim_t, dim_t)\n",
        "#         )\n",
        "\n",
        "#         # Time embedding layers\n",
        "#         self.time_embed = nn.Sequential(\n",
        "#             nn.Linear(dim_t, dim_t),\n",
        "#             self._get_activation(activation),\n",
        "#             nn.Linear(dim_t, dim_t)\n",
        "#         )\n",
        "\n",
        "#         # Sequential LSTM backbone\n",
        "#         lstm_input_size = dim_t\n",
        "#         lstm_hidden_size = hidden_layers[0] if hidden_layers else dim_t\n",
        "\n",
        "#         self.lstm = nn.LSTM(\n",
        "#             input_size=lstm_input_size,\n",
        "#             hidden_size=lstm_hidden_size,\n",
        "#             num_layers=lstm_layers,\n",
        "#             batch_first=True,\n",
        "#             bidirectional=bidirectional,\n",
        "#             dropout=dropout if lstm_layers > 1 else 0\n",
        "#         )\n",
        "\n",
        "#         # Attention mechanism for better sequence modeling\n",
        "#         lstm_output_size = lstm_hidden_size * 2 if bidirectional else lstm_hidden_size\n",
        "\n",
        "#         if use_attention:\n",
        "#             self.attention = nn.MultiheadAttention(\n",
        "#                 embed_dim=lstm_output_size,\n",
        "#                 num_heads=8,\n",
        "#                 dropout=dropout,\n",
        "#                 batch_first=True\n",
        "#             )\n",
        "#             self.norm1 = nn.LayerNorm(lstm_output_size)\n",
        "\n",
        "#         # Output projection layers\n",
        "#         output_layers = []\n",
        "#         current_dim = lstm_output_size\n",
        "\n",
        "#         for hidden_dim in hidden_layers[1:]:\n",
        "#             output_layers.extend([\n",
        "#                 nn.Linear(current_dim, hidden_dim),\n",
        "#                 self._get_activation(activation),\n",
        "#                 nn.Dropout(dropout)\n",
        "#             ])\n",
        "#             current_dim = hidden_dim\n",
        "\n",
        "#         output_layers.append(nn.Linear(current_dim, d_in))\n",
        "#         self.output_layers = nn.Sequential(*output_layers)\n",
        "\n",
        "#     def _get_activation(self, activation):\n",
        "#         \"\"\"Get activation function\"\"\"\n",
        "#         if activation == 'relu':\n",
        "#             return nn.ReLU()\n",
        "#         elif activation == 'lrelu':\n",
        "#             return nn.LeakyReLU(0.2)\n",
        "#         elif activation == 'silu':\n",
        "#             return nn.SiLU()\n",
        "#         elif activation == 'gelu':\n",
        "#             return nn.GELU()\n",
        "#         else:\n",
        "#             return nn.ReLU()\n",
        "\n",
        "#     def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "#         \"\"\"Sinusoidal time embedding\"\"\"\n",
        "#         half_dim_out = dim_out // 2\n",
        "#         freqs = torch.exp(-math.log(max_period) * torch.arange(\n",
        "#             start=0, end=half_dim_out, dtype=torch.float32) / half_dim_out)\n",
        "#         freqs = freqs.to(device=timesteps.device)\n",
        "\n",
        "#         args = timesteps[:, None].float() * freqs[None]\n",
        "#         time_embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "\n",
        "#         if dim_out % 2:\n",
        "#             time_embedding = torch.cat([\n",
        "#                 time_embedding,\n",
        "#                 torch.zeros_like(time_embedding[:, :1])\n",
        "#             ], dim=-1)\n",
        "\n",
        "#         return time_embedding\n",
        "\n",
        "#     def embed_categorical(self, x_cat):\n",
        "#         \"\"\"Embed categorical variables\"\"\"\n",
        "#         batch_size, seq_len, n_cat = x_cat.shape\n",
        "\n",
        "#         # Process each categorical feature separately and concatenate\n",
        "#         cat_embeddings = []\n",
        "#         for i in range(n_cat):\n",
        "#             cat_emb = self.cat_embedding(x_cat[:, :, i])  # (batch_size, seq_len, emb_dim)\n",
        "#             cat_embeddings.append(cat_emb)\n",
        "\n",
        "#         # Concatenate all categorical embeddings\n",
        "#         x_cat_emb = torch.cat(cat_embeddings, dim=-1)  # (batch_size, seq_len, n_cat * emb_dim)\n",
        "\n",
        "#         return x_cat_emb\n",
        "\n",
        "#     def forward(self, x_seq, timesteps):\n",
        "#         \"\"\"\n",
        "#         Forward pass for sequence data\n",
        "#         x_seq: (batch_size, seq_len, features)\n",
        "#         timesteps: (batch_size,)\n",
        "#         \"\"\"\n",
        "#         batch_size, seq_len, _ = x_seq.shape\n",
        "\n",
        "#         # Time embedding (broadcast to all sequence positions)\n",
        "#         time_emb = self.embed_time(timesteps, self.dim_t)\n",
        "#         time_emb = self.time_embed(time_emb)\n",
        "#         time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "#         # Input projection\n",
        "#         x = self.input_projection(x_seq)\n",
        "\n",
        "#         # Add time embedding\n",
        "#         x = x + time_emb\n",
        "\n",
        "#         # LSTM processing\n",
        "#         lstm_out, _ = self.lstm(x)\n",
        "\n",
        "#         # Self-attention for better sequence modeling\n",
        "#         if self.use_attention:\n",
        "#             attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
        "#             x = self.norm1(lstm_out + attn_out)\n",
        "#         else:\n",
        "#             x = lstm_out\n",
        "\n",
        "#         # Output projection\n",
        "#         output = self.output_layers(x)\n",
        "\n",
        "#         return output\n",
        "\n",
        "# # =============================================================================\n",
        "# # STUDENT-T DDPM DIFFUSER FOR SEQUENCES\n",
        "# # =============================================================================\n",
        "\n",
        "# class SequentialStudentTDDPMDiffuser:\n",
        "#     \"\"\"Student-t distribution DDPM diffuser for sequential data\"\"\"\n",
        "\n",
        "#     def __init__(self, total_steps=1000, beta_start=1e-4, beta_end=0.02,\n",
        "#                  device='cpu', scheduler='exp', df=10):\n",
        "#         self.total_steps = total_steps\n",
        "#         self.beta_start = beta_start\n",
        "#         self.beta_end = beta_end\n",
        "#         self.device = device\n",
        "#         self.df = df\n",
        "\n",
        "#         self.alphas, self.betas = self.prepare_noise_schedule(scheduler=scheduler)\n",
        "#         self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "#     def prepare_noise_schedule(self, scheduler: str):\n",
        "#         \"\"\"Prepare noise schedule\"\"\"\n",
        "#         scale = 1000 / self.total_steps\n",
        "#         beta_start = scale * self.beta_start\n",
        "#         beta_end = scale * self.beta_end\n",
        "\n",
        "#         if scheduler == 'linear':\n",
        "#             betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "#         elif scheduler == 'quad':\n",
        "#             betas = torch.linspace(self.beta_start**0.5, self.beta_end**0.5, self.total_steps) ** 2\n",
        "#         elif scheduler == 'exp':\n",
        "#             betas = torch.exp(torch.linspace(\n",
        "#                 math.log(beta_start), math.log(beta_end), self.total_steps))\n",
        "#         elif scheduler == 'sigm':\n",
        "#             x = torch.linspace(-6, 6, self.total_steps)\n",
        "#             betas = torch.sigmoid(x) * (beta_end - beta_start) + beta_start\n",
        "#         else:\n",
        "#             betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "\n",
        "#         alphas = 1.0 - betas\n",
        "#         return alphas.to(self.device), betas.to(self.device)\n",
        "\n",
        "#     def sample_random_timesteps(self, n: int):\n",
        "#         \"\"\"Sample random timesteps\"\"\"\n",
        "#         t = torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "#         return t\n",
        "\n",
        "#     def sample_student_t(self, shape):\n",
        "#         \"\"\"Generate samples from Student's t-distribution\"\"\"\n",
        "#         if self.df <= 2:\n",
        "#             df_sample = 3.0\n",
        "#         else:\n",
        "#             df_sample = float(self.df)\n",
        "\n",
        "#         # For simplicity, use scaled normal distribution as approximation\n",
        "#         # For production, implement proper t-distribution sampling\n",
        "#         x = torch.randn(shape, device=self.device)\n",
        "\n",
        "#         # Simple scaling for t-distribution approximation\n",
        "#         if df_sample > 2:\n",
        "#             scale = math.sqrt(df_sample / (df_sample - 2))\n",
        "#             x = x * scale\n",
        "\n",
        "#         return x\n",
        "\n",
        "#     def add_t_noise_sequence(self, x_seq, t):\n",
        "#         \"\"\"Add noise to sequence data\"\"\"\n",
        "#         batch_size, seq_len, features = x_seq.shape\n",
        "\n",
        "#         sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None, None]\n",
        "#         sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None, None]\n",
        "\n",
        "#         # Generate t-distributed noise for the entire sequence\n",
        "#         noise_seq = self.sample_student_t((batch_size, seq_len, features))\n",
        "\n",
        "#         x_noise_seq = sqrt_alpha_hat * x_seq + sqrt_one_minus_alpha_hat * noise_seq\n",
        "\n",
        "#         return x_noise_seq, noise_seq\n",
        "\n",
        "#     def p_sample_t_sequence(self, model_out, z_norm, timesteps):\n",
        "#         \"\"\"Sampling step for sequences\"\"\"\n",
        "#         batch_size, seq_len, features = z_norm.shape\n",
        "\n",
        "#         sqrt_alpha_t = torch.sqrt(self.alphas[timesteps])[:, None, None]\n",
        "#         betas_t = self.betas[timesteps][:, None, None]\n",
        "#         sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[timesteps])[:, None, None]\n",
        "#         epsilon_t = torch.sqrt(self.betas[timesteps])[:, None, None]\n",
        "\n",
        "#         # Generate random noise\n",
        "#         random_noise = self.sample_student_t((batch_size, seq_len, features))\n",
        "#         random_noise[timesteps == 0] = 0.0\n",
        "\n",
        "#         # Calculate model mean\n",
        "#         model_mean = ((1 / sqrt_alpha_t) * (z_norm - (betas_t * model_out / sqrt_one_minus_alpha_hat_t)))\n",
        "\n",
        "#         # Add noise\n",
        "#         z_norm = model_mean + (epsilon_t * random_noise)\n",
        "\n",
        "#         return z_norm\n",
        "\n",
        "# # =============================================================================\n",
        "# # TRAINING FUNCTION\n",
        "# # =============================================================================\n",
        "\n",
        "# def train_sequential_model(model, diffuser, dataloader, optimizer, scheduler, device, epochs=100):\n",
        "#     \"\"\"Training loop for sequential transaction model\"\"\"\n",
        "#     model.train()\n",
        "#     model = model.to(device)\n",
        "\n",
        "#     loss_fnc = nn.MSELoss()\n",
        "#     train_epoch_losses = []\n",
        "\n",
        "#     pbar = tqdm(range(epochs), desc=\"Training\")\n",
        "\n",
        "#     for epoch in pbar:\n",
        "#         epoch_losses = []\n",
        "\n",
        "#         for batch_cat, batch_num, account_ids in dataloader:\n",
        "#             batch_cat = batch_cat.to(device)\n",
        "#             batch_num = batch_num.to(device)\n",
        "\n",
        "#             batch_size, seq_len, _ = batch_cat.shape\n",
        "\n",
        "#             # Embed categorical variables\n",
        "#             batch_cat_emb = model.embed_categorical(batch_cat)\n",
        "\n",
        "#             # Combine categorical and numerical features\n",
        "#             batch_combined = torch.cat([batch_cat_emb, batch_num], dim=-1)\n",
        "\n",
        "#             # Sample timesteps\n",
        "#             timesteps = diffuser.sample_random_timesteps(batch_size)\n",
        "\n",
        "#             # Add noise to the entire sequence\n",
        "#             batch_noisy, noise_target = diffuser.add_t_noise_sequence(batch_combined, timesteps)\n",
        "\n",
        "#             # Forward pass\n",
        "#             predicted_noise = model(batch_noisy, timesteps)\n",
        "\n",
        "#             # Compute loss\n",
        "#             loss = loss_fnc(predicted_noise, noise_target)\n",
        "\n",
        "#             # Backward pass\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "#             optimizer.step()\n",
        "\n",
        "#             epoch_losses.append(loss.item())\n",
        "\n",
        "#         # Update learning rate\n",
        "#         scheduler.step()\n",
        "\n",
        "#         # Calculate mean loss\n",
        "#         mean_loss = np.mean(epoch_losses)\n",
        "#         train_epoch_losses.append(mean_loss)\n",
        "\n",
        "#         # Update progress bar\n",
        "#         pbar.set_postfix({\n",
        "#             'Loss': f'{mean_loss:.4f}',\n",
        "#             'LR': f'{scheduler.get_last_lr()[0]:.6f}'\n",
        "#         })\n",
        "\n",
        "#         # Log every 50 epochs\n",
        "#         if epoch % 50 == 0:\n",
        "#             print(f\"Epoch {epoch}: Loss = {mean_loss:.4f}\")\n",
        "\n",
        "#     return train_epoch_losses\n",
        "\n",
        "# # =============================================================================\n",
        "# # GENERATION FUNCTION\n",
        "# # =============================================================================\n",
        "\n",
        "# def generate_sequences(model, diffuser, n_sequences=100, sequence_length=50, device='cpu'):\n",
        "#     \"\"\"Generate new transaction sequences\"\"\"\n",
        "#     model.eval()\n",
        "\n",
        "#     generated_sequences = []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         # Generate in batches\n",
        "#         batch_size = 32\n",
        "#         n_batches = (n_sequences + batch_size - 1) // batch_size\n",
        "\n",
        "#         for batch_idx in tqdm(range(n_batches), desc=\"Generating sequences\"):\n",
        "#             current_batch_size = min(batch_size, n_sequences - batch_idx * batch_size)\n",
        "\n",
        "#             # Start from pure noise\n",
        "#             shape = (current_batch_size, sequence_length, model.input_projection[0].in_features)\n",
        "#             x = diffuser.sample_student_t(shape).to(device)\n",
        "\n",
        "#             # Reverse diffusion process\n",
        "#             for t in range(diffuser.total_steps - 1, -1, -1):\n",
        "#                 timesteps = torch.full((current_batch_size,), t, device=device, dtype=torch.long)\n",
        "\n",
        "#                 # Predict noise\n",
        "#                 predicted_noise = model(x, timesteps)\n",
        "\n",
        "#                 # Sample for this timestep\n",
        "#                 x = diffuser.p_sample_t_sequence(predicted_noise, x, timesteps)\n",
        "\n",
        "#             generated_sequences.append(x.cpu())\n",
        "\n",
        "#     return torch.cat(generated_sequences, dim=0)\n",
        "\n",
        "# # =============================================================================\n",
        "# # MAIN EXECUTION\n",
        "# # =============================================================================\n",
        "\n",
        "# def main():\n",
        "#     print(\"Loading and preprocessing data...\")\n",
        "\n",
        "#     # Load your data\n",
        "#     # real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "#     # For demonstration, create sample data structure\n",
        "#     # You should uncomment the line above and comment out the sample data creation\n",
        "\n",
        "#     # Sample data creation (replace with your actual data loading)\n",
        "#     np.random.seed(42)\n",
        "#     n_accounts = 100\n",
        "#     n_transactions = 10000\n",
        "\n",
        "#     sample_data = []\n",
        "#     for i in range(n_transactions):\n",
        "#         account_id = np.random.randint(1, n_accounts + 1)\n",
        "#         date = 950101 + np.random.randint(0, 3650)  # Random date in range\n",
        "#         amount = np.random.lognormal(3, 1) * 100\n",
        "#         transaction_type = np.random.choice(['CREDIT', 'DEBIT'])\n",
        "#         operation = np.random.choice(['CREDIT IN CASH', 'CASH WITHDRAWAL',\n",
        "#                                     'COLLECTION FROM ANOTHER BANK', 'REMITTANCE TO ANOTHER BANK'])\n",
        "#         k_symbol = np.random.choice(['nan', 'PAYMENT ON STATEMENT', 'HOUSEHOLD', 'INTEREST CREDITED'])\n",
        "#         age = np.random.randint(18, 80)\n",
        "\n",
        "#         sample_data.append({\n",
        "#             'account_id': account_id,\n",
        "#             'date': date,\n",
        "#             'amount': amount,\n",
        "#             'type': transaction_type,\n",
        "#             'operation': operation,\n",
        "#             'k_symbol': k_symbol,\n",
        "#             'age': age\n",
        "#         })\n",
        "\n",
        "#     real = pd.DataFrame(sample_data)\n",
        "#     # End of sample data creation\n",
        "\n",
        "#     real = real.sort_values(by=[\"account_id\", \"date\"])\n",
        "#     raw_data, LOG_AMOUNT_SCALE, TD_SCALE = preprocess_data_czech(real)\n",
        "\n",
        "#     # Define attributes\n",
        "#     cat_attrs = ['age', 'day', 'td', 'month', 'tcode']\n",
        "#     num_attrs = ['amount', 'raw_amount', 'account_id', 'year', 'balance', 'log_balance']\n",
        "\n",
        "#     print(\"Encoding features...\")\n",
        "\n",
        "#     # Encode categorical attributes\n",
        "#     df_trans_filtered = raw_data[cat_attrs + num_attrs].copy()\n",
        "\n",
        "#     # Label encode categorical attributes\n",
        "#     label_encoders = {}\n",
        "#     for attr in cat_attrs:\n",
        "#         le = LabelEncoder()\n",
        "#         df_trans_filtered[attr] = le.fit_transform(df_trans_filtered[attr].astype(str))\n",
        "#         label_encoders[attr] = le\n",
        "\n",
        "#     # Scale numerical attributes\n",
        "#     num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "#     df_trans_filtered[num_attrs] = num_scaler.fit_transform(df_trans_filtered[num_attrs])\n",
        "\n",
        "#     print(\"Creating sequential dataset...\")\n",
        "\n",
        "#     # Create sequential dataset\n",
        "#     seq_dataset = SequentialBankingDataset(\n",
        "#         df=raw_data,  # Use original data with datetime for sequencing\n",
        "#         cat_attrs=cat_attrs,\n",
        "#         num_attrs=num_attrs,\n",
        "#         sequence_length=sequence_length,\n",
        "#         min_seq_length=min_seq_length,\n",
        "#         stride=10\n",
        "#     )\n",
        "\n",
        "#     # Create dataloader\n",
        "#     seq_dataloader = DataLoader(\n",
        "#         seq_dataset,\n",
        "#         batch_size=batch_size,\n",
        "#         shuffle=True,\n",
        "#         num_workers=0\n",
        "#     )\n",
        "\n",
        "#     print(\"Initializing model...\")\n",
        "\n",
        "#     # Calculate dimensions\n",
        "#     n_cat_tokens = max([len(np.unique(df_trans_filtered[attr])) for attr in cat_attrs]) + 1\n",
        "#     cat_dim = cat_emb_dim * len(cat_attrs)\n",
        "#     num_dim = len(num_attrs)\n",
        "#     encoded_dim = cat_dim + num_dim\n",
        "\n",
        "#     # Initialize model\n",
        "#     model = SequentialLSTMSynthesizer(\n",
        "#         d_in=encoded_dim,\n",
        "#         hidden_layers=mlp_layers,\n",
        "#         activation=activation,\n",
        "#         dim_t=64,\n",
        "#         n_cat_tokens=n_cat_tokens,\n",
        "#         n_cat_emb=cat_emb_dim,\n",
        "#         sequence_length=sequence_length,\n",
        "#         lstm_layers=2,\n",
        "#         dropout=dropout_rate,\n",
        "#         use_attention=True\n",
        "#     )\n",
        "\n",
        "#     # Initialize diffuser\n",
        "#     diffuser = SequentialStudentTDDPMDiffuser(\n",
        "#         total_steps=diffusion_steps,\n",
        "#         beta_start=diffusion_beta_start,\n",
        "#         beta_end=diffusion_beta_end,\n",
        "#         scheduler='exp',\n",
        "#         device=device,\n",
        "#         df=10\n",
        "#     )\n",
        "\n",
        "#     # Initialize optimizer and scheduler\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "#     scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "#     print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "#     print(f\"Training on {len(seq_dataset)} sequences\")\n",
        "\n",
        "#     # Train model\n",
        "#     print(\"Starting training...\")\n",
        "#     train_losses = train_sequential_model(\n",
        "#         model=model,\n",
        "#         diffuser=diffuser,\n",
        "#         dataloader=seq_dataloader,\n",
        "#         optimizer=optimizer,\n",
        "#         scheduler=scheduler,\n",
        "#         device=device,\n",
        "#         epochs=epochs\n",
        "#     )\n",
        "\n",
        "#     print(\"Training completed!\")\n",
        "\n",
        "#     # Generate new sequences\n",
        "#     print(\"Generating new sequences...\")\n",
        "#     n_generate = 50\n",
        "#     generated_seqs = generate_sequences(\n",
        "#         model=model,\n",
        "#         diffuser=diffuser,\n",
        "#         n_sequences=n_generate,\n",
        "#         sequence_length=sequence_length,\n",
        "#         device=device\n",
        "#     )\n",
        "\n",
        "#     print(f\"Generated {generated_seqs.shape[0]} sequences of length {generated_seqs.shape[1]}\")\n",
        "\n",
        "#     # Save results\n",
        "#     torch.save({\n",
        "#         'model_state_dict': model.state_dict(),\n",
        "#         'generated_sequences': generated_seqs,\n",
        "#         'train_losses': train_losses,\n",
        "#         'label_encoders': label_encoders,\n",
        "#         'num_scaler': num_scaler,\n",
        "#         'cat_attrs': cat_attrs,\n",
        "#         'num_attrs': num_attrs,\n",
        "#         'LOG_AMOUNT_SCALE': LOG_AMOUNT_SCALE,\n",
        "#         'TD_SCALE': TD_SCALE\n",
        "#     }, 'sequential_banking_model.pth')\n",
        "\n",
        "#     print(\"Results saved to 'sequential_banking_model.pth'\")\n",
        "\n",
        "#     return model, diffuser, generated_seqs, train_losses\n",
        "\n",
        "# real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "\n",
        "# model, diffuser, generated_sequences, losses = main()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION AND SETUP\n",
        "# =============================================================================\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Model hyperparameters\n",
        "sequence_length = 50  # Number of transactions per sequence\n",
        "min_seq_length = 20   # Minimum sequence length for an account\n",
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "epochs = 500\n",
        "diffusion_steps = 1000\n",
        "diffusion_beta_start = 1e-4\n",
        "diffusion_beta_end = 0.02\n",
        "cat_emb_dim = 16\n",
        "mlp_layers = [256, 128]\n",
        "activation = 'relu'\n",
        "dropout_rate = 0.1\n",
        "\n",
        "# =============================================================================\n",
        "# DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "\n",
        "def preprocess_data_czech(df):\n",
        "    \"\"\"Enhanced preprocessing function for Czech banking data\"\"\"\n",
        "\n",
        "    # Parse dates\n",
        "\n",
        "    czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "    df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "    #df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
        "\n",
        "    df[\"month\"] = df[\"datetime\"].dt.month\n",
        "    df[\"day\"] = df[\"datetime\"].dt.day\n",
        "    df[\"dow\"] =  df[\"datetime\"].dt.dayofweek\n",
        "    df[\"year\"] = df[\"datetime\"].dt.year\n",
        "    df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "    df[\"td\"] = df[[\"account_id\", \"datetime\"]].groupby(\"account_id\").diff()\n",
        "    df[\"td\"] = df[\"td\"].apply(lambda x: x.days)\n",
        "    df[\"td\"].fillna(0.0, inplace=True)\n",
        "\n",
        "\n",
        "    # dtme - days till month end\n",
        "    df[\"dtme\"] = df.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "\n",
        "    df['raw_amount'] = df.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "\n",
        "    cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "    TCODE_SEP = \"__\"\n",
        "    # create tcode by concating fields in \"cat_code_fields\"\n",
        "    tcode = df[cat_code_fields[0]].astype(str)\n",
        "    for ccf in cat_code_fields[1:]:\n",
        "        tcode += TCODE_SEP + df[ccf].astype(str)\n",
        "\n",
        "    df[\"tcode\"] = tcode\n",
        "\n",
        "    conditions = [\n",
        "    (df['day'] >= 1) & (df['day'] <= 10),\n",
        "    (df['day'] > 10) & (df['day'] <= 20),\n",
        "    (df['day'] > 20) & (df['day'] <= 31)\n",
        "      ]\n",
        "\n",
        "    categories = ['first', 'middle', 'last']\n",
        "\n",
        "    # Use numpy.select() to map the numbers to categories\n",
        "    df['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "\n",
        "    bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "    labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "\n",
        "    # Use pd.cut() to convert ages to categorical groups\n",
        "    df['age_group'] = pd.cut(df['age'], bins=bin_edges, labels=labels, right=False)\n",
        "    df['age_group'] = df['age_group'].astype('object')\n",
        "\n",
        "    result = df.groupby('account_id')['datetime'].agg(['min', 'max'])\n",
        "    result['duration'] = result['max'] - result['min']\n",
        "    result_sorted = result.sort_values('duration', ascending=False)\n",
        "\n",
        "    df['log_amount'] = np.log10(df['amount'] + 1)\n",
        "    LOG_AMOUNT_SCALE = df['log_amount'].std()\n",
        "    df['log_amount_sc'] = df['log_amount']/ LOG_AMOUNT_SCALE\n",
        "    TD_SCALE = df['td'].std()\n",
        "    df['td_sc'] = df['td']/TD_SCALE\n",
        "\n",
        "    return df, LOG_AMOUNT_SCALE, TD_SCALE\n",
        "\n",
        "# =============================================================================\n",
        "# SEQUENTIAL DATASET CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class SequentialBankingDataset(Dataset):\n",
        "    \"\"\"Dataset that creates sequences of transactions per account\"\"\"\n",
        "\n",
        "    def __init__(self, df, cat_attrs, num_attrs, sequence_length=50, min_seq_length=20, stride=10):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.min_seq_length = min_seq_length\n",
        "        self.cat_attrs = cat_attrs\n",
        "        self.num_attrs = num_attrs\n",
        "        self.stride = stride\n",
        "\n",
        "        self.sequences = []\n",
        "        self.account_info = {}\n",
        "\n",
        "        print(\"Creating sequences from transaction data...\")\n",
        "\n",
        "        # Group by account and create sequences\n",
        "        for account_id in tqdm(df['account_id'].unique()):\n",
        "            account_data = df[df['account_id'] == account_id].sort_values('datetime').reset_index(drop=True)\n",
        "\n",
        "            if len(account_data) >= min_seq_length:\n",
        "                # Store account metadata\n",
        "                self.account_info[account_id] = {\n",
        "                    'age': account_data['age'].iloc[0],\n",
        "                    'age_group': account_data['age_group'].iloc[0],\n",
        "                    'total_transactions': len(account_data)\n",
        "                }\n",
        "\n",
        "                # Create sliding windows with stride\n",
        "                for i in range(0, len(account_data) - sequence_length + 1, stride):\n",
        "                    seq_data = account_data.iloc[i:i+sequence_length]\n",
        "\n",
        "                    cat_data = seq_data[cat_attrs].values\n",
        "                    num_data = seq_data[num_attrs].values\n",
        "\n",
        "                    self.sequences.append({\n",
        "                        'account_id': account_id,\n",
        "                        'cat_data': cat_data,\n",
        "                        'num_data': num_data,\n",
        "                        'start_idx': i,\n",
        "                        'dates': seq_data['datetime'].values\n",
        "                    })\n",
        "\n",
        "        print(f\"Created {len(self.sequences)} sequences from {len(df['account_id'].unique())} accounts\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         seq = self.sequences[idx]\n",
        "#         return (\n",
        "#             torch.LongTensor(seq['cat_data']),\n",
        "#             torch.FloatTensor(seq['num_data']),\n",
        "#             seq['account_id']\n",
        "#         )\n",
        "\n",
        "    # def __getitem__(self, idx):\n",
        "    #     # 'self.sequences' should be built using the 'tcode_encoded' column\n",
        "    #     seq = self.sequences[idx]\n",
        "\n",
        "    #     # This line now works because seq['cat_data'] contains numbers (e.g., [0, 1, 5, 2])\n",
        "    #     # instead of strings (e.g., ['DEBIT...', 'CREDIT...', etc.]).\n",
        "    #     cat_tensor = torch.LongTensor(seq['cat_data'])\n",
        "\n",
        "    #     num_tensor = torch.FloatTensor(seq['num_data'])\n",
        "    #     account_id = seq['account_id']\n",
        "\n",
        "    #     return (cat_tensor, num_tensor, account_id)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "\n",
        "        # Ensure cat_data is a flat list/array of integers\n",
        "        cat_data = np.array(seq['cat_data'], dtype=np.int64)  # force integer type\n",
        "        cat_tensor = torch.LongTensor(cat_data)\n",
        "\n",
        "        # Ensure num_data is a flat list/array of floats\n",
        "        num_data = np.array(seq['num_data'], dtype=np.float32)  # force float type\n",
        "        num_tensor = torch.FloatTensor(num_data)\n",
        "\n",
        "        account_id = seq['account_id']\n",
        "\n",
        "        return (cat_tensor, num_tensor, account_id)\n",
        "\n",
        "# =============================================================================\n",
        "# SEQUENTIAL LSTM SYNTHESIZER MODEL\n",
        "# =============================================================================\n",
        "\n",
        "class SequentialLSTMSynthesizer(nn.Module):\n",
        "    \"\"\"Enhanced LSTM model for sequential transaction generation\"\"\"\n",
        "\n",
        "    def __init__(self, d_in, hidden_layers, activation='relu',\n",
        "                 dim_t=64, n_cat_tokens=None, n_cat_emb=None,\n",
        "                 sequence_length=50, lstm_layers=2, bidirectional=False,\n",
        "                 dropout=0.1, use_attention=True):\n",
        "        super(SequentialLSTMSynthesizer, self).__init__()\n",
        "\n",
        "        self.dim_t = dim_t\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.sequence_length = sequence_length\n",
        "        self.use_attention = use_attention\n",
        "\n",
        "        # Categorical embeddings\n",
        "        self.cat_embedding = nn.Embedding(n_cat_tokens, n_cat_emb)\n",
        "\n",
        "        # Input projection for combined cat + num features\n",
        "        self.input_projection = nn.Sequential(\n",
        "            nn.Linear(d_in, dim_t),\n",
        "            self._get_activation(activation),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim_t, dim_t)\n",
        "        )\n",
        "\n",
        "        # Time embedding layers\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(dim_t, dim_t),\n",
        "            self._get_activation(activation),\n",
        "            nn.Linear(dim_t, dim_t)\n",
        "        )\n",
        "\n",
        "        # Sequential LSTM backbone\n",
        "        lstm_input_size = dim_t\n",
        "        lstm_hidden_size = hidden_layers[0] if hidden_layers else dim_t\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=lstm_input_size,\n",
        "            hidden_size=lstm_hidden_size,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Attention mechanism for better sequence modeling\n",
        "        lstm_output_size = lstm_hidden_size * 2 if bidirectional else lstm_hidden_size\n",
        "\n",
        "        if use_attention:\n",
        "            self.attention = nn.MultiheadAttention(\n",
        "                embed_dim=lstm_output_size,\n",
        "                num_heads=8,\n",
        "                dropout=dropout,\n",
        "                batch_first=True\n",
        "            )\n",
        "            self.norm1 = nn.LayerNorm(lstm_output_size)\n",
        "\n",
        "        # Output projection layers\n",
        "        output_layers = []\n",
        "        current_dim = lstm_output_size\n",
        "\n",
        "        for hidden_dim in hidden_layers[1:]:\n",
        "            output_layers.extend([\n",
        "                nn.Linear(current_dim, hidden_dim),\n",
        "                self._get_activation(activation),\n",
        "                nn.Dropout(dropout)\n",
        "            ])\n",
        "            current_dim = hidden_dim\n",
        "\n",
        "        output_layers.append(nn.Linear(current_dim, d_in))\n",
        "        self.output_layers = nn.Sequential(*output_layers)\n",
        "\n",
        "    def _get_activation(self, activation):\n",
        "        \"\"\"Get activation function\"\"\"\n",
        "        if activation == 'relu':\n",
        "            return nn.ReLU()\n",
        "        elif activation == 'lrelu':\n",
        "            return nn.LeakyReLU(0.2)\n",
        "        elif activation == 'silu':\n",
        "            return nn.SiLU()\n",
        "        elif activation == 'gelu':\n",
        "            return nn.GELU()\n",
        "        else:\n",
        "            return nn.ReLU()\n",
        "\n",
        "    def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "        \"\"\"Sinusoidal time embedding\"\"\"\n",
        "        half_dim_out = dim_out // 2\n",
        "        freqs = torch.exp(-math.log(max_period) * torch.arange(\n",
        "            start=0, end=half_dim_out, dtype=torch.float32) / half_dim_out)\n",
        "        freqs = freqs.to(device=timesteps.device)\n",
        "\n",
        "        args = timesteps[:, None].float() * freqs[None]\n",
        "        time_embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "\n",
        "        if dim_out % 2:\n",
        "            time_embedding = torch.cat([\n",
        "                time_embedding,\n",
        "                torch.zeros_like(time_embedding[:, :1])\n",
        "            ], dim=-1)\n",
        "\n",
        "        return time_embedding\n",
        "\n",
        "    def embed_categorical(self, x_cat):\n",
        "        \"\"\"Embed categorical variables\"\"\"\n",
        "        batch_size, seq_len, n_cat = x_cat.shape\n",
        "\n",
        "        # Process each categorical feature separately and concatenate\n",
        "        cat_embeddings = []\n",
        "        for i in range(n_cat):\n",
        "            cat_emb = self.cat_embedding(x_cat[:, :, i])  # (batch_size, seq_len, emb_dim)\n",
        "            cat_embeddings.append(cat_emb)\n",
        "\n",
        "        # Concatenate all categorical embeddings\n",
        "        x_cat_emb = torch.cat(cat_embeddings, dim=-1)  # (batch_size, seq_len, n_cat * emb_dim)\n",
        "\n",
        "        return x_cat_emb\n",
        "\n",
        "    def forward(self, x_seq, timesteps):\n",
        "        \"\"\"\n",
        "        Forward pass for sequence data\n",
        "        x_seq: (batch_size, seq_len, features)\n",
        "        timesteps: (batch_size,)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = x_seq.shape\n",
        "\n",
        "        # Time embedding (broadcast to all sequence positions)\n",
        "        time_emb = self.embed_time(timesteps, self.dim_t)\n",
        "        time_emb = self.time_embed(time_emb)\n",
        "        time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "        # Input projection\n",
        "        x = self.input_projection(x_seq)\n",
        "\n",
        "        # Add time embedding\n",
        "        x = x + time_emb\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Self-attention for better sequence modeling\n",
        "        if self.use_attention:\n",
        "            attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
        "            x = self.norm1(lstm_out + attn_out)\n",
        "        else:\n",
        "            x = lstm_out\n",
        "\n",
        "        # Output projection\n",
        "        output = self.output_layers(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "# =============================================================================\n",
        "# STUDENT-T DDPM DIFFUSER FOR SEQUENCES\n",
        "# =============================================================================\n",
        "\n",
        "class SequentialStudentTDDPMDiffuser:\n",
        "    \"\"\"Student-t distribution DDPM diffuser for sequential data\"\"\"\n",
        "\n",
        "    def __init__(self, total_steps=1000, beta_start=1e-4, beta_end=0.02,\n",
        "                 device='cpu', scheduler='exp', df=10):\n",
        "        self.total_steps = total_steps\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.device = device\n",
        "        self.df = df\n",
        "\n",
        "        self.alphas, self.betas = self.prepare_noise_schedule(scheduler=scheduler)\n",
        "        self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "    def prepare_noise_schedule(self, scheduler: str):\n",
        "        \"\"\"Prepare noise schedule\"\"\"\n",
        "        scale = 1000 / self.total_steps\n",
        "        beta_start = scale * self.beta_start\n",
        "        beta_end = scale * self.beta_end\n",
        "\n",
        "        if scheduler == 'linear':\n",
        "            betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "        elif scheduler == 'quad':\n",
        "            betas = torch.linspace(self.beta_start**0.5, self.beta_end**0.5, self.total_steps) ** 2\n",
        "        elif scheduler == 'exp':\n",
        "            betas = torch.exp(torch.linspace(\n",
        "                math.log(beta_start), math.log(beta_end), self.total_steps))\n",
        "        elif scheduler == 'sigm':\n",
        "            x = torch.linspace(-6, 6, self.total_steps)\n",
        "            betas = torch.sigmoid(x) * (beta_end - beta_start) + beta_start\n",
        "        else:\n",
        "            betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "\n",
        "        alphas = 1.0 - betas\n",
        "        return alphas.to(self.device), betas.to(self.device)\n",
        "\n",
        "    def sample_random_timesteps(self, n: int):\n",
        "        \"\"\"Sample random timesteps\"\"\"\n",
        "        t = torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "        return t\n",
        "\n",
        "    def sample_student_t(self, shape):\n",
        "        \"\"\"Generate samples from Student's t-distribution\"\"\"\n",
        "        if self.df <= 2:\n",
        "            df_sample = 3.0\n",
        "        else:\n",
        "            df_sample = float(self.df)\n",
        "\n",
        "        # For simplicity, use scaled normal distribution as approximation\n",
        "        # For production, implement proper t-distribution sampling\n",
        "        x = torch.randn(shape, device=self.device)\n",
        "\n",
        "        # Simple scaling for t-distribution approximation\n",
        "        if df_sample > 2:\n",
        "            scale = math.sqrt(df_sample / (df_sample - 2))\n",
        "            x = x * scale\n",
        "\n",
        "        return x\n",
        "\n",
        "    def add_t_noise_sequence(self, x_seq, t):\n",
        "        \"\"\"Add noise to sequence data\"\"\"\n",
        "        batch_size, seq_len, features = x_seq.shape\n",
        "\n",
        "        sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None, None]\n",
        "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None, None]\n",
        "\n",
        "        # Generate t-distributed noise for the entire sequence\n",
        "        noise_seq = self.sample_student_t((batch_size, seq_len, features))\n",
        "\n",
        "        x_noise_seq = sqrt_alpha_hat * x_seq + sqrt_one_minus_alpha_hat * noise_seq\n",
        "\n",
        "        return x_noise_seq, noise_seq\n",
        "\n",
        "    def p_sample_t_sequence(self, model_out, z_norm, timesteps):\n",
        "        \"\"\"Sampling step for sequences\"\"\"\n",
        "        batch_size, seq_len, features = z_norm.shape\n",
        "\n",
        "        sqrt_alpha_t = torch.sqrt(self.alphas[timesteps])[:, None, None]\n",
        "        betas_t = self.betas[timesteps][:, None, None]\n",
        "        sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[timesteps])[:, None, None]\n",
        "        epsilon_t = torch.sqrt(self.betas[timesteps])[:, None, None]\n",
        "\n",
        "        # Generate random noise\n",
        "        random_noise = self.sample_student_t((batch_size, seq_len, features))\n",
        "        random_noise[timesteps == 0] = 0.0\n",
        "\n",
        "        # Calculate model mean\n",
        "        model_mean = ((1 / sqrt_alpha_t) * (z_norm - (betas_t * model_out / sqrt_one_minus_alpha_hat_t)))\n",
        "\n",
        "        # Add noise\n",
        "        z_norm = model_mean + (epsilon_t * random_noise)\n",
        "\n",
        "        return z_norm\n",
        "\n",
        "# =============================================================================\n",
        "# TRAINING FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def train_sequential_model(model, diffuser, dataloader, optimizer, scheduler, device, epochs=100):\n",
        "    \"\"\"Training loop for sequential transaction model\"\"\"\n",
        "    model.train()\n",
        "    model = model.to(device)\n",
        "\n",
        "    loss_fnc = nn.MSELoss()\n",
        "    train_epoch_losses = []\n",
        "\n",
        "    pbar = tqdm(range(epochs), desc=\"Training\")\n",
        "\n",
        "    for epoch in pbar:\n",
        "        epoch_losses = []\n",
        "\n",
        "        for batch_cat, batch_num, account_ids in dataloader:\n",
        "            batch_cat = batch_cat.to(device)\n",
        "            batch_num = batch_num.to(device)\n",
        "\n",
        "            batch_size, seq_len, _ = batch_cat.shape\n",
        "\n",
        "            # Embed categorical variables\n",
        "            batch_cat_emb = model.embed_categorical(batch_cat)\n",
        "\n",
        "            # Combine categorical and numerical features\n",
        "            batch_combined = torch.cat([batch_cat_emb, batch_num], dim=-1)\n",
        "\n",
        "            # Sample timesteps\n",
        "            timesteps = diffuser.sample_random_timesteps(batch_size)\n",
        "\n",
        "            # Add noise to the entire sequence\n",
        "            batch_noisy, noise_target = diffuser.add_t_noise_sequence(batch_combined, timesteps)\n",
        "\n",
        "            # Forward pass\n",
        "            predicted_noise = model(batch_noisy, timesteps)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fnc(predicted_noise, noise_target)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_losses.append(loss.item())\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate mean loss\n",
        "        mean_loss = np.mean(epoch_losses)\n",
        "        train_epoch_losses.append(mean_loss)\n",
        "\n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            'Loss': f'{mean_loss:.4f}',\n",
        "            'LR': f'{scheduler.get_last_lr()[0]:.6f}'\n",
        "        })\n",
        "\n",
        "        # Log every 50 epochs\n",
        "        if epoch % 50 == 0:\n",
        "            print(f\"Epoch {epoch}: Loss = {mean_loss:.4f}\")\n",
        "\n",
        "    return train_epoch_losses\n",
        "\n",
        "# =============================================================================\n",
        "# GENERATION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def generate_sequences(model, diffuser, n_sequences=100, sequence_length=50, device='cpu'):\n",
        "    \"\"\"Generate new transaction sequences\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    generated_sequences = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Generate in batches\n",
        "        batch_size = 32\n",
        "        n_batches = (n_sequences + batch_size - 1) // batch_size\n",
        "\n",
        "        for batch_idx in tqdm(range(n_batches), desc=\"Generating sequences\"):\n",
        "            current_batch_size = min(batch_size, n_sequences - batch_idx * batch_size)\n",
        "\n",
        "            # Start from pure noise\n",
        "            shape = (current_batch_size, sequence_length, model.input_projection[0].in_features)\n",
        "            x = diffuser.sample_student_t(shape).to(device)\n",
        "\n",
        "            # Reverse diffusion process\n",
        "            for t in range(diffuser.total_steps - 1, -1, -1):\n",
        "                timesteps = torch.full((current_batch_size,), t, device=device, dtype=torch.long)\n",
        "\n",
        "                # Predict noise\n",
        "                predicted_noise = model(x, timesteps)\n",
        "\n",
        "                # Sample for this timestep\n",
        "                x = diffuser.p_sample_t_sequence(predicted_noise, x, timesteps)\n",
        "\n",
        "            generated_sequences.append(x.cpu())\n",
        "\n",
        "    return torch.cat(generated_sequences, dim=0)\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN EXECUTION\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "\n",
        "    # Load your data\n",
        "    # real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "    # For demonstration, create sample data structure\n",
        "    # You should uncomment the line above and comment out the sample data creation\n",
        "\n",
        "    # Sample data creation (replace with your actual data loading)\n",
        "    np.random.seed(42)\n",
        "    n_accounts = 100\n",
        "    n_transactions = 10000\n",
        "\n",
        "    sample_data = []\n",
        "    for i in range(n_transactions):\n",
        "        account_id = np.random.randint(1, n_accounts + 1)\n",
        "        date = 950101 + np.random.randint(0, 3650)  # Random date in range\n",
        "        amount = np.random.lognormal(3, 1) * 100\n",
        "        transaction_type = np.random.choice(['CREDIT', 'DEBIT'])\n",
        "        operation = np.random.choice(['CREDIT IN CASH', 'CASH WITHDRAWAL',\n",
        "                                    'COLLECTION FROM ANOTHER BANK', 'REMITTANCE TO ANOTHER BANK'])\n",
        "        k_symbol = np.random.choice(['nan', 'PAYMENT ON STATEMENT', 'HOUSEHOLD', 'INTEREST CREDITED'])\n",
        "        age = np.random.randint(18, 80)\n",
        "\n",
        "        sample_data.append({\n",
        "            'account_id': account_id,\n",
        "            'date': date,\n",
        "            'amount': amount,\n",
        "            'type': transaction_type,\n",
        "            'operation': operation,\n",
        "            'k_symbol': k_symbol,\n",
        "            'age': age\n",
        "        })\n",
        "\n",
        "    real = pd.DataFrame(sample_data)\n",
        "    # End of sample data creation\n",
        "\n",
        "    real = real.sort_values(by=[\"account_id\", \"date\"])\n",
        "    raw_data=pd.read_csv('raw_data.csv')\n",
        "    LOG_AMOUNT_SCALE=1.0625705442977056\n",
        "\n",
        "    TD_SCALE=6.063912193703339\n",
        "\n",
        "#     raw_data, LOG_AMOUNT_SCALE, TD_SCALE = preprocess_data_czech(real)\n",
        "\n",
        "    # Define attributes\n",
        "    cat_attrs = ['age', 'day', 'td', 'month', 'tcode']\n",
        "    num_attrs = ['amount', 'raw_amount', 'account_id', 'year', 'balance', 'log_balance']\n",
        "\n",
        "    print(\"Encoding features...\")\n",
        "\n",
        "    # Encode categorical attributes\n",
        "    df_trans_filtered = raw_data[cat_attrs + num_attrs].copy()\n",
        "\n",
        "    # Label encode categorical attributes\n",
        "    label_encoders = {}\n",
        "    for attr in cat_attrs:\n",
        "        le = LabelEncoder()\n",
        "        df_trans_filtered[attr] = le.fit_transform(df_trans_filtered[attr].astype(str))\n",
        "        label_encoders[attr] = le\n",
        "\n",
        "    # Scale numerical attributes\n",
        "    num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "    df_trans_filtered[num_attrs] = num_scaler.fit_transform(df_trans_filtered[num_attrs])\n",
        "\n",
        "    print(\"Creating sequential dataset...\")\n",
        "\n",
        "    # Create sequential dataset\n",
        "    seq_dataset = SequentialBankingDataset(\n",
        "        df=raw_data,  # Use original data with datetime for sequencing\n",
        "        cat_attrs=cat_attrs,\n",
        "        num_attrs=num_attrs,\n",
        "        sequence_length=sequence_length,\n",
        "        min_seq_length=min_seq_length,\n",
        "        stride=10\n",
        "    )\n",
        "\n",
        "    # Create dataloader\n",
        "    seq_dataloader = DataLoader(\n",
        "        seq_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    print(\"Initializing model...\")\n",
        "\n",
        "    # Calculate dimensions\n",
        "    n_cat_tokens = max([len(np.unique(df_trans_filtered[attr])) for attr in cat_attrs]) + 1\n",
        "    cat_dim = cat_emb_dim * len(cat_attrs)\n",
        "    num_dim = len(num_attrs)\n",
        "    encoded_dim = cat_dim + num_dim\n",
        "\n",
        "    # Initialize model\n",
        "    model = SequentialLSTMSynthesizer(\n",
        "        d_in=encoded_dim,\n",
        "        hidden_layers=mlp_layers,\n",
        "        activation=activation,\n",
        "        dim_t=64,\n",
        "        n_cat_tokens=n_cat_tokens,\n",
        "        n_cat_emb=cat_emb_dim,\n",
        "        sequence_length=sequence_length,\n",
        "        lstm_layers=2,\n",
        "        dropout=dropout_rate,\n",
        "        use_attention=True\n",
        "    )\n",
        "\n",
        "    # Initialize diffuser\n",
        "    diffuser = SequentialStudentTDDPMDiffuser(\n",
        "        total_steps=diffusion_steps,\n",
        "        beta_start=diffusion_beta_start,\n",
        "        beta_end=diffusion_beta_end,\n",
        "        scheduler='exp',\n",
        "        device=device,\n",
        "        df=10\n",
        "    )\n",
        "\n",
        "    # Initialize optimizer and scheduler\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "    print(f\"Training on {len(seq_dataset)} sequences\")\n",
        "\n",
        "    # Train model\n",
        "    print(\"Starting training...\")\n",
        "    train_losses = train_sequential_model(\n",
        "        model=model,\n",
        "        diffuser=diffuser,\n",
        "        dataloader=seq_dataloader,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        device=device,\n",
        "        epochs=epochs\n",
        "    )\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "\n",
        "    # Generate new sequences\n",
        "    print(\"Generating new sequences...\")\n",
        "    n_generate = 50\n",
        "    generated_seqs = generate_sequences(\n",
        "        model=model,\n",
        "        diffuser=diffuser,\n",
        "        n_sequences=n_generate,\n",
        "        sequence_length=sequence_length,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    print(f\"Generated {generated_seqs.shape[0]} sequences of length {generated_seqs.shape[1]}\")\n",
        "\n",
        "    # Save results\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'generated_sequences': generated_seqs,\n",
        "        'train_losses': train_losses,\n",
        "        'label_encoders': label_encoders,\n",
        "        'num_scaler': num_scaler,\n",
        "        'cat_attrs': cat_attrs,\n",
        "        'num_attrs': num_attrs,\n",
        "        'LOG_AMOUNT_SCALE': LOG_AMOUNT_SCALE,\n",
        "        'TD_SCALE': TD_SCALE\n",
        "    }, 'sequential_banking_model.pth')\n",
        "\n",
        "    print(\"Results saved to 'sequential_banking_model.pth'\")\n",
        "\n",
        "    return model, diffuser, generated_seqs, train_losses\n",
        "\n",
        "real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "model, diffuser, generated_sequences, losses = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ofj3p17ZM9nS",
        "outputId": "fad069e0-984d-4928-e859-e38af492d41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Loading and preprocessing data...\n",
            "Encoding features...\n",
            "Creating sequential dataset...\n",
            "Creating sequences from transaction data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4500/4500 [01:11<00:00, 63.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 85722 sequences from 4500 accounts\n",
            "Initializing model...\n",
            "Model has 1,183,078 parameters\n",
            "Training on 85722 sequences\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/500 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: 'CREDIT__nan__INTEREST CREDITED'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-b697bf792be0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr_by_acct_w_age.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiffuser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-b697bf792be0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m     train_losses = train_sequential_model(\n\u001b[0m\u001b[1;32m   1422\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mdiffuser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiffuser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-b697bf792be0>\u001b[0m in \u001b[0;36mtrain_sequential_model\u001b[0;34m(model, diffuser, dataloader, optimizer, scheduler, device, epochs)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \u001b[0mepoch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccount_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m             \u001b[0mbatch_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-b697bf792be0>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;31m# Ensure cat_data is a flat list/array of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0mcat_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cat_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# force integer type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m         \u001b[0mcat_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'CREDIT__nan__INTEREST CREDITED'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KrzLmIqWZDZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION AND SETUP\n",
        "# =============================================================================\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Model hyperparameters\n",
        "sequence_length = 50  # Number of transactions per sequence\n",
        "min_seq_length = 20   # Minimum sequence length for an account\n",
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "epochs = 100  # Reduced for testing\n",
        "diffusion_steps = 1000\n",
        "diffusion_beta_start = 1e-4\n",
        "diffusion_beta_end = 0.02\n",
        "cat_emb_dim = 16\n",
        "mlp_layers = [256, 128]\n",
        "activation = 'relu'\n",
        "dropout_rate = 0.1\n",
        "\n",
        "# =============================================================================\n",
        "# DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "\n",
        "def preprocess_data_czech(df):\n",
        "    \"\"\"Enhanced preprocessing function for Czech banking data\"\"\"\n",
        "\n",
        "    # Parse dates\n",
        "    czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "    df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "\n",
        "    df[\"month\"] = df[\"datetime\"].dt.month\n",
        "    df[\"day\"] = df[\"datetime\"].dt.day\n",
        "    df[\"dow\"] = df[\"datetime\"].dt.dayofweek\n",
        "    df[\"year\"] = df[\"datetime\"].dt.year\n",
        "    df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "    # Calculate time differences\n",
        "    df_sorted = df.sort_values(['account_id', 'datetime'])\n",
        "    df_sorted[\"td\"] = df_sorted.groupby(\"account_id\")[\"datetime\"].diff().dt.days\n",
        "    df_sorted[\"td\"].fillna(0.0, inplace=True)\n",
        "\n",
        "    # Days till month end\n",
        "    df_sorted[\"dtme\"] = df_sorted.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "\n",
        "    # Raw amount (considering transaction type)\n",
        "    df_sorted['raw_amount'] = df_sorted.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "    # Create transaction code\n",
        "    cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "    TCODE_SEP = \"__\"\n",
        "    tcode = df_sorted[cat_code_fields[0]].astype(str)\n",
        "    for ccf in cat_code_fields[1:]:\n",
        "        tcode += TCODE_SEP + df_sorted[ccf].astype(str)\n",
        "    df_sorted[\"tcode\"] = tcode\n",
        "\n",
        "    # Day of month categories\n",
        "    conditions = [\n",
        "        (df_sorted['day'] >= 1) & (df_sorted['day'] <= 10),\n",
        "        (df_sorted['day'] > 10) & (df_sorted['day'] <= 20),\n",
        "        (df_sorted['day'] > 20) & (df_sorted['day'] <= 31)\n",
        "    ]\n",
        "    categories = ['first', 'middle', 'last']\n",
        "    df_sorted['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "    # Age groups\n",
        "    bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "    labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "    df_sorted['age_group'] = pd.cut(df_sorted['age'], bins=bin_edges, labels=labels, right=False)\n",
        "    df_sorted['age_group'] = df_sorted['age_group'].astype('object')\n",
        "\n",
        "    # Log transformations and scaling\n",
        "    df_sorted['log_amount'] = np.log10(df_sorted['amount'] + 1)\n",
        "    LOG_AMOUNT_SCALE = df_sorted['log_amount'].std()\n",
        "    df_sorted['log_amount_sc'] = df_sorted['log_amount'] / LOG_AMOUNT_SCALE\n",
        "    TD_SCALE = df_sorted['td'].std()\n",
        "    df_sorted['td_sc'] = df_sorted['td'] / TD_SCALE\n",
        "\n",
        "    return df_sorted, LOG_AMOUNT_SCALE, TD_SCALE\n",
        "\n",
        "# =============================================================================\n",
        "# SEQUENTIAL DATASET CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class SequentialBankingDataset(Dataset):\n",
        "    \"\"\"Dataset that creates sequences of transactions per account\"\"\"\n",
        "\n",
        "    def __init__(self, df, cat_attrs, num_attrs, sequence_length=50, min_seq_length=20, stride=10):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.min_seq_length = min_seq_length\n",
        "        self.cat_attrs = cat_attrs\n",
        "        self.num_attrs = num_attrs\n",
        "        self.stride = stride\n",
        "\n",
        "        self.sequences = []\n",
        "        self.account_info = {}\n",
        "\n",
        "        print(\"Creating sequences from transaction data...\")\n",
        "\n",
        "        # Group by account and create sequences\n",
        "        for account_id in tqdm(df['account_id'].unique()):\n",
        "            account_data = df[df['account_id'] == account_id].sort_values('datetime').reset_index(drop=True)\n",
        "\n",
        "            if len(account_data) >= min_seq_length:\n",
        "                # Store account metadata\n",
        "                self.account_info[account_id] = {\n",
        "                    'age': account_data['age'].iloc[0],\n",
        "                    'total_transactions': len(account_data)\n",
        "                }\n",
        "\n",
        "                # Create sliding windows with stride\n",
        "                for i in range(0, len(account_data) - sequence_length + 1, stride):\n",
        "                    seq_data = account_data.iloc[i:i+sequence_length]\n",
        "\n",
        "                    # Get categorical and numerical data\n",
        "                    cat_data = seq_data[cat_attrs].values\n",
        "                    num_data = seq_data[num_attrs].values\n",
        "\n",
        "                    self.sequences.append({\n",
        "                        'account_id': account_id,\n",
        "                        'cat_data': cat_data,\n",
        "                        'num_data': num_data,\n",
        "                        'start_idx': i,\n",
        "                        'dates': seq_data['datetime'].values\n",
        "                    })\n",
        "\n",
        "        print(f\"Created {len(self.sequences)} sequences from {len(df['account_id'].unique())} accounts\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "\n",
        "        # Ensure cat_data is properly shaped and typed\n",
        "        cat_data = np.array(seq['cat_data'], dtype=np.int64)\n",
        "        cat_tensor = torch.LongTensor(cat_data)\n",
        "\n",
        "        # Ensure num_data is properly shaped and typed\n",
        "        num_data = np.array(seq['num_data'], dtype=np.float32)\n",
        "        num_tensor = torch.FloatTensor(num_data)\n",
        "\n",
        "        account_id = seq['account_id']\n",
        "\n",
        "        return (cat_tensor, num_tensor, account_id)\n",
        "\n",
        "# =============================================================================\n",
        "# SEQUENTIAL LSTM SYNTHESIZER MODEL\n",
        "# =============================================================================\n",
        "\n",
        "class SequentialLSTMSynthesizer(nn.Module):\n",
        "    \"\"\"Enhanced LSTM model for sequential transaction generation\"\"\"\n",
        "\n",
        "    def __init__(self, d_in, hidden_layers, activation='relu',\n",
        "                 dim_t=64, n_cat_tokens=None, n_cat_emb=None,\n",
        "                 sequence_length=50, lstm_layers=2, bidirectional=False,\n",
        "                 dropout=0.1, use_attention=True, n_cat_features=1):\n",
        "        super(SequentialLSTMSynthesizer, self).__init__()\n",
        "\n",
        "        self.dim_t = dim_t\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.sequence_length = sequence_length\n",
        "        self.use_attention = use_attention\n",
        "        self.n_cat_features = n_cat_features\n",
        "\n",
        "        # Categorical embeddings - one embedding layer per categorical feature\n",
        "        self.cat_embeddings = nn.ModuleList([\n",
        "            nn.Embedding(n_cat_tokens, n_cat_emb)\n",
        "            for _ in range(n_cat_features)\n",
        "        ])\n",
        "\n",
        "        # Input projection for combined cat + num features\n",
        "        self.input_projection = nn.Sequential(\n",
        "            nn.Linear(d_in, dim_t),\n",
        "            self._get_activation(activation),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim_t, dim_t)\n",
        "        )\n",
        "\n",
        "        # Time embedding layers\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(dim_t, dim_t),\n",
        "            self._get_activation(activation),\n",
        "            nn.Linear(dim_t, dim_t)\n",
        "        )\n",
        "\n",
        "        # Sequential LSTM backbone\n",
        "        lstm_input_size = dim_t\n",
        "        lstm_hidden_size = hidden_layers[0] if hidden_layers else dim_t\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=lstm_input_size,\n",
        "            hidden_size=lstm_hidden_size,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Attention mechanism for better sequence modeling\n",
        "        lstm_output_size = lstm_hidden_size * 2 if bidirectional else lstm_hidden_size\n",
        "\n",
        "        if use_attention:\n",
        "            self.attention = nn.MultiheadAttention(\n",
        "                embed_dim=lstm_output_size,\n",
        "                num_heads=8,\n",
        "                dropout=dropout,\n",
        "                batch_first=True\n",
        "            )\n",
        "            self.norm1 = nn.LayerNorm(lstm_output_size)\n",
        "\n",
        "        # Output projection layers\n",
        "        output_layers = []\n",
        "        current_dim = lstm_output_size\n",
        "\n",
        "        for hidden_dim in hidden_layers[1:]:\n",
        "            output_layers.extend([\n",
        "                nn.Linear(current_dim, hidden_dim),\n",
        "                self._get_activation(activation),\n",
        "                nn.Dropout(dropout)\n",
        "            ])\n",
        "            current_dim = hidden_dim\n",
        "\n",
        "        output_layers.append(nn.Linear(current_dim, d_in))\n",
        "        self.output_layers = nn.Sequential(*output_layers)\n",
        "\n",
        "    def _get_activation(self, activation):\n",
        "        \"\"\"Get activation function\"\"\"\n",
        "        if activation == 'relu':\n",
        "            return nn.ReLU()\n",
        "        elif activation == 'lrelu':\n",
        "            return nn.LeakyReLU(0.2)\n",
        "        elif activation == 'silu':\n",
        "            return nn.SiLU()\n",
        "        elif activation == 'gelu':\n",
        "            return nn.GELU()\n",
        "        else:\n",
        "            return nn.ReLU()\n",
        "\n",
        "    def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "        \"\"\"Sinusoidal time embedding\"\"\"\n",
        "        half_dim_out = dim_out // 2\n",
        "        freqs = torch.exp(-math.log(max_period) * torch.arange(\n",
        "            start=0, end=half_dim_out, dtype=torch.float32) / half_dim_out)\n",
        "        freqs = freqs.to(device=timesteps.device)\n",
        "\n",
        "        args = timesteps[:, None].float() * freqs[None]\n",
        "        time_embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "\n",
        "        if dim_out % 2:\n",
        "            time_embedding = torch.cat([\n",
        "                time_embedding,\n",
        "                torch.zeros_like(time_embedding[:, :1])\n",
        "            ], dim=-1)\n",
        "\n",
        "        return time_embedding\n",
        "\n",
        "    def embed_categorical(self, x_cat):\n",
        "        \"\"\"Embed categorical variables\"\"\"\n",
        "        batch_size, seq_len, n_cat = x_cat.shape\n",
        "\n",
        "        # Process each categorical feature separately and concatenate\n",
        "        cat_embeddings = []\n",
        "        for i in range(min(n_cat, len(self.cat_embeddings))):\n",
        "            cat_emb = self.cat_embeddings[i](x_cat[:, :, i])\n",
        "            cat_embeddings.append(cat_emb)\n",
        "\n",
        "        # Concatenate all categorical embeddings\n",
        "        if cat_embeddings:\n",
        "            x_cat_emb = torch.cat(cat_embeddings, dim=-1)\n",
        "        else:\n",
        "            # Fallback if no categorical features\n",
        "            x_cat_emb = torch.zeros(batch_size, seq_len, 0, device=x_cat.device)\n",
        "\n",
        "        return x_cat_emb\n",
        "\n",
        "    def forward(self, x_seq, timesteps):\n",
        "        \"\"\"\n",
        "        Forward pass for sequence data\n",
        "        x_seq: (batch_size, seq_len, features)\n",
        "        timesteps: (batch_size,)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = x_seq.shape\n",
        "\n",
        "        # Time embedding (broadcast to all sequence positions)\n",
        "        time_emb = self.embed_time(timesteps, self.dim_t)\n",
        "        time_emb = self.time_embed(time_emb)\n",
        "        time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "        # Input projection\n",
        "        x = self.input_projection(x_seq)\n",
        "\n",
        "        # Add time embedding\n",
        "        x = x + time_emb\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Self-attention for better sequence modeling\n",
        "        if self.use_attention:\n",
        "            attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
        "            x = self.norm1(lstm_out + attn_out)\n",
        "        else:\n",
        "            x = lstm_out\n",
        "\n",
        "        # Output projection\n",
        "        output = self.output_layers(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "# =============================================================================\n",
        "# STUDENT-T DDPM DIFFUSER FOR SEQUENCES\n",
        "# =============================================================================\n",
        "\n",
        "class SequentialStudentTDDPMDiffuser:\n",
        "    \"\"\"Student-t distribution DDPM diffuser for sequential data\"\"\"\n",
        "\n",
        "    def __init__(self, total_steps=1000, beta_start=1e-4, beta_end=0.02,\n",
        "                 device='cpu', scheduler='exp', df=10):\n",
        "        self.total_steps = total_steps\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.device = device\n",
        "        self.df = df\n",
        "\n",
        "        self.alphas, self.betas = self.prepare_noise_schedule(scheduler=scheduler)\n",
        "        self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "    def prepare_noise_schedule(self, scheduler: str):\n",
        "        \"\"\"Prepare noise schedule\"\"\"\n",
        "        scale = 1000 / self.total_steps\n",
        "        beta_start = scale * self.beta_start\n",
        "        beta_end = scale * self.beta_end\n",
        "\n",
        "        if scheduler == 'linear':\n",
        "            betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "        elif scheduler == 'quad':\n",
        "            betas = torch.linspace(self.beta_start**0.5, self.beta_end**0.5, self.total_steps) ** 2\n",
        "        elif scheduler == 'exp':\n",
        "            betas = torch.exp(torch.linspace(\n",
        "                math.log(beta_start), math.log(beta_end), self.total_steps))\n",
        "        elif scheduler == 'sigm':\n",
        "            x = torch.linspace(-6, 6, self.total_steps)\n",
        "            betas = torch.sigmoid(x) * (beta_end - beta_start) + beta_start\n",
        "        else:\n",
        "            betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "\n",
        "        alphas = 1.0 - betas\n",
        "        return alphas.to(self.device), betas.to(self.device)\n",
        "\n",
        "    def sample_random_timesteps(self, n: int):\n",
        "        \"\"\"Sample random timesteps\"\"\"\n",
        "        t = torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "        return t\n",
        "\n",
        "    def sample_student_t(self, shape):\n",
        "        \"\"\"Generate samples from Student's t-distribution\"\"\"\n",
        "        if self.df <= 2:\n",
        "            df_sample = 3.0\n",
        "        else:\n",
        "            df_sample = float(self.df)\n",
        "\n",
        "        # For simplicity, use scaled normal distribution as approximation\n",
        "        x = torch.randn(shape, device=self.device)\n",
        "\n",
        "        # Simple scaling for t-distribution approximation\n",
        "        if df_sample > 2:\n",
        "            scale = math.sqrt(df_sample / (df_sample - 2))\n",
        "            x = x * scale\n",
        "\n",
        "        return x\n",
        "\n",
        "    def add_t_noise_sequence(self, x_seq, t):\n",
        "        \"\"\"Add noise to sequence data\"\"\"\n",
        "        batch_size, seq_len, features = x_seq.shape\n",
        "\n",
        "        sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None, None]\n",
        "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None, None]\n",
        "\n",
        "        # Generate t-distributed noise for the entire sequence\n",
        "        noise_seq = self.sample_student_t((batch_size, seq_len, features))\n",
        "\n",
        "        x_noise_seq = sqrt_alpha_hat * x_seq + sqrt_one_minus_alpha_hat * noise_seq\n",
        "\n",
        "        return x_noise_seq, noise_seq\n",
        "\n",
        "    def p_sample_t_sequence(self, model_out, z_norm, timesteps):\n",
        "        \"\"\"Sampling step for sequences\"\"\"\n",
        "        batch_size, seq_len, features = z_norm.shape\n",
        "\n",
        "        sqrt_alpha_t = torch.sqrt(self.alphas[timesteps])[:, None, None]\n",
        "        betas_t = self.betas[timesteps][:, None, None]\n",
        "        sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[timesteps])[:, None, None]\n",
        "        epsilon_t = torch.sqrt(self.betas[timesteps])[:, None, None]\n",
        "\n",
        "        # Generate random noise\n",
        "        random_noise = self.sample_student_t((batch_size, seq_len, features))\n",
        "        random_noise[timesteps == 0] = 0.0\n",
        "\n",
        "        # Calculate model mean\n",
        "        model_mean = ((1 / sqrt_alpha_t) * (z_norm - (betas_t * model_out / sqrt_one_minus_alpha_hat_t)))\n",
        "\n",
        "        # Add noise\n",
        "        z_norm = model_mean + (epsilon_t * random_noise)\n",
        "\n",
        "        return z_norm\n",
        "\n",
        "# =============================================================================\n",
        "# TRAINING FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def train_sequential_model(model, diffuser, dataloader, optimizer, scheduler, device, epochs=100):\n",
        "    \"\"\"Training loop for sequential transaction model\"\"\"\n",
        "    model.train()\n",
        "    model = model.to(device)\n",
        "\n",
        "    loss_fnc = nn.MSELoss()\n",
        "    train_epoch_losses = []\n",
        "\n",
        "    pbar = tqdm(range(epochs), desc=\"Training\")\n",
        "\n",
        "    for epoch in pbar:\n",
        "        epoch_losses = []\n",
        "\n",
        "        for batch_cat, batch_num, account_ids in dataloader:\n",
        "            batch_cat = batch_cat.to(device)\n",
        "            batch_num = batch_num.to(device)\n",
        "\n",
        "            batch_size, seq_len, _ = batch_cat.shape\n",
        "\n",
        "            # Embed categorical variables\n",
        "            batch_cat_emb = model.embed_categorical(batch_cat)\n",
        "\n",
        "            # Combine categorical and numerical features\n",
        "            batch_combined = torch.cat([batch_cat_emb, batch_num], dim=-1)\n",
        "\n",
        "            # Sample timesteps\n",
        "            timesteps = diffuser.sample_random_timesteps(batch_size)\n",
        "\n",
        "            # Add noise to the entire sequence\n",
        "            batch_noisy, noise_target = diffuser.add_t_noise_sequence(batch_combined, timesteps)\n",
        "\n",
        "            # Forward pass\n",
        "            predicted_noise = model(batch_noisy, timesteps)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_fnc(predicted_noise, noise_target)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_losses.append(loss.item())\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate mean loss\n",
        "        mean_loss = np.mean(epoch_losses)\n",
        "        train_epoch_losses.append(mean_loss)\n",
        "\n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            'Loss': f'{mean_loss:.4f}',\n",
        "            'LR': f'{scheduler.get_last_lr()[0]:.6f}'\n",
        "        })\n",
        "\n",
        "        # Log every 50 epochs\n",
        "        # if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {mean_loss:.4f}\")\n",
        "\n",
        "    return train_epoch_losses\n",
        "\n",
        "# =============================================================================\n",
        "# GENERATION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def generate_sequences(model, diffuser, n_sequences=100, sequence_length=50, device='cpu'):\n",
        "    \"\"\"Generate new transaction sequences\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    generated_sequences = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Generate in batches\n",
        "        batch_size = 32\n",
        "        n_batches = (n_sequences + batch_size - 1) // batch_size\n",
        "\n",
        "        for batch_idx in tqdm(range(n_batches), desc=\"Generating sequences\"):\n",
        "            current_batch_size = min(batch_size, n_sequences - batch_idx * batch_size)\n",
        "\n",
        "            # Start from pure noise\n",
        "            shape = (current_batch_size, sequence_length, model.input_projection[0].in_features)\n",
        "            x = diffuser.sample_student_t(shape).to(device)\n",
        "\n",
        "            # Reverse diffusion process\n",
        "            for t in range(diffuser.total_steps - 1, -1, -1):\n",
        "                timesteps = torch.full((current_batch_size,), t, device=device, dtype=torch.long)\n",
        "\n",
        "                # Predict noise\n",
        "                predicted_noise = model(x, timesteps)\n",
        "\n",
        "                # Sample for this timestep\n",
        "                x = diffuser.p_sample_t_sequence(predicted_noise, x, timesteps)\n",
        "\n",
        "            generated_sequences.append(x.cpu())\n",
        "\n",
        "    return torch.cat(generated_sequences, dim=0)\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN EXECUTION\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "\n",
        "    # Create sample data for demonstration\n",
        "    np.random.seed(42)\n",
        "    n_accounts = 100\n",
        "    n_transactions = 10000\n",
        "\n",
        "    sample_data = []\n",
        "    for i in range(n_transactions):\n",
        "        account_id = np.random.randint(1, n_accounts + 1)\n",
        "        date = 950101 + np.random.randint(0, 3650)  # Random date in range\n",
        "        amount = np.random.lognormal(3, 1) * 100\n",
        "        transaction_type = np.random.choice(['CREDIT', 'DEBIT'])\n",
        "        operation = np.random.choice(['CREDIT IN CASH', 'CASH WITHDRAWAL',\n",
        "                                    'COLLECTION FROM ANOTHER BANK', 'REMITTANCE TO ANOTHER BANK'])\n",
        "        k_symbol = np.random.choice(['nan', 'PAYMENT ON STATEMENT', 'HOUSEHOLD', 'INTEREST CREDITED'])\n",
        "        age = np.random.randint(18, 80)\n",
        "\n",
        "        sample_data.append({\n",
        "            'account_id': account_id,\n",
        "            'date': date,\n",
        "            'amount': amount,\n",
        "            'type': transaction_type,\n",
        "            'operation': operation,\n",
        "            'k_symbol': k_symbol,\n",
        "            'age': age\n",
        "        })\n",
        "\n",
        "    real = pd.DataFrame(sample_data)\n",
        "    real = real.sort_values(by=[\"account_id\", \"date\"])\n",
        "    # raw_data=pd.read_csv('raw_data.csv')\n",
        "    LOG_AMOUNT_SCALE=1.0625705442977056\n",
        "\n",
        "    TD_SCALE=6.063912193703339\n",
        "\n",
        "    # Preprocess the data\n",
        "    # raw_data, LOG_AMOUNT_SCALE, TD_SCALE = preprocess_data_czech(real)\n",
        "\n",
        "    # Create balance column (mock data)\n",
        "    raw_data['balance'] = raw_data.groupby('account_id')['raw_amount'].cumsum() + np.random.normal(0, 100, len(raw_data))\n",
        "    raw_data['log_balance'] = np.log10(np.abs(raw_data['balance']) + 1)\n",
        "\n",
        "    # Define attributes\n",
        "    cat_attrs = ['age', 'day', 'month', 'tcode', 'year']  # Removed 'td' as it's numerical\n",
        "    num_attrs = ['amount', 'raw_amount', 'td', 'balance', 'log_balance', 'account_id']\n",
        "\n",
        "    print(\"Encoding features...\")\n",
        "\n",
        "    # Create a copy for processing\n",
        "    df_trans_filtered = raw_data[cat_attrs + num_attrs].copy()\n",
        "\n",
        "    # Label encode categorical attributes\n",
        "    label_encoders = {}\n",
        "    for attr in cat_attrs:\n",
        "        le = LabelEncoder()\n",
        "        df_trans_filtered[attr + '_encoded'] = le.fit_transform(df_trans_filtered[attr].astype(str))\n",
        "        label_encoders[attr] = le\n",
        "\n",
        "    # Use encoded categorical attributes\n",
        "    cat_attrs_encoded = [attr + '_encoded' for attr in cat_attrs]\n",
        "    all_attrs = cat_attrs_encoded + num_attrs\n",
        "\n",
        "    # Scale numerical attributes\n",
        "    num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "    df_trans_filtered[num_attrs] = num_scaler.fit_transform(df_trans_filtered[num_attrs])\n",
        "\n",
        "    # Add encoded categorical data back to raw_data for sequencing\n",
        "    for attr, encoded_attr in zip(cat_attrs, cat_attrs_encoded):\n",
        "        raw_data[encoded_attr] = df_trans_filtered[encoded_attr]\n",
        "\n",
        "    print(\"Creating sequential dataset...\")\n",
        "\n",
        "    # Create sequential dataset\n",
        "    seq_dataset = SequentialBankingDataset(\n",
        "        df=raw_data,\n",
        "        cat_attrs=cat_attrs_encoded,\n",
        "        num_attrs=num_attrs,\n",
        "        sequence_length=sequence_length,\n",
        "        min_seq_length=min_seq_length,\n",
        "        stride=10\n",
        "    )\n",
        "\n",
        "    # Create dataloader\n",
        "    seq_dataloader = DataLoader(\n",
        "        seq_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    print(\"Initializing model...\")\n",
        "\n",
        "    # Calculate dimensions\n",
        "    max_cat_tokens = 0\n",
        "    for attr in cat_attrs:\n",
        "        unique_vals = len(np.unique(df_trans_filtered[attr + '_encoded']))\n",
        "        max_cat_tokens = max(max_cat_tokens, unique_vals)\n",
        "\n",
        "    n_cat_tokens = max_cat_tokens + 1  # Add 1 for safety\n",
        "    cat_dim = cat_emb_dim * len(cat_attrs_encoded)\n",
        "    num_dim = len(num_attrs)\n",
        "    encoded_dim = cat_dim + num_dim\n",
        "\n",
        "    # Initialize model\n",
        "    model = SequentialLSTMSynthesizer(\n",
        "        d_in=encoded_dim,\n",
        "        hidden_layers=mlp_layers,\n",
        "        activation=activation,\n",
        "        dim_t=64,\n",
        "        n_cat_tokens=n_cat_tokens,\n",
        "        n_cat_emb=cat_emb_dim,\n",
        "        sequence_length=sequence_length,\n",
        "        lstm_layers=2,\n",
        "        dropout=dropout_rate,\n",
        "        use_attention=True,\n",
        "        n_cat_features=len(cat_attrs_encoded)\n",
        "    )\n",
        "\n",
        "    # Initialize diffuser\n",
        "    diffuser = SequentialStudentTDDPMDiffuser(\n",
        "        total_steps=diffusion_steps,\n",
        "        beta_start=diffusion_beta_start,\n",
        "        beta_end=diffusion_beta_end,\n",
        "        scheduler='exp',\n",
        "        device=device,\n",
        "        df=10\n",
        "    )\n",
        "\n",
        "    # Initialize optimizer and scheduler\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "    print(f\"Training on {len(seq_dataset)} sequences\")\n",
        "\n",
        "    # Train model\n",
        "    print(\"Starting training...\")\n",
        "    train_losses = train_sequential_model(\n",
        "        model=model,\n",
        "        diffuser=diffuser,\n",
        "        dataloader=seq_dataloader,\n",
        "        optimizer=optimizer,\n",
        "        scheduler=scheduler,\n",
        "        device=device,\n",
        "        epochs=2\n",
        "    )\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "\n",
        "    # Generate new sequences\n",
        "    print(\"Generating new sequences...\")\n",
        "    n_generate = 50\n",
        "    generated_seqs = generate_sequences(\n",
        "        model=model,\n",
        "        diffuser=diffuser,\n",
        "        n_sequences=n_generate,\n",
        "        sequence_length=sequence_length,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    print(f\"Generated {generated_seqs.shape[0]} sequences of length {generated_seqs.shape[1]}\")\n",
        "\n",
        "    # Save results\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'generated_sequences': generated_seqs,\n",
        "        'train_losses': train_losses,\n",
        "        'label_encoders': label_encoders,\n",
        "        'num_scaler': num_scaler,\n",
        "        'cat_attrs': cat_attrs,\n",
        "        'num_attrs': num_attrs,\n",
        "        'LOG_AMOUNT_SCALE': LOG_AMOUNT_SCALE,\n",
        "        'TD_SCALE': TD_SCALE\n",
        "    }, 'sequential_banking_model.pth')\n",
        "\n",
        "    print(\"Results saved to 'sequential_banking_model.pth'\")\n",
        "\n",
        "    return model, diffuser, generated_seqs, train_losses\n",
        "\n",
        "\n",
        "model, diffuser, generated_sequences, losses = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ll-Anq7ZDal",
        "outputId": "c00a7501-15b6-41ce-ea86-aff753bf5422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading and preprocessing data...\n",
            "Encoding features...\n",
            "Creating sequential dataset...\n",
            "Creating sequences from transaction data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4500/4500 [01:18<00:00, 57.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 85722 sequences from 4500 accounts\n",
            "Initializing model...\n",
            "Model has 1,187,062 parameters\n",
            "Training on 85722 sequences\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  50%|█████     | 1/2 [00:28<00:28, 28.92s/it, Loss=1.2499, LR=0.001000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 1.2499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:57<00:00, 28.87s/it, Loss=1.2499, LR=0.000999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 1.2499\n",
            "Training completed!\n",
            "Generating new sequences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating sequences: 100%|██████████| 2/2 [00:05<00:00,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 50 sequences of length 50\n",
            "Results saved to 'sequential_banking_model.pth'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3mLLEwqhnAV",
        "outputId": "3306a7f7-e409-4835-a197-5325b3c54f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.1798e+01, -1.0226e+01, -8.4833e+00,  ...,  1.0962e+01,\n",
              "           1.3610e+01,  3.9454e+00],\n",
              "         [-1.7482e+01,  5.9370e-01, -1.3386e+01,  ...,  6.1602e+00,\n",
              "          -1.9356e+00,  1.0325e+01],\n",
              "         [ 2.5243e+00, -3.6591e+00, -5.9767e+00,  ..., -6.4455e+00,\n",
              "          -1.4232e+01, -4.0998e+00],\n",
              "         ...,\n",
              "         [-7.7715e+00, -7.8127e-03, -4.3905e+00,  ..., -2.3265e+00,\n",
              "          -1.3139e+01, -2.0933e+00],\n",
              "         [-1.3913e+00,  7.1340e+00, -1.5290e+01,  ..., -2.0325e+00,\n",
              "          -6.5733e+00,  1.4432e+01],\n",
              "         [ 8.5390e+00,  7.0304e+00, -2.4532e+01,  ...,  3.0610e+00,\n",
              "          -1.2782e+01, -6.6072e+00]],\n",
              "\n",
              "        [[-1.7678e+01, -2.5623e+00, -1.4318e+01,  ...,  1.2113e+01,\n",
              "          -3.2374e+00,  7.0981e+00],\n",
              "         [ 2.6982e+00,  9.5481e+00, -9.1303e+00,  ...,  2.4264e+01,\n",
              "           2.4223e+00, -3.3412e+00],\n",
              "         [-1.5328e+01,  8.2366e+00, -1.4257e+01,  ..., -8.7646e+00,\n",
              "           9.4152e+00,  2.4414e+01],\n",
              "         ...,\n",
              "         [ 1.5325e+01,  1.4431e+01,  1.4350e+00,  ...,  1.2920e+01,\n",
              "          -9.3046e+00, -1.2086e+01],\n",
              "         [-1.9397e+01, -2.0811e+01,  5.6367e+00,  ..., -5.8507e+00,\n",
              "          -7.4818e+00,  2.2144e+00],\n",
              "         [-7.3882e-01,  1.0622e-01, -1.1576e+01,  ..., -2.0822e+00,\n",
              "          -8.1200e+00, -3.2464e-01]],\n",
              "\n",
              "        [[ 1.8369e+01,  1.7790e+01, -5.7609e+00,  ..., -3.2436e+00,\n",
              "          -7.2199e+00,  3.7583e+00],\n",
              "         [ 1.5894e+00, -1.9811e+01,  8.5702e+00,  ..., -9.4122e+00,\n",
              "          -9.0263e+00, -2.1337e+00],\n",
              "         [-1.2631e+01,  2.9643e+00, -9.2836e+00,  ..., -1.1219e+01,\n",
              "           8.5015e+00,  6.8646e+00],\n",
              "         ...,\n",
              "         [ 2.8255e+00,  7.4227e+00,  6.0828e+00,  ..., -1.5218e+01,\n",
              "           6.3175e+00, -2.5856e+00],\n",
              "         [ 4.1826e+00, -4.6753e+00, -1.5098e+00,  ..., -1.4498e+01,\n",
              "          -2.8964e+00, -5.3048e-01],\n",
              "         [-1.8037e+01,  7.0675e-01,  1.5851e+00,  ...,  2.1882e+01,\n",
              "          -2.9424e+00, -2.4310e+01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 1.6410e+01, -1.2376e+01, -2.1413e+01,  ..., -4.7276e+00,\n",
              "          -1.0483e+01, -3.2375e+00],\n",
              "         [-2.1523e+01, -1.2755e+01, -4.2117e+00,  ...,  7.2833e+00,\n",
              "          -1.1556e+01, -1.0865e+01],\n",
              "         [-1.1469e+01,  1.2234e+00, -1.0407e+01,  ..., -4.8791e+00,\n",
              "           4.6406e+00,  7.8686e-02],\n",
              "         ...,\n",
              "         [-4.1156e-01, -5.8692e-01,  1.2546e+01,  ..., -1.4140e+01,\n",
              "          -2.7970e+00, -1.8640e+00],\n",
              "         [-1.3357e+01,  1.6363e+01,  4.9194e-01,  ..., -5.5716e+00,\n",
              "           7.3518e-01,  1.3063e+01],\n",
              "         [ 2.0911e+01,  7.9438e+00, -3.2224e+00,  ...,  4.2355e+00,\n",
              "          -6.0888e+00, -2.9249e+00]],\n",
              "\n",
              "        [[-2.2558e+01,  3.9975e+00, -6.8639e+00,  ...,  2.0968e-01,\n",
              "           1.2300e+01, -1.1187e+01],\n",
              "         [ 3.7776e-01, -3.3050e+00, -2.4404e+01,  ...,  1.9998e+00,\n",
              "           8.3657e+00,  3.1854e+00],\n",
              "         [-1.3124e+01, -1.1462e+01, -5.2548e+00,  ..., -6.8400e+00,\n",
              "          -1.1677e+01,  6.4181e+00],\n",
              "         ...,\n",
              "         [-2.4621e+01,  5.6162e+00, -5.6525e+00,  ..., -7.2621e+00,\n",
              "           1.0491e+00, -6.7730e+00],\n",
              "         [-3.4727e+00, -8.4675e-01, -1.1686e+00,  ...,  1.2438e+01,\n",
              "          -1.0017e+01, -6.4324e+00],\n",
              "         [ 3.3843e+00,  1.0298e+01,  1.2548e+01,  ...,  9.4115e-01,\n",
              "           1.3610e+01,  4.0538e-01]],\n",
              "\n",
              "        [[ 1.0341e+00, -1.9310e+01, -7.6287e+00,  ..., -2.1889e-01,\n",
              "           9.1648e+00,  4.4524e+00],\n",
              "         [-3.0468e+00,  5.7128e+00, -5.2561e+00,  ..., -2.2345e+00,\n",
              "          -1.7078e+01,  2.2799e+01],\n",
              "         [ 1.0377e+01, -7.9729e+00,  1.6136e+01,  ..., -1.6703e+01,\n",
              "           4.4091e+00,  1.1944e+00],\n",
              "         ...,\n",
              "         [-6.9684e-02, -5.7067e+00,  2.1872e+00,  ...,  3.7538e+00,\n",
              "           2.2362e+00, -1.4851e+01],\n",
              "         [-8.4209e+00, -3.8503e+00, -1.1462e+01,  ..., -1.5965e+01,\n",
              "           5.4735e+00,  5.3486e+00],\n",
              "         [-1.3836e+01,  5.0081e+00,  2.6123e+00,  ...,  8.3951e+00,\n",
              "           3.1960e+00,  1.0810e+01]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "# from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.manifold import TSNE\n",
        "# from sklearn.metrics import classification_report\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import random\n",
        "# import os\n",
        "# from datetime import datetime\n",
        "# import calendar\n",
        "# from tqdm import tqdm\n",
        "# from scipy import stats, linalg\n",
        "# # from scipy.spatial.distance import wasserstein_distance\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# # =============================================================================\n",
        "# # EVALUATION METRICS CLASS\n",
        "# # =============================================================================\n",
        "\n",
        "# class SyntheticDataEvaluator:\n",
        "#     \"\"\"Comprehensive evaluation metrics for synthetic banking data\"\"\"\n",
        "\n",
        "#     def __init__(self):\n",
        "#         self.metrics_results = {}\n",
        "\n",
        "#     def sliced_jensen_distance(self, X_real, X_syn, num_projections=100):\n",
        "#         \"\"\"\n",
        "#         Compute Sliced Jensen Distance (SJD) between real and synthetic data\n",
        "#         \"\"\"\n",
        "#         if X_real.shape[1] != X_syn.shape[1]:\n",
        "#             raise ValueError(\"Real and synthetic data must have same number of features\")\n",
        "\n",
        "#         n_features = X_real.shape[1]\n",
        "#         distances = []\n",
        "\n",
        "#         for _ in range(num_projections):\n",
        "#             # Random unit vector for projection\n",
        "#             direction = np.random.randn(n_features)\n",
        "#             direction = direction / np.linalg.norm(direction)\n",
        "\n",
        "#             # Project data onto this direction\n",
        "#             proj_real = X_real @ direction\n",
        "#             proj_syn = X_syn @ direction\n",
        "\n",
        "#             # Compute Jensen-Shannon distance on projections\n",
        "#             js_dist = self._jensen_shannon_distance(proj_real, proj_syn)\n",
        "#             distances.append(js_dist)\n",
        "\n",
        "#         return np.mean(distances)\n",
        "\n",
        "#     def _jensen_shannon_distance(self, X, Y, num_bins=50):\n",
        "#         \"\"\"Compute Jensen-Shannon distance between two 1D distributions\"\"\"\n",
        "#         # Create histograms\n",
        "#         min_val = min(X.min(), Y.min())\n",
        "#         max_val = max(X.max(), Y.max())\n",
        "#         bins = np.linspace(min_val, max_val, num_bins + 1)\n",
        "\n",
        "#         hist_X, _ = np.histogram(X, bins=bins, density=True)\n",
        "#         hist_Y, _ = np.histogram(Y, bins=bins, density=True)\n",
        "\n",
        "#         # Normalize to probabilities\n",
        "#         hist_X = hist_X / (hist_X.sum() + 1e-8)\n",
        "#         hist_Y = hist_Y / (hist_Y.sum() + 1e-8)\n",
        "\n",
        "#         # Add small epsilon to avoid log(0)\n",
        "#         eps = 1e-8\n",
        "#         hist_X = hist_X + eps\n",
        "#         hist_Y = hist_Y + eps\n",
        "\n",
        "#         # Jensen-Shannon distance\n",
        "#         M = 0.5 * (hist_X + hist_Y)\n",
        "#         js_dist = 0.5 * stats.entropy(hist_X, M, base=2) + 0.5 * stats.entropy(hist_Y, M, base=2)\n",
        "\n",
        "#         return np.sqrt(js_dist)\n",
        "\n",
        "#     def wasserstein_distance_multivariate(self, X_real, X_syn):\n",
        "#         \"\"\"Compute average Wasserstein distance across features\"\"\"\n",
        "#         distances = []\n",
        "#         for i in range(X_real.shape[1]):\n",
        "#             wd = wasserstein_distance(X_real[:, i], X_syn[:, i])\n",
        "#             distances.append(wd)\n",
        "#         return np.mean(distances)\n",
        "\n",
        "#     def kolmogorov_smirnov_test(self, X_real, X_syn):\n",
        "#         \"\"\"KS test for each feature\"\"\"\n",
        "#         ks_stats = []\n",
        "#         p_values = []\n",
        "\n",
        "#         for i in range(X_real.shape[1]):\n",
        "#             ks_stat, p_val = stats.ks_2samp(X_real[:, i], X_syn[:, i])\n",
        "#             ks_stats.append(ks_stat)\n",
        "#             p_values.append(p_val)\n",
        "\n",
        "#         return {\n",
        "#             'ks_statistics': ks_stats,\n",
        "#             'p_values': p_values,\n",
        "#             'mean_ks_stat': np.mean(ks_stats),\n",
        "#             'mean_p_value': np.mean(p_values)\n",
        "#         }\n",
        "\n",
        "#     def correlation_distance(self, X_real, X_syn):\n",
        "#         \"\"\"Compare correlation matrices\"\"\"\n",
        "#         corr_real = np.corrcoef(X_real.T)\n",
        "#         corr_syn = np.corrcoef(X_syn.T)\n",
        "\n",
        "#         # Handle NaN values\n",
        "#         corr_real = np.nan_to_num(corr_real)\n",
        "#         corr_syn = np.nan_to_num(corr_syn)\n",
        "\n",
        "#         # Frobenius norm of difference\n",
        "#         corr_distance = np.linalg.norm(corr_real - corr_syn, 'fro')\n",
        "\n",
        "#         return {\n",
        "#             'correlation_distance': corr_distance,\n",
        "#             'real_correlation': corr_real,\n",
        "#             'synthetic_correlation': corr_syn\n",
        "#         }\n",
        "\n",
        "#     def statistical_moments_comparison(self, X_real, X_syn):\n",
        "#         \"\"\"Compare statistical moments\"\"\"\n",
        "#         moments = {}\n",
        "\n",
        "#         for i, stat_name in enumerate(['mean', 'std', 'skewness', 'kurtosis']):\n",
        "#             real_stats = []\n",
        "#             syn_stats = []\n",
        "\n",
        "#             for j in range(X_real.shape[1]):\n",
        "#                 if stat_name == 'mean':\n",
        "#                     real_stats.append(np.mean(X_real[:, j]))\n",
        "#                     syn_stats.append(np.mean(X_syn[:, j]))\n",
        "#                 elif stat_name == 'std':\n",
        "#                     real_stats.append(np.std(X_real[:, j]))\n",
        "#                     syn_stats.append(np.std(X_syn[:, j]))\n",
        "#                 elif stat_name == 'skewness':\n",
        "#                     real_stats.append(stats.skew(X_real[:, j]))\n",
        "#                     syn_stats.append(stats.skew(X_syn[:, j]))\n",
        "#                 elif stat_name == 'kurtosis':\n",
        "#                     real_stats.append(stats.kurtosis(X_real[:, j]))\n",
        "#                     syn_stats.append(stats.kurtosis(X_syn[:, j]))\n",
        "\n",
        "#             moments[stat_name] = {\n",
        "#                 'real': real_stats,\n",
        "#                 'synthetic': syn_stats,\n",
        "#                 'mse': np.mean((np.array(real_stats) - np.array(syn_stats))**2)\n",
        "#             }\n",
        "\n",
        "#         return moments\n",
        "\n",
        "#     def privacy_evaluation(self, X_real, X_syn, k=5):\n",
        "#         \"\"\"Distance to Closest Record (DCR) privacy evaluation\"\"\"\n",
        "#         dcr_scores = []\n",
        "\n",
        "#         for i in range(min(100, len(X_syn))):  # Sample for efficiency\n",
        "#             syn_record = X_syn[i]\n",
        "#             distances = np.linalg.norm(X_real - syn_record, axis=1)\n",
        "#             dcr_scores.append(np.min(distances))\n",
        "\n",
        "#         return {\n",
        "#             'mean_dcr': np.mean(dcr_scores),\n",
        "#             'std_dcr': np.std(dcr_scores),\n",
        "#             'min_dcr': np.min(dcr_scores)\n",
        "#         }\n",
        "\n",
        "#     def machine_learning_utility(self, X_real, y_real, X_syn, y_syn, test_size=0.2):\n",
        "#         \"\"\"Evaluate ML utility by training classifiers\"\"\"\n",
        "#         # Split real data\n",
        "#         X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(\n",
        "#             X_real, y_real, test_size=test_size, random_state=42\n",
        "#         )\n",
        "\n",
        "#         # Train on real data\n",
        "#         rf_real = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "#         rf_real.fit(X_real_train, y_real_train)\n",
        "#         real_score = rf_real.score(X_real_test, y_real_test)\n",
        "\n",
        "#         # Train on synthetic data, test on real\n",
        "#         rf_syn = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "#         rf_syn.fit(X_syn, y_syn)\n",
        "#         syn_score = rf_syn.score(X_real_test, y_real_test)\n",
        "\n",
        "#         return {\n",
        "#             'real_data_performance': real_score,\n",
        "#             'synthetic_data_performance': syn_score,\n",
        "#             'utility_score': syn_score / real_score if real_score > 0 else 0.0\n",
        "#         }\n",
        "\n",
        "#     def evaluate_all_metrics(self, X_real, X_syn, y_real=None, y_syn=None):\n",
        "#         \"\"\"Compute all evaluation metrics\"\"\"\n",
        "#         print(\"Computing evaluation metrics...\")\n",
        "\n",
        "#         results = {}\n",
        "\n",
        "#         # SJD\n",
        "#         print(\"- Computing Sliced Jensen Distance...\")\n",
        "#         results['sjd'] = self.sliced_jensen_distance(X_real, X_syn)\n",
        "\n",
        "#         # Wasserstein Distance\n",
        "#         print(\"- Computing Wasserstein Distance...\")\n",
        "#         results['wasserstein'] = self.wasserstein_distance_multivariate(X_real, X_syn)\n",
        "\n",
        "#         # KS Test\n",
        "#         print(\"- Computing Kolmogorov-Smirnov Test...\")\n",
        "#         results['ks_test'] = self.kolmogorov_smirnov_test(X_real, X_syn)\n",
        "\n",
        "#         # Correlation Distance\n",
        "#         print(\"- Computing Correlation Distance...\")\n",
        "#         results['correlation'] = self.correlation_distance(X_real, X_syn)\n",
        "\n",
        "#         # Statistical Moments\n",
        "#         print(\"- Computing Statistical Moments...\")\n",
        "#         results['moments'] = self.statistical_moments_comparison(X_real, X_syn)\n",
        "\n",
        "#         # Privacy Evaluation\n",
        "#         print(\"- Computing Privacy Metrics...\")\n",
        "#         results['privacy'] = self.privacy_evaluation(X_real, X_syn)\n",
        "\n",
        "#         # ML Utility (if labels provided)\n",
        "#         if y_real is not None and y_syn is not None:\n",
        "#             print(\"- Computing ML Utility...\")\n",
        "#             results['ml_utility'] = self.machine_learning_utility(X_real, y_real, X_syn, y_syn)\n",
        "\n",
        "#         return results\n",
        "\n",
        "# # =============================================================================\n",
        "# # DATA REVERSE TRANSFORMATION CLASS\n",
        "# # =============================================================================\n",
        "\n",
        "# class DataReverseTransformer:\n",
        "#     \"\"\"Transform generated data back to original format\"\"\"\n",
        "\n",
        "#     def __init__(self, label_encoders, num_scaler, cat_attrs, num_attrs):\n",
        "#         self.label_encoders = label_encoders\n",
        "#         self.num_scaler = num_scaler\n",
        "#         self.cat_attrs = cat_attrs\n",
        "#         self.num_attrs = num_attrs\n",
        "\n",
        "#     def reverse_transform_sequences(self, generated_sequences, cat_emb_dim=16):\n",
        "#         \"\"\"Transform generated sequences back to original format\"\"\"\n",
        "#         print(\"Reversing transformation of generated sequences...\")\n",
        "\n",
        "#         batch_size, seq_len, total_features = generated_sequences.shape\n",
        "\n",
        "#         # Calculate dimensions\n",
        "#         cat_dim = cat_emb_dim * len(self.cat_attrs)\n",
        "#         num_dim = len(self.num_attrs)\n",
        "\n",
        "#         print(f\"Total features: {total_features}, Cat dim: {cat_dim}, Num dim: {num_dim}\")\n",
        "\n",
        "#         # Split categorical embeddings and numerical features\n",
        "#         cat_embeddings = generated_sequences[:, :, :cat_dim]\n",
        "#         num_features = generated_sequences[:, :, cat_dim:cat_dim + num_dim]\n",
        "\n",
        "#         # Process categorical features (simplified approach)\n",
        "#         # Since we can't easily reverse embeddings, we'll use a heuristic approach\n",
        "#         cat_features_decoded = []\n",
        "\n",
        "#         for i, attr in enumerate(self.cat_attrs):\n",
        "#             # Take the mean of embedding dimensions for this categorical feature\n",
        "#             start_idx = i * cat_emb_dim\n",
        "#             end_idx = (i + 1) * cat_emb_dim\n",
        "#             cat_emb_feature = cat_embeddings[:, :, start_idx:end_idx].mean(dim=-1)\n",
        "\n",
        "#             # Scale and round to get categorical indices\n",
        "#             cat_emb_feature_scaled = torch.sigmoid(cat_emb_feature)  # Normalize to [0,1]\n",
        "#             n_categories = len(self.label_encoders[attr].classes_)\n",
        "#             cat_indices = (cat_emb_feature_scaled * (n_categories - 1)).round().long()\n",
        "\n",
        "#             cat_features_decoded.append(cat_indices.unsqueeze(-1))\n",
        "\n",
        "#         cat_features_decoded = torch.cat(cat_features_decoded, dim=-1)\n",
        "\n",
        "#         # Reverse transform numerical features\n",
        "#         num_features_np = num_features.cpu().numpy()\n",
        "#         num_features_reshaped = num_features_np.reshape(-1, num_features_np.shape[-1])\n",
        "\n",
        "#         # Inverse transform\n",
        "#         num_features_original = self.num_scaler.inverse_transform(num_features_reshaped)\n",
        "#         num_features_original = num_features_original.reshape(batch_size, seq_len, -1)\n",
        "\n",
        "#         # Convert categorical indices back to original values\n",
        "#         cat_features_original = []\n",
        "#         for i, attr in enumerate(self.cat_attrs):\n",
        "#             cat_indices = cat_features_decoded[:, :, i].cpu().numpy().flatten()\n",
        "\n",
        "#             # Clip indices to valid range\n",
        "#             n_categories = len(self.label_encoders[attr].classes_)\n",
        "#             cat_indices = np.clip(cat_indices, 0, n_categories - 1)\n",
        "\n",
        "#             # Inverse transform\n",
        "#             try:\n",
        "#                 cat_original = self.label_encoders[attr].inverse_transform(cat_indices)\n",
        "#                 cat_original = cat_original.reshape(batch_size, seq_len)\n",
        "#                 cat_features_original.append(cat_original)\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Warning: Could not inverse transform {attr}: {e}\")\n",
        "#                 # Fallback: use random values from the original categories\n",
        "#                 cat_original = np.random.choice(\n",
        "#                     self.label_encoders[attr].classes_,\n",
        "#                     size=(batch_size, seq_len)\n",
        "#                 )\n",
        "#                 cat_features_original.append(cat_original)\n",
        "\n",
        "#         return cat_features_original, num_features_original\n",
        "\n",
        "#     def sequences_to_dataframe(self, cat_features_original, num_features_original):\n",
        "#         \"\"\"Convert sequences back to dataframe format\"\"\"\n",
        "#         print(\"Converting sequences to dataframe...\")\n",
        "\n",
        "#         batch_size, seq_len = cat_features_original[0].shape\n",
        "#         total_samples = batch_size * seq_len\n",
        "\n",
        "#         # Create dataframe\n",
        "#         synthetic_data = {}\n",
        "\n",
        "#         # Add categorical features\n",
        "#         for i, attr in enumerate(self.cat_attrs):\n",
        "#             synthetic_data[attr.replace('_encoded', '')] = cat_features_original[i].flatten()\n",
        "\n",
        "#         # Add numerical features\n",
        "#         for i, attr in enumerate(self.num_attrs):\n",
        "#             synthetic_data[attr] = num_features_original[:, :, i].flatten()\n",
        "\n",
        "#         # Create account IDs for sequences\n",
        "#         account_ids = []\n",
        "#         for batch_idx in range(batch_size):\n",
        "#             for seq_idx in range(seq_len):\n",
        "#                 account_ids.append(f\"synthetic_account_{batch_idx}\")\n",
        "\n",
        "#         synthetic_data['synthetic_account_id'] = account_ids\n",
        "\n",
        "#         df_synthetic = pd.DataFrame(synthetic_data)\n",
        "\n",
        "#         return df_synthetic\n",
        "\n",
        "# # =============================================================================\n",
        "# # ENHANCED MAIN FUNCTION WITH EVALUATION\n",
        "# # =============================================================================\n",
        "\n",
        "# def main_with_evaluation():\n",
        "#     \"\"\"Main function with comprehensive evaluation\"\"\"\n",
        "\n",
        "#     print(\"=\"*80)\n",
        "#     print(\"SYNTHETIC BANKING DATA GENERATION AND EVALUATION\")\n",
        "#     print(\"=\"*80)\n",
        "\n",
        "#     # Set seeds for reproducibility\n",
        "#     seed = 42\n",
        "#     random.seed(seed)\n",
        "#     np.random.seed(seed)\n",
        "#     torch.manual_seed(seed)\n",
        "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#     print(f\"Using device: {device}\")\n",
        "\n",
        "#     # Load existing model and data (assuming they exist)\n",
        "#     try:\n",
        "#         checkpoint = torch.load('sequential_banking_model.pth', map_location=device)\n",
        "#         print(\"Loaded existing model checkpoint\")\n",
        "#     except:\n",
        "#         print(\"No existing checkpoint found. Please run the training first.\")\n",
        "#         return\n",
        "\n",
        "#     # Extract saved components\n",
        "#     generated_sequences = checkpoint['generated_sequences']\n",
        "#     label_encoders = checkpoint['label_encoders']\n",
        "#     num_scaler = checkpoint['num_scaler']\n",
        "#     cat_attrs = checkpoint['cat_attrs']\n",
        "#     num_attrs = checkpoint['num_attrs']\n",
        "\n",
        "#     print(f\"Generated sequences shape: {generated_sequences.shape}\")\n",
        "\n",
        "#     # Initialize reverse transformer\n",
        "#     reverse_transformer = DataReverseTransformer(\n",
        "#         label_encoders=label_encoders,\n",
        "#         num_scaler=num_scaler,\n",
        "#         cat_attrs=cat_attrs,\n",
        "#         num_attrs=num_attrs\n",
        "#     )\n",
        "\n",
        "#     # Reverse transform generated sequences\n",
        "#     cat_features_original, num_features_original = reverse_transformer.reverse_transform_sequences(\n",
        "#         generated_sequences, cat_emb_dim=16\n",
        "#     )\n",
        "\n",
        "#     # Convert to dataframe\n",
        "#     df_synthetic = reverse_transformer.sequences_to_dataframe(\n",
        "#         cat_features_original, num_features_original\n",
        "#     )\n",
        "\n",
        "#     print(f\"Generated synthetic dataframe with shape: {df_synthetic.shape}\")\n",
        "#     print(\"\\nSynthetic data sample:\")\n",
        "#     print(df_synthetic.head())\n",
        "\n",
        "#     # Create real data for comparison (using the same sample generation as in training)\n",
        "#     print(\"\\nGenerating real data for comparison...\")\n",
        "#     np.random.seed(42)\n",
        "#     n_accounts = 100\n",
        "#     n_transactions = 5000  # Smaller for comparison\n",
        "\n",
        "#     real_sample_data = []\n",
        "#     for i in range(n_transactions):\n",
        "#         account_id = np.random.randint(1, n_accounts + 1)\n",
        "#         date = 950101 + np.random.randint(0, 3650)\n",
        "#         amount = np.random.lognormal(3, 1) * 100\n",
        "#         transaction_type = np.random.choice(['CREDIT', 'DEBIT'])\n",
        "#         operation = np.random.choice(['CREDIT IN CASH', 'CASH WITHDRAWAL',\n",
        "#                                     'COLLECTION FROM ANOTHER BANK', 'REMITTANCE TO ANOTHER BANK'])\n",
        "#         k_symbol = np.random.choice(['nan', 'PAYMENT ON STATEMENT', 'HOUSEHOLD', 'INTEREST CREDITED'])\n",
        "#         age = np.random.randint(18, 80)\n",
        "\n",
        "#         real_sample_data.append({\n",
        "#             'account_id': account_id,\n",
        "#             'date': date,\n",
        "#             'amount': amount,\n",
        "#             'type': transaction_type,\n",
        "#             'operation': operation,\n",
        "#             'k_symbol': k_symbol,\n",
        "#             'age': age\n",
        "#         })\n",
        "\n",
        "#     df_real = pd.DataFrame(real_sample_data)\n",
        "\n",
        "#     # Process real data similarly to synthetic\n",
        "#     df_real['raw_amount'] = df_real.apply(\n",
        "#         lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1\n",
        "#     )\n",
        "#     df_real['balance'] = df_real.groupby('account_id')['raw_amount'].cumsum() + np.random.normal(0, 100, len(df_real))\n",
        "#     df_real['td'] = np.random.exponential(5, len(df_real))  # Mock time differences\n",
        "#     df_real['log_balance'] = np.log10(np.abs(df_real['balance']) + 1)\n",
        "\n",
        "#     print(f\"Real data shape: {df_real.shape}\")\n",
        "#     print(\"\\nReal data sample:\")\n",
        "#     print(df_real.head())\n",
        "\n",
        "#     # Prepare data for evaluation\n",
        "#     print(\"\\nPreparing data for evaluation...\")\n",
        "\n",
        "#     # Select common numerical features for evaluation\n",
        "#     eval_num_features = ['amount', 'raw_amount', 'balance', 'td']\n",
        "\n",
        "#     # Filter to common features\n",
        "#     X_real = df_real[eval_num_features].values\n",
        "#     X_syn = df_synthetic[eval_num_features].values\n",
        "\n",
        "#     # Handle any NaN or infinite values\n",
        "#     X_real = np.nan_to_num(X_real, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "#     X_syn = np.nan_to_num(X_syn, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "\n",
        "#     # Sample equal amounts for fair comparison\n",
        "#     n_samples = min(len(X_real), len(X_syn), 2000)\n",
        "#     indices_real = np.random.choice(len(X_real), n_samples, replace=False)\n",
        "#     indices_syn = np.random.choice(len(X_syn), n_samples, replace=False)\n",
        "\n",
        "#     X_real_sampled = X_real[indices_real]\n",
        "#     X_syn_sampled = X_syn[indices_syn]\n",
        "\n",
        "#     print(f\"Evaluation data shapes - Real: {X_real_sampled.shape}, Synthetic: {X_syn_sampled.shape}\")\n",
        "\n",
        "#     # Initialize evaluator\n",
        "#     evaluator = SyntheticDataEvaluator()\n",
        "\n",
        "#     # Run comprehensive evaluation\n",
        "#     print(\"\\n\" + \"=\"*50)\n",
        "#     print(\"RUNNING COMPREHENSIVE EVALUATION\")\n",
        "#     print(\"=\"*50)\n",
        "\n",
        "#     results = evaluator.evaluate_all_metrics(X_real_sampled, X_syn_sampled)\n",
        "\n",
        "#     # Print results\n",
        "#     print(\"\\n\" + \"=\"*50)\n",
        "#     print(\"EVALUATION RESULTS\")\n",
        "#     print(\"=\"*50)\n",
        "\n",
        "#     print(f\"\\n1. SLICED JENSEN DISTANCE (SJD)\")\n",
        "#     print(f\"   SJD Score: {results['sjd']:.4f}\")\n",
        "#     print(f\"   (Lower is better, 0 = perfect match)\")\n",
        "\n",
        "#     print(f\"\\n2. WASSERSTEIN DISTANCE\")\n",
        "#     print(f\"   Average Wasserstein Distance: {results['wasserstein']:.4f}\")\n",
        "#     print(f\"   (Lower is better)\")\n",
        "\n",
        "#     print(f\"\\n3. KOLMOGOROV-SMIRNOV TEST\")\n",
        "#     print(f\"   Mean KS Statistic: {results['ks_test']['mean_ks_stat']:.4f}\")\n",
        "#     print(f\"   Mean P-value: {results['ks_test']['mean_p_value']:.4f}\")\n",
        "#     print(f\"   (Lower KS stat is better, higher p-value is better)\")\n",
        "\n",
        "#     print(f\"\\n4. CORRELATION DISTANCE\")\n",
        "#     print(f\"   Correlation Matrix Distance: {results['correlation']['correlation_distance']:.4f}\")\n",
        "#     print(f\"   (Lower is better)\")\n",
        "\n",
        "#     print(f\"\\n5. STATISTICAL MOMENTS COMPARISON\")\n",
        "#     for moment, values in results['moments'].items():\n",
        "#         print(f\"   {moment.upper()} MSE: {values['mse']:.4f}\")\n",
        "\n",
        "#     print(f\"\\n6. PRIVACY EVALUATION (DCR)\")\n",
        "#     print(f\"   Mean Distance to Closest Record: {results['privacy']['mean_dcr']:.4f}\")\n",
        "#     print(f\"   Std DCR: {results['privacy']['std_dcr']:.4f}\")\n",
        "#     print(f\"   Min DCR: {results['privacy']['min_dcr']:.4f}\")\n",
        "#     print(f\"   (Higher is better for privacy)\")\n",
        "\n",
        "#     # Create visualizations\n",
        "#     print(\"\\nGenerating visualizations...\")\n",
        "\n",
        "#     # Create comparison plots\n",
        "#     fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "#     fig.suptitle('Real vs Synthetic Data Comparison', fontsize=16)\n",
        "\n",
        "#     feature_names = eval_num_features\n",
        "\n",
        "#     for i, feature in enumerate(feature_names):\n",
        "#         row, col = i // 3, i % 3\n",
        "#         if row < 2 and col < 3:\n",
        "#             ax = axes[row, col]\n",
        "\n",
        "#             # Distribution comparison\n",
        "#             ax.hist(X_real_sampled[:, i], bins=50, alpha=0.7, label='Real', density=True)\n",
        "#             ax.hist(X_syn_sampled[:, i], bins=50, alpha=0.7, label='Synthetic', density=True)\n",
        "#             ax.set_title(f'{feature} Distribution')\n",
        "#             ax.legend()\n",
        "#             ax.grid(True, alpha=0.3)\n",
        "\n",
        "#     # Remove empty subplots\n",
        "#     for i in range(len(feature_names), 6):\n",
        "#         row, col = i // 3, i % 3\n",
        "#         fig.delaxes(axes[row, col])\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig('data_comparison.png', dpi=300, bbox_inches='tight')\n",
        "#     plt.show()\n",
        "\n",
        "#     # Correlation matrix comparison\n",
        "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "#     # Real data correlation\n",
        "#     im1 = ax1.imshow(results['correlation']['real_correlation'], cmap='coolwarm', vmin=-1, vmax=1)\n",
        "#     ax1.set_title('Real Data Correlation Matrix')\n",
        "#     ax1.set_xticks(range(len(feature_names)))\n",
        "#     ax1.set_yticks(range(len(feature_names)))\n",
        "#     ax1.set_xticklabels(feature_names, rotation=45)\n",
        "#     ax1.set_yticklabels(feature_names)\n",
        "\n",
        "#     # Synthetic data correlation\n",
        "#     im2 = ax2.imshow(results['correlation']['synthetic_correlation'], cmap='coolwarm', vmin=-1, vmax=1)\n",
        "#     ax2.set_title('Synthetic Data Correlation Matrix')\n",
        "#     ax2.set_xticks(range(len(feature_names)))\n",
        "#     ax2.set_yticks(range(len(feature_names)))\n",
        "#     ax2.set_xticklabels(feature_names, rotation=45)\n",
        "#     ax2.set_yticklabels(feature_names)\n",
        "\n",
        "#     # Add colorbar\n",
        "#     plt.colorbar(im2, ax=[ax1, ax2], shrink=0.8)\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig('correlation_comparison.png', dpi=300, bbox_inches='tight')\n",
        "#     plt.show()\n",
        "\n",
        "#     # Save detailed results\n",
        "#     detailed_results = {\n",
        "#         'evaluation_metrics': results,\n",
        "#         'synthetic_data_sample': df_synthetic.head(100).to_dict(),\n",
        "#         'real_data_sample': df_real.head(100).to_dict(),\n",
        "#         'feature_names': feature_names\n",
        "#     }\n",
        "\n",
        "#     # Save as JSON for easy reading\n",
        "#     import json\n",
        "#     with open('evaluation_results.json', 'w') as f:\n",
        "#         # Convert numpy arrays to lists for JSON serialization\n",
        "#         def convert_numpy(obj):\n",
        "#             if isinstance(obj, np.ndarray):\n",
        "#                 return obj.tolist()\n",
        "#             elif isinstance(obj, np.integer):\n",
        "#                 return int(obj)\n",
        "#             elif isinstance(obj, np.floating):\n",
        "#                 return float(obj)\n",
        "#             elif isinstance(obj, dict):\n",
        "#                 return {key: convert_numpy(val) for key, val in obj.items()}\n",
        "#             elif isinstance(obj, list):\n",
        "#                 return [convert_numpy(item) for item in obj]\n",
        "#             return obj\n",
        "\n",
        "#         json.dump(convert_numpy(detailed_results), f, indent=2)\n",
        "\n",
        "#     print(\"\\nDetailed results saved to 'evaluation_results.json'\")\n",
        "#     print(\"Visualizations saved as 'data_comparison.png' and 'correlation_comparison.png'\")\n",
        "\n",
        "#     # Summary\n",
        "#     print(\"\\n\" + \"=\"*50)\n",
        "#     print(\"SUMMARY\")\n",
        "#     print(\"=\"*50)\n",
        "#     print(f\"Generated {len(df_synthetic)} synthetic transaction records\")\n",
        "#     print(f\"SJD Score: {results['sjd']:.4f} (lower is better)\")\n",
        "#     print(f\"Average Wasserstein Distance: {results['wasserstein']:.4f}\")\n",
        "#     print(f\"Correlation Distance: {results['correlation']['correlation_distance']:.4f}\")\n",
        "#     print(f\"Mean DCR (Privacy): {results['privacy']['mean_dcr']:.4f} (higher is better)\")\n",
        "\n",
        "#     return df_synthetic, df_real, results\n",
        "\n",
        "\n",
        "\n",
        "# synthetic_data, real_data, evaluation_results = main_with_evaluation()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "from tqdm import tqdm\n",
        "from scipy import stats, linalg\n",
        "from scipy.stats import wasserstein_distance # <-- FIXED: Correct import location\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# EVALUATION METRICS CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class SyntheticDataEvaluator:\n",
        "    \"\"\"Comprehensive evaluation metrics for synthetic banking data\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.metrics_results = {}\n",
        "\n",
        "    def sliced_jensen_distance(self, X_real, X_syn, num_projections=100):\n",
        "        \"\"\"\n",
        "        Compute Sliced Jensen Distance (SJD) between real and synthetic data\n",
        "        \"\"\"\n",
        "        if X_real.shape[1] != X_syn.shape[1]:\n",
        "            raise ValueError(\"Real and synthetic data must have same number of features\")\n",
        "\n",
        "        n_features = X_real.shape[1]\n",
        "        distances = []\n",
        "\n",
        "        for _ in range(num_projections):\n",
        "            # Random unit vector for projection\n",
        "            direction = np.random.randn(n_features)\n",
        "            direction = direction / np.linalg.norm(direction)\n",
        "\n",
        "            # Project data onto this direction\n",
        "            proj_real = X_real @ direction\n",
        "            proj_syn = X_syn @ direction\n",
        "\n",
        "            # Compute Jensen-Shannon distance on projections\n",
        "            js_dist = self._jensen_shannon_distance(proj_real, proj_syn)\n",
        "            distances.append(js_dist)\n",
        "\n",
        "        return np.mean(distances)\n",
        "\n",
        "    def _jensen_shannon_distance(self, X, Y, num_bins=50):\n",
        "        \"\"\"Compute Jensen-Shannon distance between two 1D distributions\"\"\"\n",
        "        # Create histograms\n",
        "        min_val = min(X.min(), Y.min())\n",
        "        max_val = max(X.max(), Y.max())\n",
        "        bins = np.linspace(min_val, max_val, num_bins + 1)\n",
        "\n",
        "        hist_X, _ = np.histogram(X, bins=bins, density=True)\n",
        "        hist_Y, _ = np.histogram(Y, bins=bins, density=True)\n",
        "\n",
        "        # Normalize to probabilities\n",
        "        hist_X = hist_X / (hist_X.sum() + 1e-10)\n",
        "        hist_Y = hist_Y / (hist_Y.sum() + 1e-10)\n",
        "\n",
        "        # Add small epsilon to avoid log(0)\n",
        "        eps = 1e-10\n",
        "        hist_X = hist_X + eps\n",
        "        hist_Y = hist_Y + eps\n",
        "\n",
        "        # Jensen-Shannon distance\n",
        "        M = 0.5 * (hist_X + hist_Y)\n",
        "        js_dist = 0.5 * stats.entropy(hist_X, M, base=2) + 0.5 * stats.entropy(hist_Y, M, base=2)\n",
        "\n",
        "        return np.sqrt(js_dist)\n",
        "\n",
        "    def wasserstein_distance_multivariate(self, X_real, X_syn):\n",
        "        \"\"\"Compute average Wasserstein distance across features\"\"\"\n",
        "        distances = []\n",
        "        for i in range(X_real.shape[1]):\n",
        "            # This function is now correctly imported from scipy.stats\n",
        "            wd = wasserstein_distance(X_real[:, i], X_syn[:, i])\n",
        "            distances.append(wd)\n",
        "        return np.mean(distances)\n",
        "\n",
        "    def kolmogorov_smirnov_test(self, X_real, X_syn):\n",
        "        \"\"\"KS test for each feature\"\"\"\n",
        "        ks_stats = []\n",
        "        p_values = []\n",
        "\n",
        "        for i in range(X_real.shape[1]):\n",
        "            ks_stat, p_val = stats.ks_2samp(X_real[:, i], X_syn[:, i])\n",
        "            ks_stats.append(ks_stat)\n",
        "            p_values.append(p_val)\n",
        "\n",
        "        return {\n",
        "            'ks_statistics': ks_stats,\n",
        "            'p_values': p_values,\n",
        "            'mean_ks_stat': np.mean(ks_stats),\n",
        "            'mean_p_value': np.mean(p_values)\n",
        "        }\n",
        "\n",
        "    def correlation_distance(self, X_real, X_syn):\n",
        "        \"\"\"Compare correlation matrices\"\"\"\n",
        "        corr_real = np.corrcoef(X_real.T)\n",
        "        corr_syn = np.corrcoef(X_syn.T)\n",
        "\n",
        "        # Handle NaN values\n",
        "        corr_real = np.nan_to_num(corr_real)\n",
        "        corr_syn = np.nan_to_num(corr_syn)\n",
        "\n",
        "        # Frobenius norm of difference\n",
        "        corr_distance = np.linalg.norm(corr_real - corr_syn, 'fro')\n",
        "\n",
        "        return {\n",
        "            'correlation_distance': corr_distance,\n",
        "            'real_correlation': corr_real,\n",
        "            'synthetic_correlation': corr_syn\n",
        "        }\n",
        "\n",
        "    def statistical_moments_comparison(self, X_real, X_syn):\n",
        "        \"\"\"Compare statistical moments\"\"\"\n",
        "        moments = {}\n",
        "\n",
        "        for i, stat_name in enumerate(['mean', 'std', 'skewness', 'kurtosis']):\n",
        "            real_stats = []\n",
        "            syn_stats = []\n",
        "\n",
        "            for j in range(X_real.shape[1]):\n",
        "                if stat_name == 'mean':\n",
        "                    real_stats.append(np.mean(X_real[:, j]))\n",
        "                    syn_stats.append(np.mean(X_syn[:, j]))\n",
        "                elif stat_name == 'std':\n",
        "                    real_stats.append(np.std(X_real[:, j]))\n",
        "                    syn_stats.append(np.std(X_syn[:, j]))\n",
        "                elif stat_name == 'skewness':\n",
        "                    real_stats.append(stats.skew(X_real[:, j]))\n",
        "                    syn_stats.append(stats.skew(X_syn[:, j]))\n",
        "                elif stat_name == 'kurtosis':\n",
        "                    real_stats.append(stats.kurtosis(X_real[:, j]))\n",
        "                    syn_stats.append(stats.kurtosis(X_syn[:, j]))\n",
        "\n",
        "            moments[stat_name] = {\n",
        "                'real': real_stats,\n",
        "                'synthetic': syn_stats,\n",
        "                'mse': np.mean((np.array(real_stats) - np.array(syn_stats))**2)\n",
        "            }\n",
        "\n",
        "        return moments\n",
        "\n",
        "    def privacy_evaluation(self, X_real, X_syn):\n",
        "        \"\"\"Distance to Closest Record (DCR) privacy evaluation\"\"\"\n",
        "        dcr_scores = []\n",
        "\n",
        "        # Sample for efficiency, can be increased for more thorough check\n",
        "        n_privacy_samples = min(200, len(X_syn))\n",
        "\n",
        "        for i in range(n_privacy_samples):\n",
        "            syn_record = X_syn[i]\n",
        "            distances = np.linalg.norm(X_real - syn_record, axis=1)\n",
        "            dcr_scores.append(np.min(distances))\n",
        "\n",
        "        return {\n",
        "            'mean_dcr': np.mean(dcr_scores),\n",
        "            'std_dcr': np.std(dcr_scores),\n",
        "            'min_dcr': np.min(dcr_scores)\n",
        "        }\n",
        "\n",
        "    def machine_learning_utility(self, X_real, y_real, X_syn, y_syn, test_size=0.2):\n",
        "        \"\"\"Evaluate ML utility by training classifiers\"\"\"\n",
        "        # Split real data\n",
        "        X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(\n",
        "            X_real, y_real, test_size=test_size, random_state=42, stratify=y_real\n",
        "        )\n",
        "\n",
        "        # Train on real data\n",
        "        rf_real = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        rf_real.fit(X_real_train, y_real_train)\n",
        "        real_score = rf_real.score(X_real_test, y_real_test)\n",
        "\n",
        "        # Train on synthetic data, test on real\n",
        "        rf_syn = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        rf_syn.fit(X_syn, y_syn)\n",
        "        syn_score = rf_syn.score(X_real_test, y_real_test)\n",
        "\n",
        "        return {\n",
        "            'real_data_performance': real_score,\n",
        "            'synthetic_data_performance': syn_score,\n",
        "            'utility_score': syn_score / real_score if real_score > 0 else 0.0\n",
        "        }\n",
        "\n",
        "    def evaluate_all_metrics(self, X_real, X_syn, y_real=None, y_syn=None):\n",
        "        \"\"\"Compute all evaluation metrics\"\"\"\n",
        "        print(\"Computing evaluation metrics...\")\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        # SJD\n",
        "        print(\"- Computing Sliced Jensen Distance...\")\n",
        "        results['sjd'] = self.sliced_jensen_distance(X_real, X_syn)\n",
        "\n",
        "        # Wasserstein Distance\n",
        "        print(\"- Computing Wasserstein Distance...\")\n",
        "        results['wasserstein'] = self.wasserstein_distance_multivariate(X_real, X_syn)\n",
        "\n",
        "        # KS Test\n",
        "        print(\"- Computing Kolmogorov-Smirnov Test...\")\n",
        "        results['ks_test'] = self.kolmogorov_smirnov_test(X_real, X_syn)\n",
        "\n",
        "        # Correlation Distance\n",
        "        print(\"- Computing Correlation Distance...\")\n",
        "        results['correlation'] = self.correlation_distance(X_real, X_syn)\n",
        "\n",
        "        # Statistical Moments\n",
        "        print(\"- Computing Statistical Moments...\")\n",
        "        results['moments'] = self.statistical_moments_comparison(X_real, X_syn)\n",
        "\n",
        "        # Privacy Evaluation\n",
        "        print(\"- Computing Privacy Metrics...\")\n",
        "        results['privacy'] = self.privacy_evaluation(X_real, X_syn)\n",
        "\n",
        "        # ML Utility (if labels provided)\n",
        "        if y_real is not None and y_syn is not None:\n",
        "            print(\"- Computing ML Utility...\")\n",
        "            results['ml_utility'] = self.machine_learning_utility(X_real, y_real, X_syn, y_syn)\n",
        "\n",
        "        return results\n",
        "\n",
        "# =============================================================================\n",
        "# DATA REVERSE TRANSFORMATION CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class DataReverseTransformer:\n",
        "    \"\"\"Transform generated data back to original format\"\"\"\n",
        "\n",
        "    def __init__(self, label_encoders, num_scaler, cat_attrs, num_attrs):\n",
        "        self.label_encoders = label_encoders\n",
        "        self.num_scaler = num_scaler\n",
        "        self.cat_attrs = cat_attrs # e.g., ['tcode', 'age_group']\n",
        "        self.num_attrs = num_attrs # e.g., ['amount', 'balance']\n",
        "\n",
        "    def reverse_transform_sequences(self, generated_sequences, cat_emb_dim=16):\n",
        "        \"\"\"\n",
        "        Transforms generated sequences back.\n",
        "        NOTE: Reversing embeddings is non-trivial and often ill-posed.\n",
        "        This function uses a nearest-neighbor-like heuristic for categorical data.\n",
        "        \"\"\"\n",
        "        print(\"Reversing transformation of generated sequences...\")\n",
        "\n",
        "        batch_size, seq_len, total_features = generated_sequences.shape\n",
        "\n",
        "        cat_dim_total = cat_emb_dim * len(self.cat_attrs)\n",
        "        num_dim_total = len(self.num_attrs)\n",
        "\n",
        "        # Split generated features into categorical and numerical parts\n",
        "        generated_cat_embeddings = generated_sequences[:, :, :cat_dim_total]\n",
        "        generated_num_features = generated_sequences[:, :, cat_dim_total:cat_dim_total + num_dim_total]\n",
        "\n",
        "        # --- Reverse transform numerical features ---\n",
        "        num_features_flat = generated_num_features.cpu().numpy().reshape(-1, num_dim_total)\n",
        "        num_features_original = self.num_scaler.inverse_transform(num_features_flat)\n",
        "        num_features_original = num_features_original.reshape(batch_size, seq_len, -1)\n",
        "\n",
        "        # --- Reverse transform categorical features ---\n",
        "        # This is a hard problem. We find the closest original embedding for each generated one.\n",
        "        cat_features_decoded = []\n",
        "        for i, attr in enumerate(self.cat_attrs):\n",
        "            encoder = self.label_encoders[attr]\n",
        "            n_categories = len(encoder.classes_)\n",
        "\n",
        "            # Get original embeddings for this attribute\n",
        "            original_indices = torch.arange(0, n_categories, device=generated_sequences.device)\n",
        "            # This requires a dummy embedding layer to get the original vectors\n",
        "            # Since we don't have it, we'll stick to a heuristic, but acknowledge it's a simplification.\n",
        "\n",
        "            # Heuristic: Take the part of the generated embedding for this feature\n",
        "            start_idx, end_idx = i * cat_emb_dim, (i + 1) * cat_emb_dim\n",
        "            feature_embedding_part = generated_cat_embeddings[:, :, start_idx:end_idx]\n",
        "\n",
        "            # A simplified approach is to map to the nearest integer index\n",
        "            # This assumes the embedding space has some ordinal structure, which is not guaranteed.\n",
        "            # Normalizing and scaling is a reasonable heuristic.\n",
        "            feature_embedding_norm = torch.sigmoid(feature_embedding_part.mean(dim=-1))\n",
        "            cat_indices = (feature_embedding_norm * (n_categories - 1)).round().long()\n",
        "            cat_indices = torch.clamp(cat_indices, 0, n_categories - 1)\n",
        "            cat_features_decoded.append(cat_indices.unsqueeze(-1))\n",
        "\n",
        "        cat_features_decoded = torch.cat(cat_features_decoded, dim=-1)\n",
        "\n",
        "        # Convert decoded categorical indices back to original labels\n",
        "        cat_features_original_dfs = {}\n",
        "        for i, attr in enumerate(self.cat_attrs):\n",
        "            indices_flat = cat_features_decoded[:, :, i].cpu().numpy().flatten()\n",
        "            labels = self.label_encoders[attr].inverse_transform(indices_flat)\n",
        "            cat_features_original_dfs[attr.replace('_encoded', '')] = labels.reshape(batch_size, seq_len)\n",
        "\n",
        "        return cat_features_original_dfs, num_features_original\n",
        "\n",
        "    def sequences_to_dataframe(self, cat_features_original_dfs, num_features_original):\n",
        "        \"\"\"Convert reversed sequences into a single DataFrame\"\"\"\n",
        "        print(\"Converting sequences to dataframe...\")\n",
        "\n",
        "        batch_size, seq_len = list(cat_features_original_dfs.values())[0].shape\n",
        "\n",
        "        synthetic_data_list = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            for j in range(seq_len):\n",
        "                record = {f'synthetic_account_id': f'syn_{i}'}\n",
        "                # Add categorical features for this record\n",
        "                for attr, values in cat_features_original_dfs.items():\n",
        "                    record[attr] = values[i, j]\n",
        "                # Add numerical features for this record\n",
        "                for k, attr in enumerate(self.num_attrs):\n",
        "                    record[attr] = num_features_original[i, j, k]\n",
        "                synthetic_data_list.append(record)\n",
        "\n",
        "        return pd.DataFrame(synthetic_data_list)\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN FUNCTION WITH EVALUATION\n",
        "# =============================================================================\n",
        "\n",
        "def main_with_evaluation():\n",
        "    \"\"\"Main function to load model, generate data, and run evaluation\"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"SYNTHETIC BANKING DATA GENERATION AND EVALUATION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # --- Setup ---\n",
        "    seed = 42\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # --- Load Model and Data from Checkpoint ---\n",
        "    checkpoint_path = 'sequential_banking_model.pth'\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        print(f\"ERROR: Checkpoint file not found at '{checkpoint_path}'.\")\n",
        "        print(\"Please run the training script first to generate the model file.\")\n",
        "        return\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    print(\"Loaded existing model checkpoint.\")\n",
        "\n",
        "    generated_sequences = checkpoint['generated_sequences']\n",
        "    label_encoders = checkpoint['label_encoders']\n",
        "    num_scaler = checkpoint['num_scaler']\n",
        "    cat_attrs = checkpoint['cat_attrs']\n",
        "    num_attrs = checkpoint['num_attrs']\n",
        "\n",
        "    print(f\"Generated sequences shape: {generated_sequences.shape}\")\n",
        "\n",
        "    # --- Reverse Transform Data ---\n",
        "    reverse_transformer = DataReverseTransformer(\n",
        "        label_encoders=label_encoders,\n",
        "        num_scaler=num_scaler,\n",
        "        cat_attrs=cat_attrs,\n",
        "        num_attrs=num_attrs\n",
        "    )\n",
        "\n",
        "    cat_features_original_dfs, num_features_original = reverse_transformer.reverse_transform_sequences(\n",
        "        generated_sequences, cat_emb_dim=16\n",
        "    )\n",
        "\n",
        "    df_synthetic = reverse_transformer.sequences_to_dataframe(\n",
        "        cat_features_original_dfs, num_features_original\n",
        "    )\n",
        "\n",
        "    print(f\"Generated synthetic dataframe with shape: {df_synthetic.shape}\")\n",
        "    print(\"\\nSynthetic data sample:\")\n",
        "    print(df_synthetic.head())\n",
        "\n",
        "    # --- Load and Prepare Real Data for Comparison ---\n",
        "    # NOTE: For a rigorous evaluation, you should use a held-out test set\n",
        "    # from your original data. Here, we generate a sample for demonstration.\n",
        "    print(\"\\nGenerating a sample of real data for comparison...\")\n",
        "    # This part should be replaced with loading your actual test data.\n",
        "    real_data_path = 'raw_data.csv' # Assuming you have this file\n",
        "    if os.path.exists(real_data_path):\n",
        "        df_real_raw = pd.read_csv(real_data_path)\n",
        "        # Apply the same initial preprocessing as in the training script\n",
        "        # This is a simplified version of your 'preprocess_data_czech'\n",
        "        df_real_raw['raw_amount'] = df_real_raw.apply(\n",
        "            lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1\n",
        "        )\n",
        "        df_real_raw['balance'] = df_real_raw.groupby('account_id')['raw_amount'].cumsum()\n",
        "        df_real_raw['td'] = df_real_raw.groupby('account_id')['date'].diff().fillna(0)\n",
        "        df_real_raw['log_balance'] = np.log10(np.abs(df_real_raw['balance']) + 1)\n",
        "        df_real = df_real_raw\n",
        "    else:\n",
        "        print(\"Warning: 'raw_data.csv' not found. Creating a mock real dataset.\")\n",
        "        # Fallback to creating a random dataset if no real data is available\n",
        "        # Your original code for creating mock data goes here\n",
        "        # This is kept for reproducibility if raw data is unavailable\n",
        "        n_transactions = 5000\n",
        "        real_sample_data = []\n",
        "        for i in range(n_transactions):\n",
        "            real_sample_data.append({\n",
        "                'account_id': np.random.randint(1, 100 + 1),\n",
        "                'date': 950101 + np.random.randint(0, 3650),\n",
        "                'amount': np.random.lognormal(3, 1) * 100,\n",
        "                'type': np.random.choice(['CREDIT', 'DEBIT']),\n",
        "                'operation': np.random.choice(['CREDIT IN CASH', 'CASH WITHDRAWAL', 'REMITTANCE TO ANOTHER BANK']),\n",
        "                'k_symbol': np.random.choice(['PAYMENT ON STATEMENT', 'HOUSEHOLD', 'INTEREST CREDITED']),\n",
        "                'age': np.random.randint(18, 80),\n",
        "                'day': np.random.randint(1, 29),\n",
        "                'month': np.random.randint(1, 13),\n",
        "                'year': np.random.randint(1995, 1998),\n",
        "                'tcode': 'mock_tcode'\n",
        "            })\n",
        "        df_real = pd.DataFrame(real_sample_data)\n",
        "        df_real['raw_amount'] = df_real.apply(lambda r: r['amount'] if r['type'] == 'CREDIT' else -r['amount'], axis=1)\n",
        "        df_real['balance'] = df_real.groupby('account_id')['raw_amount'].cumsum()\n",
        "        df_real['td'] = df_real.groupby('account_id')['date'].diff().fillna(0)\n",
        "        df_real['log_balance'] = np.log10(np.abs(df_real['balance']) + 1)\n",
        "\n",
        "\n",
        "    print(f\"Real data shape: {df_real.shape}\")\n",
        "    print(\"\\nReal data sample:\")\n",
        "    print(df_real.head())\n",
        "\n",
        "    # --- Prepare Data for Evaluation ---\n",
        "    print(\"\\nPreparing data for evaluation...\")\n",
        "\n",
        "    # Use only the numerical attributes that were scaled for a fair comparison\n",
        "    eval_num_features = num_attrs\n",
        "\n",
        "    # Filter to common features and handle missing columns\n",
        "    common_cols = [col for col in eval_num_features if col in df_real.columns and col in df_synthetic.columns]\n",
        "    print(f\"Evaluating on common numerical columns: {common_cols}\")\n",
        "\n",
        "    X_real = df_real[common_cols].values\n",
        "    X_syn = df_synthetic[common_cols].values\n",
        "\n",
        "    # Handle any NaN or infinite values\n",
        "    X_real = np.nan_to_num(X_real, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "    X_syn = np.nan_to_num(X_syn, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "\n",
        "    # Sample equal amounts for fair comparison\n",
        "    n_samples = min(len(X_real), len(X_syn))\n",
        "    indices_real = np.random.choice(len(X_real), n_samples, replace=False)\n",
        "    indices_syn = np.random.choice(len(X_syn), n_samples, replace=False)\n",
        "\n",
        "    X_real_sampled = X_real[indices_real]\n",
        "    X_syn_sampled = X_syn[indices_syn]\n",
        "\n",
        "    print(f\"Evaluation data shapes - Real: {X_real_sampled.shape}, Synthetic: {X_syn_sampled.shape}\")\n",
        "\n",
        "    # --- Run Evaluation ---\n",
        "    evaluator = SyntheticDataEvaluator()\n",
        "    results = evaluator.evaluate_all_metrics(X_real_sampled, X_syn_sampled)\n",
        "\n",
        "    # --- Display Results ---\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"EVALUATION RESULTS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    print(f\"\\n1. SLICED JENSEN DISTANCE (SJD)\")\n",
        "    print(f\"   SJD Score: {results['sjd']:.4f} (Lower is better, 0 = perfect match)\")\n",
        "\n",
        "    print(f\"\\n2. WASSERSTEIN DISTANCE\")\n",
        "    print(f\"   Average Wasserstein Distance: {results['wasserstein']:.4f} (Lower is better)\")\n",
        "\n",
        "    print(f\"\\n3. KOLMOGOROV-SMIRNOV TEST\")\n",
        "    print(f\"   Mean KS Statistic: {results['ks_test']['mean_ks_stat']:.4f} (Lower is better)\")\n",
        "    print(f\"   Mean P-value: {results['ks_test']['mean_p_value']:.4f} (Higher indicates similar distributions)\")\n",
        "\n",
        "    print(f\"\\n4. CORRELATION DISTANCE\")\n",
        "    print(f\"   Correlation Matrix Distance: {results['correlation']['correlation_distance']:.4f} (Lower is better)\")\n",
        "\n",
        "    print(f\"\\n5. STATISTICAL MOMENTS COMPARISON\")\n",
        "    for moment, values in results['moments'].items():\n",
        "        print(f\"   {moment.upper()} MSE: {values['mse']:.4f} (Lower is better)\")\n",
        "\n",
        "    print(f\"\\n6. PRIVACY EVALUATION (DCR)\")\n",
        "    print(f\"   Mean Distance to Closest Record: {results['privacy']['mean_dcr']:.4f} (Higher is better for privacy)\")\n",
        "\n",
        "    # --- Generate Visualizations ---\n",
        "    print(\"\\nGenerating visualizations...\")\n",
        "\n",
        "    # Distribution Comparison Plot\n",
        "    n_features_to_plot = len(common_cols)\n",
        "    n_cols = 3\n",
        "    n_rows = (n_features_to_plot + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows))\n",
        "    fig.suptitle('Real vs Synthetic Data Distribution Comparison', fontsize=16)\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, feature in enumerate(common_cols):\n",
        "        ax = axes[i]\n",
        "        sns.histplot(X_real_sampled[:, i], bins=50, ax=ax, color='blue', label='Real', stat='density', alpha=0.6)\n",
        "        sns.histplot(X_syn_sampled[:, i], bins=50, ax=ax, color='orange', label='Synthetic', stat='density', alpha=0.6)\n",
        "        ax.set_title(f'{feature} Distribution')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    for i in range(n_features_to_plot, len(axes)):\n",
        "        fig.delaxes(axes[i]) # Remove unused subplots\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.savefig('data_comparison.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Correlation Matrix Comparison\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
        "    sns.heatmap(results['correlation']['real_correlation'], ax=ax1, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    ax1.set_title('Real Data Correlation Matrix')\n",
        "    ax1.set_xticklabels(common_cols, rotation=45, ha='right')\n",
        "    ax1.set_yticklabels(common_cols, rotation=0)\n",
        "\n",
        "    sns.heatmap(results['correlation']['synthetic_correlation'], ax=ax2, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    ax2.set_title('Synthetic Data Correlation Matrix')\n",
        "    ax2.set_xticklabels(common_cols, rotation=45, ha='right')\n",
        "    ax2.set_yticklabels(common_cols, rotation=0)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('correlation_comparison.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nVisualizations saved as 'data_comparison.png' and 'correlation_comparison.png'\")\n",
        "\n",
        "    # --- Save Detailed Results ---\n",
        "    import json\n",
        "    def convert_for_json(obj):\n",
        "        if isinstance(obj, np.ndarray): return obj.tolist()\n",
        "        if isinstance(obj, (np.integer, np.int64)): return int(obj)\n",
        "        if isinstance(obj, (np.floating, np.float64)): return float(obj)\n",
        "        if isinstance(obj, dict): return {k: convert_for_json(v) for k, v in obj.items()}\n",
        "        if isinstance(obj, list): return [convert_for_json(i) for i in obj]\n",
        "        return obj\n",
        "\n",
        "    with open('evaluation_results.json', 'w') as f:\n",
        "        json.dump(convert_for_json(results), f, indent=4)\n",
        "\n",
        "    print(\"Detailed numerical results saved to 'evaluation_results.json'\")\n",
        "\n",
        "    return df_synthetic, df_real, results\n",
        "\n",
        "\n",
        "    # This ensures the main function runs when the script is executed\n",
        "synthetic_data, real_data, evaluation_results = main_with_evaluation()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "rNcAP8XejYtf",
        "outputId": "f28aad80-88d2-4272-d7cb-bb966963bdc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SYNTHETIC BANKING DATA GENERATION AND EVALUATION\n",
            "================================================================================\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL sklearn.preprocessing._label.LabelEncoder was not an allowed global by default. Please use `torch.serialization.add_safe_globals([LabelEncoder])` or the `torch.serialization.safe_globals([LabelEncoder])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5d8852391f20>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0;31m# This ensures the main function runs when the script is executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m \u001b[0msynthetic_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_with_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-5d8852391f20>\u001b[0m in \u001b[0;36mmain_with_evaluation\u001b[0;34m()\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded existing model checkpoint.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1468\u001b[0m                         )\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m                 return _load(\n\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL sklearn.preprocessing._label.LabelEncoder was not an allowed global by default. Please use `torch.serialization.add_safe_globals([LabelEncoder])` or the `torch.serialization.safe_globals([LabelEncoder])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "from tqdm import tqdm\n",
        "from scipy import stats, linalg\n",
        "from scipy.stats import wasserstein_distance # <-- FIXED: Correct import location\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# EVALUATION METRICS CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class SyntheticDataEvaluator:\n",
        "    \"\"\"Comprehensive evaluation metrics for synthetic banking data\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.metrics_results = {}\n",
        "\n",
        "    def sliced_jensen_distance(self, X_real, X_syn, num_projections=100):\n",
        "        \"\"\"\n",
        "        Compute Sliced Jensen Distance (SJD) between real and synthetic data\n",
        "        \"\"\"\n",
        "        if X_real.shape[1] != X_syn.shape[1]:\n",
        "            raise ValueError(\"Real and synthetic data must have same number of features\")\n",
        "\n",
        "        n_features = X_real.shape[1]\n",
        "        distances = []\n",
        "\n",
        "        for _ in range(num_projections):\n",
        "            # Random unit vector for projection\n",
        "            direction = np.random.randn(n_features)\n",
        "            direction = direction / np.linalg.norm(direction)\n",
        "\n",
        "            # Project data onto this direction\n",
        "            proj_real = X_real @ direction\n",
        "            proj_syn = X_syn @ direction\n",
        "\n",
        "            # Compute Jensen-Shannon distance on projections\n",
        "            js_dist = self._jensen_shannon_distance(proj_real, proj_syn)\n",
        "            distances.append(js_dist)\n",
        "\n",
        "        return np.mean(distances)\n",
        "\n",
        "    def _jensen_shannon_distance(self, X, Y, num_bins=50):\n",
        "        \"\"\"Compute Jensen-Shannon distance between two 1D distributions\"\"\"\n",
        "        # Create histograms\n",
        "        min_val = min(X.min(), Y.min())\n",
        "        max_val = max(X.max(), Y.max())\n",
        "        bins = np.linspace(min_val, max_val, num_bins + 1)\n",
        "\n",
        "        hist_X, _ = np.histogram(X, bins=bins, density=True)\n",
        "        hist_Y, _ = np.histogram(Y, bins=bins, density=True)\n",
        "\n",
        "        # Normalize to probabilities\n",
        "        hist_X = hist_X / (hist_X.sum() + 1e-10)\n",
        "        hist_Y = hist_Y / (hist_Y.sum() + 1e-10)\n",
        "\n",
        "        # Add small epsilon to avoid log(0)\n",
        "        eps = 1e-10\n",
        "        hist_X = hist_X + eps\n",
        "        hist_Y = hist_Y + eps\n",
        "\n",
        "        # Jensen-Shannon distance\n",
        "        M = 0.5 * (hist_X + hist_Y)\n",
        "        js_dist = 0.5 * stats.entropy(hist_X, M, base=2) + 0.5 * stats.entropy(hist_Y, M, base=2)\n",
        "\n",
        "        return np.sqrt(js_dist)\n",
        "\n",
        "    def wasserstein_distance_multivariate(self, X_real, X_syn):\n",
        "        \"\"\"Compute average Wasserstein distance across features\"\"\"\n",
        "        distances = []\n",
        "        for i in range(X_real.shape[1]):\n",
        "            # This function is now correctly imported from scipy.stats\n",
        "            wd = wasserstein_distance(X_real[:, i], X_syn[:, i])\n",
        "            distances.append(wd)\n",
        "        return np.mean(distances)\n",
        "\n",
        "    def kolmogorov_smirnov_test(self, X_real, X_syn):\n",
        "        \"\"\"KS test for each feature\"\"\"\n",
        "        ks_stats = []\n",
        "        p_values = []\n",
        "\n",
        "        for i in range(X_real.shape[1]):\n",
        "            ks_stat, p_val = stats.ks_2samp(X_real[:, i], X_syn[:, i])\n",
        "            ks_stats.append(ks_stat)\n",
        "            p_values.append(p_val)\n",
        "\n",
        "        return {\n",
        "            'ks_statistics': ks_stats,\n",
        "            'p_values': p_values,\n",
        "            'mean_ks_stat': np.mean(ks_stats),\n",
        "            'mean_p_value': np.mean(p_values)\n",
        "        }\n",
        "\n",
        "    def correlation_distance(self, X_real, X_syn):\n",
        "        \"\"\"Compare correlation matrices\"\"\"\n",
        "        corr_real = np.corrcoef(X_real.T)\n",
        "        corr_syn = np.corrcoef(X_syn.T)\n",
        "\n",
        "        # Handle NaN values\n",
        "        corr_real = np.nan_to_num(corr_real)\n",
        "        corr_syn = np.nan_to_num(corr_syn)\n",
        "\n",
        "        # Frobenius norm of difference\n",
        "        corr_distance = np.linalg.norm(corr_real - corr_syn, 'fro')\n",
        "\n",
        "        return {\n",
        "            'correlation_distance': corr_distance,\n",
        "            'real_correlation': corr_real,\n",
        "            'synthetic_correlation': corr_syn\n",
        "        }\n",
        "\n",
        "    def statistical_moments_comparison(self, X_real, X_syn):\n",
        "        \"\"\"Compare statistical moments\"\"\"\n",
        "        moments = {}\n",
        "\n",
        "        for i, stat_name in enumerate(['mean', 'std', 'skewness', 'kurtosis']):\n",
        "            real_stats = []\n",
        "            syn_stats = []\n",
        "\n",
        "            for j in range(X_real.shape[1]):\n",
        "                if stat_name == 'mean':\n",
        "                    real_stats.append(np.mean(X_real[:, j]))\n",
        "                    syn_stats.append(np.mean(X_syn[:, j]))\n",
        "                elif stat_name == 'std':\n",
        "                    real_stats.append(np.std(X_real[:, j]))\n",
        "                    syn_stats.append(np.std(X_syn[:, j]))\n",
        "                elif stat_name == 'skewness':\n",
        "                    real_stats.append(stats.skew(X_real[:, j]))\n",
        "                    syn_stats.append(stats.skew(X_syn[:, j]))\n",
        "                elif stat_name == 'kurtosis':\n",
        "                    real_stats.append(stats.kurtosis(X_real[:, j]))\n",
        "                    syn_stats.append(stats.kurtosis(X_syn[:, j]))\n",
        "\n",
        "            moments[stat_name] = {\n",
        "                'real': real_stats,\n",
        "                'synthetic': syn_stats,\n",
        "                'mse': np.mean((np.array(real_stats) - np.array(syn_stats))**2)\n",
        "            }\n",
        "\n",
        "        return moments\n",
        "\n",
        "    def privacy_evaluation(self, X_real, X_syn):\n",
        "        \"\"\"Distance to Closest Record (DCR) privacy evaluation\"\"\"\n",
        "        dcr_scores = []\n",
        "\n",
        "        # Sample for efficiency, can be increased for more thorough check\n",
        "        n_privacy_samples = min(200, len(X_syn))\n",
        "\n",
        "        for i in range(n_privacy_samples):\n",
        "            syn_record = X_syn[i]\n",
        "            distances = np.linalg.norm(X_real - syn_record, axis=1)\n",
        "            dcr_scores.append(np.min(distances))\n",
        "\n",
        "        return {\n",
        "            'mean_dcr': np.mean(dcr_scores),\n",
        "            'std_dcr': np.std(dcr_scores),\n",
        "            'min_dcr': np.min(dcr_scores)\n",
        "        }\n",
        "\n",
        "    def machine_learning_utility(self, X_real, y_real, X_syn, y_syn, test_size=0.2):\n",
        "        \"\"\"Evaluate ML utility by training classifiers\"\"\"\n",
        "        # Split real data\n",
        "        X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(\n",
        "            X_real, y_real, test_size=test_size, random_state=42, stratify=y_real\n",
        "        )\n",
        "\n",
        "        # Train on real data\n",
        "        rf_real = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        rf_real.fit(X_real_train, y_real_train)\n",
        "        real_score = rf_real.score(X_real_test, y_real_test)\n",
        "\n",
        "        # Train on synthetic data, test on real\n",
        "        rf_syn = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        rf_syn.fit(X_syn, y_syn)\n",
        "        syn_score = rf_syn.score(X_real_test, y_real_test)\n",
        "\n",
        "        return {\n",
        "            'real_data_performance': real_score,\n",
        "            'synthetic_data_performance': syn_score,\n",
        "            'utility_score': syn_score / real_score if real_score > 0 else 0.0\n",
        "        }\n",
        "\n",
        "    def evaluate_all_metrics(self, X_real, X_syn, y_real=None, y_syn=None):\n",
        "        \"\"\"Compute all evaluation metrics\"\"\"\n",
        "        print(\"Computing evaluation metrics...\")\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        # SJD\n",
        "        print(\"- Computing Sliced Jensen Distance...\")\n",
        "        results['sjd'] = self.sliced_jensen_distance(X_real, X_syn)\n",
        "\n",
        "        # Wasserstein Distance\n",
        "        print(\"- Computing Wasserstein Distance...\")\n",
        "        results['wasserstein'] = self.wasserstein_distance_multivariate(X_real, X_syn)\n",
        "\n",
        "        # KS Test\n",
        "        print(\"- Computing Kolmogorov-Smirnov Test...\")\n",
        "        results['ks_test'] = self.kolmogorov_smirnov_test(X_real, X_syn)\n",
        "\n",
        "        # Correlation Distance\n",
        "        print(\"- Computing Correlation Distance...\")\n",
        "        results['correlation'] = self.correlation_distance(X_real, X_syn)\n",
        "\n",
        "        # Statistical Moments\n",
        "        print(\"- Computing Statistical Moments...\")\n",
        "        results['moments'] = self.statistical_moments_comparison(X_real, X_syn)\n",
        "\n",
        "        # Privacy Evaluation\n",
        "        print(\"- Computing Privacy Metrics...\")\n",
        "        results['privacy'] = self.privacy_evaluation(X_real, X_syn)\n",
        "\n",
        "        # ML Utility (if labels provided)\n",
        "        if y_real is not None and y_syn is not None:\n",
        "            print(\"- Computing ML Utility...\")\n",
        "            results['ml_utility'] = self.machine_learning_utility(X_real, y_real, X_syn, y_syn)\n",
        "\n",
        "        return results\n",
        "\n",
        "# =============================================================================\n",
        "# DATA REVERSE TRANSFORMATION CLASS\n",
        "# =============================================================================\n",
        "\n",
        "class DataReverseTransformer:\n",
        "    \"\"\"Transform generated data back to original format\"\"\"\n",
        "\n",
        "    def __init__(self, label_encoders, num_scaler, cat_attrs, num_attrs):\n",
        "        self.label_encoders = label_encoders\n",
        "        self.num_scaler = num_scaler\n",
        "        self.cat_attrs = cat_attrs # e.g., ['tcode', 'age_group']\n",
        "        self.num_attrs = num_attrs # e.g., ['amount', 'balance']\n",
        "\n",
        "    def reverse_transform_sequences(self, generated_sequences, cat_emb_dim=16):\n",
        "        \"\"\"\n",
        "        Transforms generated sequences back.\n",
        "        NOTE: Reversing embeddings is non-trivial and often ill-posed.\n",
        "        This function uses a nearest-neighbor-like heuristic for categorical data.\n",
        "        \"\"\"\n",
        "        print(\"Reversing transformation of generated sequences...\")\n",
        "\n",
        "        batch_size, seq_len, total_features = generated_sequences.shape\n",
        "\n",
        "        cat_dim_total = cat_emb_dim * len(self.cat_attrs)\n",
        "        num_dim_total = len(self.num_attrs)\n",
        "\n",
        "        # Split generated features into categorical and numerical parts\n",
        "        generated_cat_embeddings = generated_sequences[:, :, :cat_dim_total]\n",
        "        generated_num_features = generated_sequences[:, :, cat_dim_total:cat_dim_total + num_dim_total]\n",
        "\n",
        "        # --- Reverse transform numerical features ---\n",
        "        num_features_flat = generated_num_features.cpu().numpy().reshape(-1, num_dim_total)\n",
        "        num_features_original = self.num_scaler.inverse_transform(num_features_flat)\n",
        "        num_features_original = num_features_original.reshape(batch_size, seq_len, -1)\n",
        "\n",
        "        # --- Reverse transform categorical features ---\n",
        "        # This is a hard problem. We find the closest original embedding for each generated one.\n",
        "        cat_features_decoded = []\n",
        "        for i, attr in enumerate(self.cat_attrs):\n",
        "            encoder = self.label_encoders[attr]\n",
        "            n_categories = len(encoder.classes_)\n",
        "\n",
        "            # Get original embeddings for this attribute\n",
        "            original_indices = torch.arange(0, n_categories, device=generated_sequences.device)\n",
        "            # This requires a dummy embedding layer to get the original vectors\n",
        "            # Since we don't have it, we'll stick to a heuristic, but acknowledge it's a simplification.\n",
        "\n",
        "            # Heuristic: Take the part of the generated embedding for this feature\n",
        "            start_idx, end_idx = i * cat_emb_dim, (i + 1) * cat_emb_dim\n",
        "            feature_embedding_part = generated_cat_embeddings[:, :, start_idx:end_idx]\n",
        "\n",
        "            # A simplified approach is to map to the nearest integer index\n",
        "            # This assumes the embedding space has some ordinal structure, which is not guaranteed.\n",
        "            # Normalizing and scaling is a reasonable heuristic.\n",
        "            feature_embedding_norm = torch.sigmoid(feature_embedding_part.mean(dim=-1))\n",
        "            cat_indices = (feature_embedding_norm * (n_categories - 1)).round().long()\n",
        "            cat_indices = torch.clamp(cat_indices, 0, n_categories - 1)\n",
        "            cat_features_decoded.append(cat_indices.unsqueeze(-1))\n",
        "\n",
        "        cat_features_decoded = torch.cat(cat_features_decoded, dim=-1)\n",
        "\n",
        "        # Convert decoded categorical indices back to original labels\n",
        "        cat_features_original_dfs = {}\n",
        "        for i, attr in enumerate(self.cat_attrs):\n",
        "            indices_flat = cat_features_decoded[:, :, i].cpu().numpy().flatten()\n",
        "            labels = self.label_encoders[attr].inverse_transform(indices_flat)\n",
        "            cat_features_original_dfs[attr.replace('_encoded', '')] = labels.reshape(batch_size, seq_len)\n",
        "\n",
        "        return cat_features_original_dfs, num_features_original\n",
        "\n",
        "    def sequences_to_dataframe(self, cat_features_original_dfs, num_features_original):\n",
        "        \"\"\"Convert reversed sequences into a single DataFrame\"\"\"\n",
        "        print(\"Converting sequences to dataframe...\")\n",
        "\n",
        "        batch_size, seq_len = list(cat_features_original_dfs.values())[0].shape\n",
        "\n",
        "        synthetic_data_list = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            for j in range(seq_len):\n",
        "                record = {f'synthetic_account_id': f'syn_{i}'}\n",
        "                # Add categorical features for this record\n",
        "                for attr, values in cat_features_original_dfs.items():\n",
        "                    record[attr] = values[i, j]\n",
        "                # Add numerical features for this record\n",
        "                for k, attr in enumerate(self.num_attrs):\n",
        "                    record[attr] = num_features_original[i, j, k]\n",
        "                synthetic_data_list.append(record)\n",
        "\n",
        "        return pd.DataFrame(synthetic_data_list)\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN FUNCTION WITH EVALUATION\n",
        "# =============================================================================\n",
        "\n",
        "def main_with_evaluation():\n",
        "    \"\"\"Main function to load model, generate data, and run evaluation\"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"SYNTHETIC BANKING DATA GENERATION AND EVALUATION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # --- Setup ---\n",
        "    seed = 42\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # --- Load Model and Data from Checkpoint ---\n",
        "    checkpoint_path = 'sequential_banking_model.pth'\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        print(f\"ERROR: Checkpoint file not found at '{checkpoint_path}'.\")\n",
        "        print(\"Please run the training script first to generate the model file.\")\n",
        "        return\n",
        "\n",
        "    # FIXED: Added weights_only=False to allow loading of sklearn objects\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "    print(\"Loaded existing model checkpoint.\")\n",
        "\n",
        "    generated_sequences = checkpoint['generated_sequences']\n",
        "    label_encoders = checkpoint['label_encoders']\n",
        "    num_scaler = checkpoint['num_scaler']\n",
        "    cat_attrs = checkpoint['cat_attrs']\n",
        "    num_attrs = checkpoint['num_attrs']\n",
        "\n",
        "    print(f\"Generated sequences shape: {generated_sequences.shape}\")\n",
        "\n",
        "    # --- Reverse Transform Data ---\n",
        "    reverse_transformer = DataReverseTransformer(\n",
        "        label_encoders=label_encoders,\n",
        "        num_scaler=num_scaler,\n",
        "        cat_attrs=cat_attrs,\n",
        "        num_attrs=num_attrs\n",
        "    )\n",
        "\n",
        "    cat_features_original_dfs, num_features_original = reverse_transformer.reverse_transform_sequences(\n",
        "        generated_sequences, cat_emb_dim=16\n",
        "    )\n",
        "\n",
        "    df_synthetic = reverse_transformer.sequences_to_dataframe(\n",
        "        cat_features_original_dfs, num_features_original\n",
        "    )\n",
        "\n",
        "    print(f\"Generated synthetic dataframe with shape: {df_synthetic.shape}\")\n",
        "    print(\"\\nSynthetic data sample:\")\n",
        "    print(df_synthetic.head())\n",
        "\n",
        "    # --- Load and Prepare Real Data for Comparison ---\n",
        "    # NOTE: For a rigorous evaluation, you should use a held-out test set\n",
        "    # from your original data. Here, we generate a sample for demonstration.\n",
        "    print(\"\\nGenerating a sample of real data for comparison...\")\n",
        "    # This part should be replaced with loading your actual test data.\n",
        "    real_data_path = 'raw_data.csv' # Assuming you have this file\n",
        "    if os.path.exists(real_data_path):\n",
        "        df_real_raw = pd.read_csv(real_data_path)\n",
        "        # Apply the same initial preprocessing as in the training script\n",
        "        # This is a simplified version of your 'preprocess_data_czech'\n",
        "        df_real_raw['raw_amount'] = df_real_raw.apply(\n",
        "            lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1\n",
        "        )\n",
        "        df_real_raw['balance'] = df_real_raw.groupby('account_id')['raw_amount'].cumsum()\n",
        "        df_real_raw['td'] = df_real_raw.groupby('account_id')['date'].diff().fillna(0)\n",
        "        df_real_raw['log_balance'] = np.log10(np.abs(df_real_raw['balance']) + 1)\n",
        "        df_real = df_real_raw\n",
        "    else:\n",
        "        print(\"Warning: 'raw_data.csv' not found. Creating a mock real dataset.\")\n",
        "        # Fallback to creating a random dataset if no real data is available\n",
        "        # Your original code for creating mock data goes here\n",
        "        # This is kept for reproducibility if raw data is unavailable\n",
        "        n_transactions = 5000\n",
        "        real_sample_data = []\n",
        "        for i in range(n_transactions):\n",
        "            real_sample_data.append({\n",
        "                'account_id': np.random.randint(1, 100 + 1),\n",
        "                'date': 950101 + np.random.randint(0, 3650),\n",
        "                'amount': np.random.lognormal(3, 1) * 100,\n",
        "                'type': np.random.choice(['CREDIT', 'DEBIT']),\n",
        "                'operation': np.random.choice(['CREDIT IN CASH', 'CASH WITHDRAWAL', 'REMITTANCE TO ANOTHER BANK']),\n",
        "                'k_symbol': np.random.choice(['PAYMENT ON STATEMENT', 'HOUSEHOLD', 'INTEREST CREDITED']),\n",
        "                'age': np.random.randint(18, 80),\n",
        "                'day': np.random.randint(1, 29),\n",
        "                'month': np.random.randint(1, 13),\n",
        "                'year': np.random.randint(1995, 1998),\n",
        "                'tcode': 'mock_tcode'\n",
        "            })\n",
        "        df_real = pd.DataFrame(real_sample_data)\n",
        "        df_real['raw_amount'] = df_real.apply(lambda r: r['amount'] if r['type'] == 'CREDIT' else -r['amount'], axis=1)\n",
        "        df_real['balance'] = df_real.groupby('account_id')['raw_amount'].cumsum()\n",
        "        df_real['td'] = df_real.groupby('account_id')['date'].diff().fillna(0)\n",
        "        df_real['log_balance'] = np.log10(np.abs(df_real['balance']) + 1)\n",
        "\n",
        "\n",
        "    print(f\"Real data shape: {df_real.shape}\")\n",
        "    print(\"\\nReal data sample:\")\n",
        "    print(df_real.head())\n",
        "\n",
        "    # --- Prepare Data for Evaluation ---\n",
        "    print(\"\\nPreparing data for evaluation...\")\n",
        "\n",
        "    # Use only the numerical attributes that were scaled for a fair comparison\n",
        "    eval_num_features = num_attrs\n",
        "\n",
        "    # Filter to common features and handle missing columns\n",
        "    common_cols = [col for col in eval_num_features if col in df_real.columns and col in df_synthetic.columns]\n",
        "    print(f\"Evaluating on common numerical columns: {common_cols}\")\n",
        "\n",
        "    X_real = df_real[common_cols].values\n",
        "    X_syn = df_synthetic[common_cols].values\n",
        "\n",
        "    # Handle any NaN or infinite values\n",
        "    X_real = np.nan_to_num(X_real, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "    X_syn = np.nan_to_num(X_syn, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "\n",
        "    # Sample equal amounts for fair comparison\n",
        "    n_samples = min(len(X_real), len(X_syn))\n",
        "    indices_real = np.random.choice(len(X_real), n_samples, replace=False)\n",
        "    indices_syn = np.random.choice(len(X_syn), n_samples, replace=False)\n",
        "\n",
        "    X_real_sampled = X_real[indices_real]\n",
        "    X_syn_sampled = X_syn[indices_syn]\n",
        "\n",
        "    print(f\"Evaluation data shapes - Real: {X_real_sampled.shape}, Synthetic: {X_syn_sampled.shape}\")\n",
        "\n",
        "    # --- Run Evaluation ---\n",
        "    evaluator = SyntheticDataEvaluator()\n",
        "    results = evaluator.evaluate_all_metrics(X_real_sampled, X_syn_sampled)\n",
        "\n",
        "    # --- Display Results ---\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"EVALUATION RESULTS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    print(f\"\\n1. SLICED JENSEN DISTANCE (SJD)\")\n",
        "    print(f\"   SJD Score: {results['sjd']:.4f} (Lower is better, 0 = perfect match)\")\n",
        "\n",
        "    print(f\"\\n2. WASSERSTEIN DISTANCE\")\n",
        "    print(f\"   Average Wasserstein Distance: {results['wasserstein']:.4f} (Lower is better)\")\n",
        "\n",
        "    print(f\"\\n3. KOLMOGOROV-SMIRNOV TEST\")\n",
        "    print(f\"   Mean KS Statistic: {results['ks_test']['mean_ks_stat']:.4f} (Lower is better)\")\n",
        "    print(f\"   Mean P-value: {results['ks_test']['mean_p_value']:.4f} (Higher indicates similar distributions)\")\n",
        "\n",
        "    print(f\"\\n4. CORRELATION DISTANCE\")\n",
        "    print(f\"   Correlation Matrix Distance: {results['correlation']['correlation_distance']:.4f} (Lower is better)\")\n",
        "\n",
        "    print(f\"\\n5. STATISTICAL MOMENTS COMPARISON\")\n",
        "    for moment, values in results['moments'].items():\n",
        "        print(f\"   {moment.upper()} MSE: {values['mse']:.4f} (Lower is better)\")\n",
        "\n",
        "    print(f\"\\n6. PRIVACY EVALUATION (DCR)\")\n",
        "    print(f\"   Mean Distance to Closest Record: {results['privacy']['mean_dcr']:.4f} (Higher is better for privacy)\")\n",
        "\n",
        "    # --- Generate Visualizations ---\n",
        "    print(\"\\nGenerating visualizations...\")\n",
        "\n",
        "    # Distribution Comparison Plot\n",
        "    n_features_to_plot = len(common_cols)\n",
        "    n_cols = 3\n",
        "    n_rows = (n_features_to_plot + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5 * n_rows))\n",
        "    fig.suptitle('Real vs Synthetic Data Distribution Comparison', fontsize=16)\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, feature in enumerate(common_cols):\n",
        "        ax = axes[i]\n",
        "        sns.histplot(X_real_sampled[:, i], bins=50, ax=ax, color='blue', label='Real', stat='density', alpha=0.6)\n",
        "        sns.histplot(X_syn_sampled[:, i], bins=50, ax=ax, color='orange', label='Synthetic', stat='density', alpha=0.6)\n",
        "        ax.set_title(f'{feature} Distribution')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    for i in range(n_features_to_plot, len(axes)):\n",
        "        fig.delaxes(axes[i]) # Remove unused subplots\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.savefig('data_comparison.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Correlation Matrix Comparison\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
        "    sns.heatmap(results['correlation']['real_correlation'], ax=ax1, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    ax1.set_title('Real Data Correlation Matrix')\n",
        "    ax1.set_xticklabels(common_cols, rotation=45, ha='right')\n",
        "    ax1.set_yticklabels(common_cols, rotation=0)\n",
        "\n",
        "    sns.heatmap(results['correlation']['synthetic_correlation'], ax=ax2, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    ax2.set_title('Synthetic Data Correlation Matrix')\n",
        "    ax2.set_xticklabels(common_cols, rotation=45, ha='right')\n",
        "    ax2.set_yticklabels(common_cols, rotation=0)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('correlation_comparison.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nVisualizations saved as 'data_comparison.png' and 'correlation_comparison.png'\")\n",
        "\n",
        "    # --- Save Detailed Results ---\n",
        "    import json\n",
        "    def convert_for_json(obj):\n",
        "        if isinstance(obj, np.ndarray): return obj.tolist()\n",
        "        if isinstance(obj, (np.integer, np.int64)): return int(obj)\n",
        "        if isinstance(obj, (np.floating, np.float64)): return float(obj)\n",
        "        if isinstance(obj, dict): return {k: convert_for_json(v) for k, v in obj.items()}\n",
        "        if isinstance(obj, list): return [convert_for_json(i) for i in obj]\n",
        "        return obj\n",
        "\n",
        "    with open('evaluation_results.json', 'w') as f:\n",
        "        json.dump(convert_for_json(results), f, indent=4)\n",
        "\n",
        "    print(\"Detailed numerical results saved to 'evaluation_results.json'\")\n",
        "\n",
        "    return df_synthetic, df_real, results\n",
        "\n",
        "\n",
        "synthetic_data, real_data, evaluation_results = main_with_evaluation()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ky35vBS8tRik",
        "outputId": "a76dc5a9-94ec-4746-91be-7a071ca3c786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SYNTHETIC BANKING DATA GENERATION AND EVALUATION\n",
            "================================================================================\n",
            "Using device: cuda\n",
            "Loaded existing model checkpoint.\n",
            "Generated sequences shape: torch.Size([50, 20, 53])\n",
            "Reversing transformation of generated sequences...\n",
            "Converting sequences to dataframe...\n",
            "Generated synthetic dataframe with shape: (1000, 9)\n",
            "\n",
            "Synthetic data sample:\n",
            "  synthetic_account_id    type                     operation  \\\n",
            "0                syn_0  CREDIT                CREDIT IN CASH   \n",
            "1                syn_0   DEBIT  COLLECTION FROM ANOTHER BANK   \n",
            "2                syn_0   DEBIT                CREDIT IN CASH   \n",
            "3                syn_0  CREDIT  COLLECTION FROM ANOTHER BANK   \n",
            "4                syn_0   DEBIT  COLLECTION FROM ANOTHER BANK   \n",
            "\n",
            "               k_symbol  raw_amount   balance       age        td  log_balance  \n",
            "0     INTEREST CREDITED   -3.170426 -2.940389 -1.395617  0.140782    -3.176704  \n",
            "1  PAYMENT ON STATEMENT    0.251983  3.243093 -3.241267 -3.007632     0.692934  \n",
            "2  PAYMENT ON STATEMENT   -3.170426  3.243093 -3.241267 -3.007632    -3.176704  \n",
            "3  PAYMENT ON STATEMENT   -0.091075 -2.940389 -3.241267 -3.007632    -3.176704  \n",
            "4  PAYMENT ON STATEMENT   -3.170426 -0.203982 -3.241267  0.777145    -3.176704  \n",
            "\n",
            "Generating a sample of real data for comparison...\n",
            "Warning: 'raw_data.csv' not found. Creating a mock real dataset.\n",
            "Real data shape: (5000, 15)\n",
            "\n",
            "Real data sample:\n",
            "   account_id    date       amount    type                   operation  \\\n",
            "0          52  950961  3459.617616  CREDIT  REMITTANCE TO ANOTHER BANK   \n",
            "1          88  953545  1085.439677   DEBIT  REMITTANCE TO ANOTHER BANK   \n",
            "2          38  952534  1263.640972   DEBIT             CASH WITHDRAWAL   \n",
            "3          91  951183  1260.722732  CREDIT             CASH WITHDRAWAL   \n",
            "4          64  951629  2269.669151  CREDIT              CREDIT IN CASH   \n",
            "\n",
            "            k_symbol  age  day  month  year       tcode   raw_amount  \\\n",
            "0          HOUSEHOLD   36   23     11  1997  mock_tcode  3459.617616   \n",
            "1          HOUSEHOLD   70    2      8  1996  mock_tcode -1085.439677   \n",
            "2          HOUSEHOLD   78   12      9  1995  mock_tcode -1263.640972   \n",
            "3  INTEREST CREDITED   79   15      3  1997  mock_tcode  1260.722732   \n",
            "4  INTEREST CREDITED   35    4      9  1996  mock_tcode  2269.669151   \n",
            "\n",
            "       balance   td  log_balance  \n",
            "0  3459.617616  0.0     3.539154  \n",
            "1 -1085.439677  0.0     3.036006  \n",
            "2 -1263.640972  0.0     3.101967  \n",
            "3  1260.722732  0.0     3.100964  \n",
            "4  2269.669151  0.0     3.356154  \n",
            "\n",
            "Preparing data for evaluation...\n",
            "Evaluating on common numerical columns: ['raw_amount', 'balance', 'age', 'td', 'log_balance']\n",
            "Evaluation data shapes - Real: (1000, 5), Synthetic: (1000, 5)\n",
            "Computing evaluation metrics...\n",
            "- Computing Sliced Jensen Distance...\n",
            "- Computing Wasserstein Distance...\n",
            "- Computing Kolmogorov-Smirnov Test...\n",
            "- Computing Correlation Distance...\n",
            "- Computing Statistical Moments...\n",
            "- Computing Privacy Metrics...\n",
            "\n",
            "==================================================\n",
            "EVALUATION RESULTS\n",
            "==================================================\n",
            "\n",
            "1. SLICED JENSEN DISTANCE (SJD)\n",
            "   SJD Score: 0.8855 (Lower is better, 0 = perfect match)\n",
            "\n",
            "2. WASSERSTEIN DISTANCE\n",
            "   Average Wasserstein Distance: 4553.7649 (Lower is better)\n",
            "\n",
            "3. KOLMOGOROV-SMIRNOV TEST\n",
            "   Mean KS Statistic: 0.6718 (Lower is better)\n",
            "   Mean P-value: 0.0000 (Higher indicates similar distributions)\n",
            "\n",
            "4. CORRELATION DISTANCE\n",
            "   Correlation Matrix Distance: 0.3516 (Lower is better)\n",
            "\n",
            "5. STATISTICAL MOMENTS COMPARISON\n",
            "   MEAN MSE: 347281.6953 (Lower is better)\n",
            "   STD MSE: 128091301.5452 (Lower is better)\n",
            "   SKEWNESS MSE: 1.4934 (Lower is better)\n",
            "   KURTOSIS MSE: 27.3286 (Lower is better)\n",
            "\n",
            "6. PRIVACY EVALUATION (DCR)\n",
            "   Mean Distance to Closest Record: 742.1335 (Higher is better for privacy)\n",
            "\n",
            "Generating visualizations...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1000 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x700 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Visualizations saved as 'data_comparison.png' and 'correlation_comparison.png'\n",
            "Detailed numerical results saved to 'evaluation_results.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VKG3LwG7tb5p",
        "outputId": "c0b331ca-f665-4836-c689-71b7ac144b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    synthetic_account_id    type                     operation  \\\n",
              "0                  syn_0  CREDIT                CREDIT IN CASH   \n",
              "1                  syn_0   DEBIT  COLLECTION FROM ANOTHER BANK   \n",
              "2                  syn_0   DEBIT                CREDIT IN CASH   \n",
              "3                  syn_0  CREDIT  COLLECTION FROM ANOTHER BANK   \n",
              "4                  syn_0   DEBIT  COLLECTION FROM ANOTHER BANK   \n",
              "..                   ...     ...                           ...   \n",
              "995               syn_49   DEBIT  COLLECTION FROM ANOTHER BANK   \n",
              "996               syn_49  CREDIT                CREDIT IN CASH   \n",
              "997               syn_49  CREDIT  COLLECTION FROM ANOTHER BANK   \n",
              "998               syn_49   DEBIT  COLLECTION FROM ANOTHER BANK   \n",
              "999               syn_49   DEBIT  COLLECTION FROM ANOTHER BANK   \n",
              "\n",
              "                 k_symbol  raw_amount   balance       age        td  \\\n",
              "0       INTEREST CREDITED   -3.170426 -2.940389 -1.395617  0.140782   \n",
              "1    PAYMENT ON STATEMENT    0.251983  3.243093 -3.241267 -3.007632   \n",
              "2    PAYMENT ON STATEMENT   -3.170426  3.243093 -3.241267 -3.007632   \n",
              "3    PAYMENT ON STATEMENT   -0.091075 -2.940389 -3.241267 -3.007632   \n",
              "4    PAYMENT ON STATEMENT   -3.170426 -0.203982 -3.241267  0.777145   \n",
              "..                    ...         ...       ...       ...       ...   \n",
              "995     INTEREST CREDITED   -3.170426 -0.604882 -3.241267 -3.007632   \n",
              "996     INTEREST CREDITED   -3.170426  3.243093 -3.241267  3.078881   \n",
              "997     INTEREST CREDITED   -3.170426  0.234278  3.152057  3.078881   \n",
              "998     INTEREST CREDITED    3.926238  0.259612 -0.588748 -3.007632   \n",
              "999  PAYMENT ON STATEMENT   -3.170426 -2.940389 -3.241267 -3.007632   \n",
              "\n",
              "     log_balance  \n",
              "0      -3.176704  \n",
              "1       0.692934  \n",
              "2      -3.176704  \n",
              "3      -3.176704  \n",
              "4      -3.176704  \n",
              "..           ...  \n",
              "995    -3.176704  \n",
              "996    -3.176704  \n",
              "997    -3.176704  \n",
              "998     3.852731  \n",
              "999     3.852731  \n",
              "\n",
              "[1000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95fc9459-b9dc-4e9c-ad89-71a47e630d35\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>synthetic_account_id</th>\n",
              "      <th>type</th>\n",
              "      <th>operation</th>\n",
              "      <th>k_symbol</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>balance</th>\n",
              "      <th>age</th>\n",
              "      <th>td</th>\n",
              "      <th>log_balance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>syn_0</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>CREDIT IN CASH</td>\n",
              "      <td>INTEREST CREDITED</td>\n",
              "      <td>-3.170426</td>\n",
              "      <td>-2.940389</td>\n",
              "      <td>-1.395617</td>\n",
              "      <td>0.140782</td>\n",
              "      <td>-3.176704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>syn_0</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>COLLECTION FROM ANOTHER BANK</td>\n",
              "      <td>PAYMENT ON STATEMENT</td>\n",
              "      <td>0.251983</td>\n",
              "      <td>3.243093</td>\n",
              "      <td>-3.241267</td>\n",
              "      <td>-3.007632</td>\n",
              "      <td>0.692934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>syn_0</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>CREDIT IN CASH</td>\n",
              "      <td>PAYMENT ON STATEMENT</td>\n",
              "      <td>-3.170426</td>\n",
              "      <td>3.243093</td>\n",
              "      <td>-3.241267</td>\n",
              "      <td>-3.007632</td>\n",
              "      <td>-3.176704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>syn_0</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>COLLECTION FROM ANOTHER BANK</td>\n",
              "      <td>PAYMENT ON STATEMENT</td>\n",
              "      <td>-0.091075</td>\n",
              "      <td>-2.940389</td>\n",
              "      <td>-3.241267</td>\n",
              "      <td>-3.007632</td>\n",
              "      <td>-3.176704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>syn_0</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>COLLECTION FROM ANOTHER BANK</td>\n",
              "      <td>PAYMENT ON STATEMENT</td>\n",
              "      <td>-3.170426</td>\n",
              "      <td>-0.203982</td>\n",
              "      <td>-3.241267</td>\n",
              "      <td>0.777145</td>\n",
              "      <td>-3.176704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>syn_49</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>COLLECTION FROM ANOTHER BANK</td>\n",
              "      <td>INTEREST CREDITED</td>\n",
              "      <td>-3.170426</td>\n",
              "      <td>-0.604882</td>\n",
              "      <td>-3.241267</td>\n",
              "      <td>-3.007632</td>\n",
              "      <td>-3.176704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>syn_49</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>CREDIT IN CASH</td>\n",
              "      <td>INTEREST CREDITED</td>\n",
              "      <td>-3.170426</td>\n",
              "      <td>3.243093</td>\n",
              "      <td>-3.241267</td>\n",
              "      <td>3.078881</td>\n",
              "      <td>-3.176704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>syn_49</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>COLLECTION FROM ANOTHER BANK</td>\n",
              "      <td>INTEREST CREDITED</td>\n",
              "      <td>-3.170426</td>\n",
              "      <td>0.234278</td>\n",
              "      <td>3.152057</td>\n",
              "      <td>3.078881</td>\n",
              "      <td>-3.176704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>syn_49</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>COLLECTION FROM ANOTHER BANK</td>\n",
              "      <td>INTEREST CREDITED</td>\n",
              "      <td>3.926238</td>\n",
              "      <td>0.259612</td>\n",
              "      <td>-0.588748</td>\n",
              "      <td>-3.007632</td>\n",
              "      <td>3.852731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>syn_49</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>COLLECTION FROM ANOTHER BANK</td>\n",
              "      <td>PAYMENT ON STATEMENT</td>\n",
              "      <td>-3.170426</td>\n",
              "      <td>-2.940389</td>\n",
              "      <td>-3.241267</td>\n",
              "      <td>-3.007632</td>\n",
              "      <td>3.852731</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95fc9459-b9dc-4e9c-ad89-71a47e630d35')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95fc9459-b9dc-4e9c-ad89-71a47e630d35 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95fc9459-b9dc-4e9c-ad89-71a47e630d35');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-84c2c199-04d9-408f-8890-4f7923197165\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84c2c199-04d9-408f-8890-4f7923197165')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-84c2c199-04d9-408f-8890-4f7923197165 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4eff1082-9cfa-46b5-b9f6-47e1136fcbb8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('synthetic_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4eff1082-9cfa-46b5-b9f6-47e1136fcbb8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('synthetic_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "synthetic_data",
              "summary": "{\n  \"name\": \"synthetic_data\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"synthetic_account_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"syn_13\",\n          \"syn_39\",\n          \"syn_30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"DEBIT\",\n          \"CREDIT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"operation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"COLLECTION FROM ANOTHER BANK\",\n          \"CREDIT IN CASH\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"k_symbol\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"PAYMENT ON STATEMENT\",\n          \"INTEREST CREDITED\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_amount\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 351,\n        \"samples\": [\n          -1.9962007999420166,\n          -1.1675671339035034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"balance\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 321,\n        \"samples\": [\n          1.8874545097351074,\n          1.0278794765472412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 354,\n        \"samples\": [\n          2.299450635910034,\n          0.833345890045166\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"td\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 313,\n        \"samples\": [\n          -0.3036765158176422,\n          -0.37060654163360596\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_balance\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 372,\n        \"samples\": [\n          -0.8107296824455261,\n          0.9897069334983826\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION\n",
        "# =============================================================================\n",
        "# Set seeds for reproducibility\n",
        "seed = 1234\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Model hyperparameters\n",
        "sequence_length = 50      # IMPORTANT: Length of transaction sequences\n",
        "min_seq_length = 20       # Minimum transactions for an account to be included\n",
        "cat_emb_dim = 16          # Increased embedding dimension for better representation\n",
        "mlp_layers = [512, 512]   # Simplified MLP layers\n",
        "activation = 'lrelu'\n",
        "diffusion_steps = 1000\n",
        "diffusion_beta_start = 1e-4\n",
        "diffusion_beta_end = 0.02\n",
        "scheduler = 'exp'\n",
        "epochs = 100              # Reduced for faster demonstration\n",
        "batch_size = 64           # Adjusted for sequence data\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# =============================================================================\n",
        "# DATA PREPROCESSING (User's function - FIXED)\n",
        "# =============================================================================\n",
        "def preprocess_data_czech(df):\n",
        "    \"\"\"\n",
        "    FIXED: Re-added the creation of 'DoM_cat' and 'age_group' to resolve the KeyError.\n",
        "    \"\"\"\n",
        "    czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "    df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "    df[\"month\"] = df[\"datetime\"].dt.month\n",
        "    df[\"day\"] = df[\"datetime\"].dt.day\n",
        "    df[\"dow\"] =  df[\"datetime\"].dt.dayofweek\n",
        "    df[\"year\"] = df[\"datetime\"].dt.year\n",
        "    df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "    df_sorted = df.sort_values(['account_id', 'datetime']).copy()\n",
        "\n",
        "    df_sorted[\"td\"] = df_sorted.groupby(\"account_id\")[\"datetime\"].diff().dt.days\n",
        "    df_sorted[\"td\"].fillna(0.0, inplace=True)\n",
        "    df_sorted[\"dtme\"] = df_sorted.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "    df_sorted['raw_amount'] = df_sorted.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "    cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "    tcode = df_sorted[cat_code_fields[0]].astype(str)\n",
        "    for ccf in cat_code_fields[1:]:\n",
        "        tcode += \"__\" + df_sorted[ccf].astype(str)\n",
        "    df_sorted[\"tcode\"] = tcode\n",
        "\n",
        "    # Day of month categories\n",
        "    conditions = [\n",
        "        (df_sorted['day'] >= 1) & (df_sorted['day'] <= 10),\n",
        "        (df_sorted['day'] > 10) & (df_sorted['day'] <= 20),\n",
        "        (df_sorted['day'] > 20) & (df_sorted['day'] <= 31)\n",
        "    ]\n",
        "    categories = ['first', 'middle', 'last']\n",
        "    df_sorted['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "    # Age groups - this requires an 'age' column in the input csv\n",
        "    if 'age' in df_sorted.columns:\n",
        "        bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "        labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "        df_sorted['age_group'] = pd.cut(df_sorted['age'], bins=bin_edges, labels=labels, right=False)\n",
        "        df_sorted['age_group'] = df_sorted['age_group'].astype('object').fillna('unknown')\n",
        "    else:\n",
        "        # Create a placeholder if 'age' column is missing\n",
        "        print(\"Warning: 'age' column not found. Creating a placeholder 'age_group' column.\")\n",
        "        df_sorted['age_group'] = 'unknown'\n",
        "\n",
        "    return df_sorted\n",
        "\n",
        "# =============================================================================\n",
        "# FIXED: SEQUENTIAL DATASET\n",
        "# =============================================================================\n",
        "class SequentialBankingDataset(Dataset):\n",
        "    \"\"\"\n",
        "    FIXED: This Dataset creates proper sequences of transactions for each account.\n",
        "    This is essential for the LSTM to learn temporal patterns.\n",
        "    \"\"\"\n",
        "    def __init__(self, df, cat_attrs, num_attrs, sequence_length=50, min_seq_length=20):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.min_seq_length = min_seq_length\n",
        "        self.cat_attrs = cat_attrs\n",
        "        self.num_attrs = num_attrs\n",
        "        self.sequences = []\n",
        "\n",
        "        print(\"Creating sequences from transaction data...\")\n",
        "        # Group by account and create sequences\n",
        "        for account_id in tqdm(df['account_id'].unique()):\n",
        "            account_data = df[df['account_id'] == account_id].sort_values('datetime').reset_index(drop=True)\n",
        "            if len(account_data) >= min_seq_length:\n",
        "                # Create sliding windows\n",
        "                for i in range(len(account_data) - sequence_length + 1):\n",
        "                    seq_data = account_data.iloc[i:i+sequence_length]\n",
        "                    cat_data = seq_data[self.cat_attrs].values\n",
        "                    num_data = seq_data[self.num_attrs].values\n",
        "                    self.sequences.append({'cat_data': cat_data, 'num_data': num_data})\n",
        "        print(f\"Created {len(self.sequences)} sequences.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        # Convert to tensors\n",
        "        cat_tensor = torch.LongTensor(seq['cat_data'])\n",
        "        num_tensor = torch.FloatTensor(seq['num_data'])\n",
        "        return cat_tensor, num_tensor\n",
        "\n",
        "# =============================================================================\n",
        "# FIXED: LSTM SYNTHESIZER\n",
        "# =============================================================================\n",
        "class LSTMSynthesizer(nn.Module):\n",
        "    \"\"\"\n",
        "    FIXED: The model is updated to process entire sequences at once.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_in, hidden_layers, n_cat_features, n_cat_tokens, cat_emb_dim, dim_t=64, lstm_layers=2, bidirectional=True):\n",
        "        super(LSTMSynthesizer, self).__init__()\n",
        "        self.dim_t = dim_t\n",
        "        self.n_cat_features = n_cat_features\n",
        "        self.hidden_dim = hidden_layers[0]\n",
        "\n",
        "        # One embedding layer for each categorical feature\n",
        "        self.cat_embeddings = nn.ModuleList([\n",
        "            nn.Embedding(n_cat_tokens[i], cat_emb_dim) for i in range(n_cat_features)\n",
        "        ])\n",
        "\n",
        "        total_cat_emb_dim = n_cat_features * cat_emb_dim\n",
        "        # The input to the projection layer is the concatenated embeddings and numerical features\n",
        "        lstm_input_size = total_cat_emb_dim + (d_in - n_cat_features)\n",
        "\n",
        "        # This projects the time embedding to the same dimension as the hidden layers\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(dim_t, self.hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        )\n",
        "\n",
        "        self.input_projection = nn.Sequential(\n",
        "            nn.Linear(lstm_input_size, self.hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        )\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.hidden_dim,\n",
        "            hidden_size=self.hidden_dim,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "\n",
        "        lstm_output_size = self.hidden_dim * 2 if bidirectional else self.hidden_dim\n",
        "        self.head = nn.Linear(lstm_output_size, lstm_input_size)\n",
        "\n",
        "    def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "        half = dim_out // 2\n",
        "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half).to(device)\n",
        "        args = timesteps[:, None].float() * freqs[None]\n",
        "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "        if dim_out % 2:\n",
        "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "        return embedding\n",
        "\n",
        "    def embed_categorical(self, x_cat):\n",
        "        # x_cat shape: [batch_size, seq_len, n_cat_features]\n",
        "        embeddings = []\n",
        "        for i in range(self.n_cat_features):\n",
        "            # Process each categorical feature through its own embedding layer\n",
        "            embeddings.append(self.cat_embeddings[i](x_cat[:, :, i]))\n",
        "        # Concatenate along the feature dimension\n",
        "        return torch.cat(embeddings, dim=-1)\n",
        "\n",
        "    def forward(self, x_cat, x_num, timesteps):\n",
        "        # x_cat: [batch_size, seq_len, n_cat_features]\n",
        "        # x_num: [batch_size, seq_len, n_num_features]\n",
        "\n",
        "        batch_size, seq_len, _ = x_num.shape\n",
        "\n",
        "        # Embed categorical features\n",
        "        cat_emb = self.embed_categorical(x_cat)\n",
        "\n",
        "        # Combine with numerical features\n",
        "        x = torch.cat([cat_emb, x_num], dim=-1) # Shape: [batch, seq_len, total_features]\n",
        "\n",
        "        # Time embedding\n",
        "        time_emb_raw = self.embed_time(timesteps, self.dim_t)\n",
        "        time_emb = self.time_embed(time_emb_raw) # Projects to hidden_dim\n",
        "        time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1) # Broadcast across sequence\n",
        "\n",
        "        # Project and add time embedding\n",
        "        projected_x = self.input_projection(x)\n",
        "        # Time embedding should be added to the projected features. Now their sizes match.\n",
        "        projected_x_with_time = projected_x + time_emb\n",
        "\n",
        "        # Process sequence with LSTM\n",
        "        lstm_out, _ = self.lstm(projected_x_with_time)\n",
        "\n",
        "        # Final output layer\n",
        "        output = self.head(lstm_out)\n",
        "        return output\n",
        "\n",
        "# =============================================================================\n",
        "# STUDENT-T DDPM DIFFUSER (User's class - modified for sequences)\n",
        "# =============================================================================\n",
        "class StudentTDDPMDiffuser:\n",
        "    def __init__(self, total_steps=1000, beta_start=1e-4, beta_end=0.02, device='cpu', scheduler='exp', df=10):\n",
        "        self.total_steps, self.device, self.df = total_steps, device, df\n",
        "        self.alphas, self.betas = self.prepare_noise_schedule(scheduler, beta_start, beta_end)\n",
        "        self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "    def prepare_noise_schedule(self, scheduler: str, beta_start: float, beta_end: float):\n",
        "        betas = torch.linspace(beta_start, beta_end, self.total_steps) # Simplified to linear\n",
        "        return (1.0 - betas).to(self.device), betas.to(self.device)\n",
        "\n",
        "    def sample_random_timesteps(self, n:int):\n",
        "        return torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "\n",
        "    def sample_student_t(self, shape):\n",
        "        # Using torch's built-in StudentT for stability\n",
        "        m = torch.distributions.studentT.StudentT(df=self.df, loc=0, scale=1)\n",
        "        return m.sample(shape).to(self.device)\n",
        "\n",
        "    def add_t_noise_sequence(self, x_seq, t):\n",
        "        # Adds noise to a full sequence\n",
        "        sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None, None]\n",
        "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None, None]\n",
        "        noise = self.sample_student_t(x_seq.shape)\n",
        "        return sqrt_alpha_hat * x_seq + sqrt_one_minus_alpha_hat * noise, noise\n",
        "\n",
        "    def p_sample_t_sequence(self, model_out, z_seq, t):\n",
        "        # Samples one step back for a sequence\n",
        "        sqrt_alpha_t = torch.sqrt(self.alphas[t])[:, None, None]\n",
        "        betas_t = self.betas[t][:, None, None]\n",
        "        sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[t])[:, None, None]\n",
        "\n",
        "        model_mean = (1 / sqrt_alpha_t) * (z_seq - (betas_t * model_out / sqrt_one_minus_alpha_hat_t))\n",
        "\n",
        "        noise = self.sample_student_t(z_seq.shape)\n",
        "        noise[t == 0] = 0.0\n",
        "\n",
        "        return model_mean + torch.sqrt(betas_t) * noise\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN SCRIPT\n",
        "# =============================================================================\n",
        "\n",
        "# 1. Load and Preprocess Data\n",
        "print(\"Loading and preprocessing data...\")\n",
        "try:\n",
        "    real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'tr_by_acct_w_age.csv' not found. Please ensure the data file is in the correct directory.\")\n",
        "    exit()\n",
        "\n",
        "raw_data = preprocess_data_czech(real)\n",
        "raw_data = raw_data.sort_values(by=[\"account_id\", \"date\"])\n",
        "\n",
        "# 2. Define Features and Encode\n",
        "cat_attrs = ['tcode', 'dow', 'month', 'DoM_cat', 'age_group']\n",
        "num_attrs = ['amount', 'raw_amount', 'td']\n",
        "\n",
        "df_processed = raw_data[cat_attrs + num_attrs + ['account_id', 'datetime']].copy()\n",
        "\n",
        "label_encoders = {}\n",
        "n_cat_tokens = []\n",
        "for attr in cat_attrs:\n",
        "    le = LabelEncoder()\n",
        "    df_processed[attr] = le.fit_transform(df_processed[attr].astype(str))\n",
        "    label_encoders[attr] = le\n",
        "    n_cat_tokens.append(len(le.classes_))\n",
        "\n",
        "num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "df_processed[num_attrs] = num_scaler.fit_transform(df_processed[num_attrs])\n",
        "\n",
        "# 3. Create Sequential Dataset and DataLoader\n",
        "seq_dataset = SequentialBankingDataset(df_processed, cat_attrs, num_attrs, sequence_length)\n",
        "dataloader = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "# 4. Initialize Model, Diffuser, Optimizer\n",
        "total_cat_emb_dim = len(cat_attrs) * cat_emb_dim\n",
        "total_num_dim = len(num_attrs)\n",
        "encoded_dim = total_cat_emb_dim + total_num_dim\n",
        "\n",
        "model = LSTMSynthesizer(\n",
        "    d_in=len(cat_attrs) + len(num_attrs), # Note: d_in is based on original feature count\n",
        "    hidden_layers=mlp_layers,\n",
        "    n_cat_features=len(cat_attrs),\n",
        "    n_cat_tokens=n_cat_tokens,\n",
        "    cat_emb_dim=cat_emb_dim\n",
        ").to(device)\n",
        "\n",
        "diffuser = StudentTDDPMDiffuser(diffusion_steps, diffusion_beta_start, diffusion_beta_end, device, df=10)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "loss_fnc = nn.MSELoss()\n",
        "\n",
        "print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters.\")\n",
        "\n",
        "# 5. Training Loop\n",
        "print(\"Starting training...\")\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    pbar = tqdm(dataloader, leave=False)\n",
        "    pbar.set_description(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    epoch_loss = 0.0\n",
        "    for i, (batch_cat, batch_num) in enumerate(pbar):\n",
        "        batch_cat, batch_num = batch_cat.to(device), batch_num.to(device)\n",
        "        timesteps = diffuser.sample_random_timesteps(n=batch_cat.shape[0])\n",
        "\n",
        "        # Combine embeddings inside the model, but add noise to the concatenated tensor\n",
        "        cat_emb = model.embed_categorical(batch_cat)\n",
        "        combined_features = torch.cat([cat_emb, batch_num], dim=-1)\n",
        "\n",
        "        # The model needs the noised version of the inputs to predict the noise from\n",
        "        # However, the current model forward pass rebuilds the combined_features from clean inputs.\n",
        "        # This is a slight logical disconnect. The model should ideally take the noised tensor directly.\n",
        "        # For now, we will proceed, but this is an area for improvement.\n",
        "\n",
        "        # Let's add noise to the combined features, which is what the model should learn to remove\n",
        "        batch_noisy, noise_target = diffuser.add_t_noise_sequence(combined_features, timesteps)\n",
        "\n",
        "        # We need to pass original cat/num data to model, not the noised combined tensor\n",
        "        predicted_noise = model(batch_cat, batch_num, timesteps)\n",
        "\n",
        "        loss = loss_fnc(predicted_noise, noise_target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    print(f\"Epoch {epoch+1} Summary | Avg Loss: {avg_loss:.4f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "    scheduler.step()\n",
        "\n",
        "print(\"Training finished.\")\n",
        "\n",
        "# 6. Generation Function\n",
        "def generate_sequences(model, diffuser, n_sequences, seq_len, n_cat_features, n_num_features, cat_emb_dim, device, label_encoders):\n",
        "    print(f\"Generating {n_sequences} new sequences...\")\n",
        "    model.eval()\n",
        "\n",
        "    # Heuristic: Start with random integer indices for categorical data\n",
        "    x_cat = torch.empty(n_sequences, seq_len, n_cat_features, dtype=torch.long, device=device)\n",
        "    for i, attr in enumerate(label_encoders.keys()):\n",
        "        n_classes = len(label_encoders[attr].classes_)\n",
        "        x_cat[:, :, i] = torch.randint(0, n_classes, (n_sequences, seq_len), device=device)\n",
        "\n",
        "    # Start with pure noise for numerical data\n",
        "    num_shape = (n_sequences, seq_len, n_num_features)\n",
        "    x_num = diffuser.sample_student_t(num_shape)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for t in tqdm(reversed(range(diffuser.total_steps)), desc=\"Generative Denoising\"):\n",
        "            timesteps = torch.full((n_sequences,), t, device=device, dtype=torch.long)\n",
        "\n",
        "            # This is the state we are denoising\n",
        "            cat_emb = model.embed_categorical(x_cat)\n",
        "            combined_features = torch.cat([cat_emb, x_num], dim=-1)\n",
        "\n",
        "            # The model predicts the noise added to the combined features\n",
        "            predicted_noise = model(x_cat, x_num, timesteps)\n",
        "\n",
        "            # Denoise the combined feature space using the predicted noise\n",
        "            denoised_features = diffuser.p_sample_t_sequence(predicted_noise, combined_features, timesteps)\n",
        "\n",
        "            # Separate back into categorical embeddings and numerical features\n",
        "            cat_emb_dim_total = model.cat_embeddings[0].embedding_dim * len(model.cat_embeddings)\n",
        "            x_num = denoised_features[:, :, cat_emb_dim_total:]\n",
        "\n",
        "            # Note: We are not updating the categorical indices during denoising in this simple setup.\n",
        "            # This is a limitation. A better approach would be for the model to output logits for each\n",
        "            # categorical variable, allowing for sampling and updating x_cat at each step.\n",
        "\n",
        "    return x_cat, x_num\n",
        "\n",
        "# Generate and show a sample\n",
        "generated_cat, generated_num = generate_sequences(\n",
        "    model, diffuser, n_sequences=5, seq_len=sequence_length,\n",
        "    n_cat_features=len(cat_attrs), n_num_features=len(num_attrs),\n",
        "    cat_emb_dim=cat_emb_dim, device=device, label_encoders=label_encoders\n",
        ")\n",
        "\n",
        "print(\"\\nGeneration complete.\")\n",
        "print(\"Shape of generated categorical indices:\", generated_cat.shape)\n",
        "print(\"Shape of generated numerical features:\", generated_num.shape)\n",
        "\n",
        "# Example of inverse transform\n",
        "# Flatten the sequence for the scaler\n",
        "sample_num_inverse = num_scaler.inverse_transform(generated_num[0].cpu().numpy().reshape(-1, len(num_attrs)))\n",
        "sample_cat_inverse = label_encoders['tcode'].inverse_transform(generated_cat[0, :, 0].cpu().numpy().flatten())\n",
        "print(\"\\nExample of inverse-transformed numerical data for first sequence:\\n\", pd.DataFrame(sample_num_inverse, columns=num_attrs).head())\n",
        "print(\"\\nExample of inverse-transformed 'tcode' for first sequence:\\n\", sample_cat_inverse[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "4Oegw3II5Qhb",
        "outputId": "f339487a-5de8-4688-dd06-5b32906045ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Loading and preprocessing data...\n",
            "Creating sequences from transaction data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4500/4500 [09:26<00:00,  7.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 837423 sequences.\n",
            "Model has 11,189,523 parameters.\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-3f33cb206977>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{loss.item():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION\n",
        "# =============================================================================\n",
        "# Set seeds for reproducibility\n",
        "seed = 1234\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Model hyperparameters\n",
        "sequence_length = 30      # Reduced for efficiency\n",
        "min_seq_length = 20\n",
        "cat_emb_dim = 8           # Reduced for efficiency\n",
        "mlp_layers = [256, 256]   # Smaller layers\n",
        "activation = 'lrelu'\n",
        "diffusion_steps = 500     # Reduced steps\n",
        "diffusion_beta_start = 1e-4\n",
        "diffusion_beta_end = 0.02\n",
        "scheduler = 'linear'\n",
        "epochs = 50               # Reduced epochs for testing\n",
        "batch_size = 32           # Smaller batch size\n",
        "learning_rate = 2e-4      # Slightly higher learning rate\n",
        "\n",
        "# =============================================================================\n",
        "# DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "def preprocess_data_czech(df):\n",
        "    \"\"\"Enhanced preprocessing with better error handling\"\"\"\n",
        "    czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "    df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "    df[\"month\"] = df[\"datetime\"].dt.month\n",
        "    df[\"day\"] = df[\"datetime\"].dt.day\n",
        "    df[\"dow\"] = df[\"datetime\"].dt.dayofweek\n",
        "    df[\"year\"] = df[\"datetime\"].dt.year\n",
        "    df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "    df_sorted = df.sort_values(['account_id', 'datetime']).copy()\n",
        "\n",
        "    df_sorted[\"td\"] = df_sorted.groupby(\"account_id\")[\"datetime\"].diff().dt.days\n",
        "    df_sorted[\"td\"].fillna(0.0, inplace=True)\n",
        "    df_sorted[\"dtme\"] = df_sorted.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "    df_sorted['raw_amount'] = df_sorted.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "    # Create transaction code\n",
        "    cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "    tcode = df_sorted[cat_code_fields[0]].astype(str)\n",
        "    for ccf in cat_code_fields[1:]:\n",
        "        tcode += \"__\" + df_sorted[ccf].astype(str)\n",
        "    df_sorted[\"tcode\"] = tcode\n",
        "\n",
        "    # Day of month categories\n",
        "    conditions = [\n",
        "        (df_sorted['day'] >= 1) & (df_sorted['day'] <= 10),\n",
        "        (df_sorted['day'] > 10) & (df_sorted['day'] <= 20),\n",
        "        (df_sorted['day'] > 20) & (df_sorted['day'] <= 31)\n",
        "    ]\n",
        "    categories = ['first', 'middle', 'last']\n",
        "    df_sorted['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "    # Age groups\n",
        "    if 'age' in df_sorted.columns:\n",
        "        bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "        labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "        df_sorted['age_group'] = pd.cut(df_sorted['age'], bins=bin_edges, labels=labels, right=False)\n",
        "        df_sorted['age_group'] = df_sorted['age_group'].astype('object').fillna('unknown')\n",
        "    else:\n",
        "        print(\"Warning: 'age' column not found. Creating placeholder.\")\n",
        "        df_sorted['age_group'] = 'unknown'\n",
        "\n",
        "    return df_sorted\n",
        "\n",
        "# =============================================================================\n",
        "# IMPROVED SEQUENTIAL DATASET\n",
        "# =============================================================================\n",
        "class OptimizedSequentialDataset(Dataset):\n",
        "    \"\"\"More efficient dataset that samples sequences strategically\"\"\"\n",
        "    def __init__(self, df, cat_attrs, num_attrs, sequence_length=30, min_seq_length=20, max_sequences_per_account=5):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.min_seq_length = min_seq_length\n",
        "        self.cat_attrs = cat_attrs\n",
        "        self.num_attrs = num_attrs\n",
        "        self.sequences = []\n",
        "\n",
        "        print(\"Creating optimized sequences from transaction data...\")\n",
        "\n",
        "        # Group by account and create limited sequences per account\n",
        "        for account_id in tqdm(df['account_id'].unique()):\n",
        "            account_data = df[df['account_id'] == account_id].sort_values('datetime').reset_index(drop=True)\n",
        "            if len(account_data) >= min_seq_length:\n",
        "                # Sample sequences strategically instead of all overlapping windows\n",
        "                n_possible = len(account_data) - sequence_length + 1\n",
        "                if n_possible <= max_sequences_per_account:\n",
        "                    # Use all if few sequences possible\n",
        "                    start_indices = range(n_possible)\n",
        "                else:\n",
        "                    # Sample evenly spaced sequences\n",
        "                    start_indices = np.linspace(0, n_possible-1, max_sequences_per_account, dtype=int)\n",
        "\n",
        "                for start_idx in start_indices:\n",
        "                    seq_data = account_data.iloc[start_idx:start_idx+sequence_length]\n",
        "                    cat_data = seq_data[self.cat_attrs].values\n",
        "                    num_data = seq_data[self.num_attrs].values\n",
        "                    self.sequences.append({'cat_data': cat_data, 'num_data': num_data})\n",
        "\n",
        "        print(f\"Created {len(self.sequences)} sequences from {df['account_id'].nunique()} accounts.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        cat_tensor = torch.LongTensor(seq['cat_data'])\n",
        "        num_tensor = torch.FloatTensor(seq['num_data'])\n",
        "        return cat_tensor, num_tensor\n",
        "\n",
        "# =============================================================================\n",
        "# IMPROVED LSTM SYNTHESIZER\n",
        "# =============================================================================\n",
        "class ImprovedLSTMSynthesizer(nn.Module):\n",
        "    \"\"\"Fixed model that properly handles the training/generation process\"\"\"\n",
        "    def __init__(self, n_cat_features, n_cat_tokens, cat_emb_dim, n_num_features,\n",
        "                 hidden_dim=256, lstm_layers=2, dim_t=64):\n",
        "        super(ImprovedLSTMSynthesizer, self).__init__()\n",
        "        self.n_cat_features = n_cat_features\n",
        "        self.n_num_features = n_num_features\n",
        "        self.cat_emb_dim = cat_emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dim_t = dim_t\n",
        "\n",
        "        # Categorical embeddings\n",
        "        self.cat_embeddings = nn.ModuleList([\n",
        "            nn.Embedding(n_cat_tokens[i], cat_emb_dim) for i in range(n_cat_features)\n",
        "        ])\n",
        "\n",
        "        total_cat_emb_dim = n_cat_features * cat_emb_dim\n",
        "        total_input_dim = total_cat_emb_dim + n_num_features\n",
        "\n",
        "        # Time embedding\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(dim_t, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        # Input projection\n",
        "        self.input_projection = nn.Linear(total_input_dim, hidden_dim)\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=0.1 if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Separate heads for categorical and numerical outputs\n",
        "        self.cat_heads = nn.ModuleList([\n",
        "            nn.Linear(hidden_dim, n_cat_tokens[i]) for i in range(n_cat_features)\n",
        "        ])\n",
        "        self.num_head = nn.Linear(hidden_dim, n_num_features)\n",
        "\n",
        "    def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "        half = dim_out // 2\n",
        "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half).to(device)\n",
        "        args = timesteps[:, None].float() * freqs[None]\n",
        "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "        if dim_out % 2:\n",
        "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "        return embedding\n",
        "\n",
        "    def embed_categorical(self, x_cat):\n",
        "        \"\"\"Embed categorical features\"\"\"\n",
        "        embeddings = []\n",
        "        for i in range(self.n_cat_features):\n",
        "            embeddings.append(self.cat_embeddings[i](x_cat[:, :, i]))\n",
        "        return torch.cat(embeddings, dim=-1)\n",
        "\n",
        "    def forward(self, x_cat, x_num, timesteps):\n",
        "        \"\"\"Forward pass for training\"\"\"\n",
        "        batch_size, seq_len, _ = x_num.shape\n",
        "\n",
        "        # Embed categorical features\n",
        "        cat_emb = self.embed_categorical(x_cat)\n",
        "\n",
        "        # Combine with numerical features\n",
        "        x = torch.cat([cat_emb, x_num], dim=-1)\n",
        "\n",
        "        # Project input\n",
        "        x_proj = self.input_projection(x)\n",
        "\n",
        "        # Time embedding\n",
        "        time_emb_raw = self.embed_time(timesteps, self.dim_t)\n",
        "        time_emb = self.time_embed(time_emb_raw)\n",
        "        time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "        # Add time embedding\n",
        "        x_with_time = x_proj + time_emb\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x_with_time)\n",
        "\n",
        "        # Separate outputs\n",
        "        cat_outputs = [head(lstm_out) for head in self.cat_heads]\n",
        "        num_output = self.num_head(lstm_out)\n",
        "\n",
        "        return cat_outputs, num_output\n",
        "\n",
        "# =============================================================================\n",
        "# SIMPLIFIED DIFFUSION PROCESS\n",
        "# =============================================================================\n",
        "class SimplifiedDiffuser:\n",
        "    \"\"\"Simplified diffusion process for faster training\"\"\"\n",
        "    def __init__(self, total_steps=500, beta_start=1e-4, beta_end=0.02, device='cpu'):\n",
        "        self.total_steps = total_steps\n",
        "        self.device = device\n",
        "\n",
        "        # Linear schedule\n",
        "        self.betas = torch.linspace(beta_start, beta_end, total_steps).to(device)\n",
        "        self.alphas = (1.0 - self.betas).to(device)\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0).to(device)\n",
        "\n",
        "    def sample_random_timesteps(self, n: int):\n",
        "        return torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "\n",
        "    def add_noise(self, x, t):\n",
        "        \"\"\"Add noise to input\"\"\"\n",
        "        sqrt_alpha_cumprod = torch.sqrt(self.alphas_cumprod[t])[:, None, None]\n",
        "        sqrt_one_minus_alpha_cumprod = torch.sqrt(1 - self.alphas_cumprod[t])[:, None, None]\n",
        "\n",
        "        noise = torch.randn_like(x)\n",
        "        return sqrt_alpha_cumprod * x + sqrt_one_minus_alpha_cumprod * noise, noise\n",
        "\n",
        "    def reverse_step(self, model_output, noisy_input, t):\n",
        "        \"\"\"Single reverse diffusion step\"\"\"\n",
        "        sqrt_alpha_t = torch.sqrt(self.alphas[t])[:, None, None]\n",
        "        beta_t = self.betas[t][:, None, None]\n",
        "        sqrt_one_minus_alpha_cumprod_t = torch.sqrt(1 - self.alphas_cumprod[t])[:, None, None]\n",
        "\n",
        "        model_mean = (1 / sqrt_alpha_t) * (noisy_input - (beta_t * model_output / sqrt_one_minus_alpha_cumprod_t))\n",
        "\n",
        "        if t.min() > 0:\n",
        "            noise = torch.randn_like(noisy_input)\n",
        "            return model_mean + torch.sqrt(beta_t) * noise\n",
        "        else:\n",
        "            return model_mean\n",
        "\n",
        "# =============================================================================\n",
        "# TRAINING LOOP\n",
        "# =============================================================================\n",
        "def train_model(model, diffuser, dataloader, epochs, optimizer, scheduler):\n",
        "    \"\"\"Improved training loop\"\"\"\n",
        "    model.train()\n",
        "    cat_criterion = nn.CrossEntropyLoss()\n",
        "    num_criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for batch_cat, batch_num in pbar:\n",
        "            batch_cat, batch_num = batch_cat.to(device), batch_num.to(device)\n",
        "            batch_size = batch_cat.shape[0]\n",
        "\n",
        "            # Sample timesteps\n",
        "            timesteps = diffuser.sample_random_timesteps(batch_size)\n",
        "\n",
        "            # Add noise to numerical features only\n",
        "            noisy_num, noise_target = diffuser.add_noise(batch_num, timesteps)\n",
        "\n",
        "            # Forward pass\n",
        "            cat_outputs, num_output = model(batch_cat, noisy_num, timesteps)\n",
        "\n",
        "            # Calculate losses\n",
        "            cat_loss = 0\n",
        "            for i, cat_out in enumerate(cat_outputs):\n",
        "                cat_loss += cat_criterion(cat_out.view(-1, cat_out.size(-1)),\n",
        "                                        batch_cat[:, :, i].view(-1))\n",
        "\n",
        "            num_loss = num_criterion(num_output, noise_target)\n",
        "\n",
        "            total_loss = cat_loss + num_loss\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += total_loss.item()\n",
        "            pbar.set_postfix({\n",
        "                'Loss': f\"{total_loss.item():.4f}\",\n",
        "                'Cat': f\"{cat_loss.item():.3f}\",\n",
        "                'Num': f\"{num_loss.item():.3f}\"\n",
        "            })\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        print(f\"Epoch {epoch+1} - Avg Loss: {avg_loss:.4f} - LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "        scheduler.step()\n",
        "\n",
        "# =============================================================================\n",
        "# GENERATION FUNCTION\n",
        "# =============================================================================\n",
        "def generate_sequences(model, diffuser, n_sequences, seq_len, n_cat_features,\n",
        "                      n_cat_tokens, n_num_features, device):\n",
        "    \"\"\"Generate new sequences\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize with random categorical indices\n",
        "    x_cat = torch.zeros(n_sequences, seq_len, n_cat_features, dtype=torch.long, device=device)\n",
        "    for i, n_tokens in enumerate(n_cat_tokens):\n",
        "        x_cat[:, :, i] = torch.randint(0, n_tokens, (n_sequences, seq_len), device=device)\n",
        "\n",
        "    # Start with pure noise for numerical features\n",
        "    x_num = torch.randn(n_sequences, seq_len, n_num_features, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for t in tqdm(reversed(range(diffuser.total_steps)), desc=\"Generating\"):\n",
        "            timesteps = torch.full((n_sequences,), t, device=device, dtype=torch.long)\n",
        "\n",
        "            # Model prediction\n",
        "            cat_outputs, num_output = model(x_cat, x_num, timesteps)\n",
        "\n",
        "            # Update numerical features through diffusion\n",
        "            x_num = diffuser.reverse_step(num_output, x_num, timesteps)\n",
        "\n",
        "            # Update categorical features by sampling from logits\n",
        "            if t % 50 == 0:  # Update less frequently for stability\n",
        "                for i, cat_out in enumerate(cat_outputs):\n",
        "                    probs = torch.softmax(cat_out, dim=-1)\n",
        "                    x_cat[:, :, i] = torch.multinomial(probs.view(-1, probs.size(-1)), 1).view(n_sequences, seq_len)\n",
        "\n",
        "    return x_cat, x_num\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN EXECUTION\n",
        "# =============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    try:\n",
        "        real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: CSV file not found. Please ensure 'tr_by_acct_w_age.csv' is in the directory.\")\n",
        "        exit()\n",
        "\n",
        "    raw_data = preprocess_data_czech(real)\n",
        "    raw_data = raw_data.sort_values(by=[\"account_id\", \"date\"])\n",
        "\n",
        "    # Define features and encode\n",
        "    cat_attrs = ['tcode', 'dow', 'month', 'DoM_cat', 'age_group']\n",
        "    num_attrs = ['amount', 'raw_amount', 'td']\n",
        "\n",
        "    df_processed = raw_data[cat_attrs + num_attrs + ['account_id', 'datetime']].copy()\n",
        "\n",
        "    # Encode categorical features\n",
        "    label_encoders = {}\n",
        "    n_cat_tokens = []\n",
        "    for attr in cat_attrs:\n",
        "        le = LabelEncoder()\n",
        "        df_processed[attr] = le.fit_transform(df_processed[attr].astype(str))\n",
        "        label_encoders[attr] = le\n",
        "        n_cat_tokens.append(len(le.classes_))\n",
        "\n",
        "    # Scale numerical features\n",
        "    num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "    df_processed[num_attrs] = num_scaler.fit_transform(df_processed[num_attrs])\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = OptimizedSequentialDataset(\n",
        "        df_processed, cat_attrs, num_attrs,\n",
        "        sequence_length, min_seq_length, max_sequences_per_account=3\n",
        "    )\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    # Initialize model, diffuser, optimizer\n",
        "    model = ImprovedLSTMSynthesizer(\n",
        "        n_cat_features=len(cat_attrs),\n",
        "        n_cat_tokens=n_cat_tokens,\n",
        "        cat_emb_dim=cat_emb_dim,\n",
        "        n_num_features=len(num_attrs),\n",
        "        hidden_dim=mlp_layers[0]\n",
        "    ).to(device)\n",
        "\n",
        "    diffuser = SimplifiedDiffuser(diffusion_steps, diffusion_beta_start, diffusion_beta_end, device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters.\")\n",
        "\n",
        "    # Train model\n",
        "    print(\"Starting training...\")\n",
        "    train_model(model, diffuser, dataloader, epochs, optimizer, scheduler)\n",
        "\n",
        "    # Generate samples\n",
        "    print(\"Generating sample sequences...\")\n",
        "    generated_cat, generated_num = generate_sequences(\n",
        "        model, diffuser, n_sequences=5, seq_len=sequence_length,\n",
        "        n_cat_features=len(cat_attrs), n_cat_tokens=n_cat_tokens,\n",
        "        n_num_features=len(num_attrs), device=device\n",
        "    )\n",
        "\n",
        "    # Show results\n",
        "    print(\"\\nGeneration complete!\")\n",
        "    print(f\"Generated categorical shape: {generated_cat.shape}\")\n",
        "    print(f\"Generated numerical shape: {generated_num.shape}\")\n",
        "\n",
        "    # Inverse transform sample\n",
        "    sample_num = generated_num[0].cpu().numpy()\n",
        "    sample_num_original = num_scaler.inverse_transform(sample_num)\n",
        "\n",
        "    print(\"\\nSample generated numerical data (first sequence):\")\n",
        "    sample_df = pd.DataFrame(sample_num_original, columns=num_attrs)\n",
        "    print(sample_df.head(10))\n",
        "\n",
        "    print(\"\\nSample generated categorical codes (first sequence, tcode):\")\n",
        "    sample_cat = generated_cat[0, :, 0].cpu().numpy()\n",
        "    sample_cat_original = label_encoders['tcode'].inverse_transform(sample_cat)\n",
        "    print(sample_cat_original[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGeiVQFPA5Sm",
        "outputId": "71a364ca-ab32-4647-9483-12061f380433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Loading and preprocessing data...\n",
            "Creating optimized sequences from transaction data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4500/4500 [00:18<00:00, 246.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 13370 sequences from 4500 accounts.\n",
            "Model has 1,158,799 parameters.\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|██████████| 418/418 [00:04<00:00, 89.74it/s, Loss=1.1632, Cat=0.741, Num=0.422]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Avg Loss: 4.5560 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|██████████| 418/418 [00:04<00:00, 93.20it/s, Loss=0.4614, Cat=0.191, Num=0.270]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Avg Loss: 0.7402 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|██████████| 418/418 [00:04<00:00, 90.53it/s, Loss=0.4033, Cat=0.104, Num=0.299]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Avg Loss: 0.4525 - LR: 0.000199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|██████████| 418/418 [00:04<00:00, 91.22it/s, Loss=0.3742, Cat=0.074, Num=0.300]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Avg Loss: 0.3677 - LR: 0.000198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|██████████| 418/418 [00:04<00:00, 92.08it/s, Loss=0.3334, Cat=0.041, Num=0.293]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Avg Loss: 0.3165 - LR: 0.000197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|██████████| 418/418 [00:04<00:00, 91.23it/s, Loss=0.2661, Cat=0.023, Num=0.243]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Avg Loss: 0.2760 - LR: 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|██████████| 418/418 [00:04<00:00, 92.39it/s, Loss=0.2449, Cat=0.030, Num=0.215]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Avg Loss: 0.2530 - LR: 0.000193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|██████████| 418/418 [00:04<00:00, 89.75it/s, Loss=0.1895, Cat=0.010, Num=0.179]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Avg Loss: 0.2322 - LR: 0.000190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|██████████| 418/418 [00:04<00:00, 92.61it/s, Loss=0.2322, Cat=0.009, Num=0.223]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Avg Loss: 0.2194 - LR: 0.000188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|██████████| 418/418 [00:04<00:00, 93.22it/s, Loss=0.1884, Cat=0.009, Num=0.180]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Avg Loss: 0.2105 - LR: 0.000184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|██████████| 418/418 [00:04<00:00, 90.80it/s, Loss=0.2160, Cat=0.008, Num=0.208]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - Avg Loss: 0.2034 - LR: 0.000181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|██████████| 418/418 [00:04<00:00, 91.87it/s, Loss=0.1309, Cat=0.006, Num=0.125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - Avg Loss: 0.1953 - LR: 0.000177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|██████████| 418/418 [00:04<00:00, 88.48it/s, Loss=0.1229, Cat=0.005, Num=0.118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 - Avg Loss: 0.1897 - LR: 0.000173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50: 100%|██████████| 418/418 [00:04<00:00, 89.71it/s, Loss=0.1591, Cat=0.005, Num=0.154]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 - Avg Loss: 0.1878 - LR: 0.000168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50: 100%|██████████| 418/418 [00:04<00:00, 90.24it/s, Loss=0.1596, Cat=0.004, Num=0.156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 - Avg Loss: 0.1804 - LR: 0.000164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50: 100%|██████████| 418/418 [00:04<00:00, 90.80it/s, Loss=0.1452, Cat=0.005, Num=0.140]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 - Avg Loss: 0.1757 - LR: 0.000159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50: 100%|██████████| 418/418 [00:04<00:00, 92.18it/s, Loss=0.2685, Cat=0.002, Num=0.266]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 - Avg Loss: 0.1761 - LR: 0.000154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50: 100%|██████████| 418/418 [00:04<00:00, 87.67it/s, Loss=0.1208, Cat=0.003, Num=0.118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 - Avg Loss: 0.1725 - LR: 0.000148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50: 100%|██████████| 418/418 [00:04<00:00, 91.20it/s, Loss=0.1549, Cat=0.002, Num=0.153]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 - Avg Loss: 0.1662 - LR: 0.000143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50: 100%|██████████| 418/418 [00:04<00:00, 90.89it/s, Loss=0.1461, Cat=0.002, Num=0.144]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 - Avg Loss: 0.1659 - LR: 0.000137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50: 100%|██████████| 418/418 [00:04<00:00, 89.91it/s, Loss=0.1891, Cat=0.002, Num=0.187]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 - Avg Loss: 0.1607 - LR: 0.000131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50: 100%|██████████| 418/418 [00:04<00:00, 92.42it/s, Loss=0.1876, Cat=0.001, Num=0.186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 - Avg Loss: 0.1613 - LR: 0.000125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50: 100%|██████████| 418/418 [00:04<00:00, 92.08it/s, Loss=0.1607, Cat=0.002, Num=0.159]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 - Avg Loss: 0.1586 - LR: 0.000119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50: 100%|██████████| 418/418 [00:04<00:00, 92.61it/s, Loss=0.1568, Cat=0.001, Num=0.156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 - Avg Loss: 0.1582 - LR: 0.000113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50: 100%|██████████| 418/418 [00:04<00:00, 89.77it/s, Loss=0.1601, Cat=0.001, Num=0.159]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 - Avg Loss: 0.1584 - LR: 0.000106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50: 100%|██████████| 418/418 [00:04<00:00, 91.24it/s, Loss=0.1273, Cat=0.001, Num=0.126]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 - Avg Loss: 0.1554 - LR: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50: 100%|██████████| 418/418 [00:04<00:00, 91.86it/s, Loss=0.1875, Cat=0.001, Num=0.187]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 - Avg Loss: 0.1500 - LR: 0.000094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50: 100%|██████████| 418/418 [00:04<00:00, 92.51it/s, Loss=0.1063, Cat=0.001, Num=0.105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 - Avg Loss: 0.1516 - LR: 0.000087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50: 100%|██████████| 418/418 [00:04<00:00, 92.36it/s, Loss=0.1652, Cat=0.001, Num=0.164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 - Avg Loss: 0.1539 - LR: 0.000081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50: 100%|██████████| 418/418 [00:04<00:00, 92.95it/s, Loss=0.1695, Cat=0.001, Num=0.169]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 - Avg Loss: 0.1491 - LR: 0.000075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|██████████| 418/418 [00:04<00:00, 90.83it/s, Loss=0.1123, Cat=0.001, Num=0.112]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 - Avg Loss: 0.1481 - LR: 0.000069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50: 100%|██████████| 418/418 [00:04<00:00, 92.39it/s, Loss=0.1212, Cat=0.001, Num=0.120]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 - Avg Loss: 0.1491 - LR: 0.000063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50: 100%|██████████| 418/418 [00:04<00:00, 90.47it/s, Loss=0.1538, Cat=0.001, Num=0.153]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 - Avg Loss: 0.1449 - LR: 0.000057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50: 100%|██████████| 418/418 [00:04<00:00, 92.02it/s, Loss=0.1599, Cat=0.001, Num=0.159]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 - Avg Loss: 0.1454 - LR: 0.000052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50: 100%|██████████| 418/418 [00:04<00:00, 91.44it/s, Loss=0.1702, Cat=0.000, Num=0.170]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 - Avg Loss: 0.1453 - LR: 0.000046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50: 100%|██████████| 418/418 [00:04<00:00, 90.75it/s, Loss=0.1424, Cat=0.001, Num=0.142]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 - Avg Loss: 0.1456 - LR: 0.000041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50: 100%|██████████| 418/418 [00:04<00:00, 91.69it/s, Loss=0.1224, Cat=0.000, Num=0.122]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 - Avg Loss: 0.1421 - LR: 0.000036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50: 100%|██████████| 418/418 [00:04<00:00, 89.40it/s, Loss=0.1078, Cat=0.001, Num=0.107]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 - Avg Loss: 0.1433 - LR: 0.000032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|██████████| 418/418 [00:04<00:00, 91.31it/s, Loss=0.1265, Cat=0.000, Num=0.126]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 - Avg Loss: 0.1434 - LR: 0.000027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|██████████| 418/418 [00:04<00:00, 90.38it/s, Loss=0.1270, Cat=0.001, Num=0.126]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 - Avg Loss: 0.1434 - LR: 0.000023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|██████████| 418/418 [00:04<00:00, 88.69it/s, Loss=0.1866, Cat=0.001, Num=0.186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 - Avg Loss: 0.1432 - LR: 0.000019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|██████████| 418/418 [00:04<00:00, 91.50it/s, Loss=0.1585, Cat=0.000, Num=0.158]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 - Avg Loss: 0.1426 - LR: 0.000016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|██████████| 418/418 [00:04<00:00, 90.83it/s, Loss=0.1130, Cat=0.000, Num=0.113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 - Avg Loss: 0.1409 - LR: 0.000012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|██████████| 418/418 [00:04<00:00, 92.08it/s, Loss=0.1194, Cat=0.000, Num=0.119]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 - Avg Loss: 0.1429 - LR: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|██████████| 418/418 [00:04<00:00, 92.35it/s, Loss=0.1311, Cat=0.001, Num=0.130]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 - Avg Loss: 0.1401 - LR: 0.000007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|██████████| 418/418 [00:04<00:00, 89.33it/s, Loss=0.1245, Cat=0.001, Num=0.124]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 - Avg Loss: 0.1420 - LR: 0.000005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|██████████| 418/418 [00:04<00:00, 92.06it/s, Loss=0.1181, Cat=0.001, Num=0.118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 - Avg Loss: 0.1404 - LR: 0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|██████████| 418/418 [00:04<00:00, 88.95it/s, Loss=0.1468, Cat=0.000, Num=0.146]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 - Avg Loss: 0.1434 - LR: 0.000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|██████████| 418/418 [00:04<00:00, 90.40it/s, Loss=0.1735, Cat=0.001, Num=0.173]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 - Avg Loss: 0.1446 - LR: 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|██████████| 418/418 [00:04<00:00, 89.08it/s, Loss=0.1052, Cat=0.000, Num=0.105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 - Avg Loss: 0.1401 - LR: 0.000000\n",
            "Generating sample sequences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 500it [00:01, 327.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generation complete!\n",
            "Generated categorical shape: torch.Size([5, 30, 5])\n",
            "Generated numerical shape: torch.Size([5, 30, 3])\n",
            "\n",
            "Sample generated numerical data (first sequence):\n",
            "        amount   raw_amount    td\n",
            "0   203.352783   212.869400   0.0\n",
            "1  2096.108398   600.000000  22.0\n",
            "2  2400.000000 -2474.615723  16.0\n",
            "3   776.697266  -589.606812   1.0\n",
            "4    14.600000   -14.600000  17.0\n",
            "5  1800.000000   309.943024   1.0\n",
            "6  4800.000000 -4800.000000   7.0\n",
            "7    14.600000  -118.949631  13.0\n",
            "8   115.479965   126.459358   0.0\n",
            "9  1800.000000   243.423401   0.0\n",
            "\n",
            "Sample generated categorical codes (first sequence, tcode):\n",
            "['CREDIT__CREDIT IN CASH__nan' 'CREDIT__CREDIT IN CASH__nan'\n",
            " 'DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD'\n",
            " 'DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE PAYMENT'\n",
            " 'DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT'\n",
            " 'CREDIT__CREDIT IN CASH__nan'\n",
            " 'DEBIT__REMITTANCE TO ANOTHER BANK__LOAN PAYMENT'\n",
            " 'DEBIT__CASH WITHDRAWAL__SANCTION INTEREST'\n",
            " 'CREDIT__nan__INTEREST CREDITED' 'CREDIT__CREDIT IN CASH__nan']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_cat_original"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBUDb2OSCBhN",
        "outputId": "c93d603f-aa56-407c-bb90-bdb7444b7d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CREDIT__CREDIT IN CASH__nan', 'CREDIT__CREDIT IN CASH__nan',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE PAYMENT',\n",
              "       'DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT',\n",
              "       'CREDIT__CREDIT IN CASH__nan',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__LOAN PAYMENT',\n",
              "       'DEBIT__CASH WITHDRAWAL__SANCTION INTEREST',\n",
              "       'CREDIT__nan__INTEREST CREDITED', 'CREDIT__CREDIT IN CASH__nan',\n",
              "       'CREDIT__COLLECTION FROM ANOTHER BANK__nan',\n",
              "       'CREDIT__nan__INTEREST CREDITED', 'DEBIT__CASH WITHDRAWAL__nan',\n",
              "       'DEBIT__CASH WITHDRAWAL__nan',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__ ',\n",
              "       'DEBIT__CASH WITHDRAWAL__HOUSEHOLD', 'CREDIT__CREDIT IN CASH__nan',\n",
              "       'CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE PENSION',\n",
              "       'CREDIT__nan__INTEREST CREDITED',\n",
              "       'DEBIT__CREDIT CARD WITHDRAWAL__nan',\n",
              "       'DEBIT__CREDIT CARD WITHDRAWAL__nan',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__ ',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD',\n",
              "       'DEBIT__CASH WITHDRAWAL__HOUSEHOLD',\n",
              "       'CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE PENSION',\n",
              "       'DEBIT__CASH WITHDRAWAL__HOUSEHOLD',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__LOAN PAYMENT',\n",
              "       'CREDIT__CREDIT IN CASH__nan',\n",
              "       'DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT',\n",
              "       'DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "ziZoBOJsCF-t",
        "outputId": "f1a7df7f-56a4-44a2-9a06-b0d5fac2355a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          amount    raw_amount    td\n",
              "0     203.352783    212.869400   0.0\n",
              "1    2096.108398    600.000000  22.0\n",
              "2    2400.000000  -2474.615723  16.0\n",
              "3     776.697266   -589.606812   1.0\n",
              "4      14.600000    -14.600000  17.0\n",
              "5    1800.000000    309.943024   1.0\n",
              "6    4800.000000  -4800.000000   7.0\n",
              "7      14.600000   -118.949631  13.0\n",
              "8     115.479965    126.459358   0.0\n",
              "9    1800.000000    243.423401   0.0\n",
              "10   2884.062500   2124.232910  19.0\n",
              "11     14.600000     62.098595   6.0\n",
              "12   4979.041016  -4500.000000   7.0\n",
              "13   3389.831055  -3380.360596   1.0\n",
              "14   2507.586182  -2513.366943   3.0\n",
              "15   3000.000000  -3265.844482   0.0\n",
              "16  24451.013672  24286.625000  13.0\n",
              "17   8100.007324   8907.077148   1.0\n",
              "18     95.642387    104.274460  18.0\n",
              "19   3512.983887  -4800.000000   1.0\n",
              "20   3000.000000  -2036.675415   6.0\n",
              "21   2688.146729  -2301.570557  12.0\n",
              "22   5953.124023  -6387.310059   2.0\n",
              "23  13494.231445  -7375.652832   5.0\n",
              "24   5087.676270   4049.737061   3.0\n",
              "25   4485.389160  -5903.312988   9.0\n",
              "26   2127.368652  -1774.142334   2.0\n",
              "27  20197.542969  18773.808594   3.0\n",
              "28     14.600000    -14.600000  17.0\n",
              "29   6869.923828  -6855.554688  22.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8eb4bf6f-7b53-4fd1-9b6e-6a03b5f8be66\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amount</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>td</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>203.352783</td>\n",
              "      <td>212.869400</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2096.108398</td>\n",
              "      <td>600.000000</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2400.000000</td>\n",
              "      <td>-2474.615723</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>776.697266</td>\n",
              "      <td>-589.606812</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14.600000</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1800.000000</td>\n",
              "      <td>309.943024</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4800.000000</td>\n",
              "      <td>-4800.000000</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>14.600000</td>\n",
              "      <td>-118.949631</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>115.479965</td>\n",
              "      <td>126.459358</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1800.000000</td>\n",
              "      <td>243.423401</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2884.062500</td>\n",
              "      <td>2124.232910</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>14.600000</td>\n",
              "      <td>62.098595</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4979.041016</td>\n",
              "      <td>-4500.000000</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3389.831055</td>\n",
              "      <td>-3380.360596</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2507.586182</td>\n",
              "      <td>-2513.366943</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3000.000000</td>\n",
              "      <td>-3265.844482</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>24451.013672</td>\n",
              "      <td>24286.625000</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8100.007324</td>\n",
              "      <td>8907.077148</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>95.642387</td>\n",
              "      <td>104.274460</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3512.983887</td>\n",
              "      <td>-4800.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3000.000000</td>\n",
              "      <td>-2036.675415</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2688.146729</td>\n",
              "      <td>-2301.570557</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>5953.124023</td>\n",
              "      <td>-6387.310059</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>13494.231445</td>\n",
              "      <td>-7375.652832</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>5087.676270</td>\n",
              "      <td>4049.737061</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>4485.389160</td>\n",
              "      <td>-5903.312988</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2127.368652</td>\n",
              "      <td>-1774.142334</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>20197.542969</td>\n",
              "      <td>18773.808594</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>14.600000</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>6869.923828</td>\n",
              "      <td>-6855.554688</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8eb4bf6f-7b53-4fd1-9b6e-6a03b5f8be66')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8eb4bf6f-7b53-4fd1-9b6e-6a03b5f8be66 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8eb4bf6f-7b53-4fd1-9b6e-6a03b5f8be66');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1db8bb71-6722-47c6-a03c-814847c0e83c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1db8bb71-6722-47c6-a03c-814847c0e83c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1db8bb71-6722-47c6-a03c-814847c0e83c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_34d58d44-c016-4b9f-a43f-64a8142a9311\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sample_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_34d58d44-c016-4b9f-a43f-64a8142a9311 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sample_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sample_df",
              "summary": "{\n  \"name\": \"sample_df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"amount\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          2884.0625,\n          3512.98388671875,\n          203.352783203125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_amount\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          243.42340087890625,\n          -1774.142333984375,\n          126.45935821533203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"td\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          3.0,\n          12.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sample_cat_original)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohp-EeaiCQJD",
        "outputId": "b91d1633-9f1c-4a3b-8979-b371c19bd927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzK7ymdNCco0",
        "outputId": "16d31273-1510-45d4-f094-3dbdf5ccb040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2,  2, 12, 13,  7,  2, 14,  8,  3,  2,  1,  3,  9,  9, 11,  5,  2,\n",
              "        0,  3, 10, 10, 11, 12,  5,  0,  5, 14,  2,  7, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "# from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import random\n",
        "# import os\n",
        "# from datetime import datetime\n",
        "# import calendar\n",
        "# from tqdm import tqdm\n",
        "# from scipy import stats\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# # =============================================================================\n",
        "# # CONFIGURATION\n",
        "# # =============================================================================\n",
        "# # Set seeds for reproducibility\n",
        "# seed = 1234\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# torch.manual_seed(seed)\n",
        "# if torch.cuda.is_available():\n",
        "#     torch.cuda.manual_seed(seed)\n",
        "#     torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# # Device configuration\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(f\"Using device: {device}\")\n",
        "\n",
        "# # Model hyperparameters\n",
        "# sequence_length = 30      # Reduced for efficiency\n",
        "# min_seq_length = 20\n",
        "# cat_emb_dim = 8           # Reduced for efficiency\n",
        "# mlp_layers = [256, 256]   # Smaller layers\n",
        "# activation = 'lrelu'\n",
        "# diffusion_steps = 500     # Reduced steps\n",
        "# diffusion_beta_start = 1e-4\n",
        "# diffusion_beta_end = 0.02\n",
        "# scheduler = 'linear'\n",
        "# epochs = 50               # Reduced epochs for testing\n",
        "# batch_size = 32           # Smaller batch size\n",
        "# learning_rate = 2e-4      # Slightly higher learning rate\n",
        "# n_sequences=20\n",
        "# # =============================================================================\n",
        "# # DATA PREPROCESSING\n",
        "# # =============================================================================\n",
        "# def preprocess_data_czech(df):\n",
        "#     \"\"\"Enhanced preprocessing with better error handling\"\"\"\n",
        "#     czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "#     df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "#     df[\"month\"] = df[\"datetime\"].dt.month\n",
        "#     df[\"day\"] = df[\"datetime\"].dt.day\n",
        "#     df[\"dow\"] = df[\"datetime\"].dt.dayofweek\n",
        "#     df[\"year\"] = df[\"datetime\"].dt.year\n",
        "#     df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "#     df_sorted = df.sort_values(['account_id', 'datetime']).copy()\n",
        "\n",
        "#     df_sorted[\"td\"] = df_sorted.groupby(\"account_id\")[\"datetime\"].diff().dt.days\n",
        "#     df_sorted[\"td\"].fillna(0.0, inplace=True)\n",
        "#     df_sorted[\"dtme\"] = df_sorted.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "#     df_sorted['raw_amount'] = df_sorted.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "#     # Create transaction code\n",
        "#     cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "#     tcode = df_sorted[cat_code_fields[0]].astype(str)\n",
        "#     for ccf in cat_code_fields[1:]:\n",
        "#         tcode += \"__\" + df_sorted[ccf].astype(str)\n",
        "#     df_sorted[\"tcode\"] = tcode\n",
        "\n",
        "#     # Day of month categories\n",
        "#     conditions = [\n",
        "#         (df_sorted['day'] >= 1) & (df_sorted['day'] <= 10),\n",
        "#         (df_sorted['day'] > 10) & (df_sorted['day'] <= 20),\n",
        "#         (df_sorted['day'] > 20) & (df_sorted['day'] <= 31)\n",
        "#     ]\n",
        "#     categories = ['first', 'middle', 'last']\n",
        "#     df_sorted['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "#     # Age groups\n",
        "#     if 'age' in df_sorted.columns:\n",
        "#         bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "#         labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "#         df_sorted['age_group'] = pd.cut(df_sorted['age'], bins=bin_edges, labels=labels, right=False)\n",
        "#         df_sorted['age_group'] = df_sorted['age_group'].astype('object').fillna('unknown')\n",
        "#     else:\n",
        "#         print(\"Warning: 'age' column not found. Creating placeholder.\")\n",
        "#         df_sorted['age_group'] = 'unknown'\n",
        "\n",
        "#     return df_sorted\n",
        "\n",
        "# # =============================================================================\n",
        "# # IMPROVED SEQUENTIAL DATASET\n",
        "# # =============================================================================\n",
        "# class OptimizedSequentialDataset(Dataset):\n",
        "#     \"\"\"More efficient dataset that samples sequences strategically\"\"\"\n",
        "#     def __init__(self, df, cat_attrs, num_attrs, sequence_length=30, min_seq_length=20, max_sequences_per_account=5):\n",
        "#         self.sequence_length = sequence_length\n",
        "#         self.min_seq_length = min_seq_length\n",
        "#         self.cat_attrs = cat_attrs\n",
        "#         self.num_attrs = num_attrs\n",
        "#         self.sequences = []\n",
        "\n",
        "#         print(\"Creating optimized sequences from transaction data...\")\n",
        "\n",
        "#         # Group by account and create limited sequences per account\n",
        "#         for account_id in tqdm(df['account_id'].unique()):\n",
        "#             account_data = df[df['account_id'] == account_id].sort_values('datetime').reset_index(drop=True)\n",
        "#             if len(account_data) >= min_seq_length:\n",
        "#                 # Sample sequences strategically instead of all overlapping windows\n",
        "#                 n_possible = len(account_data) - sequence_length + 1\n",
        "#                 if n_possible <= max_sequences_per_account:\n",
        "#                     # Use all if few sequences possible\n",
        "#                     start_indices = range(n_possible)\n",
        "#                 else:\n",
        "#                     # Sample evenly spaced sequences\n",
        "#                     start_indices = np.linspace(0, n_possible-1, max_sequences_per_account, dtype=int)\n",
        "\n",
        "#                 for start_idx in start_indices:\n",
        "#                     seq_data = account_data.iloc[start_idx:start_idx+sequence_length]\n",
        "#                     cat_data = seq_data[self.cat_attrs].values\n",
        "#                     num_data = seq_data[self.num_attrs].values\n",
        "#                     self.sequences.append({'cat_data': cat_data, 'num_data': num_data})\n",
        "\n",
        "#         print(f\"Created {len(self.sequences)} sequences from {df['account_id'].nunique()} accounts.\")\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.sequences)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         seq = self.sequences[idx]\n",
        "#         cat_tensor = torch.LongTensor(seq['cat_data'])\n",
        "#         num_tensor = torch.FloatTensor(seq['num_data'])\n",
        "#         return cat_tensor, num_tensor\n",
        "\n",
        "# # =============================================================================\n",
        "# # IMPROVED LSTM SYNTHESIZER\n",
        "# # =============================================================================\n",
        "# class ImprovedLSTMSynthesizer(nn.Module):\n",
        "#     \"\"\"Fixed model that properly handles the training/generation process\"\"\"\n",
        "#     def __init__(self, n_cat_features, n_cat_tokens, cat_emb_dim, n_num_features,\n",
        "#                  hidden_dim=256, lstm_layers=2, dim_t=64):\n",
        "#         super(ImprovedLSTMSynthesizer, self).__init__()\n",
        "#         self.n_cat_features = n_cat_features\n",
        "#         self.n_num_features = n_num_features\n",
        "#         self.cat_emb_dim = cat_emb_dim\n",
        "#         self.hidden_dim = hidden_dim\n",
        "#         self.dim_t = dim_t\n",
        "\n",
        "#         # Categorical embeddings\n",
        "#         self.cat_embeddings = nn.ModuleList([\n",
        "#             nn.Embedding(n_cat_tokens[i], cat_emb_dim) for i in range(n_cat_features)\n",
        "#         ])\n",
        "\n",
        "#         total_cat_emb_dim = n_cat_features * cat_emb_dim\n",
        "#         total_input_dim = total_cat_emb_dim + n_num_features\n",
        "\n",
        "#         # Time embedding\n",
        "#         self.time_embed = nn.Sequential(\n",
        "#             nn.Linear(dim_t, hidden_dim),\n",
        "#             nn.SiLU(),\n",
        "#             nn.Linear(hidden_dim, hidden_dim)\n",
        "#         )\n",
        "\n",
        "#         # Input projection\n",
        "#         self.input_projection = nn.Linear(total_input_dim, hidden_dim)\n",
        "\n",
        "#         # LSTM\n",
        "#         self.lstm = nn.LSTM(\n",
        "#             input_size=hidden_dim,\n",
        "#             hidden_size=hidden_dim,\n",
        "#             num_layers=lstm_layers,\n",
        "#             batch_first=True,\n",
        "#             dropout=0.1 if lstm_layers > 1 else 0\n",
        "#         )\n",
        "\n",
        "#         # Separate heads for categorical and numerical outputs\n",
        "#         self.cat_heads = nn.ModuleList([\n",
        "#             nn.Linear(hidden_dim, n_cat_tokens[i]) for i in range(n_cat_features)\n",
        "#         ])\n",
        "#         self.num_head = nn.Linear(hidden_dim, n_num_features)\n",
        "\n",
        "#     def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "#         half = dim_out // 2\n",
        "#         freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half).to(device)\n",
        "#         args = timesteps[:, None].float() * freqs[None]\n",
        "#         embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "#         if dim_out % 2:\n",
        "#             embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "#         return embedding\n",
        "\n",
        "#     def embed_categorical(self, x_cat):\n",
        "#         \"\"\"Embed categorical features\"\"\"\n",
        "#         embeddings = []\n",
        "#         for i in range(self.n_cat_features):\n",
        "#             embeddings.append(self.cat_embeddings[i](x_cat[:, :, i]))\n",
        "#         return torch.cat(embeddings, dim=-1)\n",
        "\n",
        "#     def forward(self, x_cat, x_num, timesteps):\n",
        "#         \"\"\"Forward pass for training\"\"\"\n",
        "#         batch_size, seq_len, _ = x_num.shape\n",
        "\n",
        "#         # Embed categorical features\n",
        "#         cat_emb = self.embed_categorical(x_cat)\n",
        "\n",
        "#         # Combine with numerical features\n",
        "#         x = torch.cat([cat_emb, x_num], dim=-1)\n",
        "\n",
        "#         # Project input\n",
        "#         x_proj = self.input_projection(x)\n",
        "\n",
        "#         # Time embedding\n",
        "#         time_emb_raw = self.embed_time(timesteps, self.dim_t)\n",
        "#         time_emb = self.time_embed(time_emb_raw)\n",
        "#         time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "#         # Add time embedding\n",
        "#         x_with_time = x_proj + time_emb\n",
        "\n",
        "#         # LSTM processing\n",
        "#         lstm_out, _ = self.lstm(x_with_time)\n",
        "\n",
        "#         # Separate outputs\n",
        "#         cat_outputs = [head(lstm_out) for head in self.cat_heads]\n",
        "#         num_output = self.num_head(lstm_out)\n",
        "\n",
        "#         return cat_outputs, num_output\n",
        "\n",
        "# # =============================================================================\n",
        "# # SIMPLIFIED DIFFUSION PROCESS\n",
        "# # =============================================================================\n",
        "# class SimplifiedDiffuser:\n",
        "#     \"\"\"Simplified diffusion process for faster training\"\"\"\n",
        "#     def __init__(self, total_steps=500, beta_start=1e-4, beta_end=0.02, device='cpu'):\n",
        "#         self.total_steps = total_steps\n",
        "#         self.device = device\n",
        "\n",
        "#         # Linear schedule\n",
        "#         self.betas = torch.linspace(beta_start, beta_end, total_steps).to(device)\n",
        "#         self.alphas = (1.0 - self.betas).to(device)\n",
        "#         self.alphas_cumprod = torch.cumprod(self.alphas, dim=0).to(device)\n",
        "\n",
        "#     def sample_random_timesteps(self, n: int):\n",
        "#         return torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "\n",
        "#     def add_noise(self, x, t):\n",
        "#         \"\"\"Add noise to input\"\"\"\n",
        "#         sqrt_alpha_cumprod = torch.sqrt(self.alphas_cumprod[t])[:, None, None]\n",
        "#         sqrt_one_minus_alpha_cumprod = torch.sqrt(1 - self.alphas_cumprod[t])[:, None, None]\n",
        "\n",
        "#         noise = torch.randn_like(x)\n",
        "#         return sqrt_alpha_cumprod * x + sqrt_one_minus_alpha_cumprod * noise, noise\n",
        "\n",
        "#     def reverse_step(self, model_output, noisy_input, t):\n",
        "#         \"\"\"Single reverse diffusion step\"\"\"\n",
        "#         sqrt_alpha_t = torch.sqrt(self.alphas[t])[:, None, None]\n",
        "#         beta_t = self.betas[t][:, None, None]\n",
        "#         sqrt_one_minus_alpha_cumprod_t = torch.sqrt(1 - self.alphas_cumprod[t])[:, None, None]\n",
        "\n",
        "#         model_mean = (1 / sqrt_alpha_t) * (noisy_input - (beta_t * model_output / sqrt_one_minus_alpha_cumprod_t))\n",
        "\n",
        "#         if t.min() > 0:\n",
        "#             noise = torch.randn_like(noisy_input)\n",
        "#             return model_mean + torch.sqrt(beta_t) * noise\n",
        "#         else:\n",
        "#             return model_mean\n",
        "\n",
        "# # =============================================================================\n",
        "# # TRAINING LOOP\n",
        "# # =============================================================================\n",
        "# def train_model(model, diffuser, dataloader, epochs, optimizer, scheduler):\n",
        "#     \"\"\"Improved training loop\"\"\"\n",
        "#     model.train()\n",
        "#     cat_criterion = nn.CrossEntropyLoss()\n",
        "#     num_criterion = nn.MSELoss()\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         epoch_loss = 0.0\n",
        "#         pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "#         for batch_cat, batch_num in pbar:\n",
        "#             batch_cat, batch_num = batch_cat.to(device), batch_num.to(device)\n",
        "#             batch_size = batch_cat.shape[0]\n",
        "\n",
        "#             # Sample timesteps\n",
        "#             timesteps = diffuser.sample_random_timesteps(batch_size)\n",
        "\n",
        "#             # Add noise to numerical features only\n",
        "#             noisy_num, noise_target = diffuser.add_noise(batch_num, timesteps)\n",
        "\n",
        "#             # Forward pass\n",
        "#             cat_outputs, num_output = model(batch_cat, noisy_num, timesteps)\n",
        "\n",
        "#             # Calculate losses\n",
        "#             cat_loss = 0\n",
        "#             for i, cat_out in enumerate(cat_outputs):\n",
        "#                 cat_loss += cat_criterion(cat_out.view(-1, cat_out.size(-1)),\n",
        "#                                         batch_cat[:, :, i].view(-1))\n",
        "\n",
        "#             num_loss = num_criterion(num_output, noise_target)\n",
        "\n",
        "#             total_loss = cat_loss + num_loss\n",
        "\n",
        "#             # Backward pass\n",
        "#             optimizer.zero_grad()\n",
        "#             total_loss.backward()\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "#             optimizer.step()\n",
        "\n",
        "#             epoch_loss += total_loss.item()\n",
        "#             pbar.set_postfix({\n",
        "#                 'Loss': f\"{total_loss.item():.4f}\",\n",
        "#                 'Cat': f\"{cat_loss.item():.3f}\",\n",
        "#                 'Num': f\"{num_loss.item():.3f}\"\n",
        "#             })\n",
        "\n",
        "#         avg_loss = epoch_loss / len(dataloader)\n",
        "#         print(f\"Epoch {epoch+1} - Avg Loss: {avg_loss:.4f} - LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "#         scheduler.step()\n",
        "\n",
        "# # =============================================================================\n",
        "# # GENERATION FUNCTION\n",
        "# # =============================================================================\n",
        "# def create_realistic_datetime_sequences(generated_cat, cat_attrs, label_encoders, sequence_length):\n",
        "#     \"\"\"Create more realistic datetime sequences based on temporal patterns\"\"\"\n",
        "#     # Find indices for day, month, year in categorical features\n",
        "#     day_idx = cat_attrs.index('day') if 'day' in cat_attrs else None\n",
        "#     month_idx = cat_attrs.index('month') if 'month' in cat_attrs else None\n",
        "#     year_idx = cat_attrs.index('year') if 'year' in cat_attrs else None\n",
        "\n",
        "#     if any(idx is None for idx in [day_idx, month_idx, year_idx]):\n",
        "#         def generate_sequences(model, diffuser, n_sequences, seq_len, n_cat_features,\n",
        "#                           n_cat_tokens, n_num_features, device):  # Return as-is if missing components\n",
        "\n",
        "#             # Create more realistic sequences\n",
        "#             for seq_idx in range(generated_cat.shape[0]):\n",
        "#                 # Start with a random realistic date\n",
        "#                 start_year = np.random.choice([1993, 1994, 1995, 1996, 1997])\n",
        "#                 start_month = np.random.randint(1, 13)\n",
        "#                 start_day = np.random.randint(1, 29)  # Safe day range\n",
        "\n",
        "#                 current_date = datetime(start_year, start_month, start_day)\n",
        "\n",
        "#                 for step in range(sequence_length):\n",
        "#                     # Add realistic time progression (1-30 days between transactions)\n",
        "#                     if step > 0:\n",
        "#                         days_increment = np.random.randint(1, 31)\n",
        "#                         current_date += pd.Timedelta(days=days_increment)\n",
        "\n",
        "#                     # Encode the date components\n",
        "#                     year_encoded = np.where(label_encoders['year'].classes_ == str(current_date.year))[0]\n",
        "#                     month_encoded = np.where(label_encoders['month'].classes_ == str(current_date.month))[0]\n",
        "#                     day_encoded = np.where(label_encoders['day'].classes_ == str(current_date.day))[0]\n",
        "\n",
        "#                     # Set encoded values (with fallback if not found)\n",
        "#                     if len(year_encoded) > 0:\n",
        "#                         generated_cat[seq_idx, step, year_idx] = year_encoded[0]\n",
        "#                     if len(month_encoded) > 0:\n",
        "#                         generated_cat[seq_idx, step, month_idx] = month_encoded[0]\n",
        "#                     if len(day_encoded) > 0:\n",
        "#                         generated_cat[seq_idx, step, day_idx] = day_encoded[0]\n",
        "\n",
        "#             return generated_cat\n",
        "#     \"\"\"Generate new sequences\"\"\"\n",
        "#     model.eval()\n",
        "\n",
        "#     # Initialize with random categorical indices\n",
        "#     x_cat = torch.zeros(n_sequences, seq_len, n_cat_features, dtype=torch.long, device=device)\n",
        "#     for i, n_tokens in enumerate(n_cat_tokens):\n",
        "#         x_cat[:, :, i] = torch.randint(0, n_tokens, (n_sequences, seq_len), device=device)\n",
        "\n",
        "#     # Start with pure noise for numerical features\n",
        "#     x_num = torch.randn(n_sequences, seq_len, n_num_features, device=device)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for t in tqdm(reversed(range(diffuser.total_steps)), desc=\"Generating\"):\n",
        "#             timesteps = torch.full((n_sequences,), t, device=device, dtype=torch.long)\n",
        "\n",
        "#             # Model prediction\n",
        "#             cat_outputs, num_output = model(x_cat, x_num, timesteps)\n",
        "\n",
        "#             # Update numerical features through diffusion\n",
        "#             x_num = diffuser.reverse_step(num_output, x_num, timesteps)\n",
        "\n",
        "#             # Update categorical features by sampling from logits\n",
        "#             if t % 50 == 0:  # Update less frequently for stability\n",
        "#                 for i, cat_out in enumerate(cat_outputs):\n",
        "#                     probs = torch.softmax(cat_out, dim=-1)\n",
        "#                     x_cat[:, :, i] = torch.multinomial(probs.view(-1, probs.size(-1)), 1).view(n_sequences, seq_len)\n",
        "\n",
        "#     return x_cat, x_num\n",
        "\n",
        "# # =============================================================================\n",
        "# # MAIN EXECUTION\n",
        "# # =============================================================================\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Load and preprocess data\n",
        "#     print(\"Loading and preprocessing data...\")\n",
        "#     try:\n",
        "#         real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "#     except FileNotFoundError:\n",
        "#         print(\"Error: CSV file not found. Please ensure 'tr_by_acct_w_age.csv' is in the directory.\")\n",
        "#         exit()\n",
        "\n",
        "#     raw_data = preprocess_data_czech(real)\n",
        "#     raw_data = raw_data.sort_values(by=[\"account_id\", \"date\"])\n",
        "\n",
        "#     # Define features and encode\n",
        "#     cat_attrs = ['tcode', 'dow', 'month', 'day', 'year', 'DoM_cat', 'age_group']\n",
        "#     num_attrs = ['amount', 'raw_amount', 'td']\n",
        "\n",
        "#     df_processed = raw_data[cat_attrs + num_attrs + ['account_id', 'datetime']].copy()\n",
        "\n",
        "#     # Encode categorical features\n",
        "#     label_encoders = {}\n",
        "#     n_cat_tokens = []\n",
        "#     for attr in cat_attrs:\n",
        "#         le = LabelEncoder()\n",
        "#         df_processed[attr] = le.fit_transform(df_processed[attr].astype(str))\n",
        "#         label_encoders[attr] = le\n",
        "#         n_cat_tokens.append(len(le.classes_))\n",
        "\n",
        "#     # Scale numerical features\n",
        "#     num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "#     df_processed[num_attrs] = num_scaler.fit_transform(df_processed[num_attrs])\n",
        "\n",
        "#     # Create dataset and dataloader\n",
        "#     dataset = OptimizedSequentialDataset(\n",
        "#         df_processed, cat_attrs, num_attrs,\n",
        "#         sequence_length, min_seq_length, max_sequences_per_account=3\n",
        "#     )\n",
        "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "#     # Initialize model, diffuser, optimizer\n",
        "#     model = ImprovedLSTMSynthesizer(\n",
        "#         n_cat_features=len(cat_attrs),\n",
        "#         n_cat_tokens=n_cat_tokens,\n",
        "#         cat_emb_dim=cat_emb_dim,\n",
        "#         n_num_features=len(num_attrs),\n",
        "#         hidden_dim=mlp_layers[0]\n",
        "#     ).to(device)\n",
        "\n",
        "#     diffuser = SimplifiedDiffuser(diffusion_steps, diffusion_beta_start, diffusion_beta_end, device)\n",
        "#     optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#     scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "#     print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters.\")\n",
        "\n",
        "#     # Train model\n",
        "#     print(\"Starting training...\")\n",
        "#     train_model(model, diffuser, dataloader, epochs, optimizer, scheduler)\n",
        "\n",
        "#     # Generate samples (more sequences for better final dataframe)\n",
        "#     print(\"Generating sample sequences...\")\n",
        "#     generated_cat, generated_num = generate_sequences(\n",
        "#         model, diffuser, n_sequences=20, seq_len=sequence_length,  # Generate more sequences\n",
        "#         n_cat_features=len(cat_attrs), n_cat_tokens=n_cat_tokens,\n",
        "#         n_num_features=len(num_attrs), device=device\n",
        "#     )\n",
        "\n",
        "#     # Post-process to create realistic datetime sequences\n",
        "#     generated_cat = create_realistic_datetime_sequences(\n",
        "#         generated_cat, cat_attrs, label_encoders, sequence_length\n",
        "#     )\n",
        "#     # Create final dataframe with all generated sequences\n",
        "#     final_sequences = []\n",
        "\n",
        "#     for seq_idx in range(generated_cat.shape[0]):\n",
        "#         # Inverse transform numerical data\n",
        "#         seq_num = generated_num[seq_idx].cpu().numpy()\n",
        "#         seq_num_original = num_scaler.inverse_transform(seq_num)\n",
        "\n",
        "#         # Inverse transform categorical data\n",
        "#         seq_cat = generated_cat[seq_idx].cpu().numpy()\n",
        "\n",
        "#         # Create sequence dataframe\n",
        "#         seq_df = pd.DataFrame()\n",
        "\n",
        "#         # Add numerical features\n",
        "#         for i, col in enumerate(num_attrs):\n",
        "#             seq_df[col] = seq_num_original[:, i]\n",
        "\n",
        "#         # Add categorical features (inverse transformed)\n",
        "#         for i, col in enumerate(cat_attrs):\n",
        "#             if col in label_encoders:\n",
        "#                 seq_df[col] = label_encoders[col].inverse_transform(seq_cat[:, i])\n",
        "#             else:\n",
        "#                 seq_df[col] = seq_cat[:, i]\n",
        "\n",
        "#         # Create datetime from day, month, year\n",
        "#         seq_df['datetime'] = pd.to_datetime({\n",
        "#             'year': seq_df['year'].astype(int),\n",
        "#             'month': seq_df['month'].astype(int),\n",
        "#             'day': seq_df['day'].astype(int)\n",
        "#         }, errors='coerce')\n",
        "\n",
        "#         # Add sequence identifier\n",
        "#         seq_df['sequence_id'] = seq_idx\n",
        "#         seq_df['transaction_order'] = range(len(seq_df))\n",
        "\n",
        "#         final_sequences.append(seq_df)\n",
        "\n",
        "#     # Combine all sequences\n",
        "#     all_sequences_df = pd.concat(final_sequences, ignore_index=True)\n",
        "\n",
        "#     # Create final dataframe with only requested columns\n",
        "#     final_df = all_sequences_df[['raw_amount', 'amount', 'td', 'tcode', 'datetime']].copy()\n",
        "\n",
        "#     # Clean up any invalid dates\n",
        "#     final_df = final_df.dropna(subset=['datetime'])\n",
        "\n",
        "#     print(\"\\nFinal dataframe created!\")\n",
        "#     print(f\"Shape: {final_df.shape}\")\n",
        "#     print(\"\\nColumn info:\")\n",
        "#     print(final_df.dtypes)\n",
        "\n",
        "#     print(\"\\nSample of final_df:\")\n",
        "#     print(final_df.head(15))\n",
        "\n",
        "#     print(f\"\\nUnique tcodes: {final_df['tcode'].nunique()}\")\n",
        "#     print(f\"Date range: {final_df['datetime'].min()} to {final_df['datetime'].max()}\")\n",
        "#     print(f\"Amount range: {final_df['amount'].min():.2f} to {final_df['amount'].max():.2f}\")\n",
        "#     print(f\"Raw amount range: {final_df['raw_amount'].min():.2f} to {final_df['raw_amount'].max():.2f}\")\n",
        "\n",
        "#     # Save to CSV\n",
        "#     final_df.to_csv('synthetic_transactions.csv', index=False)\n",
        "#     print(\"\\nFinal dataframe saved as 'synthetic_transactions.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dQaRThWPEAVq",
        "outputId": "84e3e5ee-1147-4729-d935-d4aa05f61569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Loading and preprocessing data...\n",
            "Creating optimized sequences from transaction data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4500/4500 [00:18<00:00, 239.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 13370 sequences from 4500 accounts.\n",
            "Model has 1,172,700 parameters.\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|██████████| 418/418 [00:05<00:00, 81.34it/s, Loss=3.2825, Cat=2.761, Num=0.521]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Avg Loss: 8.2235 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|██████████| 418/418 [00:05<00:00, 81.60it/s, Loss=1.0006, Cat=0.674, Num=0.327]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Avg Loss: 1.9041 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|██████████| 418/418 [00:05<00:00, 83.47it/s, Loss=0.5485, Cat=0.235, Num=0.314]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Avg Loss: 0.7900 - LR: 0.000199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|██████████| 418/418 [00:05<00:00, 81.97it/s, Loss=0.4876, Cat=0.161, Num=0.327]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Avg Loss: 0.5205 - LR: 0.000198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|██████████| 418/418 [00:05<00:00, 82.72it/s, Loss=0.4152, Cat=0.092, Num=0.324]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Avg Loss: 0.4084 - LR: 0.000197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|██████████| 418/418 [00:05<00:00, 82.94it/s, Loss=0.3334, Cat=0.061, Num=0.272]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Avg Loss: 0.3385 - LR: 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|██████████| 418/418 [00:05<00:00, 80.86it/s, Loss=0.2691, Cat=0.049, Num=0.220]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Avg Loss: 0.2967 - LR: 0.000193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|██████████| 418/418 [00:05<00:00, 81.76it/s, Loss=0.2372, Cat=0.041, Num=0.197]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Avg Loss: 0.2617 - LR: 0.000190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|██████████| 418/418 [00:05<00:00, 82.02it/s, Loss=0.2512, Cat=0.023, Num=0.228]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Avg Loss: 0.2387 - LR: 0.000188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|██████████| 418/418 [00:05<00:00, 81.73it/s, Loss=0.2298, Cat=0.023, Num=0.207]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Avg Loss: 0.2228 - LR: 0.000184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|██████████| 418/418 [00:05<00:00, 82.39it/s, Loss=0.2278, Cat=0.015, Num=0.213]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - Avg Loss: 0.2093 - LR: 0.000181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|██████████| 418/418 [00:05<00:00, 80.06it/s, Loss=0.1254, Cat=0.012, Num=0.113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - Avg Loss: 0.1975 - LR: 0.000177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|██████████| 418/418 [00:05<00:00, 82.72it/s, Loss=0.1468, Cat=0.013, Num=0.134]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 - Avg Loss: 0.1870 - LR: 0.000173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50: 100%|██████████| 418/418 [00:05<00:00, 82.74it/s, Loss=0.1772, Cat=0.010, Num=0.167]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 - Avg Loss: 0.1831 - LR: 0.000168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50: 100%|██████████| 418/418 [00:04<00:00, 84.48it/s, Loss=0.1589, Cat=0.009, Num=0.150]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 - Avg Loss: 0.1734 - LR: 0.000164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50: 100%|██████████| 418/418 [00:05<00:00, 82.72it/s, Loss=0.1459, Cat=0.011, Num=0.135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 - Avg Loss: 0.1666 - LR: 0.000159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50: 100%|██████████| 418/418 [00:05<00:00, 82.94it/s, Loss=0.2748, Cat=0.008, Num=0.267]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 - Avg Loss: 0.1662 - LR: 0.000154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50: 100%|██████████| 418/418 [00:05<00:00, 82.36it/s, Loss=0.1239, Cat=0.006, Num=0.118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 - Avg Loss: 0.1610 - LR: 0.000148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50: 100%|██████████| 418/418 [00:05<00:00, 83.27it/s, Loss=0.1607, Cat=0.005, Num=0.156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 - Avg Loss: 0.1538 - LR: 0.000143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50: 100%|██████████| 418/418 [00:05<00:00, 81.77it/s, Loss=0.1300, Cat=0.004, Num=0.126]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 - Avg Loss: 0.1524 - LR: 0.000137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50: 100%|██████████| 418/418 [00:04<00:00, 84.83it/s, Loss=0.1645, Cat=0.004, Num=0.160]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 - Avg Loss: 0.1459 - LR: 0.000131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50: 100%|██████████| 418/418 [00:04<00:00, 83.73it/s, Loss=0.1567, Cat=0.004, Num=0.153]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 - Avg Loss: 0.1458 - LR: 0.000125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50: 100%|██████████| 418/418 [00:05<00:00, 81.97it/s, Loss=0.1376, Cat=0.003, Num=0.135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 - Avg Loss: 0.1426 - LR: 0.000119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50: 100%|██████████| 418/418 [00:04<00:00, 84.97it/s, Loss=0.1319, Cat=0.003, Num=0.129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 - Avg Loss: 0.1418 - LR: 0.000113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50: 100%|██████████| 418/418 [00:05<00:00, 82.79it/s, Loss=0.1143, Cat=0.002, Num=0.112]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 - Avg Loss: 0.1418 - LR: 0.000106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50: 100%|██████████| 418/418 [00:04<00:00, 84.78it/s, Loss=0.1316, Cat=0.002, Num=0.129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 - Avg Loss: 0.1375 - LR: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50: 100%|██████████| 418/418 [00:04<00:00, 83.84it/s, Loss=0.1623, Cat=0.003, Num=0.160]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 - Avg Loss: 0.1331 - LR: 0.000094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50: 100%|██████████| 418/418 [00:04<00:00, 84.43it/s, Loss=0.0929, Cat=0.002, Num=0.091]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 - Avg Loss: 0.1326 - LR: 0.000087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50: 100%|██████████| 418/418 [00:04<00:00, 83.79it/s, Loss=0.1293, Cat=0.001, Num=0.128]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 - Avg Loss: 0.1346 - LR: 0.000081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50: 100%|██████████| 418/418 [00:05<00:00, 83.48it/s, Loss=0.1496, Cat=0.002, Num=0.148]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 - Avg Loss: 0.1302 - LR: 0.000075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|██████████| 418/418 [00:04<00:00, 83.96it/s, Loss=0.1016, Cat=0.002, Num=0.099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 - Avg Loss: 0.1286 - LR: 0.000069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50: 100%|██████████| 418/418 [00:05<00:00, 82.22it/s, Loss=0.1003, Cat=0.002, Num=0.099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 - Avg Loss: 0.1289 - LR: 0.000063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50: 100%|██████████| 418/418 [00:04<00:00, 84.08it/s, Loss=0.1610, Cat=0.001, Num=0.160]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 - Avg Loss: 0.1261 - LR: 0.000057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50: 100%|██████████| 418/418 [00:05<00:00, 82.52it/s, Loss=0.1373, Cat=0.001, Num=0.136]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 - Avg Loss: 0.1267 - LR: 0.000052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50: 100%|██████████| 418/418 [00:04<00:00, 83.98it/s, Loss=0.1736, Cat=0.001, Num=0.172]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 - Avg Loss: 0.1259 - LR: 0.000046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50: 100%|██████████| 418/418 [00:04<00:00, 83.93it/s, Loss=0.0831, Cat=0.001, Num=0.082]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 - Avg Loss: 0.1263 - LR: 0.000041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50: 100%|██████████| 418/418 [00:04<00:00, 83.71it/s, Loss=0.0840, Cat=0.001, Num=0.083]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 - Avg Loss: 0.1232 - LR: 0.000036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50: 100%|██████████| 418/418 [00:04<00:00, 84.09it/s, Loss=0.1324, Cat=0.001, Num=0.131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 - Avg Loss: 0.1239 - LR: 0.000032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|██████████| 418/418 [00:05<00:00, 81.41it/s, Loss=0.1331, Cat=0.001, Num=0.132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 - Avg Loss: 0.1236 - LR: 0.000027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|██████████| 418/418 [00:04<00:00, 84.04it/s, Loss=0.0939, Cat=0.002, Num=0.092]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 - Avg Loss: 0.1239 - LR: 0.000023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|██████████| 418/418 [00:05<00:00, 82.21it/s, Loss=0.1340, Cat=0.002, Num=0.132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 - Avg Loss: 0.1229 - LR: 0.000019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|██████████| 418/418 [00:05<00:00, 83.16it/s, Loss=0.1249, Cat=0.002, Num=0.123]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 - Avg Loss: 0.1228 - LR: 0.000016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|██████████| 418/418 [00:05<00:00, 83.01it/s, Loss=0.1009, Cat=0.009, Num=0.092]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 - Avg Loss: 0.1215 - LR: 0.000012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|██████████| 418/418 [00:05<00:00, 82.81it/s, Loss=0.1207, Cat=0.001, Num=0.119]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 - Avg Loss: 0.1231 - LR: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|██████████| 418/418 [00:05<00:00, 81.71it/s, Loss=0.1095, Cat=0.001, Num=0.108]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 - Avg Loss: 0.1216 - LR: 0.000007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|██████████| 418/418 [00:05<00:00, 81.74it/s, Loss=0.0873, Cat=0.001, Num=0.086]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 - Avg Loss: 0.1227 - LR: 0.000005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|██████████| 418/418 [00:05<00:00, 83.17it/s, Loss=0.1205, Cat=0.001, Num=0.119]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 - Avg Loss: 0.1209 - LR: 0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|██████████| 418/418 [00:05<00:00, 81.85it/s, Loss=0.1335, Cat=0.002, Num=0.132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 - Avg Loss: 0.1223 - LR: 0.000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|██████████| 418/418 [00:04<00:00, 84.21it/s, Loss=0.1359, Cat=0.001, Num=0.135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 - Avg Loss: 0.1241 - LR: 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|██████████| 418/418 [00:05<00:00, 81.44it/s, Loss=0.0937, Cat=0.001, Num=0.093]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 - Avg Loss: 0.1210 - LR: 0.000000\n",
            "Generating sample sequences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 500it [00:01, 363.97it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'seq_len' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-b56e37c131c4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;31m# Post-process to create realistic datetime sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m     generated_cat = create_realistic_datetime_sequences(\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0mgenerated_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_encoders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-38-b56e37c131c4>\u001b[0m in \u001b[0;36mcreate_realistic_datetime_sequences\u001b[0;34m(generated_cat, cat_attrs, label_encoders, sequence_length)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;31m# Initialize with random categorical indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0mx_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_cat_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mx_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seq_len' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Method LSTM"
      ],
      "metadata": {
        "id": "dld-S-00IL2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best model params:\n",
        "\n"
      ],
      "metadata": {
        "id": "-XCf9vb0o198"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model hyperparameters\n",
        "sequence_length = 300      # Reduced for efficiency\n",
        "min_seq_length = 100\n",
        "cat_emb_dim =  8          # Reduced for efficiency\n",
        "mlp_layers = [128, 128]   # Smaller layers\n",
        "activation = 'lrelu'\n",
        "diffusion_steps = 1000     # Reduced steps\n",
        "diffusion_beta_start = 1e-4\n",
        "diffusion_beta_end = 0.02\n",
        "scheduler = 'exp'\n",
        "epochs = 100               # Reduced epochs for testing\n",
        "batch_size = 128           # Smaller batch size\n",
        "learning_rate = 2e-4      # Slightly higher learning rate\n",
        "n_sequences = 20          # Fixed: was missing assignment operator"
      ],
      "metadata": {
        "id": "EWtrHnFSpHJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION\n",
        "# =============================================================================\n",
        "# Set seeds for reproducibility\n",
        "seed = 1234\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Model hyperparameters\n",
        "sequence_length = 300      # Reduced for efficiency\n",
        "min_seq_length = 100\n",
        "cat_emb_dim =  8          # Reduced for efficiency\n",
        "mlp_layers = [128, 128]   # Smaller layers\n",
        "activation = 'lrelu'\n",
        "diffusion_steps = 1000     # Reduced steps\n",
        "diffusion_beta_start = 1e-4\n",
        "diffusion_beta_end = 0.02\n",
        "scheduler = 'exp'\n",
        "epochs = 100               # Reduced epochs for testing\n",
        "batch_size = 128           # Smaller batch size\n",
        "learning_rate = 2e-4      # Slightly higher learning rate\n",
        "n_sequences = 20          # Fixed: was missing assignment operator\n",
        "\n",
        "# =============================================================================\n",
        "# STUDENT-T DISTRIBUTION DDPM DIFFUSER\n",
        "# =============================================================================\n",
        "class StudentTDDPMDiffuser(object):\n",
        "    def __init__(self, total_steps=1000, beta_start=1e-4, beta_end=0.02, device='cpu', scheduler='exp', df=10):\n",
        "        self.total_steps = total_steps\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.device = device\n",
        "        self.df = df\n",
        "\n",
        "        self.alphas, self.betas = self.prepare_noise_schedule(scheduler=scheduler)\n",
        "        self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "    def prepare_noise_schedule(self, scheduler: str):\n",
        "        scale = 1000 / self.total_steps\n",
        "        beta_start = scale * self.beta_start\n",
        "        beta_end = scale * self.beta_end\n",
        "\n",
        "        if scheduler == 'linear':\n",
        "            betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "            alphas = 1.0 - betas\n",
        "        elif scheduler == 'quad':\n",
        "            betas = torch.linspace(self.beta_start**0.5, self.beta_end**0.5, self.total_steps) ** 2\n",
        "            alphas = 1.0 - betas\n",
        "        elif scheduler == 'exp':\n",
        "            betas = torch.exp(torch.linspace(math.log(beta_start), math.log(beta_end), self.total_steps))\n",
        "            alphas = 1.0 - betas\n",
        "        elif scheduler == 'sigm':\n",
        "            x = torch.linspace(-6, 6, self.total_steps)\n",
        "            betas = torch.sigmoid(x) * (beta_end - beta_start) + beta_start\n",
        "            alphas = 1.0 - betas\n",
        "\n",
        "        return alphas.to(self.device), betas.to(self.device)\n",
        "\n",
        "    def sample_random_timesteps(self, n: int):\n",
        "        t = torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "        return t\n",
        "\n",
        "    def sample_student_t(self, shape):\n",
        "        if self.df <= 2:\n",
        "            df_sample = 3.0\n",
        "        else:\n",
        "            df_sample = float(self.df)\n",
        "\n",
        "        # Fix: Convert tensor shape to tuple if needed\n",
        "        if isinstance(shape, torch.Tensor):\n",
        "            shape = tuple(shape.tolist())\n",
        "\n",
        "        x = torch.randn(shape, device=self.device)\n",
        "\n",
        "        # Generate chi-squared samples using gamma distribution\n",
        "        gamma_shape = df_sample / 2.0\n",
        "        gamma_samples = torch.tensor(stats.gamma.rvs(gamma_shape, scale=2.0, size=shape[0]),\n",
        "                                     dtype=torch.float32,\n",
        "                                     device=self.device).view(-1, 1, 1)  # Fixed: Added extra dimension for broadcasting\n",
        "\n",
        "        scaling = torch.sqrt(torch.tensor(df_sample / (df_sample - 2.0), device=self.device)) if df_sample > 2 else torch.tensor(1.0, device=self.device)\n",
        "        t_noise = scaling * x / torch.sqrt(gamma_samples / df_sample)\n",
        "\n",
        "        return t_noise\n",
        "\n",
        "    def add_t_noise(self, x_num, t):\n",
        "        sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None, None]  # Fixed: Added extra None for sequence dimension\n",
        "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None, None]\n",
        "\n",
        "        noise_shape = x_num.shape\n",
        "        noise_num = self.sample_student_t(noise_shape)\n",
        "\n",
        "        x_noise_num = sqrt_alpha_hat * x_num + sqrt_one_minus_alpha_hat * noise_num\n",
        "        return x_noise_num, noise_num\n",
        "\n",
        "    def p_sample_t(self, model_out, z_norm, timesteps):\n",
        "        sqrt_alpha_t = torch.sqrt(self.alphas[timesteps])[:, None, None]  # Fixed: Added extra None\n",
        "        betas_t = self.betas[timesteps][:, None, None]\n",
        "        sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[timesteps])[:, None, None]\n",
        "        epsilon_t = torch.sqrt(self.betas[timesteps][:, None, None])\n",
        "\n",
        "        # Fixed: Use proper shape for t-distribution sampling\n",
        "        random_noise = self.sample_student_t(z_norm.shape)\n",
        "        random_noise[timesteps == 0] = 0.0\n",
        "\n",
        "        model_mean = ((1 / sqrt_alpha_t) * (z_norm - (betas_t * model_out / sqrt_one_minus_alpha_hat_t)))\n",
        "        z_norm = model_mean + (epsilon_t * random_noise)\n",
        "\n",
        "        return z_norm\n",
        "\n",
        "    def sample(self, model_out, z_norm, timesteps):\n",
        "        return self.p_sample_t(model_out, z_norm, timesteps)\n",
        "\n",
        "# =============================================================================\n",
        "# DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "def preprocess_data_czech(df):\n",
        "    \"\"\"Enhanced preprocessing with better error handling\"\"\"\n",
        "    czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "    df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "    df[\"month\"] = df[\"datetime\"].dt.month\n",
        "    df[\"day\"] = df[\"datetime\"].dt.day\n",
        "    df[\"dow\"] = df[\"datetime\"].dt.dayofweek\n",
        "    df[\"year\"] = df[\"datetime\"].dt.year\n",
        "    df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "    df_sorted = df.sort_values(['account_id', 'datetime']).copy()\n",
        "\n",
        "    df_sorted[\"td\"] = df_sorted.groupby(\"account_id\")[\"datetime\"].diff().dt.days\n",
        "    df_sorted[\"td\"].fillna(0.0, inplace=True)\n",
        "    df_sorted[\"dtme\"] = df_sorted.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "    df_sorted['raw_amount'] = df_sorted.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "    # Create transaction code\n",
        "    cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "    tcode = df_sorted[cat_code_fields[0]].astype(str)\n",
        "    for ccf in cat_code_fields[1:]:\n",
        "        tcode += \"__\" + df_sorted[ccf].astype(str)\n",
        "    df_sorted[\"tcode\"] = tcode\n",
        "\n",
        "    # Day of month categories\n",
        "    conditions = [\n",
        "        (df_sorted['day'] >= 1) & (df_sorted['day'] <= 10),\n",
        "        (df_sorted['day'] > 10) & (df_sorted['day'] <= 20),\n",
        "        (df_sorted['day'] > 20) & (df_sorted['day'] <= 31)\n",
        "    ]\n",
        "    categories = ['first', 'middle', 'last']\n",
        "    df_sorted['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "    # Age groups\n",
        "    if 'age' in df_sorted.columns:\n",
        "        bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "        labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "        df_sorted['age_group'] = pd.cut(df_sorted['age'], bins=bin_edges, labels=labels, right=False)\n",
        "        df_sorted['age_group'] = df_sorted['age_group'].astype('object').fillna('unknown')\n",
        "    else:\n",
        "        print(\"Warning: 'age' column not found. Creating placeholder.\")\n",
        "        df_sorted['age_group'] = 'unknown'\n",
        "\n",
        "    return df_sorted\n",
        "\n",
        "# =============================================================================\n",
        "# IMPROVED SEQUENTIAL DATASET\n",
        "# =============================================================================\n",
        "class OptimizedSequentialDataset(Dataset):\n",
        "    \"\"\"More efficient dataset that samples sequences strategically\"\"\"\n",
        "    def __init__(self, df, cat_attrs, num_attrs, sequence_length=30, min_seq_length=20, max_sequences_per_account=5):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.min_seq_length = min_seq_length\n",
        "        self.cat_attrs = cat_attrs\n",
        "        self.num_attrs = num_attrs\n",
        "        self.sequences = []\n",
        "\n",
        "        print(\"Creating optimized sequences from transaction data...\")\n",
        "\n",
        "        # Group by account and create limited sequences per account\n",
        "        for account_id in tqdm(df['account_id'].unique()):\n",
        "            account_data = df[df['account_id'] == account_id].sort_values('datetime').reset_index(drop=True)\n",
        "            if len(account_data) >= min_seq_length:\n",
        "                # Sample sequences strategically instead of all overlapping windows\n",
        "                n_possible = len(account_data) - sequence_length + 1\n",
        "                if n_possible <= max_sequences_per_account:\n",
        "                    # Use all if few sequences possible\n",
        "                    start_indices = range(n_possible)\n",
        "                else:\n",
        "                    # Sample evenly spaced sequences\n",
        "                    start_indices = np.linspace(0, n_possible-1, max_sequences_per_account, dtype=int)\n",
        "\n",
        "                for start_idx in start_indices:\n",
        "                    seq_data = account_data.iloc[start_idx:start_idx+sequence_length]\n",
        "                    cat_data = seq_data[self.cat_attrs].values\n",
        "                    num_data = seq_data[self.num_attrs].values\n",
        "                    self.sequences.append({'cat_data': cat_data, 'num_data': num_data})\n",
        "\n",
        "        print(f\"Created {len(self.sequences)} sequences from {df['account_id'].nunique()} accounts.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        cat_tensor = torch.LongTensor(seq['cat_data'])\n",
        "        num_tensor = torch.FloatTensor(seq['num_data'])\n",
        "        return cat_tensor, num_tensor\n",
        "\n",
        "# =============================================================================\n",
        "# IMPROVED LSTM SYNTHESIZER\n",
        "# =============================================================================\n",
        "class ImprovedLSTMSynthesizer(nn.Module):\n",
        "    \"\"\"Fixed model that properly handles the training/generation process\"\"\"\n",
        "    def __init__(self, n_cat_features, n_cat_tokens, cat_emb_dim, n_num_features,\n",
        "                 hidden_dim=256, lstm_layers=2, dim_t=64):\n",
        "        super(ImprovedLSTMSynthesizer, self).__init__()\n",
        "        self.n_cat_features = n_cat_features\n",
        "        self.n_num_features = n_num_features\n",
        "        self.cat_emb_dim = cat_emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dim_t = dim_t\n",
        "\n",
        "        # Categorical embeddings\n",
        "        self.cat_embeddings = nn.ModuleList([\n",
        "            nn.Embedding(n_cat_tokens[i], cat_emb_dim) for i in range(n_cat_features)\n",
        "        ])\n",
        "\n",
        "        total_cat_emb_dim = n_cat_features * cat_emb_dim\n",
        "        total_input_dim = total_cat_emb_dim + n_num_features\n",
        "\n",
        "        # Time embedding\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(dim_t, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        # Input projection\n",
        "        self.input_projection = nn.Linear(total_input_dim, hidden_dim)\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=0.1 if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Separate heads for categorical and numerical outputs\n",
        "        self.cat_heads = nn.ModuleList([\n",
        "            nn.Linear(hidden_dim, n_cat_tokens[i]) for i in range(n_cat_features)\n",
        "        ])\n",
        "        self.num_head = nn.Linear(hidden_dim, n_num_features)\n",
        "\n",
        "    def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "        half = dim_out // 2\n",
        "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half).to(device)\n",
        "        args = timesteps[:, None].float() * freqs[None]\n",
        "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "        if dim_out % 2:\n",
        "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "        return embedding\n",
        "\n",
        "    def embed_categorical(self, x_cat):\n",
        "        \"\"\"Embed categorical features\"\"\"\n",
        "        embeddings = []\n",
        "        for i in range(self.n_cat_features):\n",
        "            embeddings.append(self.cat_embeddings[i](x_cat[:, :, i]))\n",
        "        return torch.cat(embeddings, dim=-1)\n",
        "\n",
        "    def forward(self, x_cat, x_num, timesteps):\n",
        "        \"\"\"Forward pass for training\"\"\"\n",
        "        batch_size, seq_len, _ = x_num.shape\n",
        "\n",
        "        # Embed categorical features\n",
        "        cat_emb = self.embed_categorical(x_cat)\n",
        "\n",
        "        # Combine with numerical features\n",
        "        x = torch.cat([cat_emb, x_num], dim=-1)\n",
        "\n",
        "        # Project input\n",
        "        x_proj = self.input_projection(x)\n",
        "\n",
        "        # Time embedding\n",
        "        time_emb_raw = self.embed_time(timesteps, self.dim_t)\n",
        "        time_emb = self.time_embed(time_emb_raw)\n",
        "        time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "        # Add time embedding\n",
        "        x_with_time = x_proj + time_emb\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x_with_time)\n",
        "\n",
        "        # Separate outputs\n",
        "        cat_outputs = [head(lstm_out) for head in self.cat_heads]\n",
        "        num_output = self.num_head(lstm_out)\n",
        "\n",
        "        return cat_outputs, num_output\n",
        "\n",
        "# =============================================================================\n",
        "# TRAINING LOOP\n",
        "# =============================================================================\n",
        "\n",
        "losses=[]\n",
        "\n",
        "def train_model(model, diffuser, dataloader, epochs, optimizer, scheduler):\n",
        "    \"\"\"Improved training loop with Student-t diffusion\"\"\"\n",
        "    model.train()\n",
        "    cat_criterion = nn.CrossEntropyLoss()\n",
        "    num_criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for batch_cat, batch_num in pbar:\n",
        "            batch_cat, batch_num = batch_cat.to(device), batch_num.to(device)\n",
        "            batch_size = batch_cat.shape[0]\n",
        "\n",
        "            # Sample timesteps\n",
        "            timesteps = diffuser.sample_random_timesteps(batch_size)\n",
        "\n",
        "            # Add Student-t noise to numerical features\n",
        "            noisy_num, noise_target = diffuser.add_t_noise(batch_num, timesteps)\n",
        "\n",
        "            # Forward pass\n",
        "            cat_outputs, num_output = model(batch_cat, noisy_num, timesteps)\n",
        "\n",
        "            # Calculate losses\n",
        "            cat_loss = 0\n",
        "            for i, cat_out in enumerate(cat_outputs):\n",
        "                cat_loss += cat_criterion(cat_out.view(-1, cat_out.size(-1)),\n",
        "                                        batch_cat[:, :, i].view(-1))\n",
        "\n",
        "            num_loss = num_criterion(num_output, noise_target)\n",
        "\n",
        "            total_loss = cat_loss + num_loss\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += total_loss.item()\n",
        "            pbar.set_postfix({\n",
        "                'Loss': f\"{total_loss.item():.4f}\",\n",
        "                'Cat': f\"{cat_loss.item():.3f}\",\n",
        "                'Num': f\"{num_loss.item():.3f}\"\n",
        "            })\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        losses.append(avg_loss)\n",
        "        print(f\"Epoch {epoch+1} - Avg Loss: {avg_loss:.4f} - LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "        scheduler.step()\n",
        "\n",
        "# =============================================================================\n",
        "# GENERATION FUNCTION\n",
        "# =============================================================================\n",
        "def generate_sequences(model, diffuser, n_sequences, seq_len, n_cat_features,\n",
        "                      n_cat_tokens, n_num_features, device):\n",
        "    \"\"\"Generate new sequences using Student-t diffusion\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize with random categorical indices\n",
        "    x_cat = torch.zeros(n_sequences, seq_len, n_cat_features, dtype=torch.long, device=device)\n",
        "    for i, n_tokens in enumerate(n_cat_tokens):\n",
        "        x_cat[:, :, i] = torch.randint(0, n_tokens, (n_sequences, seq_len), device=device)\n",
        "\n",
        "    # Start with Student-t noise for numerical features\n",
        "    x_num = diffuser.sample_student_t((n_sequences, seq_len, n_num_features))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for t in tqdm(reversed(range(diffuser.total_steps)), desc=\"Generating\"):\n",
        "            timesteps = torch.full((n_sequences,), t, device=device, dtype=torch.long)\n",
        "\n",
        "            # Model prediction\n",
        "            cat_outputs, num_output = model(x_cat, x_num, timesteps)\n",
        "\n",
        "            # Update numerical features through Student-t diffusion\n",
        "            x_num = diffuser.sample(num_output, x_num, timesteps)\n",
        "\n",
        "            # Update categorical features by sampling from logits\n",
        "            if t % 50 == 0:  # Update less frequently for stability\n",
        "                for i, cat_out in enumerate(cat_outputs):\n",
        "                    probs = torch.softmax(cat_out, dim=-1)\n",
        "                    x_cat[:, :, i] = torch.multinomial(probs.view(-1, probs.size(-1)), 1).view(n_sequences, seq_len)\n",
        "\n",
        "    return x_cat, x_num\n",
        "\n",
        "def create_realistic_datetime_sequences(generated_cat, cat_attrs, label_encoders, sequence_length):\n",
        "    \"\"\"Create more realistic datetime sequences based on temporal patterns\"\"\"\n",
        "    # Find indices for day, month, year in categorical features\n",
        "    day_idx = cat_attrs.index('day') if 'day' in cat_attrs else None\n",
        "    month_idx = cat_attrs.index('month') if 'month' in cat_attrs else None\n",
        "    year_idx = cat_attrs.index('year') if 'year' in cat_attrs else None\n",
        "\n",
        "    if any(idx is None for idx in [day_idx, month_idx, year_idx]):\n",
        "        return generated_cat  # Return as-is if missing components\n",
        "\n",
        "    # Create more realistic sequences\n",
        "    for seq_idx in range(generated_cat.shape[0]):\n",
        "        # Start with a random realistic date\n",
        "        start_year = np.random.choice([1993, 1994, 1995, 1996, 1997])\n",
        "        start_month = np.random.randint(1, 13)\n",
        "        start_day = np.random.randint(1, 29)  # Safe day range\n",
        "\n",
        "        current_date = datetime(start_year, start_month, start_day)\n",
        "\n",
        "        for step in range(sequence_length):\n",
        "            # Add realistic time progression (1-30 days between transactions)\n",
        "            if step > 0:\n",
        "                days_increment = np.random.randint(1, 31)\n",
        "                current_date += pd.Timedelta(days=days_increment)\n",
        "\n",
        "            # Encode the date components\n",
        "            year_encoded = np.where(label_encoders['year'].classes_ == str(current_date.year))[0]\n",
        "            month_encoded = np.where(label_encoders['month'].classes_ == str(current_date.month))[0]\n",
        "            day_encoded = np.where(label_encoders['day'].classes_ == str(current_date.day))[0]\n",
        "\n",
        "            # Set encoded values (with fallback if not found)\n",
        "            if len(year_encoded) > 0:\n",
        "                generated_cat[seq_idx, step, year_idx] = year_encoded[0]\n",
        "            if len(month_encoded) > 0:\n",
        "                generated_cat[seq_idx, step, month_idx] = month_encoded[0]\n",
        "            if len(day_encoded) > 0:\n",
        "                generated_cat[seq_idx, step, day_idx] = day_encoded[0]\n",
        "\n",
        "    return generated_cat\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN EXECUTION\n",
        "# =============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    try:\n",
        "        real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: CSV file not found. Please ensure 'tr_by_acct_w_age.csv' is in the directory.\")\n",
        "        exit()\n",
        "\n",
        "    raw_data = preprocess_data_czech(real)\n",
        "    raw_data = raw_data.sort_values(by=[\"account_id\", \"date\"])\n",
        "\n",
        "    # Define features and encode\n",
        "    cat_attrs = ['tcode', 'dow', 'month', 'day', 'year', 'DoM_cat', 'age_group']\n",
        "    num_attrs = ['amount', 'raw_amount', 'td']\n",
        "\n",
        "    df_processed = raw_data[cat_attrs + num_attrs + ['account_id', 'datetime']].copy()\n",
        "\n",
        "    # Encode categorical features\n",
        "    label_encoders = {}\n",
        "    n_cat_tokens = []\n",
        "    for attr in cat_attrs:\n",
        "        le = LabelEncoder()\n",
        "        df_processed[attr] = le.fit_transform(df_processed[attr].astype(str))\n",
        "        label_encoders[attr] = le\n",
        "        n_cat_tokens.append(len(le.classes_))\n",
        "\n",
        "    # Scale numerical features\n",
        "    num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "    df_processed[num_attrs] = num_scaler.fit_transform(df_processed[num_attrs])\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = OptimizedSequentialDataset(\n",
        "        df_processed, cat_attrs, num_attrs,\n",
        "        sequence_length, min_seq_length, max_sequences_per_account=3\n",
        "    )\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    # Initialize model with Student-t diffuser\n",
        "    model = ImprovedLSTMSynthesizer(\n",
        "        n_cat_features=len(cat_attrs),\n",
        "        n_cat_tokens=n_cat_tokens,\n",
        "        cat_emb_dim=cat_emb_dim,\n",
        "        n_num_features=len(num_attrs),\n",
        "        hidden_dim=mlp_layers[0]\n",
        "    ).to(device)\n",
        "\n",
        "    # Use Student-t diffuser instead of simplified diffuser\n",
        "    diffuser = StudentTDDPMDiffuser(\n",
        "        total_steps=diffusion_steps,\n",
        "        beta_start=diffusion_beta_start,\n",
        "        beta_end=diffusion_beta_end,\n",
        "        device=device,\n",
        "        scheduler=scheduler,\n",
        "        df=10  # degrees of freedom for t-distribution\n",
        "    )\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters.\")\n",
        "\n",
        "    # Train model\n",
        "    print(\"Starting training...\")\n",
        "    train_model(model, diffuser, dataloader, epochs, optimizer, scheduler)\n",
        "\n",
        "    # Generate samples\n",
        "    print(\"Generating sample sequences...\")\n",
        "    generated_cat, generated_num = generate_sequences(\n",
        "        model, diffuser, n_sequences=n_sequences, seq_len=sequence_length,\n",
        "        n_cat_features=len(cat_attrs), n_cat_tokens=n_cat_tokens,\n",
        "        n_num_features=len(num_attrs), device=device\n",
        "    )\n",
        "\n",
        "    # Post-process to create realistic datetime sequences\n",
        "    generated_cat = create_realistic_datetime_sequences(\n",
        "        generated_cat, cat_attrs, label_encoders, sequence_length\n",
        "    )\n",
        "\n",
        "    # Create final dataframe with all generated sequences\n",
        "    final_sequences = []\n",
        "\n",
        "    for seq_idx in range(generated_cat.shape[0]):\n",
        "        # Inverse transform numerical data\n",
        "        seq_num = generated_num[seq_idx].cpu().numpy()\n",
        "        seq_num_original = num_scaler.inverse_transform(seq_num)\n",
        "\n",
        "        # Inverse transform categorical data\n",
        "        seq_cat = generated_cat[seq_idx].cpu().numpy()\n",
        "\n",
        "        # Create sequence dataframe\n",
        "        seq_df = pd.DataFrame()\n",
        "\n",
        "        # Add numerical features\n",
        "        for i, col in enumerate(num_attrs):\n",
        "            seq_df[col] = seq_num_original[:, i]\n",
        "\n",
        "        # Add categorical features (inverse transformed)\n",
        "        for i, col in enumerate(cat_attrs):\n",
        "            if col in label_encoders:\n",
        "                seq_df[col] = label_encoders[col].inverse_transform(seq_cat[:, i])\n",
        "            else:\n",
        "                seq_df[col] = seq_cat[:, i]\n",
        "\n",
        "        # Create datetime from day, month, year\n",
        "        seq_df['datetime'] = pd.to_datetime({\n",
        "            'year': seq_df['year'].astype(int),\n",
        "            'month': seq_df['month'].astype(int),\n",
        "            'day': seq_df['day'].astype(int)\n",
        "        }, errors='coerce')\n",
        "\n",
        "        # Add sequence identifier\n",
        "        seq_df['account_id'] = seq_idx\n",
        "        seq_df['transaction_order'] = range(len(seq_df))\n",
        "\n",
        "        final_sequences.append(seq_df)\n",
        "\n",
        "    # Combine all sequences\n",
        "    all_sequences_df = pd.concat(final_sequences, ignore_index=True)\n",
        "\n",
        "    # Create final dataframe with only requested columns\n",
        "    final_df = all_sequences_df[['account_id','raw_amount', 'amount', 'td', 'tcode', 'datetime']].copy()\n",
        "\n",
        "    # Clean up any invalid dates\n",
        "    final_df = final_df.dropna(subset=['datetime'])\n",
        "\n",
        "    print(\"\\nFinal dataframe created!\")\n",
        "    print(f\"Shape: {final_df.shape}\")\n",
        "    print(\"\\nColumn info:\")\n",
        "    print(final_df.dtypes)\n",
        "\n",
        "    print(\"\\nSample of final_df:\")\n",
        "    print(final_df.head(15))\n",
        "\n",
        "    print(f\"\\nUnique tcodes: {final_df['tcode'].nunique()}\")\n",
        "    print(f\"Date range: {final_df['datetime'].min()} to {final_df['datetime'].max()}\")\n",
        "    print(f\"Amount range: {final_df['amount'].min():.2f} to {final_df['amount'].max():.2f}\")\n",
        "    print(f\"Raw amount range: {final_df['raw_amount'].min():.2f} to {final_df['raw_amount'].max():.2f}\")\n",
        "\n",
        "    final_df = final_df.dropna(subset=['datetime'])\n",
        "\n",
        "    # FIXED: Convert the datetime column to just the date part\n",
        "    # final_df[\"td\"] = final_df.groupby(\"account_id\")[\"datetime\"].diff().dt.days\n",
        "    # final_df[\"td\"].fillna(0.0, inplace=True)\n",
        "\n",
        "    final_df['datetime'] = final_df['datetime'].dt.date\n",
        "\n",
        "\n",
        "    # Save to CSV\n",
        "    final_df.to_csv('synthetic_transactions.csv', index=False)\n",
        "    print(\"\\nFinal dataframe saved as 'synthetic_transactions.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IySKqF1JBQG",
        "outputId": "31d946d0-9404-46bd-daab-0ec905616676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Loading and preprocessing data...\n",
            "Creating optimized sequences from transaction data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4500/4500 [00:11<00:00, 408.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 4208 sequences from 4500 accounts.\n",
            "Model has 308,188 parameters.\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 33/33 [00:01<00:00, 18.37it/s, Loss=15.7144, Cat=14.231, Num=1.483]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Avg Loss: 16.4522 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100: 100%|██████████| 33/33 [00:01<00:00, 19.27it/s, Loss=13.8330, Cat=12.363, Num=1.470]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Avg Loss: 14.7691 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100: 100%|██████████| 33/33 [00:01<00:00, 19.18it/s, Loss=12.7400, Cat=11.204, Num=1.536]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Avg Loss: 13.2713 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100: 100%|██████████| 33/33 [00:01<00:00, 18.96it/s, Loss=11.9195, Cat=10.264, Num=1.656]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Avg Loss: 12.2509 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100: 100%|██████████| 33/33 [00:01<00:00, 18.88it/s, Loss=10.9425, Cat=9.376, Num=1.566]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Avg Loss: 11.3244 - LR: 0.000199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100: 100%|██████████| 33/33 [00:01<00:00, 17.09it/s, Loss=9.9668, Cat=8.390, Num=1.577]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Avg Loss: 10.3930 - LR: 0.000199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100: 100%|██████████| 33/33 [00:02<00:00, 12.60it/s, Loss=9.1495, Cat=7.598, Num=1.551]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Avg Loss: 9.5422 - LR: 0.000198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100: 100%|██████████| 33/33 [00:01<00:00, 16.53it/s, Loss=8.4081, Cat=7.069, Num=1.339]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Avg Loss: 8.7807 - LR: 0.000198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100: 100%|██████████| 33/33 [00:01<00:00, 16.65it/s, Loss=7.8205, Cat=6.434, Num=1.387]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Avg Loss: 8.1761 - LR: 0.000197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100: 100%|██████████| 33/33 [00:01<00:00, 18.07it/s, Loss=7.2693, Cat=5.930, Num=1.340]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Avg Loss: 7.6072 - LR: 0.000196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100: 100%|██████████| 33/33 [00:01<00:00, 18.71it/s, Loss=6.9350, Cat=5.583, Num=1.352]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - Avg Loss: 7.0928 - LR: 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100: 100%|██████████| 33/33 [00:01<00:00, 18.88it/s, Loss=6.3235, Cat=5.180, Num=1.143]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - Avg Loss: 6.5797 - LR: 0.000194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/100: 100%|██████████| 33/33 [00:01<00:00, 18.82it/s, Loss=5.9128, Cat=4.788, Num=1.125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 - Avg Loss: 6.0581 - LR: 0.000193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/100: 100%|██████████| 33/33 [00:01<00:00, 19.01it/s, Loss=5.3545, Cat=4.406, Num=0.949]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 - Avg Loss: 5.5902 - LR: 0.000192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/100: 100%|██████████| 33/33 [00:01<00:00, 19.25it/s, Loss=5.0343, Cat=4.126, Num=0.909]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 - Avg Loss: 5.2022 - LR: 0.000190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/100: 100%|██████████| 33/33 [00:01<00:00, 19.31it/s, Loss=4.6583, Cat=3.800, Num=0.858]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 - Avg Loss: 4.8442 - LR: 0.000189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/100: 100%|██████████| 33/33 [00:01<00:00, 19.22it/s, Loss=4.4188, Cat=3.560, Num=0.858]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 - Avg Loss: 4.5383 - LR: 0.000188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/100: 100%|██████████| 33/33 [00:01<00:00, 19.32it/s, Loss=4.0988, Cat=3.283, Num=0.815]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 - Avg Loss: 4.2763 - LR: 0.000186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/100: 100%|██████████| 33/33 [00:01<00:00, 19.33it/s, Loss=4.0490, Cat=3.131, Num=0.918]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 - Avg Loss: 4.0486 - LR: 0.000184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/100: 100%|██████████| 33/33 [00:01<00:00, 19.40it/s, Loss=3.8323, Cat=2.994, Num=0.838]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 - Avg Loss: 3.8158 - LR: 0.000183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/100: 100%|██████████| 33/33 [00:01<00:00, 19.48it/s, Loss=3.5645, Cat=2.762, Num=0.803]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 - Avg Loss: 3.6380 - LR: 0.000181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/100: 100%|██████████| 33/33 [00:01<00:00, 19.66it/s, Loss=3.3997, Cat=2.557, Num=0.842]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 - Avg Loss: 3.4510 - LR: 0.000179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/100: 100%|██████████| 33/33 [00:01<00:00, 19.77it/s, Loss=3.1273, Cat=2.409, Num=0.719]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 - Avg Loss: 3.2787 - LR: 0.000177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/100: 100%|██████████| 33/33 [00:01<00:00, 19.74it/s, Loss=3.0488, Cat=2.372, Num=0.677]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 - Avg Loss: 3.1207 - LR: 0.000175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/100: 100%|██████████| 33/33 [00:01<00:00, 19.66it/s, Loss=2.8680, Cat=2.152, Num=0.716]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 - Avg Loss: 2.9699 - LR: 0.000173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/100: 100%|██████████| 33/33 [00:01<00:00, 19.61it/s, Loss=2.7691, Cat=2.094, Num=0.675]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 - Avg Loss: 2.8294 - LR: 0.000171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/100: 100%|██████████| 33/33 [00:01<00:00, 19.78it/s, Loss=2.5430, Cat=1.917, Num=0.626]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 - Avg Loss: 2.6980 - LR: 0.000168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/100: 100%|██████████| 33/33 [00:01<00:00, 19.67it/s, Loss=2.5462, Cat=1.805, Num=0.741]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 - Avg Loss: 2.5798 - LR: 0.000166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/100: 100%|██████████| 33/33 [00:01<00:00, 19.79it/s, Loss=2.4191, Cat=1.722, Num=0.697]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 - Avg Loss: 2.4498 - LR: 0.000164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/100: 100%|██████████| 33/33 [00:01<00:00, 19.90it/s, Loss=2.2230, Cat=1.569, Num=0.654]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 - Avg Loss: 2.3514 - LR: 0.000161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/100: 100%|██████████| 33/33 [00:01<00:00, 19.77it/s, Loss=2.2648, Cat=1.546, Num=0.719]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 - Avg Loss: 2.2604 - LR: 0.000159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/100: 100%|██████████| 33/33 [00:01<00:00, 19.80it/s, Loss=2.1574, Cat=1.449, Num=0.708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 - Avg Loss: 2.1656 - LR: 0.000156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/100: 100%|██████████| 33/33 [00:01<00:00, 19.88it/s, Loss=2.1030, Cat=1.407, Num=0.696]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 - Avg Loss: 2.0806 - LR: 0.000154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/100: 100%|██████████| 33/33 [00:01<00:00, 19.74it/s, Loss=1.9197, Cat=1.308, Num=0.612]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 - Avg Loss: 2.0021 - LR: 0.000151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/100: 100%|██████████| 33/33 [00:01<00:00, 19.87it/s, Loss=1.8663, Cat=1.253, Num=0.613]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 - Avg Loss: 1.9573 - LR: 0.000148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/100: 100%|██████████| 33/33 [00:01<00:00, 19.75it/s, Loss=1.8008, Cat=1.159, Num=0.642]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 - Avg Loss: 1.8728 - LR: 0.000145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/100: 100%|██████████| 33/33 [00:01<00:00, 19.80it/s, Loss=1.7311, Cat=1.109, Num=0.623]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 - Avg Loss: 1.8028 - LR: 0.000143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/100: 100%|██████████| 33/33 [00:01<00:00, 19.77it/s, Loss=1.6771, Cat=1.048, Num=0.629]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 - Avg Loss: 1.7387 - LR: 0.000140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/100: 100%|██████████| 33/33 [00:01<00:00, 19.74it/s, Loss=1.6590, Cat=1.025, Num=0.634]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 - Avg Loss: 1.6939 - LR: 0.000137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/100: 100%|██████████| 33/33 [00:01<00:00, 19.68it/s, Loss=1.6070, Cat=1.019, Num=0.588]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 - Avg Loss: 1.6610 - LR: 0.000134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/100: 100%|██████████| 33/33 [00:01<00:00, 19.78it/s, Loss=1.5024, Cat=0.954, Num=0.549]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 - Avg Loss: 1.5951 - LR: 0.000131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/100: 100%|██████████| 33/33 [00:01<00:00, 19.72it/s, Loss=1.5293, Cat=0.927, Num=0.602]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 - Avg Loss: 1.5675 - LR: 0.000128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/100: 100%|██████████| 33/33 [00:01<00:00, 19.83it/s, Loss=1.4523, Cat=0.907, Num=0.546]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 - Avg Loss: 1.5103 - LR: 0.000125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/100: 100%|██████████| 33/33 [00:01<00:00, 19.73it/s, Loss=1.3301, Cat=0.837, Num=0.493]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 - Avg Loss: 1.4840 - LR: 0.000122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/100: 100%|██████████| 33/33 [00:01<00:00, 19.66it/s, Loss=1.4399, Cat=0.791, Num=0.649]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 - Avg Loss: 1.4509 - LR: 0.000119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/100: 100%|██████████| 33/33 [00:01<00:00, 19.60it/s, Loss=1.4723, Cat=0.797, Num=0.675]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 - Avg Loss: 1.4065 - LR: 0.000116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/100: 100%|██████████| 33/33 [00:01<00:00, 19.61it/s, Loss=1.3210, Cat=0.761, Num=0.560]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 - Avg Loss: 1.3558 - LR: 0.000113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/100: 100%|██████████| 33/33 [00:01<00:00, 19.51it/s, Loss=1.3468, Cat=0.735, Num=0.612]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 - Avg Loss: 1.3547 - LR: 0.000109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/100: 100%|██████████| 33/33 [00:01<00:00, 19.42it/s, Loss=1.3763, Cat=0.723, Num=0.654]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 - Avg Loss: 1.3367 - LR: 0.000106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/100: 100%|██████████| 33/33 [00:01<00:00, 19.66it/s, Loss=1.3012, Cat=0.706, Num=0.595]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 - Avg Loss: 1.2892 - LR: 0.000103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51/100: 100%|██████████| 33/33 [00:01<00:00, 19.48it/s, Loss=1.2760, Cat=0.683, Num=0.593]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51 - Avg Loss: 1.2814 - LR: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52/100: 100%|██████████| 33/33 [00:01<00:00, 19.46it/s, Loss=1.1900, Cat=0.642, Num=0.548]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 - Avg Loss: 1.2664 - LR: 0.000097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53/100: 100%|██████████| 33/33 [00:01<00:00, 19.44it/s, Loss=1.1984, Cat=0.652, Num=0.546]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53 - Avg Loss: 1.2277 - LR: 0.000094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54/100: 100%|██████████| 33/33 [00:01<00:00, 19.28it/s, Loss=1.1591, Cat=0.616, Num=0.543]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54 - Avg Loss: 1.1907 - LR: 0.000091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55/100: 100%|██████████| 33/33 [00:01<00:00, 19.46it/s, Loss=1.1101, Cat=0.604, Num=0.506]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55 - Avg Loss: 1.1784 - LR: 0.000087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56/100: 100%|██████████| 33/33 [00:01<00:00, 19.40it/s, Loss=1.1333, Cat=0.608, Num=0.525]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 - Avg Loss: 1.1538 - LR: 0.000084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57/100: 100%|██████████| 33/33 [00:01<00:00, 19.58it/s, Loss=1.0821, Cat=0.571, Num=0.511]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57 - Avg Loss: 1.1530 - LR: 0.000081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58/100: 100%|██████████| 33/33 [00:01<00:00, 19.44it/s, Loss=1.2043, Cat=0.579, Num=0.625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58 - Avg Loss: 1.1352 - LR: 0.000078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59/100: 100%|██████████| 33/33 [00:01<00:00, 19.31it/s, Loss=1.1782, Cat=0.525, Num=0.653]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59 - Avg Loss: 1.1327 - LR: 0.000075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60/100: 100%|██████████| 33/33 [00:01<00:00, 19.31it/s, Loss=1.0885, Cat=0.531, Num=0.557]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60 - Avg Loss: 1.0986 - LR: 0.000072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 61/100: 100%|██████████| 33/33 [00:01<00:00, 19.48it/s, Loss=1.0391, Cat=0.538, Num=0.501]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61 - Avg Loss: 1.0902 - LR: 0.000069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 62/100: 100%|██████████| 33/33 [00:01<00:00, 19.41it/s, Loss=1.1125, Cat=0.531, Num=0.582]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62 - Avg Loss: 1.0778 - LR: 0.000066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 63/100: 100%|██████████| 33/33 [00:01<00:00, 19.40it/s, Loss=1.0857, Cat=0.502, Num=0.584]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 - Avg Loss: 1.0691 - LR: 0.000063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 64/100: 100%|██████████| 33/33 [00:01<00:00, 19.41it/s, Loss=1.0807, Cat=0.523, Num=0.558]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64 - Avg Loss: 1.0498 - LR: 0.000060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 65/100: 100%|██████████| 33/33 [00:01<00:00, 19.54it/s, Loss=1.1267, Cat=0.505, Num=0.622]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65 - Avg Loss: 1.0583 - LR: 0.000057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 66/100: 100%|██████████| 33/33 [00:01<00:00, 19.30it/s, Loss=1.0016, Cat=0.497, Num=0.505]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66 - Avg Loss: 1.0473 - LR: 0.000055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 67/100: 100%|██████████| 33/33 [00:01<00:00, 19.27it/s, Loss=0.9854, Cat=0.461, Num=0.524]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67 - Avg Loss: 1.0360 - LR: 0.000052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 68/100: 100%|██████████| 33/33 [00:01<00:00, 19.45it/s, Loss=1.0262, Cat=0.479, Num=0.547]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68 - Avg Loss: 1.0292 - LR: 0.000049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 69/100: 100%|██████████| 33/33 [00:01<00:00, 19.49it/s, Loss=0.9405, Cat=0.455, Num=0.485]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69 - Avg Loss: 1.0201 - LR: 0.000046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 70/100: 100%|██████████| 33/33 [00:01<00:00, 19.45it/s, Loss=0.9736, Cat=0.449, Num=0.524]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 - Avg Loss: 1.0182 - LR: 0.000044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 71/100: 100%|██████████| 33/33 [00:01<00:00, 19.52it/s, Loss=0.9795, Cat=0.449, Num=0.530]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71 - Avg Loss: 1.0022 - LR: 0.000041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72/100: 100%|██████████| 33/33 [00:01<00:00, 19.55it/s, Loss=1.0464, Cat=0.469, Num=0.577]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72 - Avg Loss: 0.9968 - LR: 0.000039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73/100: 100%|██████████| 33/33 [00:01<00:00, 19.41it/s, Loss=0.9875, Cat=0.471, Num=0.516]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73 - Avg Loss: 0.9817 - LR: 0.000036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74/100: 100%|██████████| 33/33 [00:01<00:00, 19.35it/s, Loss=0.9184, Cat=0.427, Num=0.491]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74 - Avg Loss: 0.9781 - LR: 0.000034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75/100: 100%|██████████| 33/33 [00:01<00:00, 19.55it/s, Loss=1.0227, Cat=0.441, Num=0.581]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75 - Avg Loss: 0.9854 - LR: 0.000032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76/100: 100%|██████████| 33/33 [00:01<00:00, 19.61it/s, Loss=0.9641, Cat=0.448, Num=0.516]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76 - Avg Loss: 0.9808 - LR: 0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 77/100: 100%|██████████| 33/33 [00:01<00:00, 19.46it/s, Loss=0.9040, Cat=0.400, Num=0.504]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 - Avg Loss: 0.9866 - LR: 0.000027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 78/100: 100%|██████████| 33/33 [00:01<00:00, 19.49it/s, Loss=0.9683, Cat=0.430, Num=0.539]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78 - Avg Loss: 0.9639 - LR: 0.000025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 79/100: 100%|██████████| 33/33 [00:01<00:00, 19.58it/s, Loss=0.9689, Cat=0.420, Num=0.549]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79 - Avg Loss: 0.9595 - LR: 0.000023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 80/100: 100%|██████████| 33/33 [00:01<00:00, 19.41it/s, Loss=0.9715, Cat=0.441, Num=0.530]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80 - Avg Loss: 0.9512 - LR: 0.000021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 81/100: 100%|██████████| 33/33 [00:01<00:00, 19.44it/s, Loss=0.9682, Cat=0.430, Num=0.538]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81 - Avg Loss: 0.9606 - LR: 0.000019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 82/100: 100%|██████████| 33/33 [00:01<00:00, 19.64it/s, Loss=0.9227, Cat=0.413, Num=0.509]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82 - Avg Loss: 0.9573 - LR: 0.000017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 83/100: 100%|██████████| 33/33 [00:01<00:00, 19.65it/s, Loss=0.8817, Cat=0.411, Num=0.470]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83 - Avg Loss: 0.9627 - LR: 0.000016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 84/100: 100%|██████████| 33/33 [00:01<00:00, 19.35it/s, Loss=0.9378, Cat=0.398, Num=0.540]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 - Avg Loss: 0.9540 - LR: 0.000014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 85/100: 100%|██████████| 33/33 [00:01<00:00, 19.48it/s, Loss=0.9453, Cat=0.403, Num=0.542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85 - Avg Loss: 0.9581 - LR: 0.000012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86/100: 100%|██████████| 33/33 [00:01<00:00, 19.66it/s, Loss=0.9141, Cat=0.417, Num=0.497]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86 - Avg Loss: 0.9670 - LR: 0.000011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87/100: 100%|██████████| 33/33 [00:01<00:00, 19.47it/s, Loss=0.8390, Cat=0.410, Num=0.429]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87 - Avg Loss: 0.9349 - LR: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88/100: 100%|██████████| 33/33 [00:01<00:00, 19.48it/s, Loss=0.9706, Cat=0.403, Num=0.567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88 - Avg Loss: 0.9435 - LR: 0.000008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89/100: 100%|██████████| 33/33 [00:01<00:00, 19.76it/s, Loss=0.9600, Cat=0.415, Num=0.545]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89 - Avg Loss: 0.9440 - LR: 0.000007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90/100: 100%|██████████| 33/33 [00:01<00:00, 19.52it/s, Loss=0.9482, Cat=0.397, Num=0.551]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 - Avg Loss: 0.9319 - LR: 0.000006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 91/100: 100%|██████████| 33/33 [00:01<00:00, 19.62it/s, Loss=0.9440, Cat=0.409, Num=0.535]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91 - Avg Loss: 0.9474 - LR: 0.000005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92/100: 100%|██████████| 33/33 [00:01<00:00, 19.65it/s, Loss=0.8928, Cat=0.390, Num=0.503]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92 - Avg Loss: 0.9391 - LR: 0.000004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93/100: 100%|██████████| 33/33 [00:01<00:00, 19.57it/s, Loss=0.9014, Cat=0.400, Num=0.502]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93 - Avg Loss: 0.9312 - LR: 0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94/100: 100%|██████████| 33/33 [00:01<00:00, 19.48it/s, Loss=0.9540, Cat=0.410, Num=0.544]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94 - Avg Loss: 0.9373 - LR: 0.000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95/100: 100%|██████████| 33/33 [00:01<00:00, 19.52it/s, Loss=0.8687, Cat=0.400, Num=0.469]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 - Avg Loss: 0.9369 - LR: 0.000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 96/100: 100%|██████████| 33/33 [00:01<00:00, 19.66it/s, Loss=0.9655, Cat=0.416, Num=0.549]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96 - Avg Loss: 0.9338 - LR: 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 97/100: 100%|██████████| 33/33 [00:01<00:00, 19.43it/s, Loss=0.9668, Cat=0.396, Num=0.571]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97 - Avg Loss: 0.9379 - LR: 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 98/100: 100%|██████████| 33/33 [00:01<00:00, 19.52it/s, Loss=0.8598, Cat=0.410, Num=0.450]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98 - Avg Loss: 0.9361 - LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99/100: 100%|██████████| 33/33 [00:01<00:00, 19.68it/s, Loss=1.0085, Cat=0.433, Num=0.576]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 - Avg Loss: 0.9470 - LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 100/100: 100%|██████████| 33/33 [00:01<00:00, 19.65it/s, Loss=0.9511, Cat=0.387, Num=0.564]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100 - Avg Loss: 0.9350 - LR: 0.000000\n",
            "Generating sample sequences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 1000it [00:04, 246.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final dataframe created!\n",
            "Shape: (5997, 6)\n",
            "\n",
            "Column info:\n",
            "account_id             int64\n",
            "raw_amount           float32\n",
            "amount               float32\n",
            "td                   float32\n",
            "tcode                 object\n",
            "datetime      datetime64[ns]\n",
            "dtype: object\n",
            "\n",
            "Sample of final_df:\n",
            "    account_id   raw_amount        amount    td  \\\n",
            "0            0 -1339.810791     14.600000   0.0   \n",
            "1            0 -4855.853027   2300.000000  20.0   \n",
            "2            0  -128.370224  13974.402344   0.0   \n",
            "3            0  2977.615234  16976.861328   2.0   \n",
            "4            0 -2092.325928   1800.000000   2.0   \n",
            "5            0  -232.615128    300.011017   9.0   \n",
            "6            0    -2.874774   6332.871094   1.0   \n",
            "7            0   109.722023  12081.623047   3.0   \n",
            "8            0  3599.277832     75.447021  15.0   \n",
            "9            0   -14.600000    110.115356   0.0   \n",
            "10           0   -14.600000    270.075043   0.0   \n",
            "11           0 -3320.224854   6728.135254  12.0   \n",
            "12           0   268.324585   6090.373047   3.0   \n",
            "13           0  5548.251465  17596.529297   0.0   \n",
            "14           0 -2255.714600   5050.865234  13.0   \n",
            "\n",
            "                                              tcode   datetime  \n",
            "0         CREDIT__COLLECTION FROM ANOTHER BANK__nan 1995-11-17  \n",
            "1                       DEBIT__CASH WITHDRAWAL__nan 1995-12-17  \n",
            "2   DEBIT__REMITTANCE TO ANOTHER BANK__LOAN PAYMENT 1995-12-24  \n",
            "3                       CREDIT__CREDIT IN CASH__nan 1996-01-06  \n",
            "4                       DEBIT__CASH WITHDRAWAL__nan 1996-01-23  \n",
            "5                       DEBIT__CASH WITHDRAWAL__nan 1996-01-28  \n",
            "6              DEBIT__REMITTANCE TO ANOTHER BANK__  1996-02-17  \n",
            "7                       CREDIT__CREDIT IN CASH__nan 1996-02-24  \n",
            "8                    CREDIT__nan__INTEREST CREDITED 1996-03-25  \n",
            "9                    CREDIT__nan__INTEREST CREDITED 1996-03-29  \n",
            "10                   CREDIT__nan__INTEREST CREDITED 1996-04-08  \n",
            "11     DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD 1996-05-05  \n",
            "12           DEBIT__REMITTANCE TO ANOTHER BANK__nan 1996-05-28  \n",
            "13                      CREDIT__CREDIT IN CASH__nan 1996-06-26  \n",
            "14                      CREDIT__CREDIT IN CASH__nan 1996-07-04  \n",
            "\n",
            "Unique tcodes: 16\n",
            "Date range: 1993-01-01 00:00:00 to 1998-12-31 00:00:00\n",
            "Amount range: 0.85 to 73800.00\n",
            "Raw amount range: -64900.00 to 73800.00\n",
            "\n",
            "Final dataframe saved as 'synthetic_transactions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(epochs), losses)"
      ],
      "metadata": {
        "id": "jzg_bq6WarLZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "69c71e45-ff7a-4a4e-93a3-0f2a07d76844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a0de6794390>]"
            ]
          },
          "metadata": {},
          "execution_count": 262
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOB1JREFUeJzt3Xl8VPW9//H3mZnMZJ8skISQhUVkB9lF1OotrVCLilWvFi21vW1dWrXea5X22ts+vDZqb3ttrVdbb+vyq8ttq+BSl7qCKLKDIDsECEsISzKTdTLL+f0xyWg0Agkzc2Yyr+fjcR40Z87MfPw+0Lz7/X7O9ximaZoCAACIE5vVBQAAgNRC+AAAAHFF+AAAAHFF+AAAAHFF+AAAAHFF+AAAAHFF+AAAAHFF+AAAAHHlsLqATwuFQjpw4IBycnJkGIbV5QAAgJNgmqYaGxtVWloqm+34cxsJFz4OHDig8vJyq8sAAAC9UFNTo7KysuNek3DhIycnR1K4+NzcXIurAQAAJ8Pr9aq8vDzye/x4Ei58dC615ObmEj4AAEgyJ9MyQcMpAACIK8IHAACIK8IHAACIK8IHAACIK8IHAACIK8IHAACIK8IHAACIK8IHAACIK8IHAACIK8IHAACIK8IHAACIK8IHAACIq5QJH41tfv36H1t1+98+lGmaVpcDAEDKSpnwkWa36bdv7dD/raqRtzVgdTkAAKSslAkf6Wl29ct2SZJq6lssrgYAgNSVMuFDksryMyRJ++pbLa4EAIDUlaLhg5kPAACskmLhI1MSMx8AAFgpxcIHyy4AAFitx+FjyZIlmjNnjkpLS2UYhhYtWvSZazZv3qyLLrpIbrdbWVlZmjJlivbu3RuNek8Jyy4AAFivx+GjublZ48eP14MPPtjt6zt37tTZZ5+tESNG6J133tGHH36oO++8U+np6adc7KnqXHbZX9/KXh8AAFjE0dM3zJ49W7Nnz/7c13/yk5/oK1/5iu67777IuaFDh/auuijrnPlo9AXkbQ3InZlmcUUAAKSeqPZ8hEIh/f3vf9fpp5+uCy64QEVFRZo2bVq3SzOdfD6fvF5vlyNW2OsDAADrRTV81NXVqampSffcc49mzZqlf/zjH5o7d64uvfRSLV68uNv3VFVVye12R47y8vJolvQZNJ0CAGCtqM98SNLFF1+sH/7whzrjjDN0xx136Ktf/aoefvjhbt+zYMECeTyeyFFTUxPNkj6DplMAAKzV456P4+nXr58cDodGjRrV5fzIkSO1dOnSbt/jcrnkcrmiWcZxsdcHAADWiurMh9Pp1JQpU7R169Yu57dt26bKyspoflWvsewCAIC1ejzz0dTUpB07dkR+rq6u1rp161RQUKCKigrddttt+ud//mede+65Ov/88/Xqq6/qxRdf1DvvvBPNunuNZRcAAKzV4/CxatUqnX/++ZGfb731VknS/Pnz9dhjj2nu3Ll6+OGHVVVVpZtuuknDhw/Xs88+q7PPPjt6VZ+CT+/1YRiGxRUBAJBaDDPBdtvyer1yu93yeDzKzc2N+ue3+YMaceerkqT1P/0ye30AABAFPfn9nVLPdpHY6wMAAKulXPiQ6PsAAMBKKR4+uOMFAIB4S9HwwV4fAABYJUXDB8suAABYJcXDBzMfAADEW4qGj4+XXRLsTmMAAPq8FA0f4ZmPJl9Anla/xdUAAJBaUjJ8fHKvD5ZeAACIr5QMHxJNpwAAWIXwwcwHAABxlcLhg70+AACwQgqHD5ZdAACwAuGDmQ8AAOIqhcMHe30AAGCFFA4f7PUBAIAVUjZ8sNcHAADWSNnwIdF0CgCAFQgfYuYDAIB4SvHwEW46rTnGzAcAAPGS0uGjoiAcPvYSPgAAiJuUDh+DCsPhYw/hAwCAuEnp8FHZL0tSeNklGGKvDwAA4iGlw8eA3HQ5HTb5g6YONNB0CgBAPKR0+LDZjEjfx56jLL0AABAPKR0+pI/7PnYfbba4EgAAUkPKh4/KwnDfxx7CBwAAcUH4iMx8sOwCAEA8ED6Y+QAAIK5SPnxE9vo42qIQt9sCABBzKR8+BuZlyGEz5AuEdKixzepyAADo81I+fDjstsgD5nYfoe8DAIBY63H4WLJkiebMmaPS0lIZhqFFixZ97rXXXXedDMPQ/ffffwolxh59HwAAxE+Pw0dzc7PGjx+vBx988LjXLVy4UB988IFKS0t7XVy8DOKOFwAA4sbR0zfMnj1bs2fPPu41+/fv1w9+8AO99tpruvDCC3tdXLww8wEAQPxEvecjFArpmmuu0W233abRo0dH++NjYlA/Zj4AAIiXHs98nMi9994rh8Ohm2666aSu9/l88vl8kZ+9Xm+0SzqhT858mKYpwzDiXgMAAKkiqjMfq1ev1m9+8xs99thjJ/0LvKqqSm63O3KUl5dHs6STUpafIZshtbQHdbjJd+I3AACAXotq+Hj33XdVV1eniooKORwOORwO7dmzR//6r/+qQYMGdfueBQsWyOPxRI6amppolnRSXA67SvPCt9vydFsAAGIrqssu11xzjWbOnNnl3AUXXKBrrrlG1157bbfvcblccrlc0SyjVwYVZmlffav2HG3RlEEFVpcDAECf1ePw0dTUpB07dkR+rq6u1rp161RQUKCKigoVFhZ2uT4tLU0lJSUaPnz4qVcbQ5WFmVq6gzteAACItR6Hj1WrVun888+P/HzrrbdKkubPn6/HHnssaoXF26COplPueAEAILZ6HD7OO+88mebJP4Bt9+7dPf0KS1RGHjDHzAcAALGU8s926TSoX3jmo/pIc4/CFQAA6BnCR4eKgvDMR2NbQA0tfourAQCg7yJ8dEhPs2uAO12StJulFwAAYobw8Qkf933QdAoAQKwQPj7h4ztemPkAACBWCB+f8PEzXpj5AAAgVggfnzCosPPptsx8AAAQK4SPT2DmAwCA2CN8fEJnw+mx5nZ5WrndFgCAWCB8fEKWy6Hi3PBD7nbUNVlcDQAAfRPh41PGlLolSR/ua7C2EAAA+ijCx6eMK8uTJG3Y57G2EAAA+ijCx6eMKw/PfKxn5gMAgJggfHzKuIHh8LHrSLMa22g6BQAg2ggfn1KY7dLAvAyZprRhP0svAABEG+GjG+PLO5tOCR8AAEQb4aMbNJ0CABA7hI9udPZ90HQKAED0ET66MaYsHD721bfqaJPP4moAAOhbCB/dyE1P05D+4ee8fEjTKQAAUUX4+BzjO/o+PqwhfAAAEE2Ej88xrmPpZcP+BmsLAQCgjyF8fI7O8LF+n0emaVpcDQAAfQfh43OMGuCW3WbocKNPtd42q8sBAKDPIHx8jgynXacX50iS1tP3AQBA1BA+jmN8WedOpw3WFgIAQB9C+DiOsZGmU2Y+AACIFsLHcURut6XpFACAqCF8HMfwkhw5HTZ5Wv3ac7TF6nIAAOgTCB/HkWa3adSAXEk85wUAgGghfJzAx02n9H0AABANhI8TGNfR97GupsHSOgAA6CsIHycwsTJfUviOF18gaHE1AAAkvx6HjyVLlmjOnDkqLS2VYRhatGhR5DW/36/bb79dY8eOVVZWlkpLS/WNb3xDBw4ciGbNcTWoMFMFWU61B0L66IDX6nIAAEh6PQ4fzc3NGj9+vB588MHPvNbS0qI1a9bozjvv1Jo1a/Tcc89p69atuuiii6JSrBUMw9DEivDsx5o99RZXAwBA8nP09A2zZ8/W7Nmzu33N7Xbr9ddf73Lud7/7naZOnaq9e/eqoqKid1VabFJlvt7YfEir99TrX86xuhoAAJJbj8NHT3k8HhmGoby8vG5f9/l88vl8kZ+93sRb2pjU0fexak+9TNOUYRgWVwQAQPKKacNpW1ubbr/9dl111VXKzc3t9pqqqiq53e7IUV5eHsuSemVcmVtp9vATbvfVt1pdDgAASS1m4cPv9+uKK66QaZp66KGHPve6BQsWyOPxRI6amppYldRr6Wl2jS4N7/exmr4PAABOSUzCR2fw2LNnj15//fXPnfWQJJfLpdzc3C5HIupceiF8AABwaqIePjqDx/bt2/XGG2+osLAw2l9hCcIHAADR0eOG06amJu3YsSPyc3V1tdatW6eCggINGDBAl112mdasWaOXXnpJwWBQtbW1kqSCggI5nc7oVR5nneFjS61XTb6Asl0x79UFAKBP6vHMx6pVqzRhwgRNmDBBknTrrbdqwoQJ+ulPf6r9+/frhRde0L59+3TGGWdowIABkeP999+PevHxVJybroF5GQqZ0nq2WgcAoNd6/H/fzzvvPJmm+bmvH++1ZDepMl/7G1q1ane9ZpzWz+pyAABISjzbpQcifR976fsAAKC3CB890Bk+1u6pVyjUd2d4AACIJcJHD4woyVGm065GX0Db65qsLgcAgKRE+OgBh92mM8rzJHHLLQAAvUX46CH2+wAA4NQQPnpoYiR8HLO4EgAAkhPho4cmlofDx+6jLTrS5DvB1QAA4NMIHz3kzkzTsKJsSSy9AADQG4SPXujs+1jDfh8AAPQY4aMXJkb2+2iwthAAAJIQ4aMXOmc+1u9rUHsgZHE1AAAkF8JHLwzpl6W8zDT5AiFtOui1uhwAAJIK4aMXDMPQxAr2+wAAoDcIH70UaTolfAAA0COEj17qnPngjhcAAHqG8NFL48vdstsMHfS06UBDq9XlAACQNAgfvZTpdGjUgFxJ9H0AANAThI9TwEPmAADoOcLHKZhQkSeJvg8AAHqC8HEKOmc+Nh3wqrU9aHE1AAAkB8LHKRiYl6HiXJcCIVMf7muwuhwAAJIC4eMUGIbxcd8HSy8AAJwUwscpiuz3QdMpAAAnhfBxij55x4tpmhZXAwBA4iN8nKLRpW45HTbVt/hVfaTZ6nIAAEh4hI9T5HTYNG6gW5K0Zm+DtcUAAJAECB9RwGZjAACcPMJHFEzsCB+rdh+zuBIAABIf4SMKpgwqkCRtr2vSseZ2i6sBACCxET6ioCDLqdOLsyVJK6qPWlwNAACJjfARJWcOKZQkfbCLpRcAAI6H8BEl0wZ3hg9mPgAAOJ4eh48lS5Zozpw5Ki0tlWEYWrRoUZfXTdPUT3/6Uw0YMEAZGRmaOXOmtm/fHq16E9bUweG+j62HGtXQQt8HAACfp8fho7m5WePHj9eDDz7Y7ev33Xeffvvb3+rhhx/W8uXLlZWVpQsuuEBtbW2nXGwi65/j0tD+WTJNaUU1Sy8AAHweR0/fMHv2bM2ePbvb10zT1P33369///d/18UXXyxJeuKJJ1RcXKxFixbpyiuvPLVqE9yZQwq183CzPth1TF8eXWJ1OQAAJKSo9nxUV1ertrZWM2fOjJxzu92aNm2ali1b1u17fD6fvF5vlyNZTetoOl3OHS8AAHyuqIaP2tpaSVJxcXGX88XFxZHXPq2qqkputztylJeXR7OkuDqzo+9j00GvPK1+i6sBACAxWX63y4IFC+TxeCJHTU2N1SX1WlFuugb3C/d9rKTvAwCAbkU1fJSUhPscDh061OX8oUOHIq99msvlUm5ubpcjmZ05JDz7wdILAADdi2r4GDx4sEpKSvTmm29Gznm9Xi1fvlzTp0+P5lclrM79PpYz8wEAQLd6fLdLU1OTduzYEfm5urpa69atU0FBgSoqKnTLLbfoP//zPzVs2DANHjxYd955p0pLS3XJJZdEs+6ENa1j5mPjfo8a2/zKSU+zuCIAABJLj8PHqlWrdP7550d+vvXWWyVJ8+fP12OPPaYf/ehHam5u1ne/+101NDTo7LPP1quvvqr09PToVZ3ABrgzVFmYqT1HW7Rqd73OH1FkdUkAACQUwzRN0+oiPsnr9crtdsvj8SRt/8eP/rZef1m1T9/7whAtmD3S6nIAAIi5nvz+tvxul74o0vfBQ+YAAPgMwkcMdPZ9bNjvUZMvYHE1AAAkFsJHDJTlZ6osP0PBkKnVe+qtLgcAgIRC+IiR6R1brb+344jFlQAAkFgIHzFyzun9JUlLth22uBIAABIL4SNGzjmtnwxD2lLbqEPeNqvLAQAgYRA+YiQ/y6lxA92SmP0AAOCTCB8xdM6w8NLLu9vp+wAAoBPhI4bO7ej7WLrjiEKhhNrLDQAAyxA+YmhCRZ6yXQ4da27XxgMeq8sBACAhED5iKM1u01lDw7fc0vcBAEAY4SPGIrfc0vcBAIAkwkfMfaGj6XTNnno1tvktrgYAAOsRPmKsojBTgwozFQiZWrbzqNXlAABgOcJHHJwbWXqh7wMAAMJHHJzLfh8AAEQQPuLgzKGFctgM7Tnaoj1Hm60uBwAASxE+4iDb5dCkynxJ3HILAADhI046+z4Wb2PpBQCQ2ggfcfKFjvDx/s4jam0PWlwNAADWIXzEyejSXJXlZ6ilPai3ttRZXQ4AAJYhfMSJYRiaM75UkvTC+v0WVwMAgHUIH3F0UUf4eHvrYXnZ7RQAkKIIH3E0oiRHw4qy1R4I6bWNtVaXAwCAJQgfcWQYRmT244X1ByyuBgAAaxA+4qyz7+O9HUd0uNFncTUAAMQf4SPOBvXL0vgyt0Km9PKGg1aXAwBA3BE+LDCHpRcAQAojfFhgzvhSGYa0ek+99tW3WF0OAABxRfiwQHFuuqYNLpAkvbiepRcAQGohfFjkovEDJbH0AgBIPYQPi8weUyKHzdDmg17tqGu0uhwAAOIm6uEjGAzqzjvv1ODBg5WRkaGhQ4fqrrvukmma0f6qpJaf5Yw86XbRWmY/AACpI+rh495779VDDz2k3/3ud9q8ebPuvfde3XfffXrggQei/VVJ75IJ4aWXhWv3KxQinAEAUoMj2h/4/vvv6+KLL9aFF14oSRo0aJCefvpprVixItpflfS+PKpYOekO7W9o1fLqY5o+tNDqkgAAiLmoz3ycddZZevPNN7Vt2zZJ0vr167V06VLNnj272+t9Pp+8Xm+XI1Wkp9n11XEDJEnPrtlncTUAAMRH1MPHHXfcoSuvvFIjRoxQWlqaJkyYoFtuuUXz5s3r9vqqqiq53e7IUV5eHu2SEtqlE8skSa9sOKiW9oDF1QAAEHtRDx9/+ctf9OSTT+qpp57SmjVr9Pjjj+u//uu/9Pjjj3d7/YIFC+TxeCJHTU1NtEtKaJMr81VZmKnm9qBe+4gn3QIA+r6o93zcdtttkdkPSRo7dqz27NmjqqoqzZ8//zPXu1wuuVyuaJeRNAzD0KUTyvTfb2zTs6v3a+6EMqtLAgAgpqI+89HS0iKbrevH2u12hUKhaH9Vn3HpxPBdL+/tPKIDDa0WVwMAQGxFPXzMmTNHd999t/7+979r9+7dWrhwoX79619r7ty50f6qPqO8IFNTBxfINMO33QIA0JdFPXw88MADuuyyy3TDDTdo5MiR+rd/+zd973vf01133RXtr+pTLutoPH1uzT42ZAMA9GmGmWC/6bxer9xutzwej3Jzc60uJ24a2/yacvcbavOHtOjGGTqjPM/qkgAAOGk9+f3Ns10SRE56mmaNLpEkPbuaPT8AAH0X4SOBdO758cL6A2rzBy2uBgCA2CB8JJAZp/VTqTtdnla/Xt3Inh8AgL6J8JFA7DZDV06tkCT9+YM9FlcDAEBsED4SzJVTyuWwGVq1p15balPnOTcAgNRB+EgwRbnp+vLoYknSkx/stbgaAACij/CRgK6eVikpvOFYs4+HzQEA+hbCRwKaPrRQQ/plqckX0KJ17HgKAOhbCB8JyDAMfX1aZ+PpXnY8BQD0KYSPBHXZpDK5HDZtPujV2poGq8sBACBqCB8JKi/TqTnjSyVx2y0AoG8hfCSweR1LLy99eFD1ze0WVwMAQHQQPhLYGeV5Gl2aq/ZASH/jeS8AgD6C8JHADMPQ1WeGb7t9asVehUI0ngIAkh/hI8FdNL5UOS6Hqo806/2dR60uBwCAU0b4SHBZLofmThwoicZTAEDfQPhIAp1LL69vPqRaT5vF1QAAcGoIH0ng9OIcTR1UoGDI1DMred4LACC5ET6SxLwzw7fdPrOiRoFgyOJqAADoPcJHkpg1pkSFWU7Vetv0xuY6q8sBAKDXCB9JwuWw64op5ZKkJ5fTeAoASF6EjyTy9akVMgzp3e1HVH2k2epyAADoFcJHEikvyNR5p/eXJD3F7AcAIEkRPpJM5223f129T23+oMXVAADQc4SPJHPe8CINzMtQQ4tfL284aHU5AAD0GOEjydhthq7saDx9ajl7fgAAkg/hIwldMaVcdpuhVXvqtbW20epyAADoEcJHEirOTdeXRhZLovEUAJB8CB9J6uvTwjuePrd2v1rbaTwFACQPwkeSOvu0fqooyFRjW0AvfnjA6nIAADhphI8kZbMZumpqePbjSRpPAQBJhPCRxC6fXKY0u6H1NQ366IDH6nIAADgphI8k1i/bpS+PLpHEbbcAgOQRk/Cxf/9+XX311SosLFRGRobGjh2rVatWxeKrUt68jqWXRWv3q8kXsLgaAABOLOrho76+XjNmzFBaWppeeeUVbdq0Sb/61a+Un58f7a+CpOlDCzWkX5aa24N6YR2NpwCAxOeI9gfee++9Ki8v16OPPho5N3jw4Gh/DToYRrjx9O6XN+uJZbt11dRyGYZhdVkAAHyuqM98vPDCC5o8ebIuv/xyFRUVacKECXrkkUc+93qfzyev19vlQM9cMblcmU67ttQ2aumOI1aXAwDAcUU9fOzatUsPPfSQhg0bptdee03XX3+9brrpJj3++OPdXl9VVSW32x05ysvLo11Sn+fOTNMVk8Pj9si71RZXAwDA8RmmaZrR/ECn06nJkyfr/fffj5y76aabtHLlSi1btuwz1/t8Pvl8vsjPXq9X5eXl8ng8ys3NjWZpfdreoy0677/eVsiUXrvlXA0vybG6JABACvF6vXK73Sf1+zvqMx8DBgzQqFGjupwbOXKk9u7t/lZQl8ul3NzcLgd6rqIwU7PGhG+7feTdXRZXAwDA54t6+JgxY4a2bt3a5dy2bdtUWVkZ7a/Cp/zLOUMkSc+v2686b5vF1QAA0L2oh48f/vCH+uCDD/SLX/xCO3bs0FNPPaU//OEPuvHGG6P9VfiUiRX5mlSZL3/Q1OPLdltdDgAA3Yp6+JgyZYoWLlyop59+WmPGjNFdd92l+++/X/PmzYv2V6Eb3zknfFvznz/Yq5Z2Nh0DACSeqO/zIUlf/epX9dWvfjUWH40T+NKoElUWZmrP0Rb9bfU+fWP6IKtLAgCgC57t0sfYbYa+NSM8+/HHpdUKhqJ6MxMAAKeM8NEHXT65TO6MNO052qKXPmTLdQBAYiF89EGZTof+5ezw7McvX9sqXyBocUUAAHyM8NFHffucwSrKcWlffaue/KD7PVYAALAC4aOPynQ6dMvM0yVJD7y1Xd42v8UVAQAQRvjow66YXKYh/bNU3+LX7xfvtLocAAAkET76NIfdph9dMEJS+M6XQ+x6CgBIAISPPu6C0cWaVJmvNn9I97+xzepyAAAgfPR1hmFowezw7Mf/razRjrpGiysCAKQ6wkcKmDyoQF8aVayQKd3zytYTvwEAgBgifKSI22cNl91m6I3Nh7Rk22GrywEApDDCR4o4rShH8zue8/KzFz9SeyBkbUEAgJRF+EghN88cpsIsp3YdbtYTy3ZbXQ4AIEURPlKIOyNNt88KN5/e/8Z21TVy6y0AIP4IHynmskllGl/mVpMvoPtepfkUABB/hI8UY7MZ+tlFoyVJf1u9T2v31ltcEQAg1RA+UtCEinxdNqlMkvSzFz5SKGRaXBEAIJUQPlLU7bNGKMfl0Pp9Hv15+R6rywEApBDCR4rqn+PSv10wXJJU9fIWVR9ptrgiAECqIHyksGvOrNSM0wrV6g/q1r+sUyDI3h8AgNgjfKQwm83QLy8br5x0h9bubdDvl+yyuiQAQAogfKS40rwM/bzj7pf/fn2bNu73WFwRAKCvI3xAcycM1KzRJQqETP3rX9arzR+0uiQAQB9G+IAMw9Ddc8eoX7ZTWw816lf/YPMxAEDsED4gSSrMdqnq0nGSpEferdarGw9aXBEAoK8ifCDiS6OK9e2zB0uS/vUv67XtUKPFFQEA+iLCB7pYMHuEzhpaqOb2oL77xCp5WvxWlwQA6GMIH+jCYbfpd1+fqIF5Gdp9tEU3PbNWQbZfBwBEEeEDn1GQ5dQfvjFJ6Wk2Ld52mAZUAEBUET7QrdGlbt37tXAD6v+8s1OL1u63uCIAQF9B+MDnuviMgfreuUMkSf/21/V6e0udxRUBAPoCwgeO6/ZZI3TJGaUKhExd/+Rqrdx9zOqSAABJLubh45577pFhGLrlllti/VWIAZvN0C8vH69/GlGkNn9I33pspTYf9FpdFgAgicU0fKxcuVK///3vNW7cuFh+DWIszW7Tg1+fqCmD8tXYFtA1f1yhPUebrS4LAJCkYhY+mpqaNG/ePD3yyCPKz8+P1dcgTjKcdv3v/CkaUZKjI00+Xf3H5aprbLO6LABAEopZ+Ljxxht14YUXaubMmce9zufzyev1djmQmNwZaXri21NVWZipmmOt+uafVqqxjU3IAAA9E5Pw8cwzz2jNmjWqqqo64bVVVVVyu92Ro7y8PBYlIUqKctL1xLemql+2U5sOevXdJ1bLF+ApuACAkxf18FFTU6Obb75ZTz75pNLT0094/YIFC+TxeCJHTU1NtEtClFUWZumxa6cqy2nXsl1Hdev/rWcXVADASTNM04zqb41FixZp7ty5stvtkXPBYFCGYchms8nn83V57dO8Xq/cbrc8Ho9yc3OjWRqibOn2I7r2sRXyB03Nn16pn100WoZhWF0WAMACPfn9HfWZjy9+8YvasGGD1q1bFzkmT56sefPmad26dccNHkguZw/rp19dcYYk6fFle1T1yhaFmAEBAJyAI9ofmJOTozFjxnQ5l5WVpcLCws+cR/K7aHypjjX59LMXN+kPS3Zp95Fm3X/lGcp0Rv2vFgCgj2CHU5yyb84YrPv/+Qw57Tb9Y9MhXf7wMtV6uA0XANC9qPd8nCp6PpLX6j3H9N0nVutoc7uKc136329M0dgyt9VlAQDiwNKeD6SuSZUFWnTjDA0rytYhr09X/H6Z3tpyyOqyAAAJhvCBqCovyNSzN5ylc0/vr1Z/UN95YrWeWbHX6rIAAAmE8IGoy01P0x/nT9Zlk8oUDJm647kN+u/XtynBVvgAABYhfCAm0uw2/fKycbrpn06TJP3mze2649kNCgRDFlcGALAa4QMxYxiGbv3ycN09d4xshvR/q2p07WMr5WnheTAAkMoIH4i5edMq9ftrJisjza53tx/RJf/znnbUNVldFgDAIoQPxMWXRhXrb9dP18C8DFUfadbcB9/T21vqrC4LAGABwgfiZnSpW89/f4amDipQoy+gbz2+Ug8v3kkjKgCkGMIH4qpftkt//pdpumpqhUxTuueVLfre/1tNHwgApBDCB+LO6bDpF3PH6K5LxkS2ZL/wgXe1vqbB6tIAAHFA+IAlDMPQNWdW6tnrz1J5QYb21bfqsoff16PvVbMMAwB9HOEDlhpb5tZLPzhHs8eUyB809fMXN+l7/2+16pvbrS4NABAjhA9Yzp2Rpv+ZN1E/v2i00uyG/rHpkGb9Zone33HE6tIAADFA+EBCMAxD888apIU3zNCQ/lk65PVp3h+X655Xtqg9wK6oANCXED6QUMYMdOulH5wduRvm4cU79bWH3teOukarSwMARAnhAwkn0+lQ1aVj9fDVk5SXmaYN+z36ym+X6uHFOxUM0YwKAMmO8IGENWtMiV69+VydN7y/2gMh3fPKlo5ZELZmB4BkRvhAQitxp+vRb07RfV8bpxyXQ+tqGvSV376rh97ZKT9PyAWApET4QMIzDENXTCnXaz88V+eeHp4FuffVLZrzwFKt2VtvdXkAgB4ifCBplOZl6PFrp+iXl41TXmaattQ26msPva9/X7RBnla2ZweAZEH4QFIxDEOXTy7Xm7d+QV+bWCbTlP78wV7N/PVi/W31PoVoSAWAhGeYCbaXtdfrldvtlsfjUW5urtXlIMG9v/OI/n3hRu060ixJGjMwVz/5yihNH1pocWUAkFp68vub8IGk5wsE9dh7u/W7t3ao0ReQJH1pVLEWzB6hIf2zLa4OAFID4QMp6WiTT/e/sV1PrdirYMiU027TdV8YohvOP03paXarywOAPo3wgZS2/VCj7vr7Zi3ZdliSNKgwU3ddMkbnDOtvcWUA0Hf15Pc3Dafoc4YV5+jxa6fooXkTVZzr0u6jLbrmjyt009Nrta++xeryACDlMfOBPq2xza9fv75Nj7+/WyFTstsMXTS+VN/7whCNKOHvFwBEC8suwKds3O9R1Sub9d6Oo5Fz/zSiSNd9YaimDMqXYRgWVgcAyY/wAXyODfs8enjxTr288aA6/+aPGZirb541WHPGD5DLQWMqAPQG4QM4gV2Hm/TIu7v03Jr98gXCz4jpl+3U16dV6uozK1SUk25xhQCQXAgfwEk61tyup1fs1f9btke13jZJktNu0yUTSvUv5wzR6cU5FlcIAMmB8AH0kD8Y0qsba/Wn96q1dm9D5Px5w/vrO+cM0VlDC+kLAYDjsPRW26qqKk2ZMkU5OTkqKirSJZdcoq1bt0b7a4CoSrPbNGd8qRbeMEPPXj9ds0aXyDCkd7Ye1rz/Xa4v/mqx/vfdXapvbre6VABIelGf+Zg1a5auvPJKTZkyRYFAQD/+8Y+1ceNGbdq0SVlZWSd8PzMfSBS7jzTrT+9V69nV+9TcHpQkOR02XTh2gP55SrmmDiqQzcZsCABICbbscvjwYRUVFWnx4sU699xzT3g94QOJpskX0PPr9uup5Xv10QFv5Hx5QYYunVCmr00sU0VhpoUVAoD1Eip87NixQ8OGDdOGDRs0ZsyYz7zu8/nk8/kiP3u9XpWXlxM+kHBM09SH+zx6esVevfThQTV1PMROkiZX5mvakAKNL8vTGRV53C0DIOUkTPgIhUK66KKL1NDQoKVLl3Z7zc9+9jP9/Oc//8x5wgcSWWt7UK99VKu/rd6n93Ye0af/LSp1p+vc0/vrqqkVGlfmplkVQJ+XMOHj+uuv1yuvvKKlS5eqrKys22uY+UCyO9DQqre31ml9TYPW13i0ra6xSxgZXZqrr0+r0MVnDFS2y2FdoQAQQwkRPr7//e/r+eef15IlSzR48OCTfh89H0h2Tb6A1u6t17Or9+nljbVq79jELNNp18yRxfrK2AE6b3h/paexmyqAvsPS8GGapn7wgx9o4cKFeueddzRs2LAevZ/wgb6kvrldz67Zp6dX7NXOw82R81lOu/5pZLFmjynRuaf3Z0YEQNKzNHzccMMNeuqpp/T8889r+PDhkfNut1sZGRknfD/hA32RaZpaV9Oglzcc1MsbarW/oTXymtNu0/ShhZo5qlgzRxZpgPvE/54AQKKxNHx8XmPdo48+qm9+85snfD/hA32daZpav8+jv394QK9vOqTdR1u6vF5ekKEzyvM1vsytCRV5GjXArQwnSzQAEltC9Hz0FuEDqcQ0Te083KTXN9Xpjc2HtGZv/WfunDEMaWBehob2zw4fRVmaPqRQQ/pnW1M0AHSD8AEkKU+rXxv2ebSupl7rajxaV9OgI02+bq89rShbXx5VrAtGl3A7LwDLET6APsI0TR1rbtfOw83aebhJO+uatOmgVyuqjykQ+vhf3YIspyoLM1Wen6mKgkyVF2RofHmehhfnEEoAxEVPfn/TYg8kMMMwVJjtUmG2S1MHF0TOe1r9emdrnf6x6ZDe2VKnY83tOtbc3uWJvJLUP8elc07rp3NO76fpQ/qpONdFGAFgOWY+gCTnCwS1/VCTao61aO+xFtXUt6j6SLNW76lXmz/U5dr0NJvK8jNVlp+hsvwMDSrM0tD+2TqtKFuleRmy86A8AL3EzAeQQlwOu8YMdGvMQHeX875AUKv31Ovd7Ue0dPsRbTzgUZs/pB11TdpR19TN59g0pH+2xg10a1y5W+PL8jS8JEdpdlu8/lEApAhmPoAU4QsEdbChTfvqW7W/oUU1x1pVfSTcS7LrSHNkJ9ZPcjlsGl+WpymD8zV1cKEmVeazIRqAbtFwCqBHgiFT++pbtKW2UR/uCz+jZv2+BjW2BbpcZzOkESW5yk53yGZIhgwZhpSeZldhllOF2S71y3aqMNupkQNyNawoh6UcIEWw7AKgR+w2Q5WFWaoszNIFo0skSaGQqV1HmrV6zzEtrz6mFdXHtK++VZsOek/6c3NcDp1RkaeJFfkaOSBXWS67MtLsSu84ctMdcmemyeVgEzUglTDzAeCkHWho1cb9HvmDpkyZCpnh24Fb24M62tyuo03tOtrs00FPmz7a71Fze/CkPjfTaVdeRpr65bh0enGORg7I1cgBORo1IFd5mc4Y/1MBiAZmPgDERGlehkrzTu7ZM8GQqa21jVq9t16rdx/T7qMtavMHO46QWtoDavIFFDKllvagWtqDOuBp04f7PF0+Z4A7XcNLcsJHcY6GFeUoPytNOelpynY5WNYBkhAzHwAsEwqZamwLqKG1XQ0tfh30tGrzwUZtOujV5oNe7atvPeFnZLscKsx2aoA7XaV5GRqYl6Hi3HQ57TbJkAyF90tJT7OpMKuzJ8WlvIw02QguQNTQcAqgT/C2+bWttlFbahu1teOoPtosb6tfvm7uzukJw5DSbDbZbJLdMGSzGcp2OSL7nnQe/bKdSk+zK9PpUEaaXS6HjdACdIPwAaDPaw+E1Njml7ctoCNNPh1oaNX+hlYdaGjVIa9PwZAp0zRlSjJNqaU9oKMdO8E2tPh7/b2GEZ5tyU1PU066QznpDmW5wsEkwxluqM1yOVSY5VT/HJf6ZbvUP8elNLtNre1BtfqDamkPqD0QUobTrmyXI3x0fE6Wk6UkJCd6PgD0eU6HLbL1/OB+WT16rz8YUn1Lu/xBU6GQqZBpKhgyVd/i1866Jm2va9SOuibtPNwsb5tfre3ByEyLaUqNbYHP3IYcTVnOcIDJdjk67gyyyeWwy5VmU7rDrkxnOOiE/3QozRaeubEZhmyGlGa3KT8rTXmZTuVnOpWfmaZMp0NOh01Ou01Oh42AA0sRPgCknDS7TUU56d2+Nqkyv9vzwZCpNn9Qze2BSPhobPPL2xpQS3tAbf5w02yrP6imtvAsy+FGn440+XS40Sd/MBReuumYHXE6bGrzB9XkCzfeNvsC8gfDE9HN7UE1twdV19j9E42jMwaG3BlpcmekKT/TqbyOgOKwGbLbDDnsNtmM8AyTLxAKNwoHQjJNUw6boTS7TWl2mxx2Q4GgKV8gpPZgSO2BoOw2Q8W56RrgTleJO0MluenKctrlsNuUZg+/1+mwRW677hyTQCikFl9QLf6gWnwB+QIh2QxDDntHTTZDITNcU3vH9wWCoS6fkeG0y2Ez5A+aCoRCCgRN+YMhtfqDn5h5CsphMzS4X5bKCzLZxdcChA8AOAl2mxFeFnE5VJQTm+9o8wfV3BFGGtvCf3b+4vcFQvJ13C3UeXdQ5xJOMGQqFFJ4BscMBwFPi79jiald9S1+tfq73vbsD5o60tSuI03tkppj8w+UBBw2QxWFmRrSL0sOm00t/qDa2oNq8Qfk84fU2ZfQ2aGQnhZeKsvpWHZLT7PJ0+pXfbNfDa1+NbS0K2SanwlWGWl2pTvtSnfYleG0yWYY8vnDAcoXCKo9YEqRbwvPStmM8N+7zuBlsxkKhUz5Q6aCHeEqGDJlMwwZhqFwj7UhXyCoZl9QjR2h1hcIKsvlUE5H3eH6Hbr3a+Ms618ifABAgujcfK0w2xX1zzZNU/6gqfZgSP5AeCbA0+pXQ4s/ElDa/MHwbEHkl5sZWerp/NNmCweXzhkFfzAUmcnoXNJpD4RU623TIW+bDnraVOdtU6s/KH/HewIddbT5wwHq052HTodNWU67XA57ZEnMHwzXZTcMpX1q+ag9EL51u+UTy2NSOFg47IbSbDaldy5TpYX/bPOHVH2kWa3+oHYdbtauw309gHWdRXM5bPrl5eMtqoXwAQApwTAMOR2GnA6b5JLypZPesyWWzI6Zmpb2oBx2Q5lp4eWZ3gqFwrM/Dlt4NuBE19Z627TrcLOqj4bDR2bnbIXTLpfdJsMIP0KgU5s/2GXZzRcIyZ2RprzMcI9NXkaa7DYjEqw6l3o697fpPGeaplwdd085HeElLJsR7inqzGLBT/QjBUNmJHw57OFlsc5eH5kfz3qFzHCwyO6Ypct2OeRy2NTcMZvW6POrqe3jJT6rED4AAJYJ78ESnvGJBpvNkE0nt5RgsxmRjfPOHtYvKt+Pk0OXDQAAiCvCBwAAiCvCBwAAiCvCBwAAiCvCBwAAiCvCBwAAiCvCBwAAiCvCBwAAiCvCBwAAiCvCBwAAiCvCBwAAiCvCBwAAiCvCBwAAiKuEe6qtaYYf8+v1ei2uBAAAnKzO39udv8ePJ+HCR2NjoySpvLzc4koAAEBPNTY2yu12H/cawzyZiBJHoVBIBw4cUE5OjgzDiOpne71elZeXq6amRrm5uVH9bHTFWMcPYx0/jHX8MNbxE62xNk1TjY2NKi0tlc12/K6OhJv5sNlsKisri+l35Obm8pc5Thjr+GGs44exjh/GOn6iMdYnmvHoRMMpAACIK8IHAACIq5QKHy6XS//xH/8hl8tldSl9HmMdP4x1/DDW8cNYx48VY51wDacAAKBvS6mZDwAAYD3CBwAAiCvCBwAAiCvCBwAAiKuUCh8PPvigBg0apPT0dE2bNk0rVqywuqSkVlVVpSlTpignJ0dFRUW65JJLtHXr1i7XtLW16cYbb1RhYaGys7P1ta99TYcOHbKo4r7jnnvukWEYuuWWWyLnGOvo2b9/v66++moVFhYqIyNDY8eO1apVqyKvm6apn/70pxowYIAyMjI0c+ZMbd++3cKKk1cwGNSdd96pwYMHKyMjQ0OHDtVdd93V5fkgjHfvLFmyRHPmzFFpaakMw9CiRYu6vH4y43rs2DHNmzdPubm5ysvL07e//W01NTWdenFminjmmWdMp9Np/ulPfzI/+ugj8zvf+Y6Zl5dnHjp0yOrSktYFF1xgPvroo+bGjRvNdevWmV/5ylfMiooKs6mpKXLNddddZ5aXl5tvvvmmuWrVKvPMM880zzrrLAurTn4rVqwwBw0aZI4bN868+eabI+cZ6+g4duyYWVlZaX7zm980ly9fbu7atct87bXXzB07dkSuueeee0y3220uWrTIXL9+vXnRRReZgwcPNltbWy2sPDndfffdZmFhofnSSy+Z1dXV5l//+lczOzvb/M1vfhO5hvHunZdfftn8yU9+Yj733HOmJHPhwoVdXj+ZcZ01a5Y5fvx484MPPjDfffdd87TTTjOvuuqqU64tZcLH1KlTzRtvvDHyczAYNEtLS82qqioLq+pb6urqTEnm4sWLTdM0zYaGBjMtLc3861//Grlm8+bNpiRz2bJlVpWZ1BobG81hw4aZr7/+uvmFL3whEj4Y6+i5/fbbzbPPPvtzXw+FQmZJSYn5y1/+MnKuoaHBdLlc5tNPPx2PEvuUCy+80PzWt77V5dyll15qzps3zzRNxjtaPh0+TmZcN23aZEoyV65cGbnmlVdeMQ3DMPfv339K9aTEskt7e7tWr16tmTNnRs7ZbDbNnDlTy5Yts7CyvsXj8UiSCgoKJEmrV6+W3+/vMu4jRoxQRUUF495LN954oy688MIuYyox1tH0wgsvaPLkybr88stVVFSkCRMm6JFHHom8Xl1drdra2i5j7Xa7NW3aNMa6F8466yy9+eab2rZtmyRp/fr1Wrp0qWbPni2J8Y6VkxnXZcuWKS8vT5MnT45cM3PmTNlsNi1fvvyUvj/hHiwXC0eOHFEwGFRxcXGX88XFxdqyZYtFVfUtoVBIt9xyi2bMmKExY8ZIkmpra+V0OpWXl9fl2uLiYtXW1lpQZXJ75plntGbNGq1cufIzrzHW0bNr1y499NBDuvXWW/XjH/9YK1eu1E033SSn06n58+dHxrO7/54w1j13xx13yOv1asSIEbLb7QoGg7r77rs1b948SWK8Y+RkxrW2tlZFRUVdXnc4HCooKDjlsU+J8IHYu/HGG7Vx40YtXbrU6lL6pJqaGt188816/fXXlZ6ebnU5fVooFNLkyZP1i1/8QpI0YcIEbdy4UQ8//LDmz59vcXV9z1/+8hc9+eSTeuqppzR69GitW7dOt9xyi0pLSxnvPiwlll369esnu93+mc7/Q4cOqaSkxKKq+o7vf//7eumll/T222+rrKwscr6kpETt7e1qaGjocj3j3nOrV69WXV2dJk6cKIfDIYfDocWLF+u3v/2tHA6HiouLGesoGTBggEaNGtXl3MiRI7V3715Jiown/z2Jjttuu0133HGHrrzySo0dO1bXXHONfvjDH6qqqkoS4x0rJzOuJSUlqqur6/J6IBDQsWPHTnnsUyJ8OJ1OTZo0SW+++WbkXCgU0ptvvqnp06dbWFlyM01T3//+97Vw4UK99dZbGjx4cJfXJ02apLS0tC7jvnXrVu3du5dx76EvfvGL2rBhg9atWxc5Jk+erHnz5kX+N2MdHTNmzPjMLePbtm1TZWWlJGnw4MEqKSnpMtZer1fLly9nrHuhpaVFNlvXX0V2u12hUEgS4x0rJzOu06dPV0NDg1avXh255q233lIoFNK0adNOrYBTaldNIs8884zpcrnMxx57zNy0aZP53e9+18zLyzNra2utLi1pXX/99abb7Tbfeecd8+DBg5GjpaUlcs11111nVlRUmG+99Za5atUqc/r06eb06dMtrLrv+OTdLqbJWEfLihUrTIfDYd59993m9u3bzSeffNLMzMw0//znP0euueeee8y8vDzz+eefNz/88EPz4osv5tbPXpo/f745cODAyK22zz33nNmvXz/zRz/6UeQaxrt3GhsbzbVr15pr1641JZm//vWvzbVr15p79uwxTfPkxnXWrFnmhAkTzOXLl5tLly41hw0bxq22PfXAAw+YFRUVptPpNKdOnWp+8MEHVpeU1CR1ezz66KORa1pbW80bbrjBzM/PNzMzM825c+eaBw8etK7oPuTT4YOxjp4XX3zRHDNmjOlyucwRI0aYf/jDH7q8HgqFzDvvvNMsLi42XS6X+cUvftHcunWrRdUmN6/Xa958881mRUWFmZ6ebg4ZMsT8yU9+Yvp8vsg1jHfvvP32293+N3r+/PmmaZ7cuB49etS86qqrzOzsbDM3N9e89tprzcbGxlOuzTDNT2wjBwAAEGMp0fMBAAASB+EDAADEFeEDAADEFeEDAADEFeEDAADEFeEDAADEFeEDAADEFeEDAADEFeEDAADEFeEDAADEFeEDAADEFeEDAADE1f8HYe5KVlqOF8MAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "IzvmfccbKf73",
        "outputId": "2478466b-652d-4c0a-dbbe-4113ca50124c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      account_id   raw_amount        amount    td  \\\n",
              "0              0 -1339.810791     14.600000   0.0   \n",
              "1              0 -4855.853027   2300.000000  20.0   \n",
              "2              0  -128.370224  13974.402344   0.0   \n",
              "3              0  2977.615234  16976.861328   2.0   \n",
              "4              0 -2092.325928   1800.000000   2.0   \n",
              "...          ...          ...           ...   ...   \n",
              "5995          19   -14.600000   3119.769531  11.0   \n",
              "5996          19   -14.600000    201.256790  11.0   \n",
              "5997          19    89.025810    263.740967   1.0   \n",
              "5998          19   108.768700   1400.000000   6.0   \n",
              "5999          19   154.589844  11064.394531   0.0   \n",
              "\n",
              "                                                tcode    datetime  \n",
              "0           CREDIT__COLLECTION FROM ANOTHER BANK__nan  1995-11-17  \n",
              "1                         DEBIT__CASH WITHDRAWAL__nan  1995-12-17  \n",
              "2     DEBIT__REMITTANCE TO ANOTHER BANK__LOAN PAYMENT  1995-12-24  \n",
              "3                         CREDIT__CREDIT IN CASH__nan  1996-01-06  \n",
              "4                         DEBIT__CASH WITHDRAWAL__nan  1996-01-23  \n",
              "...                                               ...         ...  \n",
              "5995                   CREDIT__nan__INTEREST CREDITED  1993-03-26  \n",
              "5996                   CREDIT__nan__INTEREST CREDITED  1993-04-03  \n",
              "5997                   CREDIT__nan__INTEREST CREDITED  1993-04-04  \n",
              "5998        CREDIT__COLLECTION FROM ANOTHER BANK__nan  1993-04-19  \n",
              "5999     DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD  1993-04-28  \n",
              "\n",
              "[5997 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ced32dc-8c80-41e2-ac70-66420ba42373\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_id</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>amount</th>\n",
              "      <th>td</th>\n",
              "      <th>tcode</th>\n",
              "      <th>datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1339.810791</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__nan</td>\n",
              "      <td>1995-11-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>-4855.853027</td>\n",
              "      <td>2300.000000</td>\n",
              "      <td>20.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
              "      <td>1995-12-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>-128.370224</td>\n",
              "      <td>13974.402344</td>\n",
              "      <td>0.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__LOAN PAYMENT</td>\n",
              "      <td>1995-12-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>2977.615234</td>\n",
              "      <td>16976.861328</td>\n",
              "      <td>2.0</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>1996-01-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>-2092.325928</td>\n",
              "      <td>1800.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
              "      <td>1996-01-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>19</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>3119.769531</td>\n",
              "      <td>11.0</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>1993-03-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>19</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>201.256790</td>\n",
              "      <td>11.0</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>1993-04-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>19</td>\n",
              "      <td>89.025810</td>\n",
              "      <td>263.740967</td>\n",
              "      <td>1.0</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>1993-04-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>19</td>\n",
              "      <td>108.768700</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__nan</td>\n",
              "      <td>1993-04-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>19</td>\n",
              "      <td>154.589844</td>\n",
              "      <td>11064.394531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD</td>\n",
              "      <td>1993-04-28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5997 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ced32dc-8c80-41e2-ac70-66420ba42373')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ced32dc-8c80-41e2-ac70-66420ba42373 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ced32dc-8c80-41e2-ac70-66420ba42373');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ebdb7260-23e2-46a1-9779-199fd17073fa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebdb7260-23e2-46a1-9779-199fd17073fa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ebdb7260-23e2-46a1-9779-199fd17073fa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a30f79b8-cc68-45df-9895-d9ace749c06e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a30f79b8-cc68-45df-9895-d9ace749c06e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('final_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_df",
              "summary": "{\n  \"name\": \"final_df\",\n  \"rows\": 5997,\n  \"fields\": [\n    {\n      \"column\": \"account_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 19,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0,\n          17,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_amount\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4723,\n        \"samples\": [\n          6852.958984375,\n          30077.904296875,\n          -11889.259765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"amount\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5036,\n        \"samples\": [\n          3232.790771484375,\n          5954.13720703125,\n          2547.914306640625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"td\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 191,\n        \"samples\": [\n          9.442549705505371,\n          15.578995704650879,\n          1.2655320167541504\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tcode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"CREDIT__COLLECTION FROM ANOTHER BANK__nan\",\n          \"DEBIT__CASH WITHDRAWAL__nan\",\n          \"CREDIT__nan__INTEREST CREDITED\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1993-01-01\",\n        \"max\": \"1998-12-31\",\n        \"num_unique_values\": 1829,\n        \"samples\": [\n          \"1998-09-04\",\n          \"1993-12-25\",\n          \"1998-03-25\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apparanetely in the above model the temporal datetime is not learn by the model but by manaully handled function called create_realistic_datetime_sequences, in the following model we tried to let the model learn this datetime temporal"
      ],
      "metadata": {
        "id": "eALMXbuhzR-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Params yet\n",
        "\n",
        "# sequence_length = 80\n",
        "# min_seq_length = 80\n",
        "# cat_emb_dim = 4\n",
        "# mlp_layers = [128, 128]\n",
        "# diffusion_steps = 1000\n",
        "# diffusion_beta_start = 1e-4\n",
        "# diffusion_beta_end = 0.02\n",
        "# scheduler = 'exp'\n",
        "# epochs = 100\n",
        "# batch_size = 256\n",
        "# learning_rate = 2e-4\n",
        "# n_sequences = 5000\n",
        "\n",
        "\n",
        "\n",
        "# {'tcode': 0.02724600259173137,\n",
        "#  'day': 0.10728971896725675,\n",
        "#  'month': 0.0020343577502627227}\n",
        "\n",
        "# {'amount': {'wasser': np.float64(1078.7188140685037),\n",
        "#   'ks': np.float64(0.14036134959103302),\n",
        "#   'energy_d': np.float64(8.03362420434327)},\n",
        "#  'td': {'wasser': np.float64(0.5088207747652229),\n",
        "#   'ks': np.float64(0.05544429794001818),\n",
        "#   'energy_d': np.float64(0.17564403289333103)},\n",
        "#  'CF': {'wasser': np.float64(7657.992439824109),\n",
        "#   'ks': np.float64(0.17410183748396918),\n",
        "#   'energy_d': np.float64(37.93647132040205)}}\n",
        "\n",
        "#   tcode-3g= 'jsd': 0.22564342434399481,"
      ],
      "metadata": {
        "id": "-0M0hIvh26hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import calendar\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION\n",
        "# =============================================================================\n",
        "seed = 1234\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Model hyperparameters\n",
        "# sequence_length = 80\n",
        "# min_seq_length = 80\n",
        "# cat_emb_dim = 4\n",
        "# mlp_layers = [64, 64]\n",
        "# diffusion_steps = 1000\n",
        "# diffusion_beta_start = 1e-4\n",
        "# diffusion_beta_end = 0.02\n",
        "# scheduler = 'exp'\n",
        "# epochs = 100\n",
        "# batch_size = 256\n",
        "# learning_rate = 2e-4\n",
        "# n_sequences = 5000\n",
        "\n",
        "sequence_length = 80\n",
        "min_seq_length = 80\n",
        "cat_emb_dim = 4\n",
        "mlp_layers = [128, 128]\n",
        "diffusion_steps = 1000\n",
        "diffusion_beta_start = 1e-4\n",
        "diffusion_beta_end = 0.02\n",
        "scheduler = 'exp'\n",
        "epochs = 100\n",
        "batch_size = 256\n",
        "learning_rate = 2e-4\n",
        "n_sequences = 5000\n",
        "\n",
        "# =============================================================================\n",
        "# STUDENT-T DISTRIBUTION DDPM DIFFUSER\n",
        "# =============================================================================\n",
        "class StudentTDDPMDiffuser(object):\n",
        "    def __init__(self, total_steps=1000, beta_start=1e-4, beta_end=0.02, device='cpu', scheduler='exp', df=30):\n",
        "        self.total_steps = total_steps\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.device = device\n",
        "        self.df = df\n",
        "\n",
        "        self.alphas, self.betas = self.prepare_noise_schedule(scheduler=scheduler)\n",
        "        self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "    def prepare_noise_schedule(self, scheduler: str):\n",
        "        scale = 1000 / self.total_steps\n",
        "        beta_start = scale * self.beta_start\n",
        "        beta_end = scale * self.beta_end\n",
        "\n",
        "        if scheduler == 'linear':\n",
        "            betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "        elif scheduler == 'quad':\n",
        "            betas = torch.linspace(self.beta_start**0.5, self.beta_end**0.5, self.total_steps) ** 2\n",
        "        elif scheduler == 'exp':\n",
        "            betas = torch.exp(torch.linspace(math.log(beta_start), math.log(beta_end), self.total_steps))\n",
        "        elif scheduler == 'sigm':\n",
        "            x = torch.linspace(-6, 6, self.total_steps)\n",
        "            betas = torch.sigmoid(x) * (beta_end - beta_start) + beta_start\n",
        "\n",
        "        alphas = 1.0 - betas\n",
        "        return alphas.to(self.device), betas.to(self.device)\n",
        "\n",
        "    def sample_random_timesteps(self, n: int):\n",
        "        return torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "\n",
        "    def sample_student_t(self, shape):\n",
        "        if isinstance(shape, torch.Tensor):\n",
        "            shape = tuple(shape.tolist())\n",
        "\n",
        "        x = torch.randn(shape, device=self.device)\n",
        "        df_sample = max(3.0, float(self.df))\n",
        "        gamma_shape = df_sample / 2.0\n",
        "        gamma_samples = torch.tensor(stats.gamma.rvs(gamma_shape, scale=2.0, size=shape[0]),\n",
        "                                     dtype=torch.float32, device=self.device).view(-1, 1, 1)\n",
        "\n",
        "        scaling = torch.sqrt(torch.tensor(df_sample / (df_sample - 2.0), device=self.device))\n",
        "        t_noise = scaling * x / torch.sqrt(gamma_samples / df_sample)\n",
        "        return t_noise\n",
        "\n",
        "    def add_t_noise(self, x_num, t):\n",
        "        sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None, None]\n",
        "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None, None]\n",
        "\n",
        "        noise_num = self.sample_student_t(x_num.shape)\n",
        "        x_noise_num = sqrt_alpha_hat * x_num + sqrt_one_minus_alpha_hat * noise_num\n",
        "        return x_noise_num, noise_num\n",
        "\n",
        "    def p_sample_t(self, model_out, z_norm, timesteps):\n",
        "        sqrt_alpha_t = torch.sqrt(self.alphas[timesteps])[:, None, None]\n",
        "        betas_t = self.betas[timesteps][:, None, None]\n",
        "        sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[timesteps])[:, None, None]\n",
        "        epsilon_t = torch.sqrt(self.betas[timesteps][:, None, None])\n",
        "\n",
        "        random_noise = self.sample_student_t(z_norm.shape)\n",
        "        random_noise[timesteps == 0] = 0.0\n",
        "\n",
        "        model_mean = ((1 / sqrt_alpha_t) * (z_norm - (betas_t * model_out / sqrt_one_minus_alpha_hat_t)))\n",
        "        z_norm = model_mean + (epsilon_t * random_noise)\n",
        "        return z_norm\n",
        "\n",
        "    def sample(self, model_out, z_norm, timesteps):\n",
        "        return self.p_sample_t(model_out, z_norm, timesteps)\n",
        "\n",
        "# =============================================================================\n",
        "# ENHANCED DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "def preprocess_data_czech(df):\n",
        "    \"\"\"Enhanced preprocessing with proper temporal features\"\"\"\n",
        "    czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "    df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "    df[\"month\"] = df[\"datetime\"].dt.month\n",
        "    df[\"day\"] = df[\"datetime\"].dt.day\n",
        "    df[\"dow\"] = df[\"datetime\"].dt.dayofweek\n",
        "    df[\"year\"] = df[\"datetime\"].dt.year\n",
        "    df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "    df_sorted = df.sort_values(['account_id', 'datetime']).copy()\n",
        "\n",
        "    # Calculate time differences - this is what the model should learn!\n",
        "    df_sorted[\"td\"] = df_sorted.groupby(\"account_id\")[\"datetime\"].diff().dt.days\n",
        "    df_sorted[\"td\"].fillna(0.0, inplace=True)\n",
        "\n",
        "    # Days to month end\n",
        "    df_sorted[\"dtme\"] = df_sorted.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "\n",
        "    # Raw amount (signed)\n",
        "    df_sorted['raw_amount'] = df_sorted.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "    # Transaction code\n",
        "    cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "    tcode = df_sorted[cat_code_fields[0]].astype(str)\n",
        "    for ccf in cat_code_fields[1:]:\n",
        "        tcode += \"__\" + df_sorted[ccf].astype(str)\n",
        "    df_sorted[\"tcode\"] = tcode\n",
        "\n",
        "    # Day of month categories\n",
        "    conditions = [\n",
        "        (df_sorted['day'] >= 1) & (df_sorted['day'] <= 10),\n",
        "        (df_sorted['day'] > 10) & (df_sorted['day'] <= 20),\n",
        "        (df_sorted['day'] > 20) & (df_sorted['day'] <= 31)\n",
        "    ]\n",
        "    categories = ['first', 'middle', 'last']\n",
        "    df_sorted['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "    # Age groups\n",
        "    if 'age' in df_sorted.columns:\n",
        "        bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "        labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "        df_sorted['age_group'] = pd.cut(df_sorted['age'], bins=bin_edges, labels=labels, right=False)\n",
        "        df_sorted['age_group'] = df_sorted['age_group'].astype('object').fillna('unknown')\n",
        "    else:\n",
        "        df_sorted['age_group'] = 'unknown'\n",
        "\n",
        "    return df_sorted\n",
        "\n",
        "# =============================================================================\n",
        "# TEMPORAL-AWARE DATASET\n",
        "# =============================================================================\n",
        "class TemporalSequentialDataset(Dataset):\n",
        "    \"\"\"Dataset that preserves temporal dependencies within sequences\"\"\"\n",
        "    def __init__(self, df, cat_attrs, num_attrs, sequence_length=30, min_seq_length=20, max_sequences_per_account=5):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.min_seq_length = min_seq_length\n",
        "        self.cat_attrs = cat_attrs\n",
        "        self.num_attrs = num_attrs\n",
        "        self.sequences = []\n",
        "\n",
        "        print(\"Creating temporal sequences from transaction data...\")\n",
        "\n",
        "        for account_id in tqdm(df['account_id'].unique()):\n",
        "            account_data = df[df['account_id'] == account_id].sort_values('datetime').reset_index(drop=True)\n",
        "            if len(account_data) >= min_seq_length:\n",
        "                # Sample sequences that maintain temporal order\n",
        "                n_possible = len(account_data) - sequence_length + 1\n",
        "                if n_possible <= max_sequences_per_account:\n",
        "                    start_indices = range(n_possible)\n",
        "                else:\n",
        "                    start_indices = np.linspace(0, n_possible-1, max_sequences_per_account, dtype=int)\n",
        "\n",
        "                for start_idx in start_indices:\n",
        "                    seq_data = account_data.iloc[start_idx:start_idx+sequence_length]\n",
        "                    cat_data = seq_data[self.cat_attrs].values\n",
        "                    num_data = seq_data[self.num_attrs].values\n",
        "                    self.sequences.append({'cat_data': cat_data, 'num_data': num_data})\n",
        "\n",
        "        print(f\"Created {len(self.sequences)} temporal sequences from {df['account_id'].nunique()} accounts.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        cat_tensor = torch.LongTensor(seq['cat_data'])\n",
        "        num_tensor = torch.FloatTensor(seq['num_data'])\n",
        "        return cat_tensor, num_tensor\n",
        "\n",
        "# =============================================================================\n",
        "# TEMPORAL LSTM SYNTHESIZER\n",
        "# =============================================================================\n",
        "class TemporalLSTMSynthesizer(nn.Module):\n",
        "    \"\"\"LSTM that learns temporal dependencies including td and datetime components\"\"\"\n",
        "    def __init__(self, n_cat_features, n_cat_tokens, cat_emb_dim, n_num_features,\n",
        "                 hidden_dim=256, lstm_layers=2, dim_t=64):\n",
        "        super(TemporalLSTMSynthesizer, self).__init__()\n",
        "        self.n_cat_features = n_cat_features\n",
        "        self.n_num_features = n_num_features\n",
        "        self.cat_emb_dim = cat_emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dim_t = dim_t\n",
        "\n",
        "        # Categorical embeddings\n",
        "        self.cat_embeddings = nn.ModuleList([\n",
        "            nn.Embedding(n_cat_tokens[i], cat_emb_dim) for i in range(n_cat_features)\n",
        "        ])\n",
        "\n",
        "        total_cat_emb_dim = n_cat_features * cat_emb_dim\n",
        "        total_input_dim = total_cat_emb_dim + n_num_features\n",
        "\n",
        "        # Time embedding for diffusion\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(dim_t, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        # Input projection\n",
        "        self.input_projection = nn.Linear(total_input_dim, hidden_dim)\n",
        "\n",
        "        # LSTM with attention to temporal patterns\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=0.1 if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Separate heads for different outputs\n",
        "        self.cat_heads = nn.ModuleList([\n",
        "            nn.Linear(hidden_dim, n_cat_tokens[i]) for i in range(n_cat_features)\n",
        "        ])\n",
        "        self.num_head = nn.Linear(hidden_dim, n_num_features)\n",
        "\n",
        "        # Temporal consistency layer\n",
        "        self.temporal_consistency = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "        half = dim_out // 2\n",
        "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half).to(device)\n",
        "        args = timesteps[:, None].float() * freqs[None]\n",
        "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "        if dim_out % 2:\n",
        "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "        return embedding\n",
        "\n",
        "    def embed_categorical(self, x_cat):\n",
        "        embeddings = []\n",
        "        for i in range(self.n_cat_features):\n",
        "            embeddings.append(self.cat_embeddings[i](x_cat[:, :, i]))\n",
        "        return torch.cat(embeddings, dim=-1)\n",
        "\n",
        "    def forward(self, x_cat, x_num, timesteps):\n",
        "        batch_size, seq_len, _ = x_num.shape\n",
        "\n",
        "        # Embed categorical features\n",
        "        cat_emb = self.embed_categorical(x_cat)\n",
        "\n",
        "        # Combine with numerical features\n",
        "        x = torch.cat([cat_emb, x_num], dim=-1)\n",
        "\n",
        "        # Project input\n",
        "        x_proj = self.input_projection(x)\n",
        "\n",
        "        # Time embedding for diffusion process\n",
        "        time_emb_raw = self.embed_time(timesteps, self.dim_t)\n",
        "        time_emb = self.time_embed(time_emb_raw)\n",
        "        time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "        # Add temporal consistency\n",
        "        x_with_time = x_proj + time_emb\n",
        "        x_temporal = self.temporal_consistency(x_with_time)\n",
        "\n",
        "        # LSTM processing - this learns the temporal dependencies\n",
        "        lstm_out, _ = self.lstm(x_temporal)\n",
        "\n",
        "        # Generate outputs\n",
        "        cat_outputs = [head(lstm_out) for head in self.cat_heads]\n",
        "        num_output = self.num_head(lstm_out)\n",
        "\n",
        "        return cat_outputs, num_output\n",
        "\n",
        "# =============================================================================\n",
        "# TRAINING AND GENERATION\n",
        "# =============================================================================\n",
        "def train_model(model, diffuser, dataloader, epochs, optimizer, scheduler):\n",
        "    model.train()\n",
        "    cat_criterion = nn.CrossEntropyLoss()\n",
        "    num_criterion = nn.MSELoss()\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for batch_cat, batch_num in pbar:\n",
        "            batch_cat, batch_num = batch_cat.to(device), batch_num.to(device)\n",
        "            batch_size = batch_cat.shape[0]\n",
        "\n",
        "            timesteps = diffuser.sample_random_timesteps(batch_size)\n",
        "            noisy_num, noise_target = diffuser.add_t_noise(batch_num, timesteps)\n",
        "\n",
        "            cat_outputs, num_output = model(batch_cat, noisy_num, timesteps)\n",
        "\n",
        "            # Calculate losses\n",
        "            cat_loss = sum(cat_criterion(cat_out.view(-1, cat_out.size(-1)),\n",
        "                                       batch_cat[:, :, i].view(-1))\n",
        "                          for i, cat_out in enumerate(cat_outputs))\n",
        "\n",
        "            num_loss = num_criterion(num_output, noise_target)\n",
        "            total_loss = cat_loss + num_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += total_loss.item()\n",
        "            pbar.set_postfix({'Loss': f\"{total_loss.item():.4f}\"})\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Avg Loss: {avg_loss:.4f} - LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "        scheduler.step()\n",
        "\n",
        "    return losses\n",
        "\n",
        "def generate_sequences(model, diffuser, n_sequences, seq_len, n_cat_features,\n",
        "                      n_cat_tokens, n_num_features, device):\n",
        "    \"\"\"Generate sequences letting the model control ALL temporal aspects\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize with random categorical data\n",
        "    x_cat = torch.zeros(n_sequences, seq_len, n_cat_features, dtype=torch.long, device=device)\n",
        "    for i, n_tokens in enumerate(n_cat_tokens):\n",
        "        x_cat[:, :, i] = torch.randint(0, n_tokens, (n_sequences, seq_len), device=device)\n",
        "\n",
        "    # Start with noise for numerical features (including td!)\n",
        "    x_num = diffuser.sample_student_t((n_sequences, seq_len, n_num_features))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for t in tqdm(reversed(range(diffuser.total_steps)), desc=\"Generating\"):\n",
        "            timesteps = torch.full((n_sequences,), t, device=device, dtype=torch.long)\n",
        "\n",
        "            # Model predicts both categorical and numerical features\n",
        "            cat_outputs, num_output = model(x_cat, x_num, timesteps)\n",
        "\n",
        "            # Update numerical features (including td) through diffusion\n",
        "            x_num = diffuser.sample(num_output, x_num, timesteps)\n",
        "\n",
        "            # Update categorical features less frequently for stability\n",
        "            if t % 100 == 0:\n",
        "                for i, cat_out in enumerate(cat_outputs):\n",
        "                    probs = torch.softmax(cat_out, dim=-1)\n",
        "                    x_cat[:, :, i] = torch.multinomial(probs.view(-1, probs.size(-1)), 1).view(n_sequences, seq_len)\n",
        "\n",
        "    return x_cat, x_num\n",
        "\n",
        "# def create_dataframe_from_generated(generated_cat, generated_num, cat_attrs, num_attrs,\n",
        "#                                   label_encoders, num_scaler, sequence_length):\n",
        "#     \"\"\"Convert generated sequences to dataframe with proper datetime reconstruction\"\"\"\n",
        "#     final_sequences = []\n",
        "\n",
        "#     for seq_idx in range(generated_cat.shape[0]):\n",
        "#         # Inverse transform numerical data\n",
        "#         seq_num = generated_num[seq_idx].cpu().numpy()\n",
        "#         seq_num_original = num_scaler.inverse_transform(seq_num)\n",
        "\n",
        "#         # Inverse transform categorical data\n",
        "#         seq_cat = generated_cat[seq_idx].cpu().numpy()\n",
        "\n",
        "#         # Create sequence dataframe\n",
        "#         seq_df = pd.DataFrame()\n",
        "\n",
        "#         # Add numerical features\n",
        "#         for i, col in enumerate(num_attrs):\n",
        "#             seq_df[col] = seq_num_original[:, i]\n",
        "\n",
        "#         # Add categorical features\n",
        "#         for i, col in enumerate(cat_attrs):\n",
        "#             seq_df[col] = label_encoders[col].inverse_transform(seq_cat[:, i])\n",
        "\n",
        "#         # Reconstruct datetime from components using the model's learned td\n",
        "#         seq_df['year'] = seq_df['year'].astype(int)\n",
        "#         seq_df['month'] = seq_df['month'].astype(int)\n",
        "#         seq_df['day'] = seq_df['day'].astype(int)\n",
        "\n",
        "#         # Start with first transaction date\n",
        "#         first_date = datetime(seq_df['year'].iloc[0], seq_df['month'].iloc[0], seq_df['day'].iloc[0])\n",
        "#         dates = [first_date]\n",
        "\n",
        "#         # Use the model's generated td values for subsequent dates\n",
        "#         for i in range(1, len(seq_df)):\n",
        "#             td_days = max(0, int(seq_df['td'].iloc[i]))  # Ensure non-negative\n",
        "#             next_date = dates[-1] + timedelta(days=td_days)\n",
        "#             dates.append(next_date)\n",
        "\n",
        "#         seq_df['datetime'] = dates\n",
        "#         seq_df['account_id'] = seq_idx\n",
        "#         final_sequences.append(seq_df)\n",
        "\n",
        "#     return pd.concat(final_sequences, ignore_index=True)\n",
        "\n",
        "\n",
        "def create_dataframe_from_generated(generated_cat, generated_num, cat_attrs, num_attrs,\n",
        "                                  label_encoders, num_scaler, sequence_length):\n",
        "    \"\"\"Convert generated sequences to dataframe with proper datetime reconstruction\"\"\"\n",
        "    import calendar\n",
        "    from datetime import datetime, timedelta\n",
        "    import pandas as pd\n",
        "\n",
        "    def validate_and_fix_date(year, month, day):\n",
        "        \"\"\"Validate and fix date components to ensure valid date\"\"\"\n",
        "        year = max(1900, min(2100, int(year)))  # Reasonable year range\n",
        "        month = max(1, min(12, int(month)))     # Month must be 1-12\n",
        "\n",
        "        # Get maximum valid day for this month/year\n",
        "        max_day = calendar.monthrange(year, month)[1]\n",
        "        day = max(1, min(max_day, int(day)))    # Day must be valid for the month\n",
        "\n",
        "        return year, month, day\n",
        "\n",
        "    final_sequences = []\n",
        "\n",
        "    for seq_idx in range(generated_cat.shape[0]):\n",
        "        # Inverse transform numerical data\n",
        "        seq_num = generated_num[seq_idx].cpu().numpy()\n",
        "        seq_num_original = num_scaler.inverse_transform(seq_num)\n",
        "\n",
        "        # Inverse transform categorical data\n",
        "        seq_cat = generated_cat[seq_idx].cpu().numpy()\n",
        "\n",
        "        # Create sequence dataframe\n",
        "        seq_df = pd.DataFrame()\n",
        "\n",
        "        # Add numerical features\n",
        "        for i, col in enumerate(num_attrs):\n",
        "            seq_df[col] = seq_num_original[:, i]\n",
        "\n",
        "        # Add categorical features\n",
        "        for i, col in enumerate(cat_attrs):\n",
        "            seq_df[col] = label_encoders[col].inverse_transform(seq_cat[:, i])\n",
        "\n",
        "        # Validate and fix date components\n",
        "        seq_df['year'] = seq_df['year'].astype(int)\n",
        "        seq_df['month'] = seq_df['month'].astype(int)\n",
        "        seq_df['day'] = seq_df['day'].astype(int)\n",
        "\n",
        "        # Fix the first date with validation\n",
        "        try:\n",
        "            first_year, first_month, first_day = validate_and_fix_date(\n",
        "                seq_df['year'].iloc[0],\n",
        "                seq_df['month'].iloc[0],\n",
        "                seq_df['day'].iloc[0]\n",
        "            )\n",
        "            first_date = datetime(first_year, first_month, first_day)\n",
        "        except Exception as e:\n",
        "            # Fallback to a default date if validation still fails\n",
        "            print(f\"Warning: Could not create valid first date for sequence {seq_idx}, using default date\")\n",
        "            first_date = datetime(2020, 1, 1)\n",
        "\n",
        "        dates = [first_date]\n",
        "\n",
        "        # Use the model's generated td values for subsequent dates\n",
        "        for i in range(1, len(seq_df)):\n",
        "            td_days = max(0, int(seq_df['td'].iloc[i]))  # Ensure non-negative\n",
        "            next_date = dates[-1] + timedelta(days=td_days)\n",
        "            dates.append(next_date)\n",
        "\n",
        "        seq_df['datetime'] = dates\n",
        "        seq_df['account_id'] = seq_idx\n",
        "        final_sequences.append(seq_df)\n",
        "\n",
        "    return pd.concat(final_sequences, ignore_index=True)\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN EXECUTION\n",
        "# =============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    try:\n",
        "        real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: CSV file not found.\")\n",
        "        exit()\n",
        "\n",
        "    raw_data = preprocess_data_czech(real)\n",
        "    raw_data = raw_data.sort_values(by=[\"account_id\", \"date\"])\n",
        "\n",
        "    # Define features - td is now a numerical feature the model learns!\n",
        "    cat_attrs = ['tcode', 'dow', 'month', 'day', 'year', 'DoM_cat', 'age_group']\n",
        "    num_attrs = ['amount', 'raw_amount', 'td']  # td is learned by the model!\n",
        "\n",
        "    df_processed = raw_data[cat_attrs + num_attrs + ['account_id', 'datetime']].copy()\n",
        "\n",
        "    # Encode features\n",
        "    label_encoders = {}\n",
        "    n_cat_tokens = []\n",
        "    for attr in cat_attrs:\n",
        "        le = LabelEncoder()\n",
        "        df_processed[attr] = le.fit_transform(df_processed[attr].astype(str))\n",
        "        label_encoders[attr] = le\n",
        "        n_cat_tokens.append(len(le.classes_))\n",
        "\n",
        "    num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "    df_processed[num_attrs] = num_scaler.fit_transform(df_processed[num_attrs])\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = TemporalSequentialDataset(\n",
        "        df_processed, cat_attrs, num_attrs,\n",
        "        sequence_length, min_seq_length, max_sequences_per_account=3\n",
        "    )\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    # Initialize model\n",
        "    model = TemporalLSTMSynthesizer(\n",
        "        n_cat_features=len(cat_attrs),\n",
        "        n_cat_tokens=n_cat_tokens,\n",
        "        cat_emb_dim=cat_emb_dim,\n",
        "        n_num_features=len(num_attrs),\n",
        "        hidden_dim=mlp_layers[0]\n",
        "    ).to(device)\n",
        "\n",
        "    diffuser = StudentTDDPMDiffuser(\n",
        "        total_steps=diffusion_steps,\n",
        "        beta_start=diffusion_beta_start,\n",
        "        beta_end=diffusion_beta_end,\n",
        "        device=device,\n",
        "        scheduler=scheduler,\n",
        "        df=10\n",
        "    )\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters.\")\n",
        "\n",
        "    # Train model\n",
        "    print(\"Training model to learn temporal dependencies...\")\n",
        "    losses = train_model(model, diffuser, dataloader, epochs, optimizer, scheduler)\n",
        "\n",
        "    # Generate samples\n",
        "    print(\"Generating sequences with learned temporal patterns...\")\n",
        "    generated_cat, generated_num = generate_sequences(\n",
        "        model, diffuser, n_sequences=n_sequences, seq_len=sequence_length,\n",
        "        n_cat_features=len(cat_attrs), n_cat_tokens=n_cat_tokens,\n",
        "        n_num_features=len(num_attrs), device=device\n",
        "    )\n",
        "\n",
        "    # Create final dataframe\n",
        "    final_df = create_dataframe_from_generated(\n",
        "        generated_cat, generated_num, cat_attrs, num_attrs,\n",
        "        label_encoders, num_scaler, sequence_length\n",
        "    )\n",
        "\n",
        "    # Select final columns and clean\n",
        "    final_df = final_df[['account_id', 'raw_amount', 'amount', 'td', 'tcode', 'datetime']].copy()\n",
        "    final_df[\"datetime\"] = final_df[\"datetime\"].dt.date\n",
        "    # final_df['datetime'] = pd.to_datetime(final_df[['year', 'month', 'day']])\n",
        "    # final_df = final_df.dropna(subset=['datetime'])\n",
        "    # final_df['datetime'] = final_df['datetime'].dt.date\n",
        "\n",
        "    print(f\"\\nFinal shape: {final_df.shape}\")\n",
        "    print(\"\\nSample data:\")\n",
        "    print(final_df.head(15))\n",
        "    print(f\"\\nTemporal dependencies learned - td range: {final_df['td'].min():.1f} to {final_df['td'].max():.1f}\")\n",
        "\n",
        "    final_df.to_csv('synthetic_transactions.csv', index=False)\n",
        "    print(\"\\nSynthetic data saved with learned temporal patterns!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBXFCilPtOYH",
        "outputId": "e3d83886-010f-4d0b-894d-f87c285d9059"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Loading and preprocessing data...\n",
            "Creating temporal sequences from transaction data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4500/4500 [00:17<00:00, 258.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 12340 temporal sequences from 4500 accounts.\n",
            "Model has 320,792 parameters.\n",
            "Training model to learn temporal dependencies...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 49/49 [00:01<00:00, 30.15it/s, Loss=15.0781]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Avg Loss: 16.0490 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100: 100%|██████████| 49/49 [00:01<00:00, 32.74it/s, Loss=13.2264]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Avg Loss: 13.9565 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100: 100%|██████████| 49/49 [00:01<00:00, 33.16it/s, Loss=12.3419]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Avg Loss: 12.7612 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100: 100%|██████████| 49/49 [00:01<00:00, 33.41it/s, Loss=11.4474]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Avg Loss: 11.7921 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100: 100%|██████████| 49/49 [00:01<00:00, 33.24it/s, Loss=10.4181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Avg Loss: 10.8541 - LR: 0.000199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100: 100%|██████████| 49/49 [00:01<00:00, 33.21it/s, Loss=9.1300]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Avg Loss: 9.7808 - LR: 0.000199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100: 100%|██████████| 49/49 [00:01<00:00, 32.66it/s, Loss=8.2781]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Avg Loss: 8.8442 - LR: 0.000198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100: 100%|██████████| 49/49 [00:01<00:00, 33.12it/s, Loss=7.6836]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Avg Loss: 8.0683 - LR: 0.000198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100: 100%|██████████| 49/49 [00:01<00:00, 33.05it/s, Loss=7.0122]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Avg Loss: 7.3460 - LR: 0.000197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100: 100%|██████████| 49/49 [00:01<00:00, 32.96it/s, Loss=6.5484]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Avg Loss: 6.7305 - LR: 0.000196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100: 100%|██████████| 49/49 [00:01<00:00, 33.40it/s, Loss=5.9635]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - Avg Loss: 6.1851 - LR: 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100: 100%|██████████| 49/49 [00:01<00:00, 33.22it/s, Loss=5.5121]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - Avg Loss: 5.7203 - LR: 0.000194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/100: 100%|██████████| 49/49 [00:01<00:00, 33.21it/s, Loss=5.1956]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 - Avg Loss: 5.2812 - LR: 0.000193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/100: 100%|██████████| 49/49 [00:01<00:00, 32.75it/s, Loss=4.7597]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 - Avg Loss: 4.9298 - LR: 0.000192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/100: 100%|██████████| 49/49 [00:01<00:00, 32.52it/s, Loss=4.2814]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 - Avg Loss: 4.6100 - LR: 0.000190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/100: 100%|██████████| 49/49 [00:01<00:00, 32.97it/s, Loss=4.1272]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 - Avg Loss: 4.2975 - LR: 0.000189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/100: 100%|██████████| 49/49 [00:01<00:00, 32.72it/s, Loss=3.7057]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 - Avg Loss: 4.0234 - LR: 0.000188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/100: 100%|██████████| 49/49 [00:01<00:00, 33.04it/s, Loss=3.6439]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 - Avg Loss: 3.7497 - LR: 0.000186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/100: 100%|██████████| 49/49 [00:01<00:00, 33.23it/s, Loss=3.5272]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 - Avg Loss: 3.4982 - LR: 0.000184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/100: 100%|██████████| 49/49 [00:01<00:00, 33.19it/s, Loss=3.0600]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 - Avg Loss: 3.2680 - LR: 0.000183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/100: 100%|██████████| 49/49 [00:01<00:00, 32.60it/s, Loss=2.9975]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 - Avg Loss: 3.0605 - LR: 0.000181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/100: 100%|██████████| 49/49 [00:01<00:00, 30.87it/s, Loss=2.7295]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 - Avg Loss: 2.8832 - LR: 0.000179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/100: 100%|██████████| 49/49 [00:01<00:00, 31.16it/s, Loss=2.5786]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 - Avg Loss: 2.7252 - LR: 0.000177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/100: 100%|██████████| 49/49 [00:01<00:00, 31.95it/s, Loss=2.4929]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 - Avg Loss: 2.5892 - LR: 0.000175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/100: 100%|██████████| 49/49 [00:01<00:00, 31.96it/s, Loss=2.4010]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 - Avg Loss: 2.4410 - LR: 0.000173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/100: 100%|██████████| 49/49 [00:01<00:00, 33.00it/s, Loss=2.2607]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 - Avg Loss: 2.3104 - LR: 0.000171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/100: 100%|██████████| 49/49 [00:01<00:00, 32.79it/s, Loss=2.1870]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 - Avg Loss: 2.1999 - LR: 0.000168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/100: 100%|██████████| 49/49 [00:01<00:00, 32.68it/s, Loss=1.9440]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 - Avg Loss: 2.1056 - LR: 0.000166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/100: 100%|██████████| 49/49 [00:01<00:00, 32.30it/s, Loss=1.9174]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 - Avg Loss: 2.0044 - LR: 0.000164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/100: 100%|██████████| 49/49 [00:01<00:00, 26.79it/s, Loss=1.8625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 - Avg Loss: 1.9153 - LR: 0.000161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/100: 100%|██████████| 49/49 [00:01<00:00, 32.38it/s, Loss=1.7839]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 - Avg Loss: 1.8336 - LR: 0.000159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/100: 100%|██████████| 49/49 [00:01<00:00, 32.15it/s, Loss=1.7098]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 - Avg Loss: 1.7579 - LR: 0.000156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/100: 100%|██████████| 49/49 [00:01<00:00, 32.58it/s, Loss=1.7349]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 - Avg Loss: 1.7009 - LR: 0.000154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/100: 100%|██████████| 49/49 [00:01<00:00, 32.64it/s, Loss=1.4152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 - Avg Loss: 1.6235 - LR: 0.000151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/100: 100%|██████████| 49/49 [00:01<00:00, 32.61it/s, Loss=1.7485]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 - Avg Loss: 1.5823 - LR: 0.000148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/100: 100%|██████████| 49/49 [00:01<00:00, 32.40it/s, Loss=1.4565]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 - Avg Loss: 1.5249 - LR: 0.000145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/100: 100%|██████████| 49/49 [00:01<00:00, 32.33it/s, Loss=1.4875]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 - Avg Loss: 1.4786 - LR: 0.000143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/100: 100%|██████████| 49/49 [00:01<00:00, 32.10it/s, Loss=1.4553]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 - Avg Loss: 1.4269 - LR: 0.000140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/100: 100%|██████████| 49/49 [00:01<00:00, 32.12it/s, Loss=1.2136]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 - Avg Loss: 1.3879 - LR: 0.000137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/100: 100%|██████████| 49/49 [00:01<00:00, 32.22it/s, Loss=1.1948]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 - Avg Loss: 1.3520 - LR: 0.000134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/100: 100%|██████████| 49/49 [00:01<00:00, 32.60it/s, Loss=1.3075]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 - Avg Loss: 1.3009 - LR: 0.000131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/100: 100%|██████████| 49/49 [00:01<00:00, 32.16it/s, Loss=1.2678]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 - Avg Loss: 1.2757 - LR: 0.000128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/100: 100%|██████████| 49/49 [00:01<00:00, 32.12it/s, Loss=1.1620]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 - Avg Loss: 1.2337 - LR: 0.000125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/100: 100%|██████████| 49/49 [00:01<00:00, 31.78it/s, Loss=1.1263]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 - Avg Loss: 1.2173 - LR: 0.000122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/100: 100%|██████████| 49/49 [00:01<00:00, 32.00it/s, Loss=1.0779]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 - Avg Loss: 1.1862 - LR: 0.000119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/100: 100%|██████████| 49/49 [00:01<00:00, 31.98it/s, Loss=1.0715]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 - Avg Loss: 1.1546 - LR: 0.000116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/100: 100%|██████████| 49/49 [00:01<00:00, 31.56it/s, Loss=1.2045]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 - Avg Loss: 1.1326 - LR: 0.000113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/100: 100%|██████████| 49/49 [00:01<00:00, 31.81it/s, Loss=1.0986]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 - Avg Loss: 1.1156 - LR: 0.000109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/100: 100%|██████████| 49/49 [00:01<00:00, 32.17it/s, Loss=1.1331]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 - Avg Loss: 1.0948 - LR: 0.000106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/100: 100%|██████████| 49/49 [00:01<00:00, 32.11it/s, Loss=1.0914]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 - Avg Loss: 1.0880 - LR: 0.000103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51/100: 100%|██████████| 49/49 [00:01<00:00, 32.09it/s, Loss=1.0915]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51 - Avg Loss: 1.0659 - LR: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52/100: 100%|██████████| 49/49 [00:01<00:00, 31.72it/s, Loss=0.9649]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 - Avg Loss: 1.0528 - LR: 0.000097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53/100: 100%|██████████| 49/49 [00:01<00:00, 32.33it/s, Loss=1.0402]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53 - Avg Loss: 1.0236 - LR: 0.000094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54/100: 100%|██████████| 49/49 [00:01<00:00, 31.93it/s, Loss=1.0095]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54 - Avg Loss: 1.0162 - LR: 0.000091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55/100: 100%|██████████| 49/49 [00:01<00:00, 30.06it/s, Loss=0.9885]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55 - Avg Loss: 1.0080 - LR: 0.000087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56/100: 100%|██████████| 49/49 [00:01<00:00, 30.50it/s, Loss=1.0695]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 - Avg Loss: 0.9938 - LR: 0.000084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57/100: 100%|██████████| 49/49 [00:01<00:00, 31.72it/s, Loss=0.8958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57 - Avg Loss: 0.9810 - LR: 0.000081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58/100: 100%|██████████| 49/49 [00:01<00:00, 32.31it/s, Loss=1.0168]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58 - Avg Loss: 0.9746 - LR: 0.000078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59/100: 100%|██████████| 49/49 [00:01<00:00, 31.97it/s, Loss=1.0659]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59 - Avg Loss: 0.9511 - LR: 0.000075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60/100: 100%|██████████| 49/49 [00:01<00:00, 32.26it/s, Loss=0.9201]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60 - Avg Loss: 0.9460 - LR: 0.000072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 61/100: 100%|██████████| 49/49 [00:01<00:00, 32.16it/s, Loss=0.8890]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61 - Avg Loss: 0.9358 - LR: 0.000069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 62/100: 100%|██████████| 49/49 [00:01<00:00, 31.56it/s, Loss=0.9419]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62 - Avg Loss: 0.9321 - LR: 0.000066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 63/100: 100%|██████████| 49/49 [00:01<00:00, 32.26it/s, Loss=1.0550]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 - Avg Loss: 0.9171 - LR: 0.000063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 64/100: 100%|██████████| 49/49 [00:01<00:00, 32.31it/s, Loss=1.0534]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64 - Avg Loss: 0.9105 - LR: 0.000060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 65/100: 100%|██████████| 49/49 [00:01<00:00, 32.25it/s, Loss=1.0125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65 - Avg Loss: 0.9095 - LR: 0.000057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 66/100: 100%|██████████| 49/49 [00:01<00:00, 31.78it/s, Loss=0.9137]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66 - Avg Loss: 0.8956 - LR: 0.000055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 67/100: 100%|██████████| 49/49 [00:01<00:00, 31.60it/s, Loss=0.8699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67 - Avg Loss: 0.8870 - LR: 0.000052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 68/100: 100%|██████████| 49/49 [00:01<00:00, 31.65it/s, Loss=0.8697]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68 - Avg Loss: 0.8795 - LR: 0.000049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 69/100: 100%|██████████| 49/49 [00:01<00:00, 31.65it/s, Loss=0.8312]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69 - Avg Loss: 0.8783 - LR: 0.000046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 70/100: 100%|██████████| 49/49 [00:01<00:00, 31.49it/s, Loss=0.9079]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 - Avg Loss: 0.8768 - LR: 0.000044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 71/100: 100%|██████████| 49/49 [00:01<00:00, 32.12it/s, Loss=0.8883]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71 - Avg Loss: 0.8624 - LR: 0.000041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72/100: 100%|██████████| 49/49 [00:01<00:00, 32.05it/s, Loss=0.8503]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72 - Avg Loss: 0.8645 - LR: 0.000039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73/100: 100%|██████████| 49/49 [00:01<00:00, 31.97it/s, Loss=0.7937]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73 - Avg Loss: 0.8561 - LR: 0.000036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74/100: 100%|██████████| 49/49 [00:01<00:00, 26.30it/s, Loss=0.8305]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74 - Avg Loss: 0.8548 - LR: 0.000034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75/100: 100%|██████████| 49/49 [00:01<00:00, 31.84it/s, Loss=0.8367]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75 - Avg Loss: 0.8538 - LR: 0.000032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76/100: 100%|██████████| 49/49 [00:01<00:00, 31.68it/s, Loss=0.9356]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76 - Avg Loss: 0.8504 - LR: 0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 77/100: 100%|██████████| 49/49 [00:01<00:00, 30.94it/s, Loss=0.8401]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 - Avg Loss: 0.8426 - LR: 0.000027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 78/100: 100%|██████████| 49/49 [00:01<00:00, 31.91it/s, Loss=0.8526]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78 - Avg Loss: 0.8413 - LR: 0.000025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 79/100: 100%|██████████| 49/49 [00:01<00:00, 31.87it/s, Loss=0.8111]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79 - Avg Loss: 0.8433 - LR: 0.000023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 80/100: 100%|██████████| 49/49 [00:01<00:00, 31.92it/s, Loss=0.7162]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80 - Avg Loss: 0.8299 - LR: 0.000021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 81/100: 100%|██████████| 49/49 [00:01<00:00, 31.51it/s, Loss=0.7952]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81 - Avg Loss: 0.8361 - LR: 0.000019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 82/100: 100%|██████████| 49/49 [00:01<00:00, 31.91it/s, Loss=0.8726]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82 - Avg Loss: 0.8319 - LR: 0.000017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 83/100: 100%|██████████| 49/49 [00:01<00:00, 31.91it/s, Loss=0.8204]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83 - Avg Loss: 0.8312 - LR: 0.000016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 84/100: 100%|██████████| 49/49 [00:01<00:00, 31.10it/s, Loss=1.0901]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 - Avg Loss: 0.8425 - LR: 0.000014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 85/100: 100%|██████████| 49/49 [00:01<00:00, 31.43it/s, Loss=0.8351]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85 - Avg Loss: 0.8251 - LR: 0.000012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86/100: 100%|██████████| 49/49 [00:01<00:00, 31.90it/s, Loss=0.7711]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86 - Avg Loss: 0.8226 - LR: 0.000011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87/100: 100%|██████████| 49/49 [00:01<00:00, 31.64it/s, Loss=0.7513]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87 - Avg Loss: 0.8182 - LR: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88/100: 100%|██████████| 49/49 [00:01<00:00, 30.99it/s, Loss=0.8999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88 - Avg Loss: 0.8174 - LR: 0.000008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89/100: 100%|██████████| 49/49 [00:01<00:00, 31.39it/s, Loss=1.0241]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89 - Avg Loss: 0.8189 - LR: 0.000007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90/100: 100%|██████████| 49/49 [00:01<00:00, 31.29it/s, Loss=0.8398]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 - Avg Loss: 0.8108 - LR: 0.000006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 91/100: 100%|██████████| 49/49 [00:01<00:00, 30.78it/s, Loss=0.9070]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91 - Avg Loss: 0.8223 - LR: 0.000005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92/100: 100%|██████████| 49/49 [00:01<00:00, 30.49it/s, Loss=0.8793]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92 - Avg Loss: 0.8162 - LR: 0.000004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93/100: 100%|██████████| 49/49 [00:01<00:00, 30.10it/s, Loss=0.8197]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93 - Avg Loss: 0.8130 - LR: 0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94/100: 100%|██████████| 49/49 [00:01<00:00, 29.88it/s, Loss=0.8100]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94 - Avg Loss: 0.8057 - LR: 0.000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95/100: 100%|██████████| 49/49 [00:01<00:00, 30.44it/s, Loss=0.8104]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 - Avg Loss: 0.8124 - LR: 0.000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 96/100: 100%|██████████| 49/49 [00:01<00:00, 31.28it/s, Loss=0.9125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96 - Avg Loss: 0.8073 - LR: 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 97/100: 100%|██████████| 49/49 [00:01<00:00, 31.41it/s, Loss=0.7779]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97 - Avg Loss: 0.8140 - LR: 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 98/100: 100%|██████████| 49/49 [00:01<00:00, 31.10it/s, Loss=0.9288]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98 - Avg Loss: 0.8161 - LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99/100: 100%|██████████| 49/49 [00:01<00:00, 30.56it/s, Loss=0.7315]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 - Avg Loss: 0.8106 - LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 100/100: 100%|██████████| 49/49 [00:01<00:00, 31.15it/s, Loss=0.7661]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100 - Avg Loss: 0.8073 - LR: 0.000000\n",
            "Generating sequences with learned temporal patterns...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 1000it [02:52,  5.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final shape: (400000, 6)\n",
            "\n",
            "Sample data:\n",
            "    account_id    raw_amount        amount    td  \\\n",
            "0            0    146.706009    139.436646  19.0   \n",
            "1            0  -2000.000000   2298.791504   7.0   \n",
            "2            0 -16788.603516  14084.089844   3.0   \n",
            "3            0  44759.292969  36677.554688  13.0   \n",
            "4            0  -1920.196533   2933.928955   4.0   \n",
            "5            0  -3103.447266   2400.000000   2.0   \n",
            "6            0  -1297.286255   2696.279297   1.0   \n",
            "7            0   -579.585327   2200.000000   4.0   \n",
            "8            0    -14.600000    201.508865   4.0   \n",
            "9            0  -8133.693359   4800.000000   5.0   \n",
            "10           0  -1200.000000   2644.396240   1.0   \n",
            "11           0    -14.600000    118.458008   0.0   \n",
            "12           0  15838.788086  13300.666016   0.0   \n",
            "13           0    -14.600000     14.600000   7.0   \n",
            "14           0   4262.036133   3275.370605  19.0   \n",
            "\n",
            "                                                tcode   datetime  \n",
            "0                      CREDIT__nan__INTEREST CREDITED 1997-09-30  \n",
            "1                         DEBIT__CASH WITHDRAWAL__nan 1997-10-07  \n",
            "2   CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ... 1997-10-10  \n",
            "3                         CREDIT__CREDIT IN CASH__nan 1997-10-23  \n",
            "4                         DEBIT__CASH WITHDRAWAL__nan 1997-10-27  \n",
            "5                DEBIT__REMITTANCE TO ANOTHER BANK__  1997-10-29  \n",
            "6           CREDIT__COLLECTION FROM ANOTHER BANK__nan 1997-10-30  \n",
            "7                DEBIT__REMITTANCE TO ANOTHER BANK__  1997-11-03  \n",
            "8                         DEBIT__CASH WITHDRAWAL__nan 1997-11-07  \n",
            "9        DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD 1997-11-12  \n",
            "10                        DEBIT__CASH WITHDRAWAL__nan 1997-11-13  \n",
            "11  DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE P... 1997-11-13  \n",
            "12                        DEBIT__CASH WITHDRAWAL__nan 1997-11-13  \n",
            "13       DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT 1997-11-20  \n",
            "14                     CREDIT__nan__INTEREST CREDITED 1997-12-09  \n",
            "\n",
            "Temporal dependencies learned - td range: 0.0 to 31.0\n",
            "\n",
            "Synthetic data saved with learned temporal patterns!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This version also act good\n",
        "\n",
        "# seed = 1234\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# torch.manual_seed(seed)\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Model hyperparameters\n",
        "# sequence_length = 80\n",
        "# min_seq_length = 80\n",
        "# cat_emb_dim = 4\n",
        "# mlp_layers = [128, 128]\n",
        "# diffusion_steps = 500  # Reduced for efficiency\n",
        "# epochs = 50  # Reduced for efficiency\n",
        "# batch_size = 256\n",
        "# learning_rate = 2e-4\n",
        "# n_sequences = 5000\n",
        "\n",
        "# # Date constraints\n",
        "# MIN_YEAR = 1993\n",
        "# MAX_YEAR = 1998\n",
        "\n",
        "# {'jsd': 0.17666379079128386,\n",
        "#  'entr_r': np.float64(4.142583700511794),\n",
        "#  'entr_g': np.float64(4.998523941057718),\n",
        "#  'NED': np.float64(-0.855940240545924),\n",
        "#  'l1': np.float64(0.9483875141141689),\n",
        "#  'l2': 0.12218879424693639,\n",
        "#  'jac': np.float64(0.06481481481481481),\n",
        "#  'count_r': 202,\n",
        "#  'coverage_r': 0.9351851851851852,\n",
        "#  'count_g': 216,\n",
        "#  'coverage_g': 1.0,\n",
        "#  'count_max': 216,\n",
        "#  'field': 'tcode',\n",
        "#  'n': 3,\n",
        "#  'pseudo_counts': 0.0}\n",
        "\n",
        "\n",
        "# {'amount': {'wasser': np.float64(682.1070215071861),\n",
        "#   'ks': np.float64(0.140266349591033),\n",
        "#   'energy_d': np.float64(9.15508966232386)},\n",
        "#  'td': {'wasser': np.float64(0.48902485913359595),\n",
        "#   'ks': np.float64(0.11245570205998183),\n",
        "#   'energy_d': np.float64(0.19747738204716697)},\n",
        "#  'CF': {'wasser': np.float64(13021.12391497244),\n",
        "#   'ks': np.float64(0.32986821530718735),\n",
        "#   'energy_d': np.float64(67.69154098302828)}}\n",
        "\n",
        "\n",
        "#   {'tcode': 0.03598723757365223,\n",
        "#  'day': 0.0644653630179872,\n",
        "#  'month': 0.011520275842911602}\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import calendar\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Quality evaluation imports\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdv import evaluation\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION\n",
        "# =============================================================================\n",
        "seed = 1234\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model hyperparameters\n",
        "sequence_length = 80\n",
        "min_seq_length = 80\n",
        "cat_emb_dim = 4\n",
        "mlp_layers = [128, 128]\n",
        "diffusion_steps = 500  # Reduced for efficiency\n",
        "epochs = 50  # Reduced for efficiency\n",
        "batch_size = 256\n",
        "learning_rate = 2e-4\n",
        "n_sequences = 5000\n",
        "# =============================================================================\n",
        "# STUDENT-T DISTRIBUTION DDPM DIFFUSER (Condensed)\n",
        "# =============================================================================\n",
        "class StudentTDDPMDiffuser(object):\n",
        "    def __init__(self, total_steps=500, beta_start=1e-4, beta_end=0.02, device='cpu', df=10):\n",
        "        self.total_steps = total_steps\n",
        "        self.device = device\n",
        "        self.df = df\n",
        "\n",
        "        # Exponential schedule\n",
        "        scale = 1000 / total_steps\n",
        "        betas = torch.exp(torch.linspace(math.log(scale * beta_start),\n",
        "                                        math.log(scale * beta_end), total_steps))\n",
        "        self.alphas = (1.0 - betas).to(device)\n",
        "        self.betas = betas.to(device)\n",
        "        self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "    def sample_random_timesteps(self, n: int):\n",
        "        return torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "\n",
        "    def sample_student_t(self, shape):\n",
        "        x = torch.randn(shape, device=self.device)\n",
        "        df_sample = max(3.0, float(self.df))\n",
        "        gamma_shape = df_sample / 2.0\n",
        "        gamma_samples = torch.tensor(stats.gamma.rvs(gamma_shape, scale=2.0, size=shape[0]),\n",
        "                                   dtype=torch.float32, device=self.device).view(-1, 1, 1)\n",
        "        scaling = torch.sqrt(torch.tensor(df_sample / (df_sample - 2.0), device=self.device))\n",
        "        return scaling * x / torch.sqrt(gamma_samples / df_sample)\n",
        "\n",
        "    def add_t_noise(self, x_num, t):\n",
        "        sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None, None]\n",
        "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None, None]\n",
        "        noise_num = self.sample_student_t(x_num.shape)\n",
        "        return sqrt_alpha_hat * x_num + sqrt_one_minus_alpha_hat * noise_num, noise_num\n",
        "\n",
        "    def sample(self, model_out, z_norm, timesteps):\n",
        "        sqrt_alpha_t = torch.sqrt(self.alphas[timesteps])[:, None, None]\n",
        "        betas_t = self.betas[timesteps][:, None, None]\n",
        "        sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[timesteps])[:, None, None]\n",
        "        epsilon_t = torch.sqrt(self.betas[timesteps][:, None, None])\n",
        "\n",
        "        random_noise = self.sample_student_t(z_norm.shape)\n",
        "        random_noise[timesteps == 0] = 0.0\n",
        "\n",
        "        model_mean = ((1 / sqrt_alpha_t) * (z_norm - (betas_t * model_out / sqrt_one_minus_alpha_hat_t)))\n",
        "        return model_mean + (epsilon_t * random_noise)\n",
        "\n",
        "# =============================================================================\n",
        "# DATA PREPROCESSING (Streamlined)\n",
        "# =============================================================================\n",
        "def preprocess_data_czech(df):\n",
        "    czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "    df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "    df[\"month\"] = df[\"datetime\"].dt.month\n",
        "    df[\"day\"] = df[\"datetime\"].dt.day\n",
        "    df[\"dow\"] = df[\"datetime\"].dt.dayofweek\n",
        "    df[\"year\"] = df[\"datetime\"].dt.year\n",
        "\n",
        "    df_sorted = df.sort_values(['account_id', 'datetime']).copy()\n",
        "    df_sorted[\"td\"] = df_sorted.groupby(\"account_id\")[\"datetime\"].diff().dt.days.fillna(0.0)\n",
        "    df_sorted['raw_amount'] = df_sorted.apply(\n",
        "        lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "    # Simplified transaction code\n",
        "    df_sorted[\"tcode\"] = df_sorted['type'].astype(str) + \"__\" + df_sorted['operation'].astype(str)\n",
        "\n",
        "    # Day categories\n",
        "    conditions = [(df_sorted['day'] <= 10), (df_sorted['day'] <= 20)]\n",
        "    categories = ['first', 'middle', 'last']\n",
        "    df_sorted['DoM_cat'] = np.select(conditions, categories[:2], default='last')\n",
        "\n",
        "    return df_sorted\n",
        "\n",
        "# =============================================================================\n",
        "# DATASET (Simplified)\n",
        "# =============================================================================\n",
        "class TemporalSequentialDataset(Dataset):\n",
        "    def __init__(self, df, cat_attrs, num_attrs, sequence_length=30, min_seq_length=20):\n",
        "        self.sequences = []\n",
        "        for account_id in tqdm(df['account_id'].unique(), desc=\"Creating sequences\"):\n",
        "            account_data = df[df['account_id'] == account_id].sort_values('datetime').reset_index(drop=True)\n",
        "            if len(account_data) >= min_seq_length:\n",
        "                for start_idx in range(0, len(account_data) - sequence_length + 1, sequence_length//2):\n",
        "                    seq_data = account_data.iloc[start_idx:start_idx+sequence_length]\n",
        "                    self.sequences.append({\n",
        "                        'cat_data': seq_data[cat_attrs].values,\n",
        "                        'num_data': seq_data[num_attrs].values\n",
        "                    })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        return torch.LongTensor(seq['cat_data']), torch.FloatTensor(seq['num_data'])\n",
        "\n",
        "# =============================================================================\n",
        "# MODEL (Condensed)\n",
        "# =============================================================================\n",
        "class TemporalLSTMSynthesizer(nn.Module):\n",
        "    def __init__(self, n_cat_features, n_cat_tokens, cat_emb_dim, n_num_features, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.n_cat_features = n_cat_features\n",
        "        self.n_num_features = n_num_features\n",
        "\n",
        "        self.cat_embeddings = nn.ModuleList([\n",
        "            nn.Embedding(n_cat_tokens[i], cat_emb_dim) for i in range(n_cat_features)\n",
        "        ])\n",
        "\n",
        "        total_input_dim = n_cat_features * cat_emb_dim + n_num_features\n",
        "\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(64, hidden_dim), nn.SiLU(), nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "        self.input_projection = nn.Linear(total_input_dim, hidden_dim)\n",
        "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, 2, batch_first=True, dropout=0.1)\n",
        "\n",
        "        self.cat_heads = nn.ModuleList([\n",
        "            nn.Linear(hidden_dim, n_cat_tokens[i]) for i in range(n_cat_features)\n",
        "        ])\n",
        "        self.num_head = nn.Linear(hidden_dim, n_num_features)\n",
        "\n",
        "    def embed_time(self, timesteps, dim_out=64):\n",
        "        half = dim_out // 2\n",
        "        freqs = torch.exp(-math.log(1000) * torch.arange(0, half, dtype=torch.float32) / half).to(timesteps.device)\n",
        "        args = timesteps[:, None].float() * freqs[None]\n",
        "        return torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "\n",
        "    def forward(self, x_cat, x_num, timesteps):\n",
        "        batch_size, seq_len, _ = x_num.shape\n",
        "\n",
        "        # Embed categorical\n",
        "        cat_emb = torch.cat([self.cat_embeddings[i](x_cat[:, :, i])\n",
        "                           for i in range(self.n_cat_features)], dim=-1)\n",
        "\n",
        "        # Combine features\n",
        "        x = torch.cat([cat_emb, x_num], dim=-1)\n",
        "        x_proj = self.input_projection(x)\n",
        "\n",
        "        # Add time embedding\n",
        "        time_emb = self.time_embed(self.embed_time(timesteps))\n",
        "        x_with_time = x_proj + time_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x_with_time)\n",
        "\n",
        "        # Generate outputs\n",
        "        cat_outputs = [head(lstm_out) for head in self.cat_heads]\n",
        "        num_output = self.num_head(lstm_out)\n",
        "\n",
        "        return cat_outputs, num_output\n",
        "\n",
        "# =============================================================================\n",
        "# TRAINING (Streamlined)\n",
        "# =============================================================================\n",
        "def train_model(model, diffuser, dataloader, epochs, optimizer, scheduler):\n",
        "    model.train()\n",
        "    cat_criterion = nn.CrossEntropyLoss()\n",
        "    num_criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        for batch_cat, batch_num in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
        "            batch_cat, batch_num = batch_cat.to(device), batch_num.to(device)\n",
        "            timesteps = diffuser.sample_random_timesteps(batch_cat.shape[0])\n",
        "            noisy_num, noise_target = diffuser.add_t_noise(batch_num, timesteps)\n",
        "\n",
        "            cat_outputs, num_output = model(batch_cat, noisy_num, timesteps)\n",
        "\n",
        "            cat_loss = sum(cat_criterion(cat_out.view(-1, cat_out.size(-1)),\n",
        "                                       batch_cat[:, :, i].view(-1))\n",
        "                          for i, cat_out in enumerate(cat_outputs))\n",
        "            num_loss = num_criterion(num_output, noise_target)\n",
        "            total_loss = cat_loss + num_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            epoch_loss += total_loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1} - Loss: {epoch_loss/len(dataloader):.4f}\")\n",
        "        scheduler.step()\n",
        "\n",
        "# =============================================================================\n",
        "# GENERATION WITH DATE CONSTRAINTS\n",
        "# =============================================================================\n",
        "def generate_sequences(model, diffuser, n_sequences, seq_len, n_cat_features, n_cat_tokens, n_num_features):\n",
        "    model.eval()\n",
        "\n",
        "    x_cat = torch.zeros(n_sequences, seq_len, n_cat_features, dtype=torch.long, device=device)\n",
        "    for i, n_tokens in enumerate(n_cat_tokens):\n",
        "        x_cat[:, :, i] = torch.randint(0, n_tokens, (n_sequences, seq_len), device=device)\n",
        "\n",
        "    x_num = diffuser.sample_student_t((n_sequences, seq_len, n_num_features))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for t in tqdm(reversed(range(diffuser.total_steps)), desc=\"Generating\"):\n",
        "            timesteps = torch.full((n_sequences,), t, device=device, dtype=torch.long)\n",
        "            cat_outputs, num_output = model(x_cat, x_num, timesteps)\n",
        "            x_num = diffuser.sample(num_output, x_num, timesteps)\n",
        "\n",
        "            if t % 100 == 0:\n",
        "                for i, cat_out in enumerate(cat_outputs):\n",
        "                    probs = torch.softmax(cat_out, dim=-1)\n",
        "                    x_cat[:, :, i] = torch.multinomial(probs.view(-1, probs.size(-1)), 1).view(n_sequences, seq_len)\n",
        "\n",
        "    return x_cat, x_num\n",
        "\n",
        "def create_dataframe_with_date_constraints(generated_cat, generated_num, cat_attrs, num_attrs,\n",
        "                                         label_encoders, num_scaler):\n",
        "    \"\"\"Create dataframe with dates constrained to 1993-1998\"\"\"\n",
        "    final_sequences = []\n",
        "\n",
        "    for seq_idx in range(generated_cat.shape[0]):\n",
        "        seq_num = num_scaler.inverse_transform(generated_num[seq_idx].cpu().numpy())\n",
        "        seq_cat = generated_cat[seq_idx].cpu().numpy()\n",
        "\n",
        "        seq_df = pd.DataFrame()\n",
        "\n",
        "        # Add numerical features\n",
        "        for i, col in enumerate(num_attrs):\n",
        "            seq_df[col] = seq_num[:, i]\n",
        "\n",
        "        # Add categorical features\n",
        "        for i, col in enumerate(cat_attrs):\n",
        "            seq_df[col] = label_encoders[col].inverse_transform(seq_cat[:, i])\n",
        "\n",
        "        # CONSTRAIN DATES TO 1993-1998\n",
        "        # Generate random start date within range\n",
        "        start_year = random.randint(MIN_YEAR, MAX_YEAR)\n",
        "        start_month = random.randint(1, 12)\n",
        "        start_day = random.randint(1, 28)  # Safe day range\n",
        "\n",
        "        try:\n",
        "            first_date = datetime(start_year, start_month, start_day)\n",
        "        except:\n",
        "            first_date = datetime(MIN_YEAR, 1, 1)\n",
        "\n",
        "        dates = [first_date]\n",
        "\n",
        "        # Use generated td values but ensure dates stay within range\n",
        "        for i in range(1, len(seq_df)):\n",
        "            td_days = max(1, min(30, int(abs(seq_df['td'].iloc[i]))))  # Constrain td to reasonable range\n",
        "            next_date = dates[-1] + timedelta(days=td_days)\n",
        "\n",
        "            # Keep within year range\n",
        "            if next_date.year > MAX_YEAR:\n",
        "                next_date = datetime(MAX_YEAR, 12, 31)\n",
        "            elif next_date.year < MIN_YEAR:\n",
        "                next_date = datetime(MIN_YEAR, 1, 1)\n",
        "\n",
        "            dates.append(next_date)\n",
        "\n",
        "        seq_df['datetime'] = dates\n",
        "        seq_df['account_id'] = seq_idx + 1000  # Start from 1000 to avoid conflicts\n",
        "\n",
        "        # Update year/month/day to match constrained dates\n",
        "        seq_df['year'] = [d.year for d in dates]\n",
        "        seq_df['month'] = [d.month for d in dates]\n",
        "        seq_df['day'] = [d.day for d in dates]\n",
        "\n",
        "        final_sequences.append(seq_df)\n",
        "\n",
        "    return pd.concat(final_sequences, ignore_index=True)\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN EXECUTION\n",
        "# =============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Loading data...\")\n",
        "    try:\n",
        "        real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: CSV file not found.\")\n",
        "        exit()\n",
        "\n",
        "    # Preprocess\n",
        "    raw_data = preprocess_data_czech(real)\n",
        "    cat_attrs = ['tcode', 'dow', 'month', 'day', 'year', 'DoM_cat']\n",
        "    num_attrs = ['amount', 'raw_amount', 'td']\n",
        "\n",
        "    df_processed = raw_data[cat_attrs + num_attrs + ['account_id', 'datetime']].copy()\n",
        "\n",
        "    # Encode features\n",
        "    label_encoders = {}\n",
        "    n_cat_tokens = []\n",
        "    for attr in cat_attrs:\n",
        "        le = LabelEncoder()\n",
        "        df_processed[attr] = le.fit_transform(df_processed[attr].astype(str))\n",
        "        label_encoders[attr] = le\n",
        "        n_cat_tokens.append(len(le.classes_))\n",
        "\n",
        "    num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "    df_processed[num_attrs] = num_scaler.fit_transform(df_processed[num_attrs])\n",
        "\n",
        "    # Create dataset and model\n",
        "    dataset = TemporalSequentialDataset(df_processed, cat_attrs, num_attrs, sequence_length, min_seq_length)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model = TemporalLSTMSynthesizer(\n",
        "        n_cat_features=len(cat_attrs), n_cat_tokens=n_cat_tokens,\n",
        "        cat_emb_dim=cat_emb_dim, n_num_features=len(num_attrs)\n",
        "    ).to(device)\n",
        "\n",
        "    diffuser = StudentTDDPMDiffuser(device=device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    print(f\"Training model with {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters...\")\n",
        "\n",
        "    # Train\n",
        "    train_model(model, diffuser, dataloader, epochs, optimizer, scheduler)\n",
        "\n",
        "    # Generate with date constraints\n",
        "    print(\"Generating sequences with 1993-1998 date constraints...\")\n",
        "    generated_cat, generated_num = generate_sequences(\n",
        "        model, diffuser, n_sequences, sequence_length,\n",
        "        len(cat_attrs), n_cat_tokens, len(num_attrs)\n",
        "    )\n",
        "\n",
        "    # Create final dataframe with date constraints\n",
        "    synth_data = create_dataframe_with_date_constraints(\n",
        "        generated_cat, generated_num, cat_attrs, num_attrs,\n",
        "        label_encoders, num_scaler\n",
        "    )\n",
        "\n",
        "    # Prepare data for quality evaluation\n",
        "    synth_sorted = synth_data[['account_id', 'raw_amount', 'amount', 'td', 'tcode', 'datetime']].copy()\n",
        "    synth_sorted = synth_sorted.dropna()\n",
        "\n",
        "    # Prepare real data for comparison (same columns)\n",
        "    real_comparison = raw_data[['account_id', 'raw_amount', 'amount', 'td', 'tcode', 'datetime']].copy()\n",
        "    real_comparison = real_comparison.dropna()\n",
        "\n",
        "    print(f\"\\nGenerated data shape: {synth_sorted.shape}\")\n",
        "    print(f\"Date range: {synth_sorted['datetime'].min()} to {synth_sorted['datetime'].max()}\")\n",
        "    print(\"\\nSample generated data:\")\n",
        "    print(synth_sorted.head(10))\n",
        "\n",
        "    # Quality evaluation\n",
        "    # quality_report = evaluate_quality(real_comparison, synth_sorted)\n",
        "    synth_sorted[\"datetime\"] = synth_sorted[\"datetime\"].dt.date\n",
        "\n",
        "    # Save results\n",
        "    synth_sorted.to_csv('synthetic_transactions_1993_1998.csv', index=False)\n",
        "    print(f\"\\nSynthetic data saved! Dates constrained to {MIN_YEAR}-{MAX_YEAR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVoB22DA90os",
        "outputId": "45a3e81a-4404-475e-90db-e98e7e7143df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating sequences: 100%|██████████| 4500/4500 [00:21<00:00, 209.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with 301,640 parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 78/78 [00:02<00:00, 32.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 12.9857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 78/78 [00:02<00:00, 34.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Loss: 10.6194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 78/78 [00:02<00:00, 34.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Loss: 8.6611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 78/78 [00:02<00:00, 34.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Loss: 7.2249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 78/78 [00:02<00:00, 34.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Loss: 5.9879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 78/78 [00:02<00:00, 34.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Loss: 5.0227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 78/78 [00:02<00:00, 34.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Loss: 4.3996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 78/78 [00:02<00:00, 34.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Loss: 3.9411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 78/78 [00:02<00:00, 34.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Loss: 3.5395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 78/78 [00:02<00:00, 34.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Loss: 3.1809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 78/78 [00:02<00:00, 34.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - Loss: 2.8568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 78/78 [00:02<00:00, 34.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - Loss: 2.5559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 78/78 [00:02<00:00, 34.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 - Loss: 2.2823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 78/78 [00:02<00:00, 34.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 - Loss: 2.0754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 78/78 [00:02<00:00, 33.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 - Loss: 1.8909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 78/78 [00:02<00:00, 34.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 - Loss: 1.7379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 78/78 [00:02<00:00, 33.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 - Loss: 1.6146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 78/78 [00:02<00:00, 33.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 - Loss: 1.5140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 78/78 [00:02<00:00, 33.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 - Loss: 1.4249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 78/78 [00:02<00:00, 33.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 - Loss: 1.3514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 78/78 [00:02<00:00, 33.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 - Loss: 1.2936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 78/78 [00:02<00:00, 34.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 - Loss: 1.2409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 78/78 [00:02<00:00, 33.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 - Loss: 1.1913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 78/78 [00:02<00:00, 34.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 - Loss: 1.1552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 78/78 [00:02<00:00, 34.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 - Loss: 1.1109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 78/78 [00:02<00:00, 34.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 - Loss: 1.0835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 78/78 [00:02<00:00, 33.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 - Loss: 1.0585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 78/78 [00:02<00:00, 33.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 - Loss: 1.0339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 78/78 [00:02<00:00, 34.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 - Loss: 1.0022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 78/78 [00:02<00:00, 34.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 - Loss: 0.9896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31: 100%|██████████| 78/78 [00:02<00:00, 34.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 - Loss: 0.9813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32: 100%|██████████| 78/78 [00:02<00:00, 34.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 - Loss: 0.9585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33: 100%|██████████| 78/78 [00:02<00:00, 34.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 - Loss: 0.9489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34: 100%|██████████| 78/78 [00:02<00:00, 34.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 - Loss: 0.9321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35: 100%|██████████| 78/78 [00:02<00:00, 34.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 - Loss: 0.9235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36: 100%|██████████| 78/78 [00:02<00:00, 34.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 - Loss: 0.9106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37: 100%|██████████| 78/78 [00:02<00:00, 34.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 - Loss: 0.9032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38: 100%|██████████| 78/78 [00:02<00:00, 34.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 - Loss: 0.8969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39: 100%|██████████| 78/78 [00:02<00:00, 34.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 - Loss: 0.8914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40: 100%|██████████| 78/78 [00:02<00:00, 34.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 - Loss: 0.8866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41: 100%|██████████| 78/78 [00:02<00:00, 34.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 - Loss: 0.8843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42: 100%|██████████| 78/78 [00:02<00:00, 34.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 - Loss: 0.8724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43: 100%|██████████| 78/78 [00:02<00:00, 34.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 - Loss: 0.8741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44: 100%|██████████| 78/78 [00:02<00:00, 34.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 - Loss: 0.8698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45: 100%|██████████| 78/78 [00:02<00:00, 34.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 - Loss: 0.8748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46: 100%|██████████| 78/78 [00:02<00:00, 34.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 - Loss: 0.8670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47: 100%|██████████| 78/78 [00:02<00:00, 34.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 - Loss: 0.8751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48: 100%|██████████| 78/78 [00:02<00:00, 34.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 - Loss: 0.8680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49: 100%|██████████| 78/78 [00:02<00:00, 34.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 - Loss: 0.8698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50: 100%|██████████| 78/78 [00:02<00:00, 34.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 - Loss: 0.8661\n",
            "Generating sequences with 1993-1998 date constraints...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 500it [01:21,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated data shape: (400000, 6)\n",
            "Date range: 1993-01-01 00:00:00 to 1998-12-31 00:00:00\n",
            "\n",
            "Sample generated data:\n",
            "   account_id    raw_amount        amount    td  \\\n",
            "0        1000  -1900.480957   1900.000000  10.0   \n",
            "1        1000    212.714706   1473.842041   6.0   \n",
            "2        1000  -6427.645020   6898.974121   9.0   \n",
            "3        1000  55721.019531  68192.421875   0.0   \n",
            "4        1000  27362.675781  25304.757812   0.0   \n",
            "5        1000 -17836.152344  20582.343750  24.0   \n",
            "6        1000  -6588.882812   5107.594727   3.0   \n",
            "7        1000  27058.498047  25215.886719   4.0   \n",
            "8        1000    659.321655   8567.794922  10.0   \n",
            "9        1000   6608.120117  11542.677734   4.0   \n",
            "\n",
            "                                  tcode   datetime  \n",
            "0                DEBIT__CASH WITHDRAWAL 1996-02-01  \n",
            "1                           CREDIT__nan 1996-02-07  \n",
            "2     DEBIT__REMITTANCE TO ANOTHER BANK 1996-02-16  \n",
            "3                CREDIT__CREDIT IN CASH 1996-02-17  \n",
            "4  CREDIT__COLLECTION FROM ANOTHER BANK 1996-02-18  \n",
            "5                DEBIT__CASH WITHDRAWAL 1996-03-13  \n",
            "6     DEBIT__REMITTANCE TO ANOTHER BANK 1996-03-16  \n",
            "7  CREDIT__COLLECTION FROM ANOTHER BANK 1996-03-20  \n",
            "8                CREDIT__CREDIT IN CASH 1996-03-30  \n",
            "9  CREDIT__COLLECTION FROM ANOTHER BANK 1996-04-03  \n",
            "\n",
            "Synthetic data saved! Dates constrained to 1993-1998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # using RBF encoding\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "# from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "# from sklego.preprocessing import RepeatingBasisFunction\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import random\n",
        "# import os\n",
        "# from datetime import datetime, timedelta\n",
        "# import calendar\n",
        "# from tqdm import tqdm\n",
        "# from scipy import stats\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# # =============================================================================\n",
        "# # CONFIGURATION\n",
        "# # =============================================================================\n",
        "# seed = 1234\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# torch.manual_seed(seed)\n",
        "# if torch.cuda.is_available():\n",
        "#     torch.cuda.manual_seed(seed)\n",
        "#     torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(f\"Using device: {device}\")\n",
        "\n",
        "# # Model hyperparameters\n",
        "# sequence_length = 80\n",
        "# min_seq_length = 80\n",
        "# cat_emb_dim = 4\n",
        "# mlp_layers = [64, 64]\n",
        "# diffusion_steps = 1000\n",
        "# diffusion_beta_start = 1e-4\n",
        "# diffusion_beta_end = 0.02\n",
        "# scheduler = 'exp'\n",
        "# epochs = 100\n",
        "# batch_size = 256\n",
        "# learning_rate = 2e-4\n",
        "# n_sequences = 5000\n",
        "\n",
        "# # RBF parameters\n",
        "# rbf_n_periods = 2  # Number of periods for RBF encoding\n",
        "\n",
        "# # =============================================================================\n",
        "# # STUDENT-T DISTRIBUTION DDPM DIFFUSER\n",
        "# # =============================================================================\n",
        "# class StudentTDDPMDiffuser(object):\n",
        "#     def __init__(self, total_steps=1000, beta_start=1e-4, beta_end=0.02, device='cpu', scheduler='exp', df=30):\n",
        "#         self.total_steps = total_steps\n",
        "#         self.beta_start = beta_start\n",
        "#         self.beta_end = beta_end\n",
        "#         self.device = device\n",
        "#         self.df = df\n",
        "\n",
        "#         self.alphas, self.betas = self.prepare_noise_schedule(scheduler=scheduler)\n",
        "#         self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "#     def prepare_noise_schedule(self, scheduler: str):\n",
        "#         scale = 1000 / self.total_steps\n",
        "#         beta_start = scale * self.beta_start\n",
        "#         beta_end = scale * self.beta_end\n",
        "\n",
        "#         if scheduler == 'linear':\n",
        "#             betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "#         elif scheduler == 'quad':\n",
        "#             betas = torch.linspace(self.beta_start**0.5, self.beta_end**0.5, self.total_steps) ** 2\n",
        "#         elif scheduler == 'exp':\n",
        "#             betas = torch.exp(torch.linspace(math.log(beta_start), math.log(beta_end), self.total_steps))\n",
        "#         elif scheduler == 'sigm':\n",
        "#             x = torch.linspace(-6, 6, self.total_steps)\n",
        "#             betas = torch.sigmoid(x) * (beta_end - beta_start) + beta_start\n",
        "\n",
        "#         alphas = 1.0 - betas\n",
        "#         return alphas.to(self.device), betas.to(self.device)\n",
        "\n",
        "#     def sample_random_timesteps(self, n: int):\n",
        "#         return torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "\n",
        "#     def sample_student_t(self, shape):\n",
        "#         if isinstance(shape, torch.Tensor):\n",
        "#             shape = tuple(shape.tolist())\n",
        "\n",
        "#         x = torch.randn(shape, device=self.device)\n",
        "#         df_sample = max(3.0, float(self.df))\n",
        "#         gamma_shape = df_sample / 2.0\n",
        "#         gamma_samples = torch.tensor(stats.gamma.rvs(gamma_shape, scale=2.0, size=shape[0]),\n",
        "#                                      dtype=torch.float32, device=self.device).view(-1, 1, 1)\n",
        "\n",
        "#         scaling = torch.sqrt(torch.tensor(df_sample / (df_sample - 2.0), device=self.device))\n",
        "#         t_noise = scaling * x / torch.sqrt(gamma_samples / df_sample)\n",
        "#         return t_noise\n",
        "\n",
        "#     def add_t_noise(self, x_num, t):\n",
        "#         sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None, None]\n",
        "#         sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None, None]\n",
        "\n",
        "#         noise_num = self.sample_student_t(x_num.shape)\n",
        "#         x_noise_num = sqrt_alpha_hat * x_num + sqrt_one_minus_alpha_hat * noise_num\n",
        "#         return x_noise_num, noise_num\n",
        "\n",
        "#     def p_sample_t(self, model_out, z_norm, timesteps):\n",
        "#         sqrt_alpha_t = torch.sqrt(self.alphas[timesteps])[:, None, None]\n",
        "#         betas_t = self.betas[timesteps][:, None, None]\n",
        "#         sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[timesteps])[:, None, None]\n",
        "#         epsilon_t = torch.sqrt(self.betas[timesteps][:, None, None])\n",
        "\n",
        "#         random_noise = self.sample_student_t(z_norm.shape)\n",
        "#         random_noise[timesteps == 0] = 0.0\n",
        "\n",
        "#         model_mean = ((1 / sqrt_alpha_t) * (z_norm - (betas_t * model_out / sqrt_one_minus_alpha_hat_t)))\n",
        "#         z_norm = model_mean + (epsilon_t * random_noise)\n",
        "#         return z_norm\n",
        "\n",
        "#     def sample(self, model_out, z_norm, timesteps):\n",
        "#         return self.p_sample_t(model_out, z_norm, timesteps)\n",
        "\n",
        "# # =============================================================================\n",
        "# # RBF ENCODING FUNCTIONS\n",
        "# # =============================================================================\n",
        "# def setup_rbf_encoders(n_periods=2):\n",
        "#     \"\"\"Setup RBF encoders for temporal features\"\"\"\n",
        "#     rbf_encoders = {}\n",
        "\n",
        "#     # Day of month (1-31)\n",
        "#     rbf_encoders['day'] = RepeatingBasisFunction(\n",
        "#         n_periods=n_periods,\n",
        "#         column='day',\n",
        "#         input_range=(1, 31),\n",
        "#         remainder='drop'\n",
        "#     )\n",
        "\n",
        "#     # Month (1-12)\n",
        "#     rbf_encoders['month'] = RepeatingBasisFunction(\n",
        "#         n_periods=n_periods,\n",
        "#         column='month',\n",
        "#         input_range=(1, 12),\n",
        "#         remainder='drop'\n",
        "#     )\n",
        "\n",
        "#     # Day of week (0-6)\n",
        "#     rbf_encoders['dow'] = RepeatingBasisFunction(\n",
        "#         n_periods=n_periods,\n",
        "#         column='dow',\n",
        "#         input_range=(0, 6),\n",
        "#         remainder='drop'\n",
        "#     )\n",
        "\n",
        "#     # Year - we'll use a larger range to accommodate different years\n",
        "#     rbf_encoders['year'] = RepeatingBasisFunction(\n",
        "#         n_periods=n_periods,\n",
        "#         column='year',\n",
        "#         input_range=(1990, 2030),\n",
        "#         remainder='drop'\n",
        "#     )\n",
        "\n",
        "#     return rbf_encoders\n",
        "\n",
        "# def apply_rbf_encoding(df, rbf_encoders):\n",
        "#     \"\"\"Apply RBF encoding to temporal features\"\"\"\n",
        "#     rbf_features = {}\n",
        "\n",
        "#     for feature_name, encoder in rbf_encoders.items():\n",
        "#         # Create temporary dataframe with the feature\n",
        "#         temp_df = pd.DataFrame({feature_name: df[feature_name]})\n",
        "\n",
        "#         # Apply RBF encoding\n",
        "#         rbf_encoded = encoder.fit_transform(temp_df)\n",
        "\n",
        "#         # Store the encoded features\n",
        "#         rbf_features[feature_name] = rbf_encoded\n",
        "\n",
        "#         print(f\"RBF encoded {feature_name}: shape {rbf_encoded.shape}\")\n",
        "\n",
        "#     return rbf_features\n",
        "\n",
        "# # =============================================================================\n",
        "# # ENHANCED DATA PREPROCESSING\n",
        "# # =============================================================================\n",
        "# def preprocess_data_czech(df):\n",
        "#     \"\"\"Enhanced preprocessing with proper temporal features\"\"\"\n",
        "#     czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "#     df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "#     df[\"month\"] = df[\"datetime\"].dt.month\n",
        "#     df[\"day\"] = df[\"datetime\"].dt.day\n",
        "#     df[\"dow\"] = df[\"datetime\"].dt.dayofweek\n",
        "#     df[\"year\"] = df[\"datetime\"].dt.year\n",
        "#     df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "#     df_sorted = df.sort_values(['account_id', 'datetime']).copy()\n",
        "\n",
        "#     # Calculate time differences - this is what the model should learn!\n",
        "#     df_sorted[\"td\"] = df_sorted.groupby(\"account_id\")[\"datetime\"].diff().dt.days\n",
        "#     df_sorted[\"td\"].fillna(0.0, inplace=True)\n",
        "\n",
        "#     # Days to month end\n",
        "#     df_sorted[\"dtme\"] = df_sorted.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "\n",
        "#     # Raw amount (signed)\n",
        "#     df_sorted['raw_amount'] = df_sorted.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "#     # Transaction code\n",
        "#     cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "#     tcode = df_sorted[cat_code_fields[0]].astype(str)\n",
        "#     for ccf in cat_code_fields[1:]:\n",
        "#         tcode += \"__\" + df_sorted[ccf].astype(str)\n",
        "#     df_sorted[\"tcode\"] = tcode\n",
        "\n",
        "#     # Day of month categories\n",
        "#     conditions = [\n",
        "#         (df_sorted['day'] >= 1) & (df_sorted['day'] <= 10),\n",
        "#         (df_sorted['day'] > 10) & (df_sorted['day'] <= 20),\n",
        "#         (df_sorted['day'] > 20) & (df_sorted['day'] <= 31)\n",
        "#     ]\n",
        "#     categories = ['first', 'middle', 'last']\n",
        "#     df_sorted['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "#     # Age groups\n",
        "#     if 'age' in df_sorted.columns:\n",
        "#         bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "#         labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "#         df_sorted['age_group'] = pd.cut(df_sorted['age'], bins=bin_edges, labels=labels, right=False)\n",
        "#         df_sorted['age_group'] = df_sorted['age_group'].astype('object').fillna('unknown')\n",
        "#     else:\n",
        "#         df_sorted['age_group'] = 'unknown'\n",
        "\n",
        "#     return df_sorted\n",
        "\n",
        "# # =============================================================================\n",
        "# # TEMPORAL-AWARE DATASET WITH RBF\n",
        "# # =============================================================================\n",
        "# class TemporalSequentialDatasetWithRBF(Dataset):\n",
        "#     \"\"\"Dataset that preserves temporal dependencies and includes RBF features\"\"\"\n",
        "#     def __init__(self, df, cat_attrs, num_attrs, rbf_features, sequence_length=30, min_seq_length=20, max_sequences_per_account=5):\n",
        "#         self.sequence_length = sequence_length\n",
        "#         self.min_seq_length = min_seq_length\n",
        "#         self.cat_attrs = cat_attrs\n",
        "#         self.num_attrs = num_attrs\n",
        "#         self.rbf_features = rbf_features\n",
        "#         self.sequences = []\n",
        "\n",
        "#         print(\"Creating temporal sequences with RBF features from transaction data...\")\n",
        "\n",
        "#         for account_id in tqdm(df['account_id'].unique()):\n",
        "#             account_data = df[df['account_id'] == account_id].sort_values('datetime').reset_index(drop=True)\n",
        "#             if len(account_data) >= min_seq_length:\n",
        "#                 # Sample sequences that maintain temporal order\n",
        "#                 n_possible = len(account_data) - sequence_length + 1\n",
        "#                 if n_possible <= max_sequences_per_account:\n",
        "#                     start_indices = range(n_possible)\n",
        "#                 else:\n",
        "#                     start_indices = np.linspace(0, n_possible-1, max_sequences_per_account, dtype=int)\n",
        "\n",
        "#                 for start_idx in start_indices:\n",
        "#                     seq_data = account_data.iloc[start_idx:start_idx+sequence_length]\n",
        "#                     cat_data = seq_data[self.cat_attrs].values\n",
        "#                     num_data = seq_data[self.num_attrs].values\n",
        "\n",
        "#                     # Extract RBF features for this sequence\n",
        "#                     rbf_data = []\n",
        "#                     for feature_name in ['day', 'month', 'year', 'dow']:\n",
        "#                         feature_rbf = self.rbf_features[feature_name][seq_data.index]\n",
        "#                         rbf_data.append(feature_rbf)\n",
        "\n",
        "#                     # Concatenate all RBF features\n",
        "#                     rbf_data = np.concatenate(rbf_data, axis=1)\n",
        "\n",
        "#                     self.sequences.append({\n",
        "#                         'cat_data': cat_data,\n",
        "#                         'num_data': num_data,\n",
        "#                         'rbf_data': rbf_data\n",
        "#                     })\n",
        "\n",
        "#         print(f\"Created {len(self.sequences)} temporal sequences with RBF features from {df['account_id'].nunique()} accounts.\")\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.sequences)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         seq = self.sequences[idx]\n",
        "#         cat_tensor = torch.LongTensor(seq['cat_data'])\n",
        "#         num_tensor = torch.FloatTensor(seq['num_data'])\n",
        "#         rbf_tensor = torch.FloatTensor(seq['rbf_data'])\n",
        "#         return cat_tensor, num_tensor, rbf_tensor\n",
        "\n",
        "# # =============================================================================\n",
        "# # TEMPORAL LSTM SYNTHESIZER WITH RBF\n",
        "# # =============================================================================\n",
        "# class TemporalLSTMSynthesizerWithRBF(nn.Module):\n",
        "#     \"\"\"LSTM that learns temporal dependencies with RBF encoding\"\"\"\n",
        "#     def __init__(self, n_cat_features, n_cat_tokens, cat_emb_dim, n_num_features,\n",
        "#                  n_rbf_features, hidden_dim=256, lstm_layers=2, dim_t=64):\n",
        "#         super(TemporalLSTMSynthesizerWithRBF, self).__init__()\n",
        "#         self.n_cat_features = n_cat_features\n",
        "#         self.n_num_features = n_num_features\n",
        "#         self.n_rbf_features = n_rbf_features\n",
        "#         self.cat_emb_dim = cat_emb_dim\n",
        "#         self.hidden_dim = hidden_dim\n",
        "#         self.dim_t = dim_t\n",
        "\n",
        "#         # Categorical embeddings\n",
        "#         self.cat_embeddings = nn.ModuleList([\n",
        "#             nn.Embedding(n_cat_tokens[i], cat_emb_dim) for i in range(n_cat_features)\n",
        "#         ])\n",
        "\n",
        "#         total_cat_emb_dim = n_cat_features * cat_emb_dim\n",
        "#         total_input_dim = total_cat_emb_dim + n_num_features + n_rbf_features\n",
        "\n",
        "#         # Time embedding for diffusion\n",
        "#         self.time_embed = nn.Sequential(\n",
        "#             nn.Linear(dim_t, hidden_dim),\n",
        "#             nn.SiLU(),\n",
        "#             nn.Linear(hidden_dim, hidden_dim)\n",
        "#         )\n",
        "\n",
        "#         # Input projection\n",
        "#         self.input_projection = nn.Linear(total_input_dim, hidden_dim)\n",
        "\n",
        "#         # RBF feature projection\n",
        "#         self.rbf_projection = nn.Linear(n_rbf_features, hidden_dim // 4)\n",
        "\n",
        "#         # LSTM with attention to temporal patterns\n",
        "#         self.lstm = nn.LSTM(\n",
        "#             input_size=hidden_dim,\n",
        "#             hidden_size=hidden_dim,\n",
        "#             num_layers=lstm_layers,\n",
        "#             batch_first=True,\n",
        "#             dropout=0.1 if lstm_layers > 1 else 0\n",
        "#         )\n",
        "\n",
        "#         # Separate heads for different outputs\n",
        "#         self.cat_heads = nn.ModuleList([\n",
        "#             nn.Linear(hidden_dim, n_cat_tokens[i]) for i in range(n_cat_features)\n",
        "#         ])\n",
        "#         self.num_head = nn.Linear(hidden_dim, n_num_features)\n",
        "\n",
        "#         # Temporal consistency layer\n",
        "#         self.temporal_consistency = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "#     def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "#         half = dim_out // 2\n",
        "#         freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half).to(device)\n",
        "#         args = timesteps[:, None].float() * freqs[None]\n",
        "#         embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "#         if dim_out % 2:\n",
        "#             embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "#         return embedding\n",
        "\n",
        "#     def embed_categorical(self, x_cat):\n",
        "#         embeddings = []\n",
        "#         for i in range(self.n_cat_features):\n",
        "#             embeddings.append(self.cat_embeddings[i](x_cat[:, :, i]))\n",
        "#         return torch.cat(embeddings, dim=-1)\n",
        "\n",
        "#     def forward(self, x_cat, x_num, x_rbf, timesteps):\n",
        "#         batch_size, seq_len, _ = x_num.shape\n",
        "\n",
        "#         # Embed categorical features\n",
        "#         cat_emb = self.embed_categorical(x_cat)\n",
        "\n",
        "#         # Combine with numerical and RBF features\n",
        "#         x = torch.cat([cat_emb, x_num, x_rbf], dim=-1)\n",
        "\n",
        "#         # Project input\n",
        "#         x_proj = self.input_projection(x)\n",
        "\n",
        "#         # Time embedding for diffusion process\n",
        "#         time_emb_raw = self.embed_time(timesteps, self.dim_t)\n",
        "#         time_emb = self.time_embed(time_emb_raw)\n",
        "#         time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "#         # Add temporal consistency\n",
        "#         x_with_time = x_proj + time_emb\n",
        "#         x_temporal = self.temporal_consistency(x_with_time)\n",
        "\n",
        "#         # LSTM processing - this learns the temporal dependencies\n",
        "#         lstm_out, _ = self.lstm(x_temporal)\n",
        "\n",
        "#         # Generate outputs\n",
        "#         cat_outputs = [head(lstm_out) for head in self.cat_heads]\n",
        "#         num_output = self.num_head(lstm_out)\n",
        "\n",
        "#         return cat_outputs, num_output\n",
        "\n",
        "# # =============================================================================\n",
        "# # TRAINING AND GENERATION WITH RBF\n",
        "# # =============================================================================\n",
        "# def train_model_with_rbf(model, diffuser, dataloader, epochs, optimizer, scheduler):\n",
        "#     model.train()\n",
        "#     cat_criterion = nn.CrossEntropyLoss()\n",
        "#     num_criterion = nn.MSELoss()\n",
        "#     losses = []\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         epoch_loss = 0.0\n",
        "#         pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "#         for batch_cat, batch_num, batch_rbf in pbar:\n",
        "#             batch_cat = batch_cat.to(device)\n",
        "#             batch_num = batch_num.to(device)\n",
        "#             batch_rbf = batch_rbf.to(device)\n",
        "#             batch_size = batch_cat.shape[0]\n",
        "\n",
        "#             timesteps = diffuser.sample_random_timesteps(batch_size)\n",
        "#             noisy_num, noise_target = diffuser.add_t_noise(batch_num, timesteps)\n",
        "\n",
        "#             cat_outputs, num_output = model(batch_cat, noisy_num, batch_rbf, timesteps)\n",
        "\n",
        "#             # Calculate losses\n",
        "#             cat_loss = sum(cat_criterion(cat_out.view(-1, cat_out.size(-1)),\n",
        "#                                        batch_cat[:, :, i].view(-1))\n",
        "#                           for i, cat_out in enumerate(cat_outputs))\n",
        "\n",
        "#             num_loss = num_criterion(num_output, noise_target)\n",
        "#             total_loss = cat_loss + num_loss\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "#             total_loss.backward()\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "#             optimizer.step()\n",
        "\n",
        "#             epoch_loss += total_loss.item()\n",
        "#             pbar.set_postfix({'Loss': f\"{total_loss.item():.4f}\"})\n",
        "\n",
        "#         avg_loss = epoch_loss / len(dataloader)\n",
        "#         losses.append(avg_loss)\n",
        "\n",
        "#         print(f\"Epoch {epoch+1} - Avg Loss: {avg_loss:.4f} - LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "#         scheduler.step()\n",
        "\n",
        "#     return losses\n",
        "\n",
        "# def generate_sequences_with_rbf(model, diffuser, n_sequences, seq_len, n_cat_features,\n",
        "#                                n_cat_tokens, n_num_features, n_rbf_features, device):\n",
        "#     \"\"\"Generate sequences with RBF features\"\"\"\n",
        "#     model.eval()\n",
        "\n",
        "#     # Initialize with random categorical data\n",
        "#     x_cat = torch.zeros(n_sequences, seq_len, n_cat_features, dtype=torch.long, device=device)\n",
        "#     for i, n_tokens in enumerate(n_cat_tokens):\n",
        "#         x_cat[:, :, i] = torch.randint(0, n_tokens, (n_sequences, seq_len), device=device)\n",
        "\n",
        "#     # Start with noise for numerical features\n",
        "#     x_num = diffuser.sample_student_t((n_sequences, seq_len, n_num_features))\n",
        "\n",
        "#     # Initialize random RBF features\n",
        "#     x_rbf = torch.randn(n_sequences, seq_len, n_rbf_features, device=device)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for t in tqdm(reversed(range(diffuser.total_steps)), desc=\"Generating\"):\n",
        "#             timesteps = torch.full((n_sequences,), t, device=device, dtype=torch.long)\n",
        "\n",
        "#             # Model predicts both categorical and numerical features\n",
        "#             cat_outputs, num_output = model(x_cat, x_num, x_rbf, timesteps)\n",
        "\n",
        "#             # Update numerical features through diffusion\n",
        "#             x_num = diffuser.sample(num_output, x_num, timesteps)\n",
        "\n",
        "#             # Update categorical features less frequently for stability\n",
        "#             if t % 100 == 0:\n",
        "#                 for i, cat_out in enumerate(cat_outputs):\n",
        "#                     probs = torch.softmax(cat_out, dim=-1)\n",
        "#                     x_cat[:, :, i] = torch.multinomial(probs.view(-1, probs.size(-1)), 1).view(n_sequences, seq_len)\n",
        "\n",
        "#     return x_cat, x_num\n",
        "\n",
        "# def create_dataframe_from_generated_rbf(generated_cat, generated_num, cat_attrs, num_attrs,\n",
        "#                                        label_encoders, num_scaler, sequence_length):\n",
        "#     \"\"\"Convert generated sequences to dataframe with proper datetime reconstruction\"\"\"\n",
        "#     import calendar\n",
        "#     from datetime import datetime, timedelta\n",
        "#     import pandas as pd\n",
        "\n",
        "#     def validate_and_fix_date(year, month, day):\n",
        "#         \"\"\"Validate and fix date components to ensure valid date\"\"\"\n",
        "#         year = max(1993, min(1998, int(year)))  # Reasonable year range\n",
        "#         month = max(1, min(12, int(month)))     # Month must be 1-12\n",
        "\n",
        "#         # Get maximum valid day for this month/year\n",
        "#         max_day = calendar.monthrange(year, month)[1]\n",
        "#         day = max(1, min(max_day, int(day)))    # Day must be valid for the month\n",
        "\n",
        "#         return year, month, day\n",
        "\n",
        "#     final_sequences = []\n",
        "\n",
        "#     for seq_idx in range(generated_cat.shape[0]):\n",
        "#         # Inverse transform numerical data\n",
        "#         seq_num = generated_num[seq_idx].cpu().numpy()\n",
        "#         seq_num_original = num_scaler.inverse_transform(seq_num)\n",
        "\n",
        "#         # Inverse transform categorical data\n",
        "#         seq_cat = generated_cat[seq_idx].cpu().numpy()\n",
        "\n",
        "#         # Create sequence dataframe\n",
        "#         seq_df = pd.DataFrame()\n",
        "\n",
        "#         # Add numerical features\n",
        "#         for i, col in enumerate(num_attrs):\n",
        "#             seq_df[col] = seq_num_original[:, i]\n",
        "\n",
        "#         # Add categorical features\n",
        "#         for i, col in enumerate(cat_attrs):\n",
        "#             seq_df[col] = label_encoders[col].inverse_transform(seq_cat[:, i])\n",
        "\n",
        "#         # Validate and fix date components\n",
        "#         seq_df['year'] = seq_df['year'].astype(int)\n",
        "#         seq_df['month'] = seq_df['month'].astype(int)\n",
        "#         seq_df['day'] = seq_df['day'].astype(int)\n",
        "\n",
        "#         # Fix the first date with validation\n",
        "#         try:\n",
        "#             first_year, first_month, first_day = validate_and_fix_date(\n",
        "#                 seq_df['year'].iloc[0],\n",
        "#                 seq_df['month'].iloc[0],\n",
        "#                 seq_df['day'].iloc[0]\n",
        "#             )\n",
        "#             first_date = datetime(first_year, first_month, first_day)\n",
        "#         except Exception as e:\n",
        "#             print(f\"Warning: Could not create valid first date for sequence {seq_idx}, using default date\")\n",
        "#             first_date = datetime(2020, 1, 1)\n",
        "\n",
        "#         dates = [first_date]\n",
        "\n",
        "#         # Use the model's generated td values for subsequent dates\n",
        "#         for i in range(1, len(seq_df)):\n",
        "#             td_days = max(0, int(seq_df['td'].iloc[i]))  # Ensure non-negative\n",
        "#             next_date = dates[-1] + timedelta(days=td_days)\n",
        "#             dates.append(next_date)\n",
        "\n",
        "#         seq_df['datetime'] = dates\n",
        "#         seq_df['account_id'] = seq_idx\n",
        "#         final_sequences.append(seq_df)\n",
        "\n",
        "#     return pd.concat(final_sequences, ignore_index=True)\n",
        "\n",
        "# # =============================================================================\n",
        "# # MAIN EXECUTION\n",
        "# # =============================================================================\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"Loading and preprocessing data...\")\n",
        "#     try:\n",
        "#         real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "#     except FileNotFoundError:\n",
        "#         print(\"Error: CSV file not found.\")\n",
        "#         exit()\n",
        "\n",
        "#     raw_data = preprocess_data_czech(real)\n",
        "#     raw_data = raw_data.sort_values(by=[\"account_id\", \"date\"])\n",
        "\n",
        "#     # Define features - remove temporal features from categorical since we'll use RBF\n",
        "#     cat_attrs = ['tcode', 'DoM_cat', 'age_group', 'year','month','day'] # Removed day, month, year, dow\n",
        "#     num_attrs = ['amount', 'raw_amount', 'td']\n",
        "\n",
        "#     df_processed = raw_data[cat_attrs + num_attrs + ['account_id', 'datetime', 'dow']].copy()\n",
        "\n",
        "#     # Setup and apply RBF encoding for temporal features\n",
        "#     print(\"Setting up RBF encoders...\")\n",
        "#     rbf_encoders = setup_rbf_encoders(n_periods=rbf_n_periods)\n",
        "#     rbf_features = apply_rbf_encoding(df_processed, rbf_encoders)\n",
        "\n",
        "#     # Calculate total RBF feature dimension\n",
        "#     n_rbf_features = sum(rbf_feat.shape[1] for rbf_feat in rbf_features.values())\n",
        "#     print(f\"Total RBF features dimension: {n_rbf_features}\")\n",
        "\n",
        "#     # Encode categorical features\n",
        "#     label_encoders = {}\n",
        "#     n_cat_tokens = []\n",
        "#     for attr in cat_attrs:\n",
        "#         le = LabelEncoder()\n",
        "#         df_processed[attr] = le.fit_transform(df_processed[attr].astype(str))\n",
        "#         label_encoders[attr] = le\n",
        "#         n_cat_tokens.append(len(le.classes_))\n",
        "\n",
        "#     # Scale numerical features\n",
        "#     num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "#     df_processed[num_attrs] = num_scaler.fit_transform(df_processed[num_attrs])\n",
        "\n",
        "#     # Create dataset with RBF features\n",
        "#     dataset = TemporalSequentialDatasetWithRBF(\n",
        "#         df_processed, cat_attrs, num_attrs, rbf_features,\n",
        "#         sequence_length, min_seq_length, max_sequences_per_account=3\n",
        "#     )\n",
        "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "#     # Initialize model with RBF features\n",
        "#     model = TemporalLSTMSynthesizerWithRBF(\n",
        "#         n_cat_features=len(cat_attrs),\n",
        "#         n_cat_tokens=n_cat_tokens,\n",
        "#         cat_emb_dim=cat_emb_dim,\n",
        "#         n_num_features=len(num_attrs),\n",
        "#         n_rbf_features=n_rbf_features,\n",
        "#         hidden_dim=mlp_layers[0]\n",
        "#     ).to(device)\n",
        "\n",
        "#     diffuser = StudentTDDPMDiffuser(\n",
        "#         total_steps=diffusion_steps,\n",
        "#         beta_start=diffusion_beta_start,\n",
        "#         beta_end=diffusion_beta_end,\n",
        "#         device=device,\n",
        "#         scheduler=scheduler,\n",
        "#         df=10\n",
        "#     )\n",
        "\n",
        "#     optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#     scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "#     print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters.\")\n",
        "\n",
        "#     # Train model\n",
        "#     print(\"Training model with RBF temporal features...\")\n",
        "#     losses = train_model_with_rbf(model, diffuser, dataloader, epochs, optimizer, scheduler)\n",
        "\n",
        "#     # Generate samples\n",
        "#     print(\"Generating sequences with RBF temporal features...\")\n",
        "#     generated_cat, generated_num = generate_sequences_with_rbf(\n",
        "#         model, diffuser, n_sequences=n_sequences, seq_len=sequence_length,\n",
        "#         n_cat_features=len(cat_attrs), n_cat_tokens=n_cat_tokens,\n",
        "#         n_num_features=len(num_attrs), n_rbf_features=n_rbf_features, device=device\n",
        "#     )\n",
        "\n",
        "#     # Create final dataframe\n",
        "#     final_df = create_dataframe_from_generated_rbf(\n",
        "#         generated_cat, generated_num, cat_attrs, num_attrs,\n",
        "#         label_encoders, num_scaler, sequence_length\n",
        "#     )\n",
        "\n",
        "#     # Select final columns and clean\n",
        "#     final_df = final_df[['account_id', 'raw_amount', 'amount', 'td', 'tcode', 'day','month','year']].copy()\n",
        "#     final_df['datetime'] = pd.to_datetime(final_df[['year', 'month', 'day']])\n",
        "#     final_df = final_df.dropna(subset=['datetime'])\n",
        "#     final_df['datetime'] = final_df['datetime'].dt.date\n",
        "\n",
        "#     print(f\"\\nFinal shape: {final_df.shape}\")\n",
        "#     print(\"\\nSample data:\")\n",
        "#     print(final_df.head(15))\n",
        "#     print(f\"\\nTemporal dependencies with RBF encoding - td range: {final_df['td'].min():.1f} to {final_df['td'].max():.1f}\")\n",
        "\n",
        "#     final_df.to_csv('synthetic_transactions_rbf.csv', index=False)\n",
        "#     print(\"\\nSynthetic data saved with RBF temporal encoding!\")\n",
        "\n",
        "# using RBF encoding\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "from sklego.preprocessing import RepeatingBasisFunction\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import calendar\n",
        "from tqdm import tqdm\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION\n",
        "# =============================================================================\n",
        "seed = 1234\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Model hyperparameters\n",
        "sequence_length = 80\n",
        "min_seq_length = 80\n",
        "cat_emb_dim = 4\n",
        "mlp_layers = [128, 128]\n",
        "diffusion_steps = 1000\n",
        "diffusion_beta_start = 1e-4\n",
        "diffusion_beta_end = 0.02\n",
        "scheduler = 'exp'\n",
        "epochs = 100 # Reduced for quick testing; set back to 100 for full training\n",
        "batch_size = 256\n",
        "learning_rate = 2e-4\n",
        "n_sequences = 500 # Reduced for quick testing; set back to 5000\n",
        "\n",
        "# RBF parameters\n",
        "rbf_n_periods = 8  # Number of periods for RBF encoding\n",
        "\n",
        "# =============================================================================\n",
        "# STUDENT-T DISTRIBUTION DDPM DIFFUSER\n",
        "# =============================================================================\n",
        "class StudentTDDPMDiffuser(object):\n",
        "    def __init__(self, total_steps=1000, beta_start=1e-4, beta_end=0.02, device='cpu', scheduler='exp', df=30):\n",
        "        self.total_steps = total_steps\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.device = device\n",
        "        self.df = df\n",
        "\n",
        "        self.alphas, self.betas = self.prepare_noise_schedule(scheduler=scheduler)\n",
        "        self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "    def prepare_noise_schedule(self, scheduler: str):\n",
        "        scale = 1000 / self.total_steps\n",
        "        beta_start = scale * self.beta_start\n",
        "        beta_end = scale * self.beta_end\n",
        "\n",
        "        if scheduler == 'linear':\n",
        "            betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
        "        elif scheduler == 'quad':\n",
        "            betas = torch.linspace(self.beta_start**0.5, self.beta_end**0.5, self.total_steps) ** 2\n",
        "        elif scheduler == 'exp':\n",
        "            betas = torch.exp(torch.linspace(math.log(beta_start), math.log(beta_end), self.total_steps))\n",
        "        elif scheduler == 'sigm':\n",
        "            x = torch.linspace(-6, 6, self.total_steps)\n",
        "            betas = torch.sigmoid(x) * (beta_end - beta_start) + beta_start\n",
        "\n",
        "        alphas = 1.0 - betas\n",
        "        return alphas.to(self.device), betas.to(self.device)\n",
        "\n",
        "    def sample_random_timesteps(self, n: int):\n",
        "        return torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "\n",
        "    def sample_student_t(self, shape):\n",
        "        if isinstance(shape, torch.Tensor):\n",
        "            shape = tuple(shape.tolist())\n",
        "\n",
        "        x = torch.randn(shape, device=self.device)\n",
        "        df_sample = max(3.0, float(self.df))\n",
        "        gamma_shape = df_sample / 2.0\n",
        "        # Ensure gamma_samples has the correct shape for broadcasting\n",
        "        gamma_samples = torch.tensor(stats.gamma.rvs(gamma_shape, scale=2.0, size=shape[0]),\n",
        "                                     dtype=torch.float32, device=self.device).view(-1, 1, 1)\n",
        "\n",
        "        scaling = torch.sqrt(torch.tensor(df_sample / (df_sample - 2.0), device=self.device))\n",
        "        t_noise = scaling * x / torch.sqrt(gamma_samples / df_sample)\n",
        "        return t_noise\n",
        "\n",
        "    def add_t_noise(self, x_num, t):\n",
        "        sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None, None]\n",
        "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None, None]\n",
        "\n",
        "        noise_num = self.sample_student_t(x_num.shape)\n",
        "        x_noise_num = sqrt_alpha_hat * x_num + sqrt_one_minus_alpha_hat * noise_num\n",
        "        return x_noise_num, noise_num\n",
        "\n",
        "    def p_sample_t(self, model_out, z_norm, timesteps):\n",
        "        sqrt_alpha_t = torch.sqrt(self.alphas[timesteps])[:, None, None]\n",
        "        betas_t = self.betas[timesteps][:, None, None]\n",
        "        sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[timesteps])[:, None, None]\n",
        "        epsilon_t = torch.sqrt(self.betas[timesteps][:, None, None])\n",
        "\n",
        "        random_noise = self.sample_student_t(z_norm.shape)\n",
        "        # No noise at the final step\n",
        "        random_noise[timesteps == 0] = 0.0\n",
        "\n",
        "        model_mean = ((1 / sqrt_alpha_t) * (z_norm - (betas_t * model_out / sqrt_one_minus_alpha_hat_t)))\n",
        "        z_norm = model_mean + (epsilon_t * random_noise)\n",
        "        return z_norm\n",
        "\n",
        "    def sample(self, model_out, z_norm, timesteps):\n",
        "        return self.p_sample_t(model_out, z_norm, timesteps)\n",
        "\n",
        "# =============================================================================\n",
        "# RBF ENCODING FUNCTIONS\n",
        "# =============================================================================\n",
        "def setup_rbf_encoders(n_periods=2):\n",
        "    \"\"\"Setup RBF encoders for temporal features\"\"\"\n",
        "    rbf_encoders = {}\n",
        "    rbf_encoders['day'] = RepeatingBasisFunction(n_periods=n_periods, column='day', input_range=(1, 31), remainder='drop')\n",
        "    rbf_encoders['month'] = RepeatingBasisFunction(n_periods=n_periods, column='month', input_range=(1, 12), remainder='drop')\n",
        "    rbf_encoders['dow'] = RepeatingBasisFunction(n_periods=n_periods, column='dow', input_range=(0, 6), remainder='drop')\n",
        "    rbf_encoders['year'] = RepeatingBasisFunction(n_periods=n_periods, column='year', input_range=(1990, 2030), remainder='drop')\n",
        "    return rbf_encoders\n",
        "\n",
        "def apply_rbf_encoding(df, rbf_encoders):\n",
        "    \"\"\"Apply RBF encoding to temporal features\"\"\"\n",
        "    rbf_features = {}\n",
        "    for feature_name, encoder in rbf_encoders.items():\n",
        "        temp_df = pd.DataFrame({feature_name: df[feature_name]})\n",
        "        rbf_encoded = encoder.fit_transform(temp_df)\n",
        "        rbf_features[feature_name] = rbf_encoded\n",
        "        print(f\"RBF encoded {feature_name}: shape {rbf_encoded.shape}\")\n",
        "    return rbf_features\n",
        "\n",
        "# =============================================================================\n",
        "# ENHANCED DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "def preprocess_data_czech(df):\n",
        "    \"\"\"Enhanced preprocessing with proper temporal features\"\"\"\n",
        "    czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "    df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "    df[\"month\"] = df[\"datetime\"].dt.month\n",
        "    df[\"day\"] = df[\"datetime\"].dt.day\n",
        "    df[\"dow\"] = df[\"datetime\"].dt.dayofweek\n",
        "    df[\"year\"] = df[\"datetime\"].dt.year\n",
        "    df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "    df_sorted = df.sort_values(['account_id', 'datetime']).copy()\n",
        "    df_sorted[\"td\"] = df_sorted.groupby(\"account_id\")[\"datetime\"].diff().dt.days.fillna(0.0)\n",
        "    df_sorted[\"dtme\"] = df_sorted.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "    df_sorted['raw_amount'] = df_sorted.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "    cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "    tcode = df_sorted[cat_code_fields[0]].astype(str)\n",
        "    for ccf in cat_code_fields[1:]:\n",
        "        tcode += \"__\" + df_sorted[ccf].astype(str).fillna('nan')\n",
        "    df_sorted[\"tcode\"] = tcode\n",
        "\n",
        "    conditions = [\n",
        "        (df_sorted['day'] >= 1) & (df_sorted['day'] <= 10),\n",
        "        (df_sorted['day'] > 10) & (df_sorted['day'] <= 20),\n",
        "        (df_sorted['day'] > 20) & (df_sorted['day'] <= 31)\n",
        "    ]\n",
        "    categories = ['first', 'middle', 'last']\n",
        "    df_sorted['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "    if 'age' in df_sorted.columns:\n",
        "        bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "        labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "        df_sorted['age_group'] = pd.cut(df_sorted['age'], bins=bin_edges, labels=labels, right=False).astype('object').fillna('unknown')\n",
        "    else:\n",
        "        df_sorted['age_group'] = 'unknown'\n",
        "\n",
        "    return df_sorted\n",
        "\n",
        "# =============================================================================\n",
        "# TEMPORAL-AWARE DATASET WITH RBF (BUG-FIXED)\n",
        "# =============================================================================\n",
        "class TemporalSequentialDatasetWithRBF(Dataset):\n",
        "    \"\"\"Dataset that preserves temporal dependencies and includes RBF features\"\"\"\n",
        "    def __init__(self, df, cat_attrs, num_attrs, rbf_features, sequence_length=30, min_seq_length=20, max_sequences_per_account=5):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.min_seq_length = min_seq_length\n",
        "        self.cat_attrs = cat_attrs\n",
        "        self.num_attrs = num_attrs\n",
        "        self.rbf_features = rbf_features\n",
        "        self.sequences = []\n",
        "\n",
        "        print(\"Creating temporal sequences with RBF features from transaction data...\")\n",
        "\n",
        "        for account_id in tqdm(df['account_id'].unique()):\n",
        "            # FIX: Keep the original index to correctly map RBF features later.\n",
        "            # Do NOT use drop=True, so the original index is preserved in a column named 'index'.\n",
        "            account_data = df[df['account_id'] == account_id].sort_values('datetime').reset_index()\n",
        "\n",
        "            if len(account_data) >= min_seq_length:\n",
        "                n_possible = len(account_data) - sequence_length + 1\n",
        "                if n_possible <= 0: continue\n",
        "\n",
        "                if n_possible <= max_sequences_per_account:\n",
        "                    start_indices = range(n_possible)\n",
        "                else:\n",
        "                    start_indices = np.linspace(0, n_possible-1, max_sequences_per_account, dtype=int)\n",
        "\n",
        "                for start_idx in start_indices:\n",
        "                    seq_data = account_data.iloc[start_idx:start_idx+sequence_length]\n",
        "                    cat_data = seq_data[self.cat_attrs].values\n",
        "                    num_data = seq_data[self.num_attrs].values\n",
        "\n",
        "                    # FIX: Use the preserved 'index' column to get the original row numbers\n",
        "                    original_indices = seq_data['index'].values\n",
        "\n",
        "                    # Extract RBF features for this sequence using the correct original indices\n",
        "                    rbf_data = []\n",
        "                    for feature_name in ['day', 'month', 'year', 'dow']:\n",
        "                        # This now correctly slices the RBF features for the specific sequence\n",
        "                        feature_rbf = self.rbf_features[feature_name][original_indices]\n",
        "                        rbf_data.append(feature_rbf)\n",
        "\n",
        "                    rbf_data = np.concatenate(rbf_data, axis=1)\n",
        "\n",
        "                    self.sequences.append({\n",
        "                        'cat_data': cat_data,\n",
        "                        'num_data': num_data,\n",
        "                        'rbf_data': rbf_data\n",
        "                    })\n",
        "\n",
        "        print(f\"Created {len(self.sequences)} temporal sequences with RBF features from {df['account_id'].nunique()} accounts.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        cat_tensor = torch.LongTensor(seq['cat_data'])\n",
        "        num_tensor = torch.FloatTensor(seq['num_data'])\n",
        "        rbf_tensor = torch.FloatTensor(seq['rbf_data'])\n",
        "        return cat_tensor, num_tensor, rbf_tensor\n",
        "\n",
        "# =============================================================================\n",
        "# TEMPORAL LSTM SYNTHESIZER WITH RBF\n",
        "# =============================================================================\n",
        "class TemporalLSTMSynthesizerWithRBF(nn.Module):\n",
        "    \"\"\"LSTM that learns temporal dependencies with RBF encoding\"\"\"\n",
        "    def __init__(self, n_cat_features, n_cat_tokens, cat_emb_dim, n_num_features,\n",
        "                 n_rbf_features, hidden_dim=256, lstm_layers=2, dim_t=64):\n",
        "        super(TemporalLSTMSynthesizerWithRBF, self).__init__()\n",
        "        self.n_cat_features = n_cat_features\n",
        "        self.n_num_features = n_num_features\n",
        "        self.n_rbf_features = n_rbf_features\n",
        "        self.cat_emb_dim = cat_emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dim_t = dim_t\n",
        "\n",
        "        self.cat_embeddings = nn.ModuleList([\n",
        "            nn.Embedding(n_cat_tokens[i], cat_emb_dim) for i in range(n_cat_features)\n",
        "        ])\n",
        "\n",
        "        total_cat_emb_dim = n_cat_features * cat_emb_dim\n",
        "        total_input_dim = total_cat_emb_dim + n_num_features + n_rbf_features\n",
        "\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(dim_t, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        self.input_projection = nn.Linear(total_input_dim, hidden_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=0.1 if lstm_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        self.cat_heads = nn.ModuleList([\n",
        "            nn.Linear(hidden_dim, n_cat_tokens[i]) for i in range(n_cat_features)\n",
        "        ])\n",
        "        self.num_head = nn.Linear(hidden_dim, n_num_features)\n",
        "        self.temporal_consistency = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def embed_time(self, timesteps, dim_out, max_period=10000):\n",
        "        half = dim_out // 2\n",
        "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half).to(device)\n",
        "        args = timesteps[:, None].float() * freqs[None]\n",
        "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "        if dim_out % 2:\n",
        "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "        return embedding\n",
        "\n",
        "    def embed_categorical(self, x_cat):\n",
        "        embeddings = [self.cat_embeddings[i](x_cat[:, :, i]) for i in range(self.n_cat_features)]\n",
        "        return torch.cat(embeddings, dim=-1)\n",
        "\n",
        "    def forward(self, x_cat, x_num, x_rbf, timesteps):\n",
        "        batch_size, seq_len, _ = x_num.shape\n",
        "        cat_emb = self.embed_categorical(x_cat)\n",
        "        x = torch.cat([cat_emb, x_num, x_rbf], dim=-1)\n",
        "        x_proj = self.input_projection(x)\n",
        "\n",
        "        time_emb_raw = self.embed_time(timesteps, self.dim_t)\n",
        "        time_emb = self.time_embed(time_emb_raw).unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "        x_with_time = x_proj + time_emb\n",
        "        x_temporal = self.temporal_consistency(x_with_time)\n",
        "        lstm_out, _ = self.lstm(x_temporal)\n",
        "\n",
        "        cat_outputs = [head(lstm_out) for head in self.cat_heads]\n",
        "        num_output = self.num_head(lstm_out)\n",
        "        return cat_outputs, num_output\n",
        "\n",
        "# =============================================================================\n",
        "# TRAINING AND GENERATION WITH RBF\n",
        "# =============================================================================\n",
        "def train_model_with_rbf(model, diffuser, dataloader, epochs, optimizer, scheduler):\n",
        "    model.train()\n",
        "    cat_criterion = nn.CrossEntropyLoss()\n",
        "    num_criterion = nn.MSELoss()\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for batch_cat, batch_num, batch_rbf in pbar:\n",
        "            batch_cat, batch_num, batch_rbf = batch_cat.to(device), batch_num.to(device), batch_rbf.to(device)\n",
        "            batch_size = batch_cat.shape[0]\n",
        "\n",
        "            timesteps = diffuser.sample_random_timesteps(batch_size)\n",
        "            noisy_num, noise_target = diffuser.add_t_noise(batch_num, timesteps)\n",
        "\n",
        "            cat_outputs, num_output = model(batch_cat, noisy_num, batch_rbf, timesteps)\n",
        "\n",
        "            cat_loss = sum(cat_criterion(cat_out.view(-1, cat_out.size(-1)), batch_cat[:, :, i].view(-1))\n",
        "                          for i, cat_out in enumerate(cat_outputs))\n",
        "            num_loss = num_criterion(num_output, noise_target)\n",
        "            total_loss = cat_loss + num_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += total_loss.item()\n",
        "            pbar.set_postfix({'Loss': f\"{total_loss.item():.4f}\"})\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        losses.append(avg_loss)\n",
        "        print(f\"Epoch {epoch+1} - Avg Loss: {avg_loss:.4f} - LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "        scheduler.step()\n",
        "    return losses\n",
        "\n",
        "def generate_sequences_with_rbf(model, diffuser, n_sequences, seq_len, n_cat_features,\n",
        "                               n_cat_tokens, n_num_features, n_rbf_features, device):\n",
        "    model.eval()\n",
        "    x_cat = torch.zeros(n_sequences, seq_len, n_cat_features, dtype=torch.long, device=device)\n",
        "    for i, n_tokens in enumerate(n_cat_tokens):\n",
        "        x_cat[:, :, i] = torch.randint(0, n_tokens, (n_sequences, seq_len), device=device)\n",
        "\n",
        "    x_num = diffuser.sample_student_t((n_sequences, seq_len, n_num_features))\n",
        "    # We don't need to generate RBF features; the model takes them as input during training\n",
        "    # For generation, we can feed in random noise as a placeholder, as the model should have\n",
        "    # learned to associate the primary features without relying on RBF for generation output.\n",
        "    x_rbf = torch.randn(n_sequences, seq_len, n_rbf_features, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for t in tqdm(reversed(range(diffuser.total_steps)), desc=\"Generating\"):\n",
        "            timesteps = torch.full((n_sequences,), t, device=device, dtype=torch.long)\n",
        "            cat_outputs, num_output = model(x_cat, x_num, x_rbf, timesteps)\n",
        "            x_num = diffuser.sample(num_output, x_num, timesteps)\n",
        "            if t > 0 and t % 100 == 0: # Update categorical features periodically\n",
        "                for i, cat_out in enumerate(cat_outputs):\n",
        "                    probs = torch.softmax(cat_out, dim=-1)\n",
        "                    x_cat[:, :, i] = torch.multinomial(probs.view(-1, probs.size(-1)), 1).view(n_sequences, seq_len)\n",
        "    return x_cat, x_num\n",
        "\n",
        "def create_dataframe_from_generated_rbf(generated_cat, generated_num, cat_attrs, num_attrs,\n",
        "                                       label_encoders, num_scaler):\n",
        "    \"\"\"(IMPROVED) Convert generated sequences to a clean dataframe with proper datetime reconstruction.\"\"\"\n",
        "    def validate_and_fix_date(year, month, day):\n",
        "        try:\n",
        "            year = int(year)\n",
        "            month = int(month)\n",
        "            day = int(day)\n",
        "            year = max(1993, min(2010, year)) # Constrain to a reasonable range from the data\n",
        "            month = max(1, min(12, month))\n",
        "            max_day = calendar.monthrange(year, month)[1]\n",
        "            day = max(1, min(max_day, day))\n",
        "            return year, month, day\n",
        "        except (ValueError, TypeError):\n",
        "             # Return a default if values are not convertible to int\n",
        "            return 1995, 1, 1\n",
        "\n",
        "\n",
        "    final_sequences = []\n",
        "    for seq_idx in range(generated_cat.shape[0]):\n",
        "        seq_num_original = num_scaler.inverse_transform(generated_num[seq_idx].cpu().numpy())\n",
        "        seq_cat = generated_cat[seq_idx].cpu().numpy()\n",
        "\n",
        "        seq_df = pd.DataFrame(seq_num_original, columns=num_attrs)\n",
        "        for i, col in enumerate(cat_attrs):\n",
        "             # Ensure indices are within the valid range for the encoder\n",
        "            encoded_labels = seq_cat[:, i]\n",
        "            valid_indices = np.where(encoded_labels < len(label_encoders[col].classes_))\n",
        "            decoded_labels = np.full_like(encoded_labels, fill_value='unknown', dtype=object)\n",
        "\n",
        "            if len(valid_indices[0]) > 0:\n",
        "                decoded_labels[valid_indices] = label_encoders[col].inverse_transform(encoded_labels[valid_indices])\n",
        "\n",
        "            seq_df[col] = decoded_labels\n",
        "\n",
        "        try:\n",
        "            first_year, first_month, first_day = validate_and_fix_date(\n",
        "                seq_df['year'].iloc[0], seq_df['month'].iloc[0], seq_df['day'].iloc[0]\n",
        "            )\n",
        "            first_date = datetime(first_year, first_month, first_day)\n",
        "        except Exception:\n",
        "            first_date = datetime(1995, 1, 1) # Fallback default\n",
        "\n",
        "        dates = [first_date]\n",
        "        for i in range(1, len(seq_df)):\n",
        "            td_days = max(0, int(seq_df['td'].iloc[i]))\n",
        "            next_date = dates[-1] + timedelta(days=td_days)\n",
        "            dates.append(next_date)\n",
        "\n",
        "        seq_df['datetime'] = dates\n",
        "        seq_df['account_id'] = seq_idx\n",
        "        final_sequences.append(seq_df)\n",
        "\n",
        "    # REFACTORED: Consolidate final processing here\n",
        "    if not final_sequences:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    final_df = pd.concat(final_sequences, ignore_index=True)\n",
        "    # Re-derive day/month/year from the consistent 'datetime' column\n",
        "    final_df['day'] = final_df['datetime'].dt.day\n",
        "    final_df['month'] = final_df['datetime'].dt.month\n",
        "    final_df['year'] = final_df['datetime'].dt.year\n",
        "\n",
        "    # Select final columns and clean\n",
        "    final_cols = ['account_id', 'datetime', 'raw_amount', 'amount', 'td', 'tcode', 'day','month','year']\n",
        "    final_df = final_df[final_cols].copy()\n",
        "    final_df['datetime'] = final_df['datetime'].dt.date\n",
        "    final_df = final_df.dropna()\n",
        "\n",
        "    return final_df\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN EXECUTION (CLEANED)\n",
        "# =============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    try:\n",
        "        # Make sure the CSV is in the same directory or provide a full path\n",
        "        real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: 'tr_by_acct_w_age.csv' not found. Please place it in the correct directory.\")\n",
        "        exit()\n",
        "\n",
        "    raw_data = preprocess_data_czech(real)\n",
        "\n",
        "    # The model will learn to generate these features\n",
        "    cat_attrs = ['tcode', 'DoM_cat', 'age_group', 'year', 'month', 'day']\n",
        "    num_attrs = ['amount', 'raw_amount', 'td']\n",
        "    # These features are needed for RBF encoding and data setup\n",
        "    utility_attrs = ['account_id', 'datetime', 'dow']\n",
        "\n",
        "    df_processed = raw_data[cat_attrs + num_attrs + utility_attrs].copy().dropna()\n",
        "\n",
        "    print(\"Setting up RBF encoders...\")\n",
        "    rbf_encoders = setup_rbf_encoders(n_periods=rbf_n_periods)\n",
        "    rbf_features = apply_rbf_encoding(df_processed, rbf_encoders)\n",
        "\n",
        "    n_rbf_features = sum(rbf_feat.shape[1] for rbf_feat in rbf_features.values())\n",
        "    print(f\"Total RBF features dimension: {n_rbf_features}\")\n",
        "\n",
        "    label_encoders = {}\n",
        "    n_cat_tokens = []\n",
        "    for attr in cat_attrs:\n",
        "        le = LabelEncoder()\n",
        "        df_processed[attr] = le.fit_transform(df_processed[attr].astype(str))\n",
        "        label_encoders[attr] = le\n",
        "        n_cat_tokens.append(len(le.classes_))\n",
        "\n",
        "    num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "    df_processed[num_attrs] = num_scaler.fit_transform(df_processed[num_attrs])\n",
        "\n",
        "    dataset = TemporalSequentialDatasetWithRBF(\n",
        "        df_processed, cat_attrs, num_attrs, rbf_features,\n",
        "        sequence_length, min_seq_length, max_sequences_per_account=3\n",
        "    )\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    model = TemporalLSTMSynthesizerWithRBF(\n",
        "        n_cat_features=len(cat_attrs),\n",
        "        n_cat_tokens=n_cat_tokens,\n",
        "        cat_emb_dim=cat_emb_dim,\n",
        "        n_num_features=len(num_attrs),\n",
        "        n_rbf_features=n_rbf_features,\n",
        "        hidden_dim=mlp_layers[0]\n",
        "    ).to(device)\n",
        "\n",
        "    diffuser = StudentTDDPMDiffuser(\n",
        "        total_steps=diffusion_steps, beta_start=diffusion_beta_start, beta_end=diffusion_beta_end,\n",
        "        device=device, scheduler=scheduler, df=10\n",
        "    )\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler_lr = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
        "\n",
        "    print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters.\")\n",
        "\n",
        "    print(\"Training model with RBF temporal features...\")\n",
        "    losses = train_model_with_rbf(model, diffuser, dataloader, epochs, optimizer, scheduler_lr)\n",
        "\n",
        "    print(\"Generating sequences with RBF temporal features...\")\n",
        "    generated_cat, generated_num = generate_sequences_with_rbf(\n",
        "        model, diffuser, n_sequences=n_sequences, seq_len=sequence_length,\n",
        "        n_cat_features=len(cat_attrs), n_cat_tokens=n_cat_tokens,\n",
        "        n_num_features=len(num_attrs), n_rbf_features=n_rbf_features, device=device\n",
        "    )\n",
        "\n",
        "    print(\"Creating final dataframe from generated sequences...\")\n",
        "    final_df = create_dataframe_from_generated_rbf(\n",
        "        generated_cat, generated_num, cat_attrs, num_attrs,\n",
        "        label_encoders, num_scaler\n",
        "    )\n",
        "\n",
        "    if not final_df.empty:\n",
        "        print(f\"\\nFinal shape: {final_df.shape}\")\n",
        "        print(\"\\nSample of generated data:\")\n",
        "        print(final_df.head(15))\n",
        "        print(f\"\\nTemporal dependencies with RBF encoding - td range: {final_df['td'].min():.1f} to {final_df['td'].max():.1f}\")\n",
        "\n",
        "        final_df.to_csv('synthetic_transactions_rbf_corrected.csv', index=False)\n",
        "        print(\"\\nSynthetic data saved to 'synthetic_transactions_rbf_corrected.csv'!\")\n",
        "    else:\n",
        "        print(\"\\nWarning: No data was generated. The dataset might be too small or parameters need adjustment.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "506NVAE4VR1T",
        "outputId": "6c196e1b-331b-4556-c263-859843e8af47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Loading and preprocessing data...\n",
            "Setting up RBF encoders...\n",
            "RBF encoded day: shape (1056320, 8)\n",
            "RBF encoded month: shape (1056320, 8)\n",
            "RBF encoded dow: shape (1056320, 8)\n",
            "RBF encoded year: shape (1056320, 8)\n",
            "Total RBF features dimension: 32\n",
            "Creating temporal sequences with RBF features from transaction data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4500/4500 [00:17<00:00, 252.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 12340 temporal sequences with RBF features from 4500 accounts.\n",
            "Model has 323,445 parameters.\n",
            "Training model with RBF temporal features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 49/49 [00:01<00:00, 27.57it/s, Loss=13.2500]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Avg Loss: 14.1402 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100: 100%|██████████| 49/49 [00:01<00:00, 29.32it/s, Loss=11.0499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Avg Loss: 12.0443 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100: 100%|██████████| 49/49 [00:01<00:00, 29.35it/s, Loss=10.3082]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Avg Loss: 10.6496 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100: 100%|██████████| 49/49 [00:01<00:00, 29.54it/s, Loss=9.5734]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Avg Loss: 9.7719 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100: 100%|██████████| 49/49 [00:01<00:00, 29.70it/s, Loss=9.0945]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Avg Loss: 9.0716 - LR: 0.000199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100: 100%|██████████| 49/49 [00:01<00:00, 29.58it/s, Loss=7.5285]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Avg Loss: 8.1757 - LR: 0.000199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100: 100%|██████████| 49/49 [00:01<00:00, 29.65it/s, Loss=6.7910]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Avg Loss: 7.2537 - LR: 0.000198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100: 100%|██████████| 49/49 [00:01<00:00, 29.43it/s, Loss=6.1078]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Avg Loss: 6.5402 - LR: 0.000198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100: 100%|██████████| 49/49 [00:01<00:00, 29.10it/s, Loss=5.6139]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Avg Loss: 5.9427 - LR: 0.000197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100: 100%|██████████| 49/49 [00:01<00:00, 28.97it/s, Loss=5.2137]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Avg Loss: 5.4748 - LR: 0.000196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100: 100%|██████████| 49/49 [00:01<00:00, 29.08it/s, Loss=5.0232]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - Avg Loss: 5.0705 - LR: 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100: 100%|██████████| 49/49 [00:01<00:00, 29.13it/s, Loss=4.5496]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - Avg Loss: 4.7019 - LR: 0.000194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/100: 100%|██████████| 49/49 [00:01<00:00, 29.19it/s, Loss=4.2584]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 - Avg Loss: 4.3153 - LR: 0.000193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/100: 100%|██████████| 49/49 [00:01<00:00, 29.12it/s, Loss=3.8322]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 - Avg Loss: 4.0110 - LR: 0.000192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/100: 100%|██████████| 49/49 [00:01<00:00, 29.12it/s, Loss=3.6955]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 - Avg Loss: 3.7730 - LR: 0.000191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/100: 100%|██████████| 49/49 [00:01<00:00, 28.70it/s, Loss=3.3621]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 - Avg Loss: 3.5482 - LR: 0.000189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/100: 100%|██████████| 49/49 [00:01<00:00, 28.79it/s, Loss=3.2064]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 - Avg Loss: 3.3778 - LR: 0.000188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/100: 100%|██████████| 49/49 [00:01<00:00, 29.01it/s, Loss=3.0296]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 - Avg Loss: 3.1948 - LR: 0.000186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/100: 100%|██████████| 49/49 [00:01<00:00, 29.08it/s, Loss=3.1288]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 - Avg Loss: 3.0353 - LR: 0.000185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/100: 100%|██████████| 49/49 [00:01<00:00, 29.26it/s, Loss=2.7480]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 - Avg Loss: 2.8790 - LR: 0.000183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/100: 100%|██████████| 49/49 [00:01<00:00, 29.51it/s, Loss=2.7486]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 - Avg Loss: 2.7306 - LR: 0.000181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/100: 100%|██████████| 49/49 [00:01<00:00, 29.46it/s, Loss=2.4833]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 - Avg Loss: 2.5974 - LR: 0.000179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/100: 100%|██████████| 49/49 [00:01<00:00, 28.76it/s, Loss=2.3211]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 - Avg Loss: 2.4776 - LR: 0.000177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/100: 100%|██████████| 49/49 [00:01<00:00, 29.39it/s, Loss=2.2430]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 - Avg Loss: 2.3700 - LR: 0.000175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/100: 100%|██████████| 49/49 [00:01<00:00, 29.54it/s, Loss=2.1079]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 - Avg Loss: 2.2490 - LR: 0.000173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/100: 100%|██████████| 49/49 [00:01<00:00, 29.61it/s, Loss=2.1439]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 - Avg Loss: 2.1436 - LR: 0.000171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/100: 100%|██████████| 49/49 [00:01<00:00, 28.83it/s, Loss=1.9325]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 - Avg Loss: 2.0520 - LR: 0.000169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/100: 100%|██████████| 49/49 [00:01<00:00, 29.39it/s, Loss=1.9037]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 - Avg Loss: 1.9758 - LR: 0.000166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/100: 100%|██████████| 49/49 [00:01<00:00, 29.33it/s, Loss=1.7705]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 - Avg Loss: 1.8826 - LR: 0.000164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/100: 100%|██████████| 49/49 [00:01<00:00, 28.66it/s, Loss=1.7496]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 - Avg Loss: 1.8010 - LR: 0.000161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/100: 100%|██████████| 49/49 [00:01<00:00, 29.37it/s, Loss=1.6442]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 - Avg Loss: 1.7185 - LR: 0.000159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/100: 100%|██████████| 49/49 [00:01<00:00, 29.72it/s, Loss=1.5431]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 - Avg Loss: 1.6438 - LR: 0.000156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/100: 100%|██████████| 49/49 [00:01<00:00, 29.25it/s, Loss=1.5978]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 - Avg Loss: 1.5860 - LR: 0.000154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/100: 100%|██████████| 49/49 [00:01<00:00, 28.82it/s, Loss=1.3285]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 - Avg Loss: 1.5086 - LR: 0.000151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/100: 100%|██████████| 49/49 [00:01<00:00, 29.76it/s, Loss=1.5110]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 - Avg Loss: 1.4645 - LR: 0.000148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/100: 100%|██████████| 49/49 [00:01<00:00, 29.25it/s, Loss=1.3534]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 - Avg Loss: 1.4144 - LR: 0.000146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/100: 100%|██████████| 49/49 [00:01<00:00, 28.74it/s, Loss=1.4622]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 - Avg Loss: 1.3681 - LR: 0.000143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/100: 100%|██████████| 49/49 [00:01<00:00, 29.53it/s, Loss=1.3605]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 - Avg Loss: 1.3174 - LR: 0.000140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/100: 100%|██████████| 49/49 [00:01<00:00, 29.32it/s, Loss=1.1251]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 - Avg Loss: 1.2763 - LR: 0.000137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/100: 100%|██████████| 49/49 [00:01<00:00, 29.06it/s, Loss=1.1614]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 - Avg Loss: 1.2496 - LR: 0.000134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/100: 100%|██████████| 49/49 [00:01<00:00, 29.45it/s, Loss=1.2755]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 - Avg Loss: 1.2073 - LR: 0.000131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/100: 100%|██████████| 49/49 [00:01<00:00, 29.17it/s, Loss=1.2011]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 - Avg Loss: 1.1837 - LR: 0.000128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/100: 100%|██████████| 49/49 [00:01<00:00, 28.94it/s, Loss=1.1129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 - Avg Loss: 1.1451 - LR: 0.000125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/100: 100%|██████████| 49/49 [00:01<00:00, 29.17it/s, Loss=1.0308]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 - Avg Loss: 1.1283 - LR: 0.000122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/100: 100%|██████████| 49/49 [00:01<00:00, 29.87it/s, Loss=1.0771]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 - Avg Loss: 1.1002 - LR: 0.000119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/100: 100%|██████████| 49/49 [00:01<00:00, 29.92it/s, Loss=1.0062]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 - Avg Loss: 1.0686 - LR: 0.000116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/100: 100%|██████████| 49/49 [00:01<00:00, 29.79it/s, Loss=1.1038]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 - Avg Loss: 1.0458 - LR: 0.000113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/100: 100%|██████████| 49/49 [00:01<00:00, 29.60it/s, Loss=1.0462]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 - Avg Loss: 1.0293 - LR: 0.000110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/100: 100%|██████████| 49/49 [00:01<00:00, 29.62it/s, Loss=0.9855]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 - Avg Loss: 1.0084 - LR: 0.000107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/100: 100%|██████████| 49/49 [00:01<00:00, 28.82it/s, Loss=0.9296]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 - Avg Loss: 0.9982 - LR: 0.000104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51/100: 100%|██████████| 49/49 [00:01<00:00, 29.12it/s, Loss=0.9354]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51 - Avg Loss: 0.9768 - LR: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52/100: 100%|██████████| 49/49 [00:01<00:00, 29.57it/s, Loss=0.8355]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52 - Avg Loss: 0.9633 - LR: 0.000097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53/100: 100%|██████████| 49/49 [00:01<00:00, 28.88it/s, Loss=0.8998]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53 - Avg Loss: 0.9349 - LR: 0.000094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54/100: 100%|██████████| 49/49 [00:01<00:00, 28.91it/s, Loss=0.9355]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54 - Avg Loss: 0.9281 - LR: 0.000091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55/100: 100%|██████████| 49/49 [00:01<00:00, 28.89it/s, Loss=0.8679]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55 - Avg Loss: 0.9182 - LR: 0.000088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56/100: 100%|██████████| 49/49 [00:01<00:00, 28.58it/s, Loss=0.9275]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 - Avg Loss: 0.9023 - LR: 0.000085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57/100: 100%|██████████| 49/49 [00:01<00:00, 28.21it/s, Loss=0.8481]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57 - Avg Loss: 0.8917 - LR: 0.000082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58/100: 100%|██████████| 49/49 [00:01<00:00, 28.41it/s, Loss=0.8828]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58 - Avg Loss: 0.8826 - LR: 0.000079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59/100: 100%|██████████| 49/49 [00:01<00:00, 28.72it/s, Loss=0.9125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59 - Avg Loss: 0.8607 - LR: 0.000076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60/100: 100%|██████████| 49/49 [00:01<00:00, 28.66it/s, Loss=0.8863]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60 - Avg Loss: 0.8594 - LR: 0.000073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 61/100: 100%|██████████| 49/49 [00:01<00:00, 28.85it/s, Loss=0.7880]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61 - Avg Loss: 0.8499 - LR: 0.000070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 62/100: 100%|██████████| 49/49 [00:01<00:00, 28.60it/s, Loss=0.9035]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62 - Avg Loss: 0.8436 - LR: 0.000067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 63/100: 100%|██████████| 49/49 [00:01<00:00, 28.53it/s, Loss=0.9183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 - Avg Loss: 0.8310 - LR: 0.000064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 64/100: 100%|██████████| 49/49 [00:01<00:00, 28.19it/s, Loss=0.8879]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64 - Avg Loss: 0.8226 - LR: 0.000061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 65/100: 100%|██████████| 49/49 [00:01<00:00, 28.64it/s, Loss=0.9059]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65 - Avg Loss: 0.8238 - LR: 0.000058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 66/100: 100%|██████████| 49/49 [00:01<00:00, 28.76it/s, Loss=0.8232]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66 - Avg Loss: 0.8103 - LR: 0.000055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 67/100: 100%|██████████| 49/49 [00:01<00:00, 28.77it/s, Loss=0.7966]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67 - Avg Loss: 0.8006 - LR: 0.000053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 68/100: 100%|██████████| 49/49 [00:01<00:00, 28.65it/s, Loss=0.7722]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68 - Avg Loss: 0.7931 - LR: 0.000050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 69/100: 100%|██████████| 49/49 [00:01<00:00, 28.53it/s, Loss=0.7115]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69 - Avg Loss: 0.7917 - LR: 0.000047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 70/100: 100%|██████████| 49/49 [00:01<00:00, 28.92it/s, Loss=0.8295]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 - Avg Loss: 0.7917 - LR: 0.000045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 71/100: 100%|██████████| 49/49 [00:01<00:00, 29.06it/s, Loss=0.7558]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71 - Avg Loss: 0.7760 - LR: 0.000042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72/100: 100%|██████████| 49/49 [00:01<00:00, 29.16it/s, Loss=0.7199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72 - Avg Loss: 0.7777 - LR: 0.000040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73/100: 100%|██████████| 49/49 [00:01<00:00, 29.10it/s, Loss=0.7338]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73 - Avg Loss: 0.7708 - LR: 0.000037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74/100: 100%|██████████| 49/49 [00:01<00:00, 29.31it/s, Loss=0.7187]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74 - Avg Loss: 0.7691 - LR: 0.000035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75/100: 100%|██████████| 49/49 [00:01<00:00, 29.43it/s, Loss=0.7682]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75 - Avg Loss: 0.7678 - LR: 0.000032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76/100: 100%|██████████| 49/49 [00:01<00:00, 29.14it/s, Loss=0.8384]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76 - Avg Loss: 0.7643 - LR: 0.000030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 77/100: 100%|██████████| 49/49 [00:01<00:00, 29.12it/s, Loss=0.7018]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 - Avg Loss: 0.7576 - LR: 0.000028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 78/100: 100%|██████████| 49/49 [00:01<00:00, 28.94it/s, Loss=0.7577]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78 - Avg Loss: 0.7555 - LR: 0.000026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 79/100: 100%|██████████| 49/49 [00:01<00:00, 29.52it/s, Loss=0.7323]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79 - Avg Loss: 0.7575 - LR: 0.000024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 80/100: 100%|██████████| 49/49 [00:01<00:00, 29.27it/s, Loss=0.6905]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80 - Avg Loss: 0.7443 - LR: 0.000022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 81/100: 100%|██████████| 49/49 [00:01<00:00, 29.54it/s, Loss=0.7332]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81 - Avg Loss: 0.7513 - LR: 0.000020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 82/100: 100%|██████████| 49/49 [00:01<00:00, 29.54it/s, Loss=0.7645]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82 - Avg Loss: 0.7458 - LR: 0.000018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 83/100: 100%|██████████| 49/49 [00:01<00:00, 29.42it/s, Loss=0.7089]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83 - Avg Loss: 0.7460 - LR: 0.000016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 84/100: 100%|██████████| 49/49 [00:01<00:00, 29.28it/s, Loss=0.9560]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 - Avg Loss: 0.7565 - LR: 0.000015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 85/100: 100%|██████████| 49/49 [00:01<00:00, 29.29it/s, Loss=0.7785]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85 - Avg Loss: 0.7410 - LR: 0.000013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86/100: 100%|██████████| 49/49 [00:01<00:00, 29.51it/s, Loss=0.6980]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86 - Avg Loss: 0.7386 - LR: 0.000012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87/100: 100%|██████████| 49/49 [00:01<00:00, 29.44it/s, Loss=0.6862]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87 - Avg Loss: 0.7373 - LR: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88/100: 100%|██████████| 49/49 [00:01<00:00, 25.28it/s, Loss=0.8150]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88 - Avg Loss: 0.7366 - LR: 0.000009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89/100: 100%|██████████| 49/49 [00:01<00:00, 29.22it/s, Loss=0.9117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89 - Avg Loss: 0.7373 - LR: 0.000008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90/100: 100%|██████████| 49/49 [00:01<00:00, 29.03it/s, Loss=0.7450]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 - Avg Loss: 0.7307 - LR: 0.000007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 91/100: 100%|██████████| 49/49 [00:01<00:00, 28.84it/s, Loss=0.7317]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91 - Avg Loss: 0.7402 - LR: 0.000006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92/100: 100%|██████████| 49/49 [00:01<00:00, 29.16it/s, Loss=0.7430]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92 - Avg Loss: 0.7334 - LR: 0.000005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93/100: 100%|██████████| 49/49 [00:01<00:00, 28.82it/s, Loss=0.6773]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93 - Avg Loss: 0.7310 - LR: 0.000004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94/100: 100%|██████████| 49/49 [00:01<00:00, 29.05it/s, Loss=0.7227]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94 - Avg Loss: 0.7268 - LR: 0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95/100: 100%|██████████| 49/49 [00:01<00:00, 28.99it/s, Loss=0.7490]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 - Avg Loss: 0.7316 - LR: 0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 96/100: 100%|██████████| 49/49 [00:01<00:00, 28.53it/s, Loss=0.7952]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96 - Avg Loss: 0.7261 - LR: 0.000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 97/100: 100%|██████████| 49/49 [00:01<00:00, 28.99it/s, Loss=0.6891]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97 - Avg Loss: 0.7327 - LR: 0.000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 98/100: 100%|██████████| 49/49 [00:01<00:00, 28.41it/s, Loss=0.8037]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98 - Avg Loss: 0.7346 - LR: 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99/100: 100%|██████████| 49/49 [00:01<00:00, 29.01it/s, Loss=0.6640]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 - Avg Loss: 0.7297 - LR: 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 100/100: 100%|██████████| 49/49 [00:01<00:00, 29.03it/s, Loss=0.6776]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100 - Avg Loss: 0.7261 - LR: 0.000001\n",
            "Generating sequences with RBF temporal features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 1000it [00:17, 56.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating final dataframe from generated sequences...\n",
            "\n",
            "Final shape: (40000, 9)\n",
            "\n",
            "Sample of generated data:\n",
            "    account_id    datetime    raw_amount        amount    td  \\\n",
            "0            0  1996-01-08    180.983185    122.417511  30.0   \n",
            "1            0  1996-01-23    169.095947     14.600000  15.0   \n",
            "2            0  1996-01-27    -14.600000   5000.210938   4.0   \n",
            "3            0  1996-01-29    136.791977   1000.000000   2.0   \n",
            "4            0  1996-02-04     74.257866    208.895096   6.0   \n",
            "5            0  1996-02-22  13711.835938   1999.143188  18.0   \n",
            "6            0  1996-02-22     80.085236     14.600000   0.0   \n",
            "7            0  1996-02-22     50.390862    136.859177   0.0   \n",
            "8            0  1996-02-23  -1800.000000   2269.186768   1.0   \n",
            "9            0  1996-02-23     85.547699    600.000000   0.0   \n",
            "10           0  1996-02-23   -506.519073   1563.869751   0.0   \n",
            "11           0  1996-02-29    138.537125   7618.906250   6.0   \n",
            "12           0  1996-02-29  -4013.203125   6076.787109   0.0   \n",
            "13           0  1996-03-17    144.328552  23454.095703  17.0   \n",
            "14           0  1996-03-17  31011.878906  23977.851562   0.0   \n",
            "\n",
            "                                                tcode  day  month  year  \n",
            "0   DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE P...    8      1  1996  \n",
            "1        DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT   23      1  1996  \n",
            "2                         DEBIT__CASH WITHDRAWAL__nan   27      1  1996  \n",
            "3        DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT   29      1  1996  \n",
            "4                         CREDIT__CREDIT IN CASH__nan    4      2  1996  \n",
            "5                         CREDIT__CREDIT IN CASH__nan   22      2  1996  \n",
            "6        DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT   22      2  1996  \n",
            "7                      CREDIT__nan__INTEREST CREDITED   22      2  1996  \n",
            "8                         DEBIT__CASH WITHDRAWAL__nan   23      2  1996  \n",
            "9                         DEBIT__CASH WITHDRAWAL__nan   23      2  1996  \n",
            "10               DEBIT__REMITTANCE TO ANOTHER BANK__    23      2  1996  \n",
            "11       DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD   29      2  1996  \n",
            "12                        DEBIT__CASH WITHDRAWAL__nan   29      2  1996  \n",
            "13                        DEBIT__CASH WITHDRAWAL__nan   17      3  1996  \n",
            "14                        CREDIT__CREDIT IN CASH__nan   17      3  1996  \n",
            "\n",
            "Temporal dependencies with RBF encoding - td range: 0.0 to 31.0\n",
            "\n",
            "Synthetic data saved to 'synthetic_transactions_rbf_corrected.csv'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "t78ARCyzqDl0",
        "outputId": "cdf93565-5737-4306-d291-774a4329b159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        account_id    raw_amount        amount    td  \\\n",
              "0                0     70.888054    374.191162   4.0   \n",
              "1                0    -14.600000   5289.441895   0.0   \n",
              "2                0 -13837.727539  23464.589844  31.0   \n",
              "3                0  36568.246094     14.600000  31.0   \n",
              "4                0  -2276.346436  11215.634766  31.0   \n",
              "...            ...           ...           ...   ...   \n",
              "399995        4999  -7024.736328   9236.980469   0.0   \n",
              "399996        4999    -14.600000  73800.000000   0.0   \n",
              "399997        4999    -14.600000   1800.000000   0.0   \n",
              "399998        4999  -4343.492188  18733.396484   0.0   \n",
              "399999        4999    110.646019     14.600000   0.0   \n",
              "\n",
              "                                                    tcode  day  month  year  \n",
              "0                          CREDIT__nan__INTEREST CREDITED   31      9  1997  \n",
              "1       CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...   13     10  1997  \n",
              "2       CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...   14     11  1997  \n",
              "3       CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...   30     11  1997  \n",
              "4                             DEBIT__CASH WITHDRAWAL__nan   18      1  1998  \n",
              "...                                                   ...  ...    ...   ...  \n",
              "399995               DEBIT__REMITTANCE TO ANOTHER BANK__    14      6  1998  \n",
              "399996       DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD   14      6  1998  \n",
              "399997       DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT   31      8  1998  \n",
              "399998                        CREDIT__CREDIT IN CASH__nan   12      6  1998  \n",
              "399999       DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD    6      4  1998  \n",
              "\n",
              "[400000 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e602efca-5478-4b15-8458-da892847e1b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_id</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>amount</th>\n",
              "      <th>td</th>\n",
              "      <th>tcode</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70.888054</td>\n",
              "      <td>374.191162</td>\n",
              "      <td>4.0</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>31</td>\n",
              "      <td>9</td>\n",
              "      <td>1997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>5289.441895</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>1997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>-13837.727539</td>\n",
              "      <td>23464.589844</td>\n",
              "      <td>31.0</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>1997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>36568.246094</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>31.0</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>30</td>\n",
              "      <td>11</td>\n",
              "      <td>1997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>-2276.346436</td>\n",
              "      <td>11215.634766</td>\n",
              "      <td>31.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399995</th>\n",
              "      <td>4999</td>\n",
              "      <td>-7024.736328</td>\n",
              "      <td>9236.980469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399996</th>\n",
              "      <td>4999</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>73800.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399997</th>\n",
              "      <td>4999</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>1800.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT</td>\n",
              "      <td>31</td>\n",
              "      <td>8</td>\n",
              "      <td>1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399998</th>\n",
              "      <td>4999</td>\n",
              "      <td>-4343.492188</td>\n",
              "      <td>18733.396484</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399999</th>\n",
              "      <td>4999</td>\n",
              "      <td>110.646019</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>1998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400000 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e602efca-5478-4b15-8458-da892847e1b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e602efca-5478-4b15-8458-da892847e1b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e602efca-5478-4b15-8458-da892847e1b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b7c6aa72-069a-411e-afc0-3ce62feb1408\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7c6aa72-069a-411e-afc0-3ce62feb1408')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b7c6aa72-069a-411e-afc0-3ce62feb1408 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a529c93d-7699-4705-b390-bd76b86698c8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('synth')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a529c93d-7699-4705-b390-bd76b86698c8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('synth');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "synth"
            }
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklego"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHKEPJRJA0hj",
        "outputId": "e4beda5a-974c-4224-e7a1-fdc0440bc9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklego\n",
            "  Downloading sklego-0.0-py2.py3-none-any.whl.metadata (375 bytes)\n",
            "Collecting scikit-lego (from sklego)\n",
            "  Downloading scikit_lego-0.9.5-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: narwhals>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-lego->sklego) (1.41.0)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from scikit-lego->sklego) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-lego->sklego) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from scikit-lego->sklego) (0.1.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->scikit-lego->sklego) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->scikit-lego->sklego) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->scikit-lego->sklego) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->scikit-lego->sklego) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->scikit-lego->sklego) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->scikit-lego->sklego) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->scikit-lego->sklego) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->scikit-lego->sklego) (1.17.0)\n",
            "Downloading sklego-0.0-py2.py3-none-any.whl (1.1 kB)\n",
            "Downloading scikit_lego-0.9.5-py2.py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-lego, sklego\n",
            "Successfully installed scikit-lego-0.9.5 sklego-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df=pd.read_csv('synthetic_transactions_transformer.csv')"
      ],
      "metadata": {
        "id": "fJ6B8t4DlmtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# synth_sorted\n",
        "\n",
        "final_df['datetime'] = pd.to_datetime(final_df[['year', 'month', 'day']])\n"
      ],
      "metadata": {
        "id": "_tkfA-OAOHGs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "8ebbb012-d22b-442c-8641-74da6b19dd56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot assemble the datetimes: day is out of range for month, at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_assemble_from_unit_mappings\u001b[0;34m(arg, errors, utc)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%Y%m%d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mcache_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;31m# GH#45319\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"mixed\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_strptime_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtz_out\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mstrptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mstrptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mstrptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: day is out of range for month, at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-2896108469>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# synth_sorted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datetime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'day'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_assemble_from_unit_mappings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_assemble_from_unit_mappings\u001b[0;34m(arg, errors, utc)\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%Y%m%d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot assemble the datetimes: {err}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m     \u001b[0munits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnitChoices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ms\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"us\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ns\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot assemble the datetimes: day is out of range for month, at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.drop(['date'], axis=1, inplace=True, errors='ignore')\n"
      ],
      "metadata": {
        "id": "b6UY-9GkcA3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6-5d5D5IcSif",
        "outputId": "131f940d-2c85-4dda-d266-001ffdb7e08a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        account_id    raw_amount        amount    td  \\\n",
              "0                0    146.706009    139.436646  19.0   \n",
              "1                0  -2000.000000   2298.791504   7.0   \n",
              "2                0 -16788.603516  14084.089844   3.0   \n",
              "3                0  44759.292969  36677.554688  13.0   \n",
              "4                0  -1920.196533   2933.928955   4.0   \n",
              "...            ...           ...           ...   ...   \n",
              "399995        4999 -20498.070312  23995.017578   8.0   \n",
              "399996        4999  21643.031250  32448.328125   1.0   \n",
              "399997        4999    -14.600000     14.600000  17.0   \n",
              "399998        4999   -552.324158  22294.279297  10.0   \n",
              "399999        4999    -14.600000     14.600000  10.0   \n",
              "\n",
              "                                                    tcode   datetime  \n",
              "0                          CREDIT__nan__INTEREST CREDITED 1997-09-30  \n",
              "1                             DEBIT__CASH WITHDRAWAL__nan 1997-10-07  \n",
              "2       CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ... 1997-10-10  \n",
              "3                             CREDIT__CREDIT IN CASH__nan 1997-10-23  \n",
              "4                             DEBIT__CASH WITHDRAWAL__nan 1997-10-27  \n",
              "...                                                   ...        ...  \n",
              "399995       DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD 1998-02-20  \n",
              "399996                        CREDIT__CREDIT IN CASH__nan 1998-02-21  \n",
              "399997       DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT 1998-03-10  \n",
              "399998                        CREDIT__CREDIT IN CASH__nan 1998-03-20  \n",
              "399999       DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT 1998-03-30  \n",
              "\n",
              "[400000 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e6cece9-4657-48c0-8ef8-7ebd6fe32d7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_id</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>amount</th>\n",
              "      <th>td</th>\n",
              "      <th>tcode</th>\n",
              "      <th>datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>146.706009</td>\n",
              "      <td>139.436646</td>\n",
              "      <td>19.0</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>1997-09-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>-2000.000000</td>\n",
              "      <td>2298.791504</td>\n",
              "      <td>7.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
              "      <td>1997-10-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>-16788.603516</td>\n",
              "      <td>14084.089844</td>\n",
              "      <td>3.0</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>1997-10-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>44759.292969</td>\n",
              "      <td>36677.554688</td>\n",
              "      <td>13.0</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>1997-10-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>-1920.196533</td>\n",
              "      <td>2933.928955</td>\n",
              "      <td>4.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
              "      <td>1997-10-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399995</th>\n",
              "      <td>4999</td>\n",
              "      <td>-20498.070312</td>\n",
              "      <td>23995.017578</td>\n",
              "      <td>8.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD</td>\n",
              "      <td>1998-02-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399996</th>\n",
              "      <td>4999</td>\n",
              "      <td>21643.031250</td>\n",
              "      <td>32448.328125</td>\n",
              "      <td>1.0</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>1998-02-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399997</th>\n",
              "      <td>4999</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>17.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT</td>\n",
              "      <td>1998-03-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399998</th>\n",
              "      <td>4999</td>\n",
              "      <td>-552.324158</td>\n",
              "      <td>22294.279297</td>\n",
              "      <td>10.0</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>1998-03-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399999</th>\n",
              "      <td>4999</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT</td>\n",
              "      <td>1998-03-30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400000 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e6cece9-4657-48c0-8ef8-7ebd6fe32d7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e6cece9-4657-48c0-8ef8-7ebd6fe32d7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e6cece9-4657-48c0-8ef8-7ebd6fe32d7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e99fadbd-7c58-407e-abeb-c858d14268d7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e99fadbd-7c58-407e-abeb-c858d14268d7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e99fadbd-7c58-407e-abeb-c858d14268d7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8b2a612f-1896-45f5-b07b-3497c0e65594\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8b2a612f-1896-45f5-b07b-3497c0e65594 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('final_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "# synth = pd.read_csv('/content/Synth.csv')\n",
        "synth=final_df\n",
        "czech_date_parser = lambda x: datetime.strptime(str(x), \"%Y-%m-%d\")\n",
        "synth[\"datetime\"] = synth[\"datetime\"].apply(czech_date_parser)\n",
        "synth[\"month\"] = synth[\"datetime\"].dt.month\n",
        "synth[\"day\"] = synth[\"datetime\"].dt.day\n",
        "synth[\"dow\"] =  synth[\"datetime\"].dt.dayofweek\n",
        "synth[\"year\"] = synth[\"datetime\"].dt.year\n",
        "\n",
        "synth[\"td\"] = synth[[\"account_id\", \"datetime\"]].groupby(\"account_id\").diff()\n",
        "synth[\"td\"] = synth[\"td\"].apply(lambda x: x.days)\n",
        "synth[\"td\"].fillna(0.0, inplace=True)\n",
        "\n",
        "# synth.rename(columns={'days_passed': 'td'}, inplace=True)\n",
        "synth['type'] = synth['tcode'].str.split('__').str[0]\n",
        "synth['raw_amount'] = synth.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "synth[\"dtme\"] = synth.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "\n",
        "synth_sorted = synth.sort_values(['account_id', 'year', 'month', 'day'])\n",
        "\n",
        "\n",
        "synth_cf = synth[[\"account_id\", \"month\", \"raw_amount\", \"year\"]].groupby([\"account_id\", \"month\", \"year\"],as_index=False)[\"raw_amount\"].sum()"
      ],
      "metadata": {
        "id": "BH7DcS2hSza3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synth_sorted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "trRJUvE7VxgA",
        "outputId": "70d9e51a-81a5-4cd4-fb3d-23270760b6b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        account_id    raw_amount        amount    td  \\\n",
              "0                0    139.436646    139.436646   0.0   \n",
              "1                0  -2298.791504   2298.791504   7.0   \n",
              "2                0  14084.089844  14084.089844   3.0   \n",
              "3                0  36677.554688  36677.554688  13.0   \n",
              "4                0  -2933.928955   2933.928955   4.0   \n",
              "...            ...           ...           ...   ...   \n",
              "399995        4999 -23995.017578  23995.017578   8.0   \n",
              "399996        4999  32448.328125  32448.328125   1.0   \n",
              "399997        4999    -14.600000     14.600000  17.0   \n",
              "399998        4999  22294.279297  22294.279297  10.0   \n",
              "399999        4999    -14.600000     14.600000  10.0   \n",
              "\n",
              "                                                    tcode   datetime  month  \\\n",
              "0                          CREDIT__nan__INTEREST CREDITED 1997-09-30      9   \n",
              "1                             DEBIT__CASH WITHDRAWAL__nan 1997-10-07     10   \n",
              "2       CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ... 1997-10-10     10   \n",
              "3                             CREDIT__CREDIT IN CASH__nan 1997-10-23     10   \n",
              "4                             DEBIT__CASH WITHDRAWAL__nan 1997-10-27     10   \n",
              "...                                                   ...        ...    ...   \n",
              "399995       DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD 1998-02-20      2   \n",
              "399996                        CREDIT__CREDIT IN CASH__nan 1998-02-21      2   \n",
              "399997       DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT 1998-03-10      3   \n",
              "399998                        CREDIT__CREDIT IN CASH__nan 1998-03-20      3   \n",
              "399999       DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT 1998-03-30      3   \n",
              "\n",
              "        day  dow  year    type  dtme  \n",
              "0        30    1  1997  CREDIT     0  \n",
              "1         7    1  1997   DEBIT    24  \n",
              "2        10    4  1997  CREDIT    21  \n",
              "3        23    3  1997  CREDIT     8  \n",
              "4        27    0  1997   DEBIT     4  \n",
              "...     ...  ...   ...     ...   ...  \n",
              "399995   20    4  1998   DEBIT     8  \n",
              "399996   21    5  1998  CREDIT     7  \n",
              "399997   10    1  1998   DEBIT    21  \n",
              "399998   20    4  1998  CREDIT    11  \n",
              "399999   30    0  1998   DEBIT     1  \n",
              "\n",
              "[400000 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34a51c40-fbeb-4d57-a16d-0f51d4681793\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_id</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>amount</th>\n",
              "      <th>td</th>\n",
              "      <th>tcode</th>\n",
              "      <th>datetime</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>dow</th>\n",
              "      <th>year</th>\n",
              "      <th>type</th>\n",
              "      <th>dtme</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>139.436646</td>\n",
              "      <td>139.436646</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>1997-09-30</td>\n",
              "      <td>9</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>1997</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>-2298.791504</td>\n",
              "      <td>2298.791504</td>\n",
              "      <td>7.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
              "      <td>1997-10-07</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1997</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>14084.089844</td>\n",
              "      <td>14084.089844</td>\n",
              "      <td>3.0</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>1997-10-10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>1997</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>36677.554688</td>\n",
              "      <td>36677.554688</td>\n",
              "      <td>13.0</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>1997-10-23</td>\n",
              "      <td>10</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>1997</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>-2933.928955</td>\n",
              "      <td>2933.928955</td>\n",
              "      <td>4.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
              "      <td>1997-10-27</td>\n",
              "      <td>10</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>1997</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399995</th>\n",
              "      <td>4999</td>\n",
              "      <td>-23995.017578</td>\n",
              "      <td>23995.017578</td>\n",
              "      <td>8.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__HOUSEHOLD</td>\n",
              "      <td>1998-02-20</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>1998</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399996</th>\n",
              "      <td>4999</td>\n",
              "      <td>32448.328125</td>\n",
              "      <td>32448.328125</td>\n",
              "      <td>1.0</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>1998-02-21</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>1998</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399997</th>\n",
              "      <td>4999</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>17.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT</td>\n",
              "      <td>1998-03-10</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1998</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399998</th>\n",
              "      <td>4999</td>\n",
              "      <td>22294.279297</td>\n",
              "      <td>22294.279297</td>\n",
              "      <td>10.0</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>1998-03-20</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>1998</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399999</th>\n",
              "      <td>4999</td>\n",
              "      <td>-14.600000</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__PAYMENT ON STATEMENT</td>\n",
              "      <td>1998-03-30</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>1998</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400000 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34a51c40-fbeb-4d57-a16d-0f51d4681793')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-34a51c40-fbeb-4d57-a16d-0f51d4681793 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-34a51c40-fbeb-4d57-a16d-0f51d4681793');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fb7a0a1b-246e-4449-b071-1ba0a5240c08\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb7a0a1b-246e-4449-b071-1ba0a5240c08')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fb7a0a1b-246e-4449-b071-1ba0a5240c08 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_68e2a3e6-20a9-4fce-bde4-a0bb910fd2e3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('synth_sorted')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_68e2a3e6-20a9-4fce-bde4-a0bb910fd2e3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('synth_sorted');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "synth_sorted"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synth_sorted.year.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ3TArLuxl8b",
        "outputId": "d8a5a0dc-4f52-485e-cf4b-475305782832"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1997, 1998, 1995, 1996, 1999, 1994, 1993, 2000], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# df2 = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "# df2 = df.sort_values(by = [\"account_id\", \"date\"])\n",
        "# data, LOG_AMOUNT_SCALE, TD_SCALE,_ = preprocess_data_czech(df2)\n",
        "\n",
        "\n",
        "df2 = raw_data[['account_id','tcode', 'datetime','amount', 'raw_amount']]\n",
        "real = df2.copy()\n",
        "real[\"month\"] = real[\"datetime\"].dt.month\n",
        "real[\"day\"] = real[\"datetime\"].dt.day\n",
        "real[\"dow\"] =  real[\"datetime\"].dt.dayofweek\n",
        "real[\"year\"] = real[\"datetime\"].dt.year\n",
        "\n",
        "real[\"td\"] = real[[\"account_id\", \"datetime\"]].groupby(\"account_id\").diff()\n",
        "real[\"td\"] = real[\"td\"].apply(lambda x: x.days)\n",
        "real[\"td\"].fillna(0.0, inplace=True)\n",
        "real['type'] = real['tcode'].str.split('__').str[0]\n",
        "\n",
        "# dtme - days till month end\n",
        "real[\"dtme\"] = real.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "\n",
        "real_cf = real[[\"account_id\", \"month\", \"raw_amount\", \"year\"]].groupby([\"account_id\", \"month\", \"year\"],as_index=False)[\"raw_amount\"].sum()\n",
        "real_sorted = real.sort_values(['account_id', 'year', 'month', 'day'])\n",
        "real"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "tjrkZmLTV8h0",
        "outputId": "4ae08d75-306a-4cbf-b12e-1dff4986fb4b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         account_id                                      tcode   datetime  \\\n",
              "0                 1                CREDIT__CREDIT IN CASH__nan 1995-03-24   \n",
              "1                 1  CREDIT__COLLECTION FROM ANOTHER BANK__nan 1995-04-13   \n",
              "2                 1                CREDIT__CREDIT IN CASH__nan 1995-04-23   \n",
              "3                 1             CREDIT__nan__INTEREST CREDITED 1995-04-30   \n",
              "4                 1  CREDIT__COLLECTION FROM ANOTHER BANK__nan 1995-05-13   \n",
              "...             ...                                        ...        ...   \n",
              "1056315       11382                DEBIT__CASH WITHDRAWAL__nan 1998-12-02   \n",
              "1056316       11382  CREDIT__COLLECTION FROM ANOTHER BANK__nan 1998-12-10   \n",
              "1056317       11382                DEBIT__CASH WITHDRAWAL__nan 1998-12-25   \n",
              "1056318       11382             CREDIT__nan__INTEREST CREDITED 1998-12-31   \n",
              "1056319       11382             CREDIT__nan__INTEREST CREDITED 1998-12-31   \n",
              "\n",
              "          amount  raw_amount  month  day  dow  year    td    type  dtme  \n",
              "0         1000.0      1000.0      3   24    4  1995   0.0  CREDIT     7  \n",
              "1         3679.0      3679.0      4   13    3  1995  20.0  CREDIT    17  \n",
              "2        12600.0     12600.0      4   23    6  1995  10.0  CREDIT     7  \n",
              "3           19.2        19.2      4   30    6  1995   7.0  CREDIT     0  \n",
              "4         3679.0      3679.0      5   13    5  1995  13.0  CREDIT    18  \n",
              "...          ...         ...    ...  ...  ...   ...   ...     ...   ...  \n",
              "1056315  25600.0    -25600.0     12    2    2  1998   2.0   DEBIT    29  \n",
              "1056316  46248.0     46248.0     12   10    3  1998   8.0  CREDIT    21  \n",
              "1056317   6300.0     -6300.0     12   25    4  1998  15.0   DEBIT     6  \n",
              "1056318    311.3       311.3     12   31    3  1998   6.0  CREDIT     0  \n",
              "1056319    301.1       301.1     12   31    3  1998   0.0  CREDIT     0  \n",
              "\n",
              "[1056320 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f241740b-74f6-4d56-a738-bdbcb7c2bd71\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_id</th>\n",
              "      <th>tcode</th>\n",
              "      <th>datetime</th>\n",
              "      <th>amount</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>dow</th>\n",
              "      <th>year</th>\n",
              "      <th>td</th>\n",
              "      <th>type</th>\n",
              "      <th>dtme</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>1995-03-24</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>1995</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__nan</td>\n",
              "      <td>1995-04-13</td>\n",
              "      <td>3679.0</td>\n",
              "      <td>3679.0</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>1995</td>\n",
              "      <td>20.0</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>1995-04-23</td>\n",
              "      <td>12600.0</td>\n",
              "      <td>12600.0</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>1995</td>\n",
              "      <td>10.0</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>1995-04-30</td>\n",
              "      <td>19.2</td>\n",
              "      <td>19.2</td>\n",
              "      <td>4</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>1995</td>\n",
              "      <td>7.0</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__nan</td>\n",
              "      <td>1995-05-13</td>\n",
              "      <td>3679.0</td>\n",
              "      <td>3679.0</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>1995</td>\n",
              "      <td>13.0</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056315</th>\n",
              "      <td>11382</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
              "      <td>1998-12-02</td>\n",
              "      <td>25600.0</td>\n",
              "      <td>-25600.0</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1998</td>\n",
              "      <td>2.0</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056316</th>\n",
              "      <td>11382</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__nan</td>\n",
              "      <td>1998-12-10</td>\n",
              "      <td>46248.0</td>\n",
              "      <td>46248.0</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>1998</td>\n",
              "      <td>8.0</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056317</th>\n",
              "      <td>11382</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__nan</td>\n",
              "      <td>1998-12-25</td>\n",
              "      <td>6300.0</td>\n",
              "      <td>-6300.0</td>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>1998</td>\n",
              "      <td>15.0</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056318</th>\n",
              "      <td>11382</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>1998-12-31</td>\n",
              "      <td>311.3</td>\n",
              "      <td>311.3</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>3</td>\n",
              "      <td>1998</td>\n",
              "      <td>6.0</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056319</th>\n",
              "      <td>11382</td>\n",
              "      <td>CREDIT__nan__INTEREST CREDITED</td>\n",
              "      <td>1998-12-31</td>\n",
              "      <td>301.1</td>\n",
              "      <td>301.1</td>\n",
              "      <td>12</td>\n",
              "      <td>31</td>\n",
              "      <td>3</td>\n",
              "      <td>1998</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CREDIT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1056320 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f241740b-74f6-4d56-a738-bdbcb7c2bd71')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f241740b-74f6-4d56-a738-bdbcb7c2bd71 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f241740b-74f6-4d56-a738-bdbcb7c2bd71');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-76af12c5-ccff-44f8-8c59-f076891d2806\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76af12c5-ccff-44f8-8c59-f076891d2806')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-76af12c5-ccff-44f8-8c59-f076891d2806 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f13ee64a-67f0-4ef7-abf8-40236d130374\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('real')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f13ee64a-67f0-4ef7-abf8-40236d130374 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('real');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "real"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "t1iUaXCvcyy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from scipy.special import rel_entr\n",
        "from scipy.special import entr\n",
        "from scipy.spatial import distance\n",
        "\n",
        "from scipy.stats import energy_distance\n",
        "from scipy.stats import wasserstein_distance\n",
        "from scipy.stats import ks_2samp\n",
        "import random\n",
        "import os\n",
        "\n",
        "# random.seed(0)\n",
        "# np.random.seed(0)\n",
        "# os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ks_dist(real_obs, gen_obs):\n",
        "    stat, pval = ks_2samp(real_obs, gen_obs)\n",
        "\n",
        "    return stat\n",
        "\n",
        "def comapre_unidist_cont(CONT_FIELDS,CF_FIELD, real, synth, real_cf, synth_cf):\n",
        "    \"\"\"\n",
        "    CONT_FIELDS : list of continuous columns\n",
        "    CF_FIELD: name of the column in real_cf and synth_cf (used for computing cash flow)\n",
        "    CONTINUOUS_METRICS = {\"wasser\": wasserstein_distance, \"ks\": ks_dist,\"energy_d\": energy_distance}\n",
        "    real_cf, synth_cf: groupby([\"account_id\", \"month\", \"year\"]) real, and synth. and compute the sum of the raw_amount.\n",
        "\n",
        "    \"\"\"\n",
        "    CONTINUOUS_METRICS = {\"wasser\": wasserstein_distance, \"ks\": ks_dist,\"energy_d\": energy_distance}\n",
        "    univariate_cont_res = {}\n",
        "\n",
        "    for field in CONT_FIELDS:\n",
        "        univariate_cont_res[field] = {}\n",
        "        for name, fn in CONTINUOUS_METRICS.items():\n",
        "            univariate_cont_res[field][name] = fn(real[field], synth[field])\n",
        "\n",
        "    univariate_cont_res['CF'] = {}\n",
        "    for name, fn in CONTINUOUS_METRICS.items():\n",
        "        univariate_cont_res['CF'][name] = fn(real_cf[CF_FIELD], synth_cf[CF_FIELD])\n",
        "    return univariate_cont_res\n",
        "\n",
        "def comapre_unidist_cat(real, synth, field):\n",
        "    real_distribution = real[field].value_counts(normalize=True).sort_index()\n",
        "    synthetic_distribution = synth[field].value_counts(normalize=True).sort_index()\n",
        "    df_tcode = pd.merge(real_distribution, synthetic_distribution, left_index=True, right_index=True, how='outer')\n",
        "    df_tcode.columns = ['real', 'synthetic']\n",
        "\n",
        "    # Fill missing values with 0\n",
        "    df_tcode.fillna(0, inplace=True)\n",
        "    df_tcode['mid'] = (df_tcode['real'] + df_tcode['synthetic'])/2\n",
        "    kl_real_M = sum(rel_entr(df_tcode['real'], df_tcode['mid']))\n",
        "    kl_gen_M = sum(rel_entr(df_tcode['synthetic'], df_tcode['mid']))\n",
        "\n",
        "    jsd = (kl_real_M + kl_gen_M)/2\n",
        "    return jsd\n",
        "\n",
        "def create_ngramcount_df(df, n, field):\n",
        "    #gb = df.sort_values(by=[\"account_id\", \"datetime\"]).groupby(\"account_id\", sort=False)[field]\n",
        "    gb = df.groupby(\"account_id\", sort=False)[field]\n",
        "    ngram_list = gb.apply(lambda x: list(ngrams(x, n=n)))\n",
        "\n",
        "    counts = {}\n",
        "    for ngram_seq in ngram_list:\n",
        "        for ngram in ngram_seq:\n",
        "            ngram = str(ngram)[1:-1]\n",
        "            counts[ngram] = counts.get(ngram, 0) + 1\n",
        "\n",
        "\n",
        "    df = pd.DataFrame.from_dict(counts, orient=\"index\", columns=[\"counts\"]).sort_values(\"counts\", ascending=False)\n",
        "\n",
        "\n",
        "    return df.reset_index().rename(columns={\"index\": \"ngram\"})\n",
        "\n",
        "def compute_ngram_metrics(real_df, gen_df, field, n , pseudo_counts=0.0):\n",
        "\n",
        "\n",
        "    n_codes_unique = len(set(real_df[field].unique()).union(set(gen_df[field].unique())))\n",
        "\n",
        "\n",
        "    # create combo_df, which contains counts of all ngrams for both datasets (note: it omits any ngrams which do not occur in either dataset)\n",
        "    real_ngrams = create_ngramcount_df(real_df, n, field)\n",
        "    gen_ngrams = create_ngramcount_df(gen_df, n, field)\n",
        "    combo_df = pd.merge(real_ngrams, gen_ngrams, on=\"ngram\", how=\"outer\", suffixes=(\"_real\", \"_gen\")).fillna(0.0)\n",
        "\n",
        "\n",
        "    N_obs_real = real_ngrams[\"counts\"].sum()\n",
        "    N_obs_gen = gen_ngrams[\"counts\"].sum()\n",
        "    N_possible_ngrams = n_codes_unique**n\n",
        "\n",
        "\n",
        "    # add psudo-counts\n",
        "    combo_df[\"counts_real\"] += pseudo_counts\n",
        "    combo_df[\"ps_real\"] = combo_df[\"counts_real\"] / (N_obs_real + N_possible_ngrams*pseudo_counts)\n",
        "    combo_df[\"counts_gen\"] += pseudo_counts\n",
        "    combo_df[\"ps_gen\"] = combo_df[\"counts_gen\"] / (N_obs_gen + N_possible_ngrams*pseudo_counts)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # compute jsd (note: contribution to jsd from any ngram not in either dataset is 0)\n",
        "    combo_df[\"ps_mid\"] = (combo_df[\"ps_real\"] + combo_df[\"ps_gen\"])/2\n",
        "    kl_real_M = sum(rel_entr(combo_df[\"ps_real\"], combo_df[\"ps_mid\"]))\n",
        "    kl_gen_M = sum(rel_entr(combo_df[\"ps_gen\"], combo_df[\"ps_mid\"]))\n",
        "\n",
        "    jsd = (kl_real_M + kl_gen_M)/2\n",
        "\n",
        "\n",
        "    # compute entropy for both distributions\n",
        "    n_unobs = N_possible_ngrams - len(combo_df)\n",
        "\n",
        "    entr_r = entr(combo_df[\"ps_real\"]).sum()  # from observed\n",
        "\n",
        "    entr_g = entr(combo_df[\"ps_gen\"]).sum()  # from observed\n",
        "\n",
        "    results = {\"jsd\":jsd,\n",
        "                      \"entr_r\":entr_r,\n",
        "                      \"entr_g\":entr_g,\n",
        "                      \"NED\": entr_r - entr_g,\n",
        "                      \"l1\":distance.minkowski(combo_df[\"ps_real\"], combo_df[\"ps_gen\"], p=1),\n",
        "                      \"l2\":distance.minkowski(combo_df[\"ps_real\"], combo_df[\"ps_gen\"], p=2),\n",
        "                      \"jac\": distance.jaccard(combo_df[\"counts_real\"]>0, combo_df[\"counts_gen\"] > 0),\n",
        "                      \"count_r\": len(real_ngrams),\n",
        "                      \"coverage_r\": len(real_ngrams)/N_possible_ngrams,\n",
        "                      \"count_g\": len(gen_ngrams),\n",
        "                      \"coverage_g\": len(gen_ngrams)/N_possible_ngrams,\n",
        "                      \"count_max\": N_possible_ngrams,\n",
        "                      \"field\": field,\n",
        "                       \"n\":n,\n",
        "                       \"pseudo_counts\":pseudo_counts}\n",
        "\n",
        "    return combo_df, results\n",
        "\n",
        "#joint distribution of two categorical columns\n",
        "def compute_2d_categorical_metrics(real_df, gen_df, field1, field2):\n",
        "    f1_opts = set(real_df[field1].unique()).union(set(gen_df[field1].unique()))\n",
        "    f2_opts = set(real_df[field2].unique()).union(set(gen_df[field2].unique()))\n",
        "\n",
        "    n_opts_total = len(f1_opts) * len(f2_opts)\n",
        "\n",
        "    kl_r_m = 0.\n",
        "    kl_g_m = 0.\n",
        "    entr_r = 0.\n",
        "    entr_g = 0.\n",
        "    l1_d = 0.\n",
        "    l2_d = 0.\n",
        "    count_g = 0.\n",
        "    count_r = 0.\n",
        "\n",
        "    observed_opts = 0\n",
        "\n",
        "    cont_metric_results = {}\n",
        "    for code_1 in f1_opts:\n",
        "        for code_2 in f2_opts:\n",
        "            cond_r = np.logical_and(real_df[field1] == code_1, real_df[field2] == code_2)\n",
        "            cond_g = np.logical_and(gen_df[field1] == code_1, gen_df[field2] == code_2)\n",
        "\n",
        "            p_r = (np.sum(cond_r)) / (len(cond_r))\n",
        "            p_g = (np.sum(cond_g)) / (len(cond_g))\n",
        "            p_m = (p_r + p_g) / 2.\n",
        "\n",
        "            if np.sum(cond_r) + np.sum(cond_g) > 0:\n",
        "                observed_opts += 1\n",
        "\n",
        "\n",
        "            count_r += int(np.sum(cond_r) > 0)\n",
        "            count_g += int(np.sum(cond_g) > 0)\n",
        "\n",
        "            l1_d += np.abs(p_r - p_g)\n",
        "            l2_d += (p_r - p_g) ** 2\n",
        "\n",
        "\n",
        "            if p_r > 0:\n",
        "                kl_r_m += p_r * np.log(p_r / p_m)\n",
        "                entr_r += - p_r * np.log(p_r)\n",
        "\n",
        "            if p_g > 0:\n",
        "                kl_g_m += p_g * np.log(p_g / p_m)\n",
        "                entr_g += - p_g * np.log(p_g)\n",
        "\n",
        "    # compute jaccard\n",
        "    sr = set(zip(real_df[field1].to_list(), real_df[field2].to_list()))\n",
        "    sg = set(zip(gen_df[field1].to_list(), gen_df[field2].to_list()))\n",
        "    s_union = len(sr.union(sg))\n",
        "    s_inter = len(sr.intersection(sg))\n",
        "    jacc_d = (s_union - s_inter) / s_union\n",
        "\n",
        "    # finshed l2\n",
        "    l2_d = np.sqrt(l2_d)\n",
        "\n",
        "    # coverage\n",
        "    coverage_g = count_g / n_opts_total\n",
        "    coverage_r = count_r / n_opts_total\n",
        "\n",
        "    #jsd\n",
        "    jsd = (kl_r_m + kl_g_m) / 2\n",
        "\n",
        "\n",
        "    result = {'jsd': jsd,\n",
        "                    'entr_r': entr_r,\n",
        "                    'entr_g': entr_g,\n",
        "                    'l1': l1_d,\n",
        "                    'l2': l2_d,\n",
        "                    'jac': jacc_d,\n",
        "                    'count_r': count_r,\n",
        "                    'coverage_r': coverage_r,\n",
        "                    'count_g': count_g,\n",
        "                    'coverage_g': coverage_g,\n",
        "                    'count_max': n_opts_total}\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "1Qq4viLuXVYc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combo_df, result = compute_ngram_metrics(real_sorted, synth_sorted, 'tcode', 3)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSgQGB2LWTRp",
        "outputId": "ac22bcfe-eb1b-4429-bfee-a63d15239752"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'jsd': 0.22560765460817214,\n",
              " 'entr_r': np.float64(5.425261658301508),\n",
              " 'entr_g': np.float64(6.643082185774299),\n",
              " 'NED': np.float64(-1.2178205274727905),\n",
              " 'l1': np.float64(1.038496281106257),\n",
              " 'l2': 0.08259590994988075,\n",
              " 'jac': np.float64(0.5801948051948052),\n",
              " 'count_r': 1431,\n",
              " 'coverage_r': 0.349365234375,\n",
              " 'count_g': 2942,\n",
              " 'coverage_g': 0.71826171875,\n",
              " 'count_max': 4096,\n",
              " 'field': 'tcode',\n",
              " 'n': 3,\n",
              " 'pseudo_counts': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CAT_FIELDS = ['tcode']\n",
        "result_jst_cat = {}\n",
        "for field in CAT_FIELDS:\n",
        "    result_jst_cat[field] = comapre_unidist_cat(real_sorted, synth_sorted, field)\n",
        "result_jst_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFtKSlJEXd-g",
        "outputId": "ef95e995-7aff-47f5-fa1f-d17312b8b9c8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tcode': 0.02725844124460378}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONT_FIELDS = [\"amount\", \"td\"]\n",
        "\n",
        "CF_FIELD = 'raw_amount'\n",
        "\n",
        "#compare univariate distribution of continuous columns\n",
        "comapre_unidist_cont(CONT_FIELDS,CF_FIELD, real_sorted, synth_sorted, real_cf, synth_cf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAxwA8sVWT-1",
        "outputId": "fb25287e-7b15-4d94-9886-6b16875232da"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'amount': {'wasser': np.float64(1079.0130296369023),\n",
              "  'ks': np.float64(0.140366349591033),\n",
              "  'energy_d': np.float64(8.03558913165906)},\n",
              " 'td': {'wasser': np.float64(0.5084357747652227),\n",
              "  'ks': np.float64(0.05544429794001818),\n",
              "  'energy_d': np.float64(0.17547848905236355)},\n",
              " 'CF': {'wasser': np.float64(7639.341604275838),\n",
              "  'ks': np.float64(0.17410313942372224),\n",
              "  'energy_d': np.float64(37.874694103269285)}}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# JSD result comparing the univariate distributions of the tcode (Tcode), and DOM\n",
        "CAT_FIELDS = ['tcode', 'day', 'month']\n",
        "result_jst_cat = {}\n",
        "for field in CAT_FIELDS:\n",
        "    result_jst_cat[field] = comapre_unidist_cat(real, synth_sorted, field)\n",
        "result_jst_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_9EHtzvXpM_",
        "outputId": "334b053c-3794-464e-cf00-8f966ccb5c94"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tcode': 0.02725844124460378,\n",
              " 'day': 0.10712147200236755,\n",
              " 'month': 0.0020172976844036487}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONT_FIELDS = [\"amount\", \"td\"]\n",
        "\n",
        "CF_FIELD = 'raw_amount'\n",
        "\n",
        "#compare univariate distribution of continuous columns\n",
        "comapre_unidist_cont(CONT_FIELDS,CF_FIELD, real, synth_sorted, real_cf, synth_cf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCqjaQboXtVv",
        "outputId": "0dac32f2-b703-494b-a101-f9043555c184"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'amount': {'wasser': np.float64(1079.0130296369023),\n",
              "  'ks': np.float64(0.140366349591033),\n",
              "  'energy_d': np.float64(8.03558913165906)},\n",
              " 'td': {'wasser': np.float64(0.5084357747652227),\n",
              "  'ks': np.float64(0.05544429794001818),\n",
              "  'energy_d': np.float64(0.17547848905236355)},\n",
              " 'CF': {'wasser': np.float64(7639.341604275838),\n",
              "  'ks': np.float64(0.17410313942372224),\n",
              "  'energy_d': np.float64(37.874694103269285)}}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build a metadata for evaluation (from SDV)\n",
        "metadata= SingleTableMetadata()\n",
        "metadata.detect_from_dataframe(data=real)\n",
        "\n",
        "#generate quality report\n",
        "quality_report= sdv_st.evaluate_quality(\n",
        "    real_data=real,\n",
        "    synthetic_data=synth_sorted,\n",
        "    metadata=metadata\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXrmPvWCWK-u",
        "outputId": "f76dae45-f296-4c4d-9eb4-16b34190b934"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating report ...\n",
            "\n",
            "(1/2) Evaluating Column Shapes: |██████████| 12/12 [00:01<00:00,  6.12it/s]|\n",
            "Column Shapes Score: 87.97%\n",
            "\n",
            "(2/2) Evaluating Column Pair Trends: |██████████| 66/66 [00:05<00:00, 12.73it/s]|\n",
            "Column Pair Trends Score: 79.4%\n",
            "\n",
            "Overall Score (Average): 83.68%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = quality_report.get_visualization(property_name='Column Shapes')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Lp1b6SFxYSKZ",
        "outputId": "0f810f62-3ef4-4182-9e6c-2185c733c1ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4e208ea8-81b7-4e1d-8cbb-d514e7669130\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4e208ea8-81b7-4e1d-8cbb-d514e7669130\")) {                    Plotly.newPlot(                        \"4e208ea8-81b7-4e1d-8cbb-d514e7669130\",                        [{\"alignmentgroup\":\"True\",\"customdata\":[[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"],[\"TVComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"tcode\",\"dow\",\"year\",\"type\"],\"legendgroup\":\"TVComplement\",\"marker\":{\"color\":\"#03AFF1\",\"pattern\":{\"shape\":\"\"}},\"name\":\"TVComplement\",\"offsetgroup\":\"TVComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"tcode\",\"dow\",\"year\",\"type\"],\"xaxis\":\"x\",\"y\":[0.8218901355649804,0.9889406369282036,0.8911924144209036,0.9806151181460164],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"customdata\":[[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"],[\"KSComplement\"]],\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eMetric=%{customdata[0]}\\u003cbr\\u003eScore=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"datetime\",\"amount\",\"raw_amount\",\"month\",\"day\",\"td\",\"dtme\"],\"legendgroup\":\"KSComplement\",\"marker\":{\"color\":\"#000036\",\"pattern\":{\"shape\":\"\\u002f\"}},\"name\":\"KSComplement\",\"offsetgroup\":\"KSComplement\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"datetime\",\"amount\",\"raw_amount\",\"month\",\"day\",\"td\",\"dtme\"],\"xaxis\":\"x\",\"y\":[0.8970127688579219,0.859633650408967,0.8805732414419872,0.9719296054225992,0.7373646455619509,0.9445557020599818,0.7028590404422903],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Column\"},\"categoryorder\":\"total ascending\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Score\"},\"range\":[0,1]},\"legend\":{\"title\":{\"text\":\"Metric\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Data Quality: Column Shapes (Average Score=0.88)\"},\"barmode\":\"relative\",\"margin\":{\"t\":150},\"font\":{\"size\":18},\"plot_bgcolor\":\"#F5F5F8\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4e208ea8-81b7-4e1d-8cbb-d514e7669130');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "# from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import random\n",
        "# import os\n",
        "# from datetime import datetime\n",
        "# import calendar\n",
        "# from tqdm import tqdm\n",
        "# from scipy import stats\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# # =============================================================================\n",
        "# # CONFIGURATION\n",
        "# # =============================================================================\n",
        "# # Set seeds for reproducibility\n",
        "# seed = 1234\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# torch.manual_seed(seed)\n",
        "# if torch.cuda.is_available():\n",
        "#     torch.cuda.manual_seed(seed)\n",
        "#     torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# # Device configuration\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(f\"Using device: {device}\")\n",
        "\n",
        "# # Model hyperparameters\n",
        "# sequence_length = 300      # Reduced for efficiency\n",
        "# min_seq_length = 20\n",
        "# cat_emb_dim = 8           # Reduced for efficiency\n",
        "# mlp_layers = [256, 256]   # Smaller layers\n",
        "# activation = 'lrelu'\n",
        "# diffusion_steps = 500     # Reduced steps\n",
        "# diffusion_beta_start = 1e-4\n",
        "# diffusion_beta_end = 0.02\n",
        "# scheduler = 'linear'\n",
        "# epochs = 50               # Reduced epochs for testing\n",
        "# batch_size = 32           # Smaller batch size\n",
        "# learning_rate = 2e-4      # Slightly higher learning rate\n",
        "# n_sequences = 20          # Number of synthetic accounts to generate\n",
        "\n",
        "# # =============================================================================\n",
        "# # DATA PREPROCESSING\n",
        "# # =============================================================================\n",
        "# def preprocess_data_czech(df):\n",
        "#     \"\"\"Enhanced preprocessing with better error handling\"\"\"\n",
        "#     czech_date_parser = lambda x: datetime.strptime(str(x), \"%y%m%d\")\n",
        "#     df[\"datetime\"] = df[\"date\"].apply(czech_date_parser)\n",
        "#     df[\"month\"] = df[\"datetime\"].dt.month\n",
        "#     df[\"day\"] = df[\"datetime\"].dt.day\n",
        "#     df[\"dow\"] = df[\"datetime\"].dt.dayofweek\n",
        "#     df[\"year\"] = df[\"datetime\"].dt.year\n",
        "#     df[\"doy\"] = df[\"datetime\"].dt.dayofyear\n",
        "\n",
        "#     df_sorted = df.sort_values(['account_id', 'datetime']).copy()\n",
        "\n",
        "#     df_sorted[\"td\"] = df_sorted.groupby(\"account_id\")[\"datetime\"].diff().dt.days\n",
        "#     df_sorted[\"td\"].fillna(0.0, inplace=True)\n",
        "#     df_sorted[\"dtme\"] = df_sorted.datetime.apply(lambda dt: calendar.monthrange(dt.year, dt.month)[1] - dt.day)\n",
        "#     df_sorted['raw_amount'] = df_sorted.apply(lambda row: row['amount'] if row['type'] == 'CREDIT' else -row['amount'], axis=1)\n",
        "\n",
        "#     # Create transaction code\n",
        "#     cat_code_fields = ['type', 'operation', 'k_symbol']\n",
        "#     tcode = df_sorted[cat_code_fields[0]].astype(str)\n",
        "#     for ccf in cat_code_fields[1:]:\n",
        "#         tcode += \"__\" + df_sorted[ccf].astype(str)\n",
        "#     df_sorted[\"tcode\"] = tcode\n",
        "\n",
        "#     # Day of month categories\n",
        "#     conditions = [\n",
        "#         (df_sorted['day'] >= 1) & (df_sorted['day'] <= 10),\n",
        "#         (df_sorted['day'] > 10) & (df_sorted['day'] <= 20),\n",
        "#         (df_sorted['day'] > 20) & (df_sorted['day'] <= 31)\n",
        "#     ]\n",
        "#     categories = ['first', 'middle', 'last']\n",
        "#     df_sorted['DoM_cat'] = np.select(conditions, categories, default='unknown')\n",
        "\n",
        "#     # Age groups\n",
        "#     if 'age' in df_sorted.columns:\n",
        "#         bin_edges = [17, 30, 40, 50, 60, 81]\n",
        "#         labels = ['18-30', '31-40', '41-50', '51-60', '61+']\n",
        "#         df_sorted['age_group'] = pd.cut(df_sorted['age'], bins=bin_edges, labels=labels, right=False)\n",
        "#         df_sorted['age_group'] = df_sorted['age_group'].astype('object').fillna('unknown')\n",
        "#     else:\n",
        "#         print(\"Warning: 'age' column not found. Creating placeholder.\")\n",
        "#         df_sorted['age_group'] = 'unknown'\n",
        "\n",
        "#     return df_sorted\n",
        "\n",
        "# # =============================================================================\n",
        "# # IMPROVED SEQUENTIAL DATASET\n",
        "# # =============================================================================\n",
        "# class OptimizedSequentialDataset(Dataset):\n",
        "#     \"\"\"More efficient dataset that samples sequences strategically\"\"\"\n",
        "#     def __init__(self, df, cat_attrs, num_attrs, sequence_length=30, min_seq_length=20, max_sequences_per_account=5):\n",
        "#         self.sequence_length = sequence_length\n",
        "#         self.min_seq_length = min_seq_length\n",
        "#         self.cat_attrs = cat_attrs\n",
        "#         self.num_attrs = num_attrs\n",
        "#         self.sequences = []\n",
        "\n",
        "#         print(\"Creating optimized sequences from transaction data...\")\n",
        "\n",
        "#         # Group by account and create limited sequences per account\n",
        "#         for account_id in tqdm(df['account_id'].unique()):\n",
        "#             account_data = df[df['account_id'] == account_id].sort_values('datetime').reset_index(drop=True)\n",
        "#             if len(account_data) >= min_seq_length:\n",
        "#                 # Sample sequences strategically instead of all overlapping windows\n",
        "#                 n_possible = len(account_data) - sequence_length + 1\n",
        "#                 if n_possible <= max_sequences_per_account:\n",
        "#                     # Use all if few sequences possible\n",
        "#                     start_indices = range(n_possible)\n",
        "#                 else:\n",
        "#                     # Sample evenly spaced sequences\n",
        "#                     start_indices = np.linspace(0, n_possible-1, max_sequences_per_account, dtype=int)\n",
        "\n",
        "#                 for start_idx in start_indices:\n",
        "#                     seq_data = account_data.iloc[start_idx:start_idx+sequence_length]\n",
        "#                     cat_data = seq_data[self.cat_attrs].values\n",
        "#                     num_data = seq_data[self.num_attrs].values\n",
        "#                     self.sequences.append({'cat_data': cat_data, 'num_data': num_data})\n",
        "\n",
        "#         print(f\"Created {len(self.sequences)} sequences from {df['account_id'].nunique()} accounts.\")\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.sequences)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         seq = self.sequences[idx]\n",
        "#         cat_tensor = torch.LongTensor(seq['cat_data'])\n",
        "#         num_tensor = torch.FloatTensor(seq['num_data'])\n",
        "#         return cat_tensor, num_tensor\n",
        "\n",
        "# # =============================================================================\n",
        "# # IMPROVED LSTM SYNTHESIZER\n",
        "# # =============================================================================\n",
        "# class ImprovedLSTMSynthesizer(nn.Module):\n",
        "#     \"\"\"Fixed model that properly handles the training/generation process\"\"\"\n",
        "#     def __init__(self, n_cat_features, n_cat_tokens, cat_emb_dim, n_num_features,\n",
        "#                  hidden_dim=256, lstm_layers=2, dim_t=64):\n",
        "#         super(ImprovedLSTMSynthesizer, self).__init__()\n",
        "#         self.n_cat_features = n_cat_features\n",
        "#         self.n_num_features = n_num_features\n",
        "#         self.cat_emb_dim = cat_emb_dim\n",
        "#         self.hidden_dim = hidden_dim\n",
        "#         self.dim_t = dim_t\n",
        "\n",
        "#         # Categorical embeddings\n",
        "#         self.cat_embeddings = nn.ModuleList([\n",
        "#             nn.Embedding(n_cat_tokens[i], cat_emb_dim) for i in range(n_cat_features)\n",
        "#         ])\n",
        "\n",
        "#         total_cat_emb_dim = n_cat_features * cat_emb_dim\n",
        "#         total_input_dim = total_cat_emb_dim + n_num_features\n",
        "\n",
        "#         # Time embedding\n",
        "#         self.time_embed = nn.Sequential(\n",
        "#             nn.Linear(dim_t, hidden_dim),\n",
        "#             nn.SiLU(),\n",
        "#             nn.Linear(hidden_dim, hidden_dim)\n",
        "#         )\n",
        "\n",
        "#         # Input projection\n",
        "#         self.input_projection = nn.Linear(total_input_dim, hidden_dim)\n",
        "\n",
        "#         # LSTM\n",
        "#         self.lstm = nn.LSTM(\n",
        "#             input_size=hidden_dim,\n",
        "#             hidden_size=hidden_dim,\n",
        "#             num_layers=lstm_layers,\n",
        "#             batch_first=True,\n",
        "#             dropout=0.1 if lstm_layers > 1 else 0\n",
        "#         )\n",
        "\n",
        "#         # This model now predicts the original data, not noise or logits\n",
        "#         self.output_head = nn.Linear(hidden_dim, total_input_dim)\n",
        "\n",
        "#     def embed_time(self, timesteps, dim_out, max_period=1000):\n",
        "#         half = dim_out // 2\n",
        "#         freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half).to(device)\n",
        "#         args = timesteps[:, None].float() * freqs[None]\n",
        "#         embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "#         if dim_out % 2:\n",
        "#             embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "#         return embedding\n",
        "\n",
        "#     def embed_categorical(self, x_cat):\n",
        "#         \"\"\"Embed categorical features\"\"\"\n",
        "#         embeddings = []\n",
        "#         for i in range(self.n_cat_features):\n",
        "#             embeddings.append(self.cat_embeddings[i](x_cat[:, :, i]))\n",
        "#         return torch.cat(embeddings, dim=-1)\n",
        "\n",
        "#     def forward(self, x_cat, x_num, timesteps):\n",
        "#         \"\"\"Forward pass for training\"\"\"\n",
        "#         batch_size, seq_len, _ = x_num.shape\n",
        "\n",
        "#         cat_emb = self.embed_categorical(x_cat)\n",
        "#         x = torch.cat([cat_emb, x_num], dim=-1)\n",
        "#         x_proj = self.input_projection(x)\n",
        "\n",
        "#         time_emb_raw = self.embed_time(timesteps, self.dim_t)\n",
        "#         time_emb = self.time_embed(time_emb_raw)\n",
        "#         time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "#         x_with_time = x_proj + time_emb\n",
        "#         lstm_out, _ = self.lstm(x_with_time)\n",
        "\n",
        "#         # Predict the original combined (cat_emb + num) features\n",
        "#         output = self.output_head(lstm_out)\n",
        "\n",
        "#         return output\n",
        "\n",
        "# # =============================================================================\n",
        "# # SIMPLIFIED DIFFUSION PROCESS\n",
        "# # =============================================================================\n",
        "# class SimplifiedDiffuser:\n",
        "#     \"\"\"Simplified diffusion process for faster training\"\"\"\n",
        "#     def __init__(self, total_steps=500, beta_start=1e-4, beta_end=0.02, device='cpu'):\n",
        "#         self.total_steps = total_steps\n",
        "#         self.device = device\n",
        "\n",
        "#         self.betas = torch.linspace(beta_start, beta_end, total_steps).to(device)\n",
        "#         self.alphas = (1.0 - self.betas).to(device)\n",
        "#         self.alphas_cumprod = torch.cumprod(self.alphas, dim=0).to(device)\n",
        "\n",
        "#     def sample_random_timesteps(self, n: int):\n",
        "#         return torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
        "\n",
        "#     def add_noise(self, x, t):\n",
        "#         \"\"\"Add noise to input\"\"\"\n",
        "#         sqrt_alpha_cumprod = torch.sqrt(self.alphas_cumprod[t])[:, None, None]\n",
        "#         sqrt_one_minus_alpha_cumprod = torch.sqrt(1 - self.alphas_cumprod[t])[:, None, None]\n",
        "\n",
        "#         noise = torch.randn_like(x)\n",
        "#         return sqrt_alpha_cumprod * x + sqrt_one_minus_alpha_cumprod * noise, noise\n",
        "\n",
        "#     def reverse_step(self, model_output, noisy_input, t):\n",
        "#         \"\"\"Single reverse diffusion step\"\"\"\n",
        "#         # This function is not used in the simplified training loop below\n",
        "#         pass\n",
        "\n",
        "# # =============================================================================\n",
        "# # TRAINING LOOP\n",
        "# # =============================================================================\n",
        "# def train_model(model, diffuser, dataloader, epochs, optimizer, scheduler):\n",
        "#     \"\"\"Simplified training loop where the model predicts the original data\"\"\"\n",
        "#     model.train()\n",
        "#     criterion = nn.MSELoss()\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         epoch_loss = 0.0\n",
        "#         pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "#         for batch_cat, batch_num in pbar:\n",
        "#             batch_cat, batch_num = batch_cat.to(device), batch_num.to(device)\n",
        "#             batch_size = batch_cat.shape[0]\n",
        "\n",
        "#             timesteps = diffuser.sample_random_timesteps(batch_size)\n",
        "\n",
        "#             cat_emb_target = model.embed_categorical(batch_cat)\n",
        "#             combined_target = torch.cat([cat_emb_target, batch_num], dim=-1)\n",
        "\n",
        "#             # Add noise to the target\n",
        "#             noisy_combined, _ = diffuser.add_noise(combined_target, timesteps)\n",
        "\n",
        "#             # The model's task is to predict the clean data from the noisy data\n",
        "#             # To do this, it needs the noisy version of numerical data and the original categorical data\n",
        "#             noisy_num = noisy_combined[:, :, cat_emb_target.shape[-1]:]\n",
        "\n",
        "#             predicted_combined = model(batch_cat, noisy_num, timesteps)\n",
        "\n",
        "#             loss = criterion(predicted_combined, combined_target)\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "#             optimizer.step()\n",
        "\n",
        "#             epoch_loss += loss.item()\n",
        "#             pbar.set_postfix({'Loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "#         avg_loss = epoch_loss / len(dataloader)\n",
        "#         print(f\"Epoch {epoch+1} - Avg Loss: {avg_loss:.4f} - LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "#         scheduler.step()\n",
        "\n",
        "# # =============================================================================\n",
        "# # GENERATION FUNCTIONS\n",
        "# # =============================================================================\n",
        "# def generate_sequences(model, diffuser, n_sequences, seq_len, cat_attrs, num_attrs, n_cat_tokens, device):\n",
        "#     \"\"\"Generate new sequences\"\"\"\n",
        "#     model.eval()\n",
        "\n",
        "#     n_cat_features = len(cat_attrs)\n",
        "#     n_num_features = len(num_attrs)\n",
        "\n",
        "#     # Start with random categorical indices\n",
        "#     x_cat = torch.zeros(n_sequences, seq_len, n_cat_features, dtype=torch.long, device=device)\n",
        "#     for i, n_tokens in enumerate(n_cat_tokens):\n",
        "#         x_cat[:, :, i] = torch.randint(0, n_tokens, (n_sequences, seq_len), device=device)\n",
        "\n",
        "#     # Start with pure noise for numerical features\n",
        "#     x_num = torch.randn(n_sequences, seq_len, n_num_features, device=device)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for t in tqdm(reversed(range(diffuser.total_steps)), desc=\"Generating\"):\n",
        "#             timesteps = torch.full((n_sequences,), t, device=device, dtype=torch.long)\n",
        "\n",
        "#             predicted_combined = model(x_cat, x_num, timesteps)\n",
        "\n",
        "#             cat_emb_dim_total = model.cat_emb_dim * n_cat_features\n",
        "\n",
        "#             # Denoise numerical part using the prediction from the model\n",
        "#             # This is a simplified reverse process\n",
        "#             pred_num = predicted_combined[:, :, cat_emb_dim_total:]\n",
        "\n",
        "#             # Simple reverse step - move towards prediction from noise\n",
        "#             alpha_t = diffuser.alphas[t]\n",
        "#             x_num = (1 / torch.sqrt(alpha_t)) * (x_num - (1 - alpha_t) * pred_num)\n",
        "#             if t > 0:\n",
        "#                 x_num += torch.sqrt(diffuser.betas[t]) * torch.randn_like(x_num)\n",
        "\n",
        "#             # We don't update categorical here for simplicity, but could be done with predicted embeddings\n",
        "\n",
        "#     return x_cat, x_num\n",
        "\n",
        "# # =============================================================================\n",
        "# # MAIN EXECUTION\n",
        "# # =============================================================================\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"Loading and preprocessing data...\")\n",
        "#     try:\n",
        "#         real = pd.read_csv('tr_by_acct_w_age.csv')\n",
        "#     except FileNotFoundError:\n",
        "#         print(\"Error: CSV file not found. Please ensure 'tr_by_acct_w_age.csv' is in the directory.\")\n",
        "#         exit()\n",
        "\n",
        "#     raw_data = preprocess_data_czech(real)\n",
        "\n",
        "#     cat_attrs = ['tcode', 'dow', 'month', 'day', 'year', 'DoM_cat', 'age_group']\n",
        "#     num_attrs = ['amount', 'raw_amount', 'td']\n",
        "\n",
        "#     df_processed = raw_data[cat_attrs + num_attrs + ['account_id', 'datetime']].copy()\n",
        "\n",
        "#     label_encoders = {}\n",
        "#     n_cat_tokens = []\n",
        "#     for attr in cat_attrs:\n",
        "#         le = LabelEncoder()\n",
        "#         df_processed[attr] = le.fit_transform(df_processed[attr].astype(str))\n",
        "#         label_encoders[attr] = le\n",
        "#         n_cat_tokens.append(len(le.classes_))\n",
        "\n",
        "#     num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
        "#     df_processed[num_attrs] = num_scaler.fit_transform(df_processed[num_attrs])\n",
        "\n",
        "#     dataset = OptimizedSequentialDataset(\n",
        "#         df_processed, cat_attrs, num_attrs,\n",
        "#         sequence_length, min_seq_length, max_sequences_per_account=5\n",
        "#     )\n",
        "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "#     model = ImprovedLSTMSynthesizer(\n",
        "#         n_cat_features=len(cat_attrs),\n",
        "#         n_cat_tokens=n_cat_tokens,\n",
        "#         cat_emb_dim=cat_emb_dim,\n",
        "#         n_num_features=len(num_attrs),\n",
        "#         hidden_dim=mlp_layers[0]\n",
        "#     ).to(device)\n",
        "\n",
        "#     diffuser = SimplifiedDiffuser(diffusion_steps, diffusion_beta_start, diffusion_beta_end, device)\n",
        "#     optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#     scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "#     print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} parameters.\")\n",
        "#     print(\"Starting training...\")\n",
        "#     train_model(model, diffuser, dataloader, epochs, optimizer, scheduler)\n",
        "\n",
        "#     print(\"Generating sample sequences...\")\n",
        "#     generated_cat, generated_num = generate_sequences(\n",
        "#         model, diffuser, n_sequences=n_sequences, seq_len=sequence_length,\n",
        "#         cat_attrs=cat_attrs, num_attrs=num_attrs,\n",
        "#         n_cat_tokens=n_cat_tokens, device=device\n",
        "#     )\n",
        "\n",
        "#     final_sequences = []\n",
        "#     for seq_idx in range(generated_cat.shape[0]):\n",
        "#         seq_num_original = num_scaler.inverse_transform(generated_num[seq_idx].cpu().numpy())\n",
        "#         seq_cat = generated_cat[seq_idx].cpu().numpy()\n",
        "\n",
        "#         seq_df = pd.DataFrame()\n",
        "#         for i, col in enumerate(num_attrs):\n",
        "#             seq_df[col] = seq_num_original[:, i]\n",
        "\n",
        "#         for i, col in enumerate(cat_attrs):\n",
        "#             seq_df[col] = label_encoders[col].inverse_transform(seq_cat[:, i])\n",
        "\n",
        "#         # FIXED: Add account_id to the dataframe\n",
        "#         seq_df['account_id'] = seq_idx\n",
        "\n",
        "#         try:\n",
        "#             seq_df['datetime'] = pd.to_datetime({\n",
        "#                 'year': seq_df['year'].astype(int),\n",
        "#                 'month': seq_df['month'].astype(int),\n",
        "#                 'day': seq_df['day'].astype(int)\n",
        "#             }, errors='coerce')\n",
        "#         except:\n",
        "#             seq_df['datetime'] = pd.NaT\n",
        "\n",
        "#         final_sequences.append(seq_df)\n",
        "\n",
        "#     all_sequences_df = pd.concat(final_sequences, ignore_index=True)\n",
        "\n",
        "#     # FIXED: Include account_id in the final selection\n",
        "#     final_df = all_sequences_df[['account_id', 'raw_amount', 'amount', 'td', 'tcode', 'datetime']].copy()\n",
        "#     final_df = final_df.dropna(subset=['datetime'])\n",
        "#     final_df = final_df.sort_values(by=['account_id', 'datetime']).reset_index(drop=True)\n",
        "\n",
        "#     # print(\"\\nFinal dataframe created!\")\n",
        "#     # print(f\"Shape: {final_df.shape}\")\n",
        "#     # print(\"\\nSample of final_df:\")\n",
        "#     # print(final_df.head(15))\n",
        "\n",
        "#     final_df = final_df.dropna(subset=['datetime'])\n",
        "\n",
        "#     # FIXED: Convert the datetime column to just the date part\n",
        "#     final_df['datetime'] = final_df['datetime'].dt.date\n",
        "\n",
        "#     final_df.to_csv('synthetic_transactions_with_account_id.csv', index=False)\n",
        "#     print(\"\\nFinal dataframe saved as 'synthetic_transactions_with_account_id.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKrWiNRqL9sz",
        "outputId": "efe244af-d3cd-44ca-a627-7e8938ed6b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Loading and preprocessing data...\n",
            "Creating optimized sequences from transaction data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4500/4500 [00:13<00:00, 322.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 6962 sequences from 4500 accounts.\n",
            "Model has 1,166,275 parameters.\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|██████████| 218/218 [00:08<00:00, 26.36it/s, Loss=0.2117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Avg Loss: 0.5458 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|██████████| 218/218 [00:08<00:00, 25.57it/s, Loss=0.0916]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Avg Loss: 0.1256 - LR: 0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|██████████| 218/218 [00:08<00:00, 25.39it/s, Loss=0.0710]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Avg Loss: 0.0725 - LR: 0.000199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|██████████| 218/218 [00:08<00:00, 26.27it/s, Loss=0.0524]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Avg Loss: 0.0560 - LR: 0.000198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|██████████| 218/218 [00:08<00:00, 26.85it/s, Loss=0.0474]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Avg Loss: 0.0477 - LR: 0.000197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|██████████| 218/218 [00:08<00:00, 26.96it/s, Loss=0.0355]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Avg Loss: 0.0433 - LR: 0.000195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|██████████| 218/218 [00:08<00:00, 27.15it/s, Loss=0.0386]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Avg Loss: 0.0395 - LR: 0.000193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|██████████| 218/218 [00:08<00:00, 27.05it/s, Loss=0.0324]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Avg Loss: 0.0371 - LR: 0.000190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|██████████| 218/218 [00:08<00:00, 27.21it/s, Loss=0.0363]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Avg Loss: 0.0353 - LR: 0.000188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|██████████| 218/218 [00:08<00:00, 26.80it/s, Loss=0.0276]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Avg Loss: 0.0333 - LR: 0.000184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|██████████| 218/218 [00:08<00:00, 26.82it/s, Loss=0.0403]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - Avg Loss: 0.0322 - LR: 0.000181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|██████████| 218/218 [00:08<00:00, 26.67it/s, Loss=0.0191]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - Avg Loss: 0.0306 - LR: 0.000177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|██████████| 218/218 [00:08<00:00, 26.72it/s, Loss=0.0216]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 - Avg Loss: 0.0294 - LR: 0.000173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50: 100%|██████████| 218/218 [00:08<00:00, 26.67it/s, Loss=0.0341]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 - Avg Loss: 0.0286 - LR: 0.000168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50: 100%|██████████| 218/218 [00:08<00:00, 26.82it/s, Loss=0.0263]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 - Avg Loss: 0.0277 - LR: 0.000164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50: 100%|██████████| 218/218 [00:08<00:00, 26.90it/s, Loss=0.0208]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 - Avg Loss: 0.0262 - LR: 0.000159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50: 100%|██████████| 218/218 [00:08<00:00, 26.91it/s, Loss=0.0330]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 - Avg Loss: 0.0260 - LR: 0.000154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50: 100%|██████████| 218/218 [00:08<00:00, 26.83it/s, Loss=0.0248]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 - Avg Loss: 0.0253 - LR: 0.000148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50: 100%|██████████| 218/218 [00:08<00:00, 26.91it/s, Loss=0.0211]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 - Avg Loss: 0.0245 - LR: 0.000143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50: 100%|██████████| 218/218 [00:08<00:00, 26.80it/s, Loss=0.0228]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 - Avg Loss: 0.0242 - LR: 0.000137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50: 100%|██████████| 218/218 [00:08<00:00, 26.83it/s, Loss=0.0179]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 - Avg Loss: 0.0231 - LR: 0.000131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50: 100%|██████████| 218/218 [00:08<00:00, 26.71it/s, Loss=0.0204]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 - Avg Loss: 0.0226 - LR: 0.000125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50: 100%|██████████| 218/218 [00:08<00:00, 26.66it/s, Loss=0.0173]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 - Avg Loss: 0.0222 - LR: 0.000119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50: 100%|██████████| 218/218 [00:08<00:00, 26.74it/s, Loss=0.0274]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 - Avg Loss: 0.0218 - LR: 0.000113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50: 100%|██████████| 218/218 [00:08<00:00, 26.60it/s, Loss=0.0165]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 - Avg Loss: 0.0205 - LR: 0.000106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50: 100%|██████████| 218/218 [00:08<00:00, 26.60it/s, Loss=0.0174]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 - Avg Loss: 0.0182 - LR: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50: 100%|██████████| 218/218 [00:08<00:00, 26.60it/s, Loss=0.0135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 - Avg Loss: 0.0164 - LR: 0.000094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50: 100%|██████████| 218/218 [00:08<00:00, 26.90it/s, Loss=0.0113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 - Avg Loss: 0.0150 - LR: 0.000087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50: 100%|██████████| 218/218 [00:08<00:00, 26.79it/s, Loss=0.0125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 - Avg Loss: 0.0146 - LR: 0.000081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50: 100%|██████████| 218/218 [00:08<00:00, 26.91it/s, Loss=0.0126]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 - Avg Loss: 0.0139 - LR: 0.000075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|██████████| 218/218 [00:08<00:00, 26.56it/s, Loss=0.0144]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 - Avg Loss: 0.0136 - LR: 0.000069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50: 100%|██████████| 218/218 [00:08<00:00, 26.66it/s, Loss=0.0130]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 - Avg Loss: 0.0133 - LR: 0.000063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50: 100%|██████████| 218/218 [00:08<00:00, 26.86it/s, Loss=0.0104]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 - Avg Loss: 0.0130 - LR: 0.000057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50: 100%|██████████| 218/218 [00:08<00:00, 26.74it/s, Loss=0.0133]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 - Avg Loss: 0.0128 - LR: 0.000052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50: 100%|██████████| 218/218 [00:08<00:00, 26.89it/s, Loss=0.0112]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 - Avg Loss: 0.0127 - LR: 0.000046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50: 100%|██████████| 218/218 [00:08<00:00, 26.96it/s, Loss=0.0105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 - Avg Loss: 0.0126 - LR: 0.000041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50: 100%|██████████| 218/218 [00:08<00:00, 26.91it/s, Loss=0.0178]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 - Avg Loss: 0.0125 - LR: 0.000036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50: 100%|██████████| 218/218 [00:08<00:00, 26.85it/s, Loss=0.0088]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 - Avg Loss: 0.0123 - LR: 0.000032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|██████████| 218/218 [00:08<00:00, 26.78it/s, Loss=0.0121]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 - Avg Loss: 0.0122 - LR: 0.000027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|██████████| 218/218 [00:08<00:00, 26.76it/s, Loss=0.0101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40 - Avg Loss: 0.0122 - LR: 0.000023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|██████████| 218/218 [00:08<00:00, 26.87it/s, Loss=0.0104]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41 - Avg Loss: 0.0119 - LR: 0.000019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|██████████| 218/218 [00:08<00:00, 26.91it/s, Loss=0.0095]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 - Avg Loss: 0.0120 - LR: 0.000016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|██████████| 218/218 [00:08<00:00, 26.79it/s, Loss=0.0097]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 - Avg Loss: 0.0118 - LR: 0.000012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|██████████| 218/218 [00:08<00:00, 26.86it/s, Loss=0.0103]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 - Avg Loss: 0.0119 - LR: 0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|██████████| 218/218 [00:08<00:00, 26.78it/s, Loss=0.0116]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 - Avg Loss: 0.0120 - LR: 0.000007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|██████████| 218/218 [00:08<00:00, 26.89it/s, Loss=0.0183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 - Avg Loss: 0.0119 - LR: 0.000005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|██████████| 218/218 [00:08<00:00, 26.81it/s, Loss=0.0107]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 - Avg Loss: 0.0119 - LR: 0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|██████████| 218/218 [00:08<00:00, 26.73it/s, Loss=0.0131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 - Avg Loss: 0.0120 - LR: 0.000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|██████████| 218/218 [00:08<00:00, 26.80it/s, Loss=0.0125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 - Avg Loss: 0.0117 - LR: 0.000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|██████████| 218/218 [00:08<00:00, 26.81it/s, Loss=0.0095]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 - Avg Loss: 0.0117 - LR: 0.000000\n",
            "Generating sample sequences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 500it [00:04, 107.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final dataframe saved as 'synthetic_transactions_with_account_id.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "g_EY6KB8Qex2",
        "outputId": "362afe30-017b-43a0-bba7-f5bafe008e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      account_id    raw_amount        amount    td  \\\n",
              "0              0  73800.000000      0.300000  30.0   \n",
              "1              0  45658.656250  52022.609375  31.0   \n",
              "2              0 -64900.000000      0.300000   0.0   \n",
              "3              0 -64900.000000  73800.000000   5.0   \n",
              "4              0 -64900.000000  55673.980469   0.0   \n",
              "...          ...           ...           ...   ...   \n",
              "5871          19 -63847.667969     40.141190  31.0   \n",
              "5872          19  66310.632812   6946.898926   0.0   \n",
              "5873          19  73800.000000      1.150939   0.0   \n",
              "5874          19 -64900.000000  73800.000000   0.0   \n",
              "5875          19 -64897.726562  73780.281250  31.0   \n",
              "\n",
              "                                                  tcode    datetime  \n",
              "0     DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE P...  1993-01-04  \n",
              "1     DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE P...  1993-01-20  \n",
              "2             DEBIT__CASH WITHDRAWAL__INSURANCE PAYMENT  1993-02-02  \n",
              "3                           CREDIT__CREDIT IN CASH__nan  1993-02-02  \n",
              "4     CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...  1993-02-09  \n",
              "...                                                 ...         ...  \n",
              "5871                          DEBIT__CASH WITHDRAWAL__   1998-11-12  \n",
              "5872                          DEBIT__CASH WITHDRAWAL__   1998-11-24  \n",
              "5873  DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE P...  1998-11-26  \n",
              "5874          DEBIT__CASH WITHDRAWAL__INSURANCE PAYMENT  1998-12-01  \n",
              "5875                 DEBIT__CREDIT CARD WITHDRAWAL__nan  1998-12-13  \n",
              "\n",
              "[5876 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d45c8ce6-175b-481e-a2be-8e121152e9f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_id</th>\n",
              "      <th>raw_amount</th>\n",
              "      <th>amount</th>\n",
              "      <th>td</th>\n",
              "      <th>tcode</th>\n",
              "      <th>datetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>73800.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>30.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE P...</td>\n",
              "      <td>1993-01-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>45658.656250</td>\n",
              "      <td>52022.609375</td>\n",
              "      <td>31.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE P...</td>\n",
              "      <td>1993-01-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>-64900.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__INSURANCE PAYMENT</td>\n",
              "      <td>1993-02-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>-64900.000000</td>\n",
              "      <td>73800.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>CREDIT__CREDIT IN CASH__nan</td>\n",
              "      <td>1993-02-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>-64900.000000</td>\n",
              "      <td>55673.980469</td>\n",
              "      <td>0.0</td>\n",
              "      <td>CREDIT__COLLECTION FROM ANOTHER BANK__OLD AGE ...</td>\n",
              "      <td>1993-02-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5871</th>\n",
              "      <td>19</td>\n",
              "      <td>-63847.667969</td>\n",
              "      <td>40.141190</td>\n",
              "      <td>31.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__</td>\n",
              "      <td>1998-11-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5872</th>\n",
              "      <td>19</td>\n",
              "      <td>66310.632812</td>\n",
              "      <td>6946.898926</td>\n",
              "      <td>0.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__</td>\n",
              "      <td>1998-11-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5873</th>\n",
              "      <td>19</td>\n",
              "      <td>73800.000000</td>\n",
              "      <td>1.150939</td>\n",
              "      <td>0.0</td>\n",
              "      <td>DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE P...</td>\n",
              "      <td>1998-11-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5874</th>\n",
              "      <td>19</td>\n",
              "      <td>-64900.000000</td>\n",
              "      <td>73800.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>DEBIT__CASH WITHDRAWAL__INSURANCE PAYMENT</td>\n",
              "      <td>1998-12-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5875</th>\n",
              "      <td>19</td>\n",
              "      <td>-64897.726562</td>\n",
              "      <td>73780.281250</td>\n",
              "      <td>31.0</td>\n",
              "      <td>DEBIT__CREDIT CARD WITHDRAWAL__nan</td>\n",
              "      <td>1998-12-13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5876 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d45c8ce6-175b-481e-a2be-8e121152e9f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d45c8ce6-175b-481e-a2be-8e121152e9f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d45c8ce6-175b-481e-a2be-8e121152e9f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-40b7ca0e-d0e6-4441-81c1-67cc4fd93e12\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40b7ca0e-d0e6-4441-81c1-67cc4fd93e12')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-40b7ca0e-d0e6-4441-81c1-67cc4fd93e12 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_14b2d39d-9829-48c0-9e6e-7302d66d4c75\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('final_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_14b2d39d-9829-48c0-9e6e-7302d66d4c75 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('final_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_df",
              "summary": "{\n  \"name\": \"final_df\",\n  \"rows\": 5876,\n  \"fields\": [\n    {\n      \"column\": \"account_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 19,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0,\n          17,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_amount\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1188,\n        \"samples\": [\n          -6682.0205078125,\n          14314.6376953125,\n          -64856.48046875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"amount\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1245,\n        \"samples\": [\n          21427.359375,\n          48359.81640625,\n          5533.40380859375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"td\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 109,\n        \"samples\": [\n          30.74394416809082,\n          3.0,\n          16.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tcode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"DEBIT__REMITTANCE TO ANOTHER BANK__INSURANCE PAYMENT\",\n          \"DEBIT__CASH WITHDRAWAL__INSURANCE PAYMENT\",\n          \"DEBIT__REMITTANCE TO ANOTHER BANK__ \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1993-01-01\",\n        \"max\": \"1998-12-31\",\n        \"num_unique_values\": 2041,\n        \"samples\": [\n          \"1998-04-13\",\n          \"1995-08-20\",\n          \"1998-04-23\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}